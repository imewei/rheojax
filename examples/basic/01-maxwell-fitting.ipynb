{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": "# Maxwell Model: Stress Relaxation Fitting\n\n## What is This?\n\nThis notebook introduces **RheoJAX** through the **simplest viscoelastic model**: the Maxwell model. The Maxwell element combines a spring and dashpot in series, providing the foundation for understanding all linear viscoelastic behavior.\n\n**Why Maxwell?** It captures the essence of viscoelasticity with only 2 parameters and analytical solutions, making it the perfect gateway to modern rheological analysis.\n\n## The Maxwell Model\n\n**Constitutive Equation (Differential Form):**\n$$\\sigma + \\frac{\\eta}{G}\\dot{\\sigma} = \\eta\\dot{\\gamma}$$\n\n**Relaxation Modulus:**\n$$G(t) = G \\exp\\left(-\\frac{t}{\\tau}\\right), \\quad \\tau = \\frac{\\eta}{G}$$\n\n**Storage and Loss Moduli (Oscillatory):**\n$$G'(\\omega) = G\\frac{(\\omega\\tau)^2}{1 + (\\omega\\tau)^2}, \\quad G''(\\omega) = G\\frac{\\omega\\tau}{1 + (\\omega\\tau)^2}$$\n\nwhere:\n- $G$ = spring modulus (Pa) — instantaneous elastic response\n- $\\eta$ = dashpot viscosity (Pa·s) — resistance to flow\n- $\\tau = \\eta/G$ = relaxation time (s) — characteristic timescale\n\n**Physical Meaning:**\n- At short times/high frequencies: elastic solid-like ($G' \\to G$)\n- At long times/low frequencies: viscous liquid-like ($G' \\sim \\omega^2$, $G'' \\sim \\omega$)\n- The relaxation time $\\tau$ separates these two regimes\n\n> **Handbook:** See [Maxwell Model](../../docs/source/models/classical/maxwell.rst) for comprehensive theory, [Classical Models Overview](../../docs/source/models/classical/index.rst) for model selection guidance, and Ferry (1980) *Viscoelastic Properties of Polymers* for canonical reference.\n\n## Learning Objectives\n\nAfter completing this notebook, you will be able to:\n- Fit the Maxwell model using both Pipeline API and Modular API approaches\n- Leverage NLSQ optimization for 5-270x speedup over SciPy\n- Perform Bayesian inference with NLSQ→NUTS warm-start workflow\n- Interpret all 6 ArviZ diagnostic plots for MCMC convergence\n- Extract physically meaningful parameters with uncertainty quantification\n\n## Prerequisites\n\nBasic understanding of:\n- Rheological concepts (stress, strain, relaxation)\n- Linear viscoelasticity\n- Python and NumPy\n\n**Estimated Time:** 30-40 minutes"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:10:29.808127Z",
     "iopub.status.busy": "2026-02-09T21:10:29.807904Z",
     "iopub.status.idle": "2026-02-09T21:10:29.813907Z",
     "shell.execute_reply": "2026-02-09T21:10:29.812929Z"
    }
   },
   "outputs": [],
   "source": [
    "# Google Colab Setup - Run this cell first!\n",
    "# Skip if running locally with rheojax already installed\n",
    "\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install rheojax and dependencies\n",
    "    !pip install -q rheojax\n",
    "    \n",
    "    # Colab uses float32 by default - we need float64 for numerical stability\n",
    "    # This MUST be set before importing JAX\n",
    "    import os\n",
    "    os.environ['JAX_ENABLE_X64'] = 'true'\n",
    "    \n",
    "    print(\"✓ RheoJAX installed successfully!\")\n",
    "    print(\"✓ Float64 precision enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-intro",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "We start by importing necessary libraries. Note the **safe JAX import pattern** - this is critical for ensuring float64 precision throughout the entire JAX stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:10:29.816524Z",
     "iopub.status.busy": "2026-02-09T21:10:29.816302Z",
     "iopub.status.idle": "2026-02-09T21:10:32.134888Z",
     "shell.execute_reply": "2026-02-09T21:10:32.134114Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# MUST come before importing matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard scientific computing imports\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from rheojax.models import Maxwell\n",
    "\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.core.jax_config import safe_import_jax, verify_float64\n",
    "\n",
    "# Rheo imports - always explicit\n",
    "from rheojax.pipeline.base import Pipeline\n",
    "from rheojax.pipeline.bayesian import BayesianPipeline\n",
    "\n",
    "# Safe JAX import - REQUIRED for all notebooks using JAX\n",
    "# This pattern ensures float64 precision enforcement throughout\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "# Verify float64 is enabled (educational demonstration)\n",
    "verify_float64()\n",
    "print(f\"✓ JAX float64 precision enabled (default dtype bits: {jax.config.jax_default_dtype_bits})\")\n",
    "\n",
    "# Set reproducible random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib for publication-quality plots\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(\"\")))\n",
    "from utils.plotting_utils import (\n",
    "    plot_nlsq_fit, display_arviz_diagnostics, plot_posterior_predictive\n",
    ")\n",
    "\n",
    "FAST_MODE = os.environ.get(\"FAST_MODE\", \"1\") == \"1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maxwell-theory",
   "metadata": {},
   "source": [
    "## Maxwell Model Theory\n",
    "\n",
    "The Maxwell model represents a viscoelastic material as a spring and dashpot in series:\n",
    "\n",
    "$$G(t) = G_0 \\exp\\left(-\\frac{t}{\\tau}\\right)$$\n",
    "\n",
    "where:\n",
    "- $G(t)$ = relaxation modulus (Pa)\n",
    "- $G_0$ = initial modulus (Pa) - represents elastic response\n",
    "- $\\tau = \\eta / G_0$ = relaxation time (s) - characterizes viscous response\n",
    "- $\\eta$ = viscosity (Pa·s)\n",
    "\n",
    "**Physical Interpretation:**\n",
    "- **$G_0$**: Instantaneous elastic modulus - material stiffness at $t=0$\n",
    "- **$\\eta$**: Viscosity - resistance to flow\n",
    "- **$\\tau$**: Time scale for stress relaxation - larger $\\tau$ means slower relaxation\n",
    "\n",
    "**Applicability:**\n",
    "- Simple polymer melts and solutions\n",
    "- Materials with single dominant relaxation time\n",
    "- Limited to small strains (linear viscoelastic regime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-intro",
   "metadata": {},
   "source": [
    "## Generate Synthetic Relaxation Data\n",
    "\n",
    "We create synthetic stress relaxation data with known parameters to validate our fitting workflow. This allows us to verify numerical accuracy by comparing fitted parameters to true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-data",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:10:32.136414Z",
     "iopub.status.busy": "2026-02-09T21:10:32.136249Z",
     "iopub.status.idle": "2026-02-09T21:10:32.140321Z",
     "shell.execute_reply": "2026-02-09T21:10:32.139578Z"
    }
   },
   "outputs": [],
   "source": [
    "# True Maxwell parameters\n",
    "G0_true = 1e5  # Pa\n",
    "eta_true = 1e3  # Pa·s\n",
    "tau_true = eta_true / G0_true  # s\n",
    "\n",
    "print(f\"True Parameters:\")\n",
    "print(f\"  G0  = {G0_true:.2e} Pa\")\n",
    "print(f\"  eta = {eta_true:.2e} Pa·s\")\n",
    "print(f\"  tau = {tau_true:.4f} s\")\n",
    "\n",
    "# Generate time array (logarithmically spaced for relaxation)\n",
    "t = np.logspace(-2, 2, 50)  # 0.01 to 100 seconds\n",
    "\n",
    "# True relaxation modulus\n",
    "G_t_true = G0_true * np.exp(-t / tau_true)\n",
    "\n",
    "# Add realistic Gaussian noise (1-2% relative error)\n",
    "noise_level = 0.015  # 1.5%\n",
    "noise = np.random.normal(0, noise_level * G_t_true)\n",
    "G_t_noisy = G_t_true + noise\n",
    "\n",
    "print(f\"\\nData characteristics:\")\n",
    "print(f\"  Time range: {t.min():.2f} - {t.max():.2f} s\")\n",
    "print(f\"  Number of points: {len(t)}\")\n",
    "print(f\"  Noise level: {noise_level*100:.1f}% relative\")\n",
    "print(f\"  SNR: {np.mean(G_t_true) / np.std(noise):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-data",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:10:32.141712Z",
     "iopub.status.busy": "2026-02-09T21:10:32.141595Z",
     "iopub.status.idle": "2026-02-09T21:10:32.354688Z",
     "shell.execute_reply": "2026-02-09T21:10:32.354030Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize raw data\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.loglog(t, G_t_noisy, 'o', markersize=6, alpha=0.7, label='Synthetic Data (with noise)')\n",
    "plt.loglog(t, G_t_true, '--', linewidth=2, alpha=0.5, label='True Maxwell Response')\n",
    "plt.xlabel('Time (s)', fontsize=12)\n",
    "plt.ylabel('Relaxation Modulus G(t) (Pa)', fontsize=12)\n",
    "plt.title('Stress Relaxation Data', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, which='both')\n",
    "plt.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-intro",
   "metadata": {},
   "source": [
    "## Approach 1: Pipeline API (Recommended for Standard Workflows)\n",
    "\n",
    "The **Pipeline API** provides a fluent interface for common analysis tasks. It's ideal for rapid prototyping and standardized workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipeline-fit",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:10:32.356237Z",
     "iopub.status.busy": "2026-02-09T21:10:32.356140Z",
     "iopub.status.idle": "2026-02-09T21:10:33.742405Z",
     "shell.execute_reply": "2026-02-09T21:10:33.741987Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create RheoData container with metadata\n",
    "data = RheoData(\n",
    "    x=t,\n",
    "    y=G_t_noisy,\n",
    "    x_units='s',\n",
    "    y_units='Pa',\n",
    "    domain='time',\n",
    ")\n",
    "\n",
    "# Pipeline API workflow with timing\n",
    "start_pipeline = time.time()\n",
    "\n",
    "pipeline = Pipeline(data)\n",
    "pipeline.fit('maxwell')\n",
    "\n",
    "pipeline_time = time.time() - start_pipeline\n",
    "\n",
    "# Extract fitted parameters\n",
    "model = pipeline.get_last_model()\n",
    "G0_pipeline = model.parameters.get_value('G0')\n",
    "eta_pipeline = model.parameters.get_value('eta')\n",
    "tau_pipeline = eta_pipeline / G0_pipeline\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PIPELINE API RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Fitted Parameters:\")\n",
    "print(f\"  G0  = {G0_pipeline:.4e} Pa  (true: {G0_true:.4e})\")\n",
    "print(f\"  eta = {eta_pipeline:.4e} Pa·s  (true: {eta_true:.4e})\")\n",
    "print(f\"  tau = {tau_pipeline:.6f} s  (true: {tau_true:.6f})\")\n",
    "print(f\"\\nRelative Errors:\")\n",
    "print(f\"  G0:  {abs(G0_pipeline - G0_true) / G0_true * 100:.4f}%\")\n",
    "print(f\"  eta: {abs(eta_pipeline - eta_true) / eta_true * 100:.4f}%\")\n",
    "print(f\"\\nOptimization time: {pipeline_time:.4f} s\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-intro",
   "metadata": {},
   "source": [
    "## Approach 2: Modular API (Recommended for Customization)\n",
    "\n",
    "The **Modular API** provides direct access to model classes with scikit-learn compatible interface. Use this when you need fine control over parameters, bounds, or optimization settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-fit",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:10:33.743702Z",
     "iopub.status.busy": "2026-02-09T21:10:33.743601Z",
     "iopub.status.idle": "2026-02-09T21:10:34.091909Z",
     "shell.execute_reply": "2026-02-09T21:10:34.091507Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Maxwell model instance\n",
    "model = Maxwell()\n",
    "\n",
    "# Set parameter bounds (optional but recommended)\n",
    "model.parameters.set_bounds('G0', (1e3, 1e7))  # Reasonable modulus range\n",
    "model.parameters.set_bounds('eta', (1e1, 1e5))  # Reasonable viscosity range\n",
    "\n",
    "# Fit with timing\n",
    "start_modular = time.time()\n",
    "\n",
    "model.fit(t, G_t_noisy)\n",
    "\n",
    "modular_time = time.time() - start_modular\n",
    "\n",
    "# Extract fitted parameters\n",
    "G0_modular = model.parameters.get_value('G0')\n",
    "eta_modular = model.parameters.get_value('eta')\n",
    "tau_modular = eta_modular / G0_modular\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODULAR API RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Fitted Parameters:\")\n",
    "print(f\"  G0  = {G0_modular:.4e} Pa  (true: {G0_true:.4e})\")\n",
    "print(f\"  eta = {eta_modular:.4e} Pa·s  (true: {eta_true:.4e})\")\n",
    "print(f\"  tau = {tau_modular:.6f} s  (true: {tau_true:.6f})\")\n",
    "print(f\"\\nRelative Errors:\")\n",
    "print(f\"  G0:  {abs(G0_modular - G0_true) / G0_true * 100:.4f}%\")\n",
    "print(f\"  eta: {abs(eta_modular - eta_true) / eta_true * 100:.4f}%\")\n",
    "print(f\"\\nOptimization time: {modular_time:.4f} s\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verify both approaches give same results\n",
    "assert np.allclose(G0_pipeline, G0_modular, rtol=1e-2), \"Pipeline and Modular should give identical results\"\n",
    "assert np.allclose(eta_pipeline, eta_modular, rtol=1e-2), \"Pipeline and Modular should give identical results\"\n",
    "print(\"\\n✓ Pipeline and Modular APIs produce identical results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "performance-intro",
   "metadata": {},
   "source": [
    "## Performance Benchmark: NLSQ vs SciPy\n",
    "\n",
    "Rheo uses **NLSQ** (GPU-accelerated nonlinear least squares) as the default optimization backend, providing 5-270x speedup over SciPy's `curve_fit`.\n",
    "\n",
    "The speedup comes from:\n",
    "1. **JAX JIT compilation** - compiles optimization to optimized XLA code\n",
    "2. **Automatic differentiation** - exact gradients without numerical approximation\n",
    "3. **GPU acceleration** - parallel computation on CUDA devices (if available)\n",
    "\n",
    "Let's measure actual performance on your hardware:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark-timing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:10:34.093391Z",
     "iopub.status.busy": "2026-02-09T21:10:34.093292Z",
     "iopub.status.idle": "2026-02-09T21:10:37.013744Z",
     "shell.execute_reply": "2026-02-09T21:10:37.013168Z"
    }
   },
   "outputs": [],
   "source": [
    "# Benchmark: Multiple fits to get reliable timing\n",
    "n_runs = 10\n",
    "times = []\n",
    "\n",
    "for i in range(n_runs):\n",
    "    model_bench = Maxwell()\n",
    "    start = time.time()\n",
    "    model_bench.fit(t, G_t_noisy)\n",
    "    times.append(time.time() - start)\n",
    "\n",
    "nlsq_mean = np.mean(times[1:])  # Exclude first run (JIT compilation)\n",
    "nlsq_std = np.std(times[1:])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERFORMANCE BENCHMARK (NLSQ)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Number of runs: {n_runs}\")\n",
    "print(f\"First run (with JIT): {times[0]:.4f} s\")\n",
    "print(f\"Subsequent runs: {nlsq_mean:.4f} ± {nlsq_std:.4f} s\")\n",
    "print(f\"JIT overhead: {times[0] - nlsq_mean:.4f} s\")\n",
    "print(f\"\\nNOTE: SciPy curve_fit typically takes 0.05-0.5s for this problem\")\n",
    "print(f\"Expected speedup: 5-270x depending on problem size and GPU\")\n",
    "print(f\"For this small dataset ({len(t)} points), speedup may be modest.\")\n",
    "print(f\"Speedup increases dramatically with dataset size (>1000 points).\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-intro",
   "metadata": {},
   "source": [
    "## Results Visualization\n",
    "\n",
    "We create publication-quality visualizations showing:\n",
    "1. **Fit quality** - data vs model prediction\n",
    "2. **Residual analysis** - systematic errors or outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-fit",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:10:37.015515Z",
     "iopub.status.busy": "2026-02-09T21:10:37.015376Z",
     "iopub.status.idle": "2026-02-09T21:10:37.291364Z",
     "shell.execute_reply": "2026-02-09T21:10:37.290947Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "G_t_pred = model.predict(t)\n",
    "residuals = G_t_noisy - G_t_pred\n",
    "relative_residuals = residuals / G_t_noisy * 100\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Left: Fit quality\n",
    "ax1.loglog(t, G_t_noisy, 'o', markersize=6, alpha=0.7, label='Data', color='#1f77b4')\n",
    "ax1.loglog(t, G_t_true, '--', linewidth=2, alpha=0.4, label='True', color='gray')\n",
    "ax1.loglog(t, G_t_pred, '-', linewidth=2.5, label='Fitted', color='#ff7f0e')\n",
    "ax1.set_xlabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Relaxation Modulus G(t) (Pa)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Maxwell Model Fit', fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, which='both')\n",
    "ax1.legend(fontsize=11, framealpha=0.9)\n",
    "\n",
    "# Right: Residual analysis\n",
    "ax2.semilogx(t, relative_residuals, 'o', markersize=6, alpha=0.7, color='#2ca02c')\n",
    "ax2.axhline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax2.axhline(noise_level * 100, color='red', linestyle=':', linewidth=1.5, alpha=0.5, label=f'Expected noise: ±{noise_level*100:.1f}%')\n",
    "ax2.axhline(-noise_level * 100, color='red', linestyle=':', linewidth=1.5, alpha=0.5)\n",
    "ax2.set_xlabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Relative Residuals (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Residual Analysis', fontsize=13, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(fontsize=10, framealpha=0.9)\n",
    "\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "# Compute fit quality metrics\n",
    "ss_res = np.sum(residuals**2)\n",
    "ss_tot = np.sum((G_t_noisy - np.mean(G_t_noisy))**2)\n",
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "rmse = np.sqrt(np.mean(residuals**2))\n",
    "\n",
    "print(\"\\nFit Quality Metrics:\")\n",
    "print(f\"  R² = {r_squared:.6f}\")\n",
    "print(f\"  RMSE = {rmse:.2e} Pa\")\n",
    "print(f\"  Mean |residual| = {np.mean(np.abs(residuals)):.2e} Pa ({np.mean(np.abs(relative_residuals)):.2f}%)\")\n",
    "print(f\"  Max |residual| = {np.max(np.abs(residuals)):.2e} Pa ({np.max(np.abs(relative_residuals)):.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bayesian-intro",
   "metadata": {},
   "source": [
    "## Bayesian Inference: Uncertainty Quantification\n",
    "\n",
    "While NLSQ provides fast point estimates, **Bayesian inference** quantifies parameter uncertainty through posterior distributions. This is essential when:\n",
    "- Parameters are poorly constrained by data\n",
    "- Understanding parameter correlations is important\n",
    "- Propagating uncertainty to predictions is needed\n",
    "- Comparing competing models statistically\n",
    "\n",
    "### Two-Stage Workflow: NLSQ → NUTS\n",
    "\n",
    "1. **NLSQ optimization** (fast) - find approximate maximum likelihood parameters\n",
    "2. **NUTS sampling** (slower) - warm-start from NLSQ for 2-5x faster convergence\n",
    "\n",
    "This warm-start strategy dramatically reduces:\n",
    "- Number of iterations to convergence\n",
    "- Divergent transitions (MCMC failures)\n",
    "- Total computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bayesian-fit",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:10:37.292799Z",
     "iopub.status.busy": "2026-02-09T21:10:37.292693Z",
     "iopub.status.idle": "2026-02-09T21:10:40.359397Z",
     "shell.execute_reply": "2026-02-09T21:10:40.358845Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BAYESIAN INFERENCE WITH WARM-START\")\n",
    "print(\"=\"*60)\n",
    "print(\"Running MCMC sampling... (this may take 1-2 minutes)\\n\")\n",
    "\n",
    "# Bayesian inference using warm-start from NLSQ\n",
    "bayesian_start = time.time()\n",
    "\n",
    "result = model.fit_bayesian(\n",
    "    t, G_t_noisy,\n",
    "    num_warmup=1000,   # Burn-in iterations\n",
    "    num_samples=2000,  # Posterior samples\n",
    "    num_chains=1,      # Single chain (faster for demo); use num_chains=4 for production\n",
    "    initial_values={   # Warm-start from NLSQ\n",
    "        'G0': model.parameters.get_value('G0'),\n",
    "        'eta': model.parameters.get_value('eta')\n",
    "    }\n",
    ")\n",
    "\n",
    "bayesian_time = time.time() - bayesian_start\n",
    "\n",
    "print(f\"\\nBayesian inference completed in {bayesian_time:.2f} s\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bayesian-results",
   "metadata": {},
   "source": [
    "### Posterior Summary and Convergence Diagnostics\n",
    "\n",
    "Key metrics for MCMC quality:\n",
    "- **R-hat < 1.01**: Chains have converged (all parameters must meet this)\n",
    "- **ESS > 400**: Effective sample size ensures reliable estimates\n",
    "- **Divergences < 1%**: NUTS sampler is well-behaved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bayesian-summary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:10:40.361221Z",
     "iopub.status.busy": "2026-02-09T21:10:40.361094Z",
     "iopub.status.idle": "2026-02-09T21:10:40.367150Z",
     "shell.execute_reply": "2026-02-09T21:10:40.366751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract posterior samples and diagnostics\n",
    "posterior = result.posterior_samples\n",
    "diagnostics = result.diagnostics\n",
    "summary = result.summary\n",
    "\n",
    "# Get credible intervals\n",
    "credible_intervals = model.get_credible_intervals(posterior, credibility=0.95)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POSTERIOR SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nParameter Estimates (posterior mean ± std):\")\n",
    "print(f\"  G0  = {summary['G0']['mean']:.4e} ± {summary['G0']['std']:.4e} Pa\")\n",
    "print(f\"  eta = {summary['eta']['mean']:.4e} ± {summary['eta']['std']:.4e} Pa·s\")\n",
    "\n",
    "print(f\"\\n95% Credible Intervals:\")\n",
    "print(f\"  G0:  [{credible_intervals['G0'][0]:.4e}, {credible_intervals['G0'][1]:.4e}] Pa\")\n",
    "print(f\"  eta: [{credible_intervals['eta'][0]:.4e}, {credible_intervals['eta'][1]:.4e}] Pa·s\")\n",
    "\n",
    "print(f\"\\nConvergence Diagnostics:\")\n",
    "print(f\"  R-hat (G0):  {diagnostics['r_hat']['G0']:.4f}  {'✓' if diagnostics['r_hat']['G0'] < 1.01 else '✗ POOR'}\")\n",
    "print(f\"  R-hat (eta): {diagnostics['r_hat']['eta']:.4f}  {'✓' if diagnostics['r_hat']['eta'] < 1.01 else '✗ POOR'}\")\n",
    "print(f\"  ESS (G0):    {diagnostics['ess']['G0']:.0f}  {'✓' if diagnostics['ess']['G0'] > 400 else '✗ LOW'}\")\n",
    "print(f\"  ESS (eta):   {diagnostics['ess']['eta']:.0f}  {'✓' if diagnostics['ess']['eta'] > 400 else '✗ LOW'}\")\n",
    "\n",
    "if 'num_divergences' in diagnostics:\n",
    "    div_rate = diagnostics['num_divergences'] / result.num_samples * 100\n",
    "    print(f\"  Divergences: {diagnostics['num_divergences']} ({div_rate:.2f}%)  {'✓' if div_rate < 1 else '✗ HIGH'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Check convergence\n",
    "converged = all([\n",
    "    diagnostics['r_hat']['G0'] < 1.01,\n",
    "    diagnostics['r_hat']['eta'] < 1.01,\n",
    "    diagnostics['ess']['G0'] > 400,\n",
    "    diagnostics['ess']['eta'] > 400\n",
    "])\n",
    "\n",
    "if converged:\n",
    "    print(\"\\n✓ EXCELLENT CONVERGENCE - All diagnostic criteria met!\")\n",
    "else:\n",
    "    print(\"\\n⚠ WARNING: Convergence criteria not met. Increase num_warmup or num_samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dadd911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:10:40.368809Z",
     "iopub.status.busy": "2026-02-09T21:10:40.368641Z",
     "iopub.status.idle": "2026-02-09T21:10:41.333599Z",
     "shell.execute_reply": "2026-02-09T21:10:41.333098Z"
    }
   },
   "outputs": [],
   "source": [
    "# ArviZ diagnostic plots (trace, pair, forest, energy, autocorr, rank)\n",
    "display_arviz_diagnostics(result, ['G0', 'eta'], fast_mode=FAST_MODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-summary",
   "metadata": {},
   "source": [
    "## Diagnostic Plot Summary\n",
    "\n",
    "### Quick Reference Guide\n",
    "\n",
    "| Plot | Purpose | Good Result | Bad Result | Fix |\n",
    "|------|---------|-------------|------------|-----|\n",
    "| **Trace** | Visualize sampling | Fuzzy caterpillar | Trends, jumps | Increase warmup |\n",
    "| **Pair** | Correlations, divergences | Elliptical, no divergences | Funnel, many divergences | Better priors, reparameterize |\n",
    "| **Forest** | Credible intervals | Narrow intervals | Very wide | More data, tighter priors |\n",
    "| **Autocorr** | Mixing quality | Fast decay to 0 | Slow decay | More samples |\n",
    "| **Rank** | Convergence | Uniform histogram | Non-uniform | More warmup |\n",
    "| **ESS** | Sample efficiency | ESS > 400 | ESS < 100 | More samples, check mixing |\n",
    "\n",
    "### Troubleshooting Workflow\n",
    "\n",
    "If you encounter convergence issues:\n",
    "\n",
    "1. **Check R-hat and ESS first** (numerical diagnostics)\n",
    "2. **Rank plot** - most sensitive convergence check\n",
    "3. **Trace plot** - visual inspection of chains\n",
    "4. **Autocorr plot** - if ESS is low, check mixing\n",
    "5. **Pair plot** - if divergences present, check geometry\n",
    "6. **Forest plot** - assess parameter uncertainty\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "**High R-hat (> 1.01):**\n",
    "- Increase `num_warmup` (try 2000 or 5000)\n",
    "- Use multiple chains (`num_chains=4`)\n",
    "- Ensure warm-start from NLSQ\n",
    "\n",
    "**Low ESS (< 400):**\n",
    "- Increase `num_samples` (try 5000 or 10000)\n",
    "- Check autocorrelation plot - if high, mixing is poor\n",
    "- Use warm-start to improve initial proposal\n",
    "\n",
    "**Many divergences (> 1%):**\n",
    "- **Critical issue** - results unreliable!\n",
    "- Warm-start from NLSQ (reduces divergences 10-100x)\n",
    "- Tighter parameter bounds/priors\n",
    "- Reparameterize model (e.g., log-transform parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-interpretation",
   "metadata": {},
   "source": [
    "## Physical Interpretation\n",
    "\n",
    "Let's interpret the fitted parameters in the context of material behavior:\n",
    "\n",
    "### Parameter Meanings\n",
    "\n",
    "**Initial Modulus (G₀):**\n",
    "- Represents instantaneous elastic response\n",
    "- For our fit: ~1×10⁵ Pa (100 kPa)\n",
    "- Physical meaning: Material stiffness at t=0\n",
    "- Typical range: 10² - 10⁹ Pa depending on material\n",
    "\n",
    "**Viscosity (η):**\n",
    "- Represents resistance to flow\n",
    "- For our fit: ~1×10³ Pa·s\n",
    "- Physical meaning: Controls stress relaxation rate\n",
    "- Typical range: 10⁻² - 10⁶ Pa·s\n",
    "\n",
    "**Relaxation Time (τ = η/G₀):**\n",
    "- Time scale for stress decay to 1/e (~37%) of initial value\n",
    "- For our fit: ~0.01 s\n",
    "- Physical meaning: Fast relaxation → fluid-like behavior\n",
    "- Slow relaxation → solid-like behavior\n",
    "\n",
    "### Material Classification\n",
    "\n",
    "Based on relaxation time:\n",
    "- **τ < 0.1 s**: Predominantly viscous (fluid-like)\n",
    "- **0.1 < τ < 100 s**: Viscoelastic (mixed behavior)\n",
    "- **τ > 100 s**: Predominantly elastic (solid-like)\n",
    "\n",
    "Our material (τ ≈ 0.01 s) exhibits **fluid-like behavior** with rapid stress relaxation.\n",
    "\n",
    "### Model Limitations\n",
    "\n",
    "The Maxwell model is valid when:\n",
    "- ✓ Small strains (linear viscoelastic regime, typically < 10%)\n",
    "- ✓ Single dominant relaxation time\n",
    "- ✓ Isothermal conditions\n",
    "\n",
    "Consider alternative models if:\n",
    "- ✗ Multiple relaxation times needed → Generalized Maxwell\n",
    "- ✗ Non-exponential decay → Fractional Maxwell\n",
    "- ✗ Finite equilibrium modulus → Zener (Standard Linear Solid)\n",
    "- ✗ Large strain behavior → Nonlinear models (Gent, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parameter-summary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:10:41.335333Z",
     "iopub.status.busy": "2026-02-09T21:10:41.335231Z",
     "iopub.status.idle": "2026-02-09T21:10:41.338979Z",
     "shell.execute_reply": "2026-02-09T21:10:41.338516Z"
    }
   },
   "outputs": [],
   "source": [
    "# Summary table of results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL PARAMETER SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Method':<20} {'G0 (Pa)':<15} {'eta (Pa·s)':<15} {'tau (s)':<10}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'True Values':<20} {G0_true:<15.4e} {eta_true:<15.4e} {tau_true:<10.6f}\")\n",
    "print(f\"{'NLSQ (Point)':<20} {G0_modular:<15.4e} {eta_modular:<15.4e} {tau_modular:<10.6f}\")\n",
    "print(f\"{'Bayesian (Mean)':<20} {summary['G0']['mean']:<15.4e} {summary['eta']['mean']:<15.4e} {summary['eta']['mean']/summary['G0']['mean']:<10.6f}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Uncertainty from Bayesian inference\n",
    "print(f\"\\n{'Bayesian Uncertainty (1σ):':<20} {summary['G0']['std']:<15.4e} {summary['eta']['std']:<15.4e}\")\n",
    "print(f\"{'Relative Uncertainty:':<20} {summary['G0']['std']/summary['G0']['mean']*100:<15.2f}% {summary['eta']['std']/summary['eta']['mean']*100:<15.2f}%\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "print(f\"\\nPhysical Interpretation:\")\n",
    "print(f\"  Material Type: {'Fluid-like (fast relaxation)' if tau_modular < 0.1 else 'Viscoelastic' if tau_modular < 100 else 'Solid-like'}\")\n",
    "print(f\"  Relaxation Time: {tau_modular:.6f} s (time to decay to 37% of initial stress)\")\n",
    "print(f\"  Initial Stiffness: {G0_modular:.2e} Pa ({G0_modular/1e3:.1f} kPa)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "key-takeaways",
   "metadata": {},
   "source": "## Key Takeaways\n\n### Main Concepts\n\n1. **Two API Approaches:**\n   - **Pipeline API**: Fluent interface for rapid workflows (`Pipeline().load().fit().plot()`)\n   - **Modular API**: Direct model control for customization (`Maxwell().fit()`)\n   - Both produce identical numerical results\n\n2. **NLSQ Optimization:**\n   - Default backend provides 5-270x speedup vs SciPy\n   - JAX JIT compilation + automatic differentiation\n   - GPU acceleration available (additional 10-100x for large datasets)\n   - Float64 precision enforced via safe_import_jax()\n\n3. **Bayesian Uncertainty Quantification:**\n   - Two-stage workflow: NLSQ (fast) → NUTS (warm-start)\n   - Warm-start reduces convergence time 2-5x\n   - Provides credible intervals and parameter correlations\n   - Essential for poorly-constrained parameters\n\n4. **ArviZ Diagnostic Suite:**\n   - **6 essential plots** assess MCMC quality comprehensively\n   - Must check: R-hat < 1.01, ESS > 400, divergences < 1%\n   - Rank plot is most sensitive convergence diagnostic\n   - Pair plot reveals parameter correlations and divergences\n\n### When to Use Maxwell Model\n\n**Appropriate for:**\n- ✓ Polymer melts and solutions with single relaxation time\n- ✓ Small strain linear viscoelastic regime\n- ✓ Rapid screening of relaxation behavior\n- ✓ Materials with predominantly viscous character\n\n**Consider alternatives for:**\n- ✗ Multiple relaxation times → Generalized Maxwell (Prony series)\n- ✗ Non-exponential decay → Fractional Maxwell\n- ✗ Finite equilibrium modulus → Zener model\n- ✗ Solid-like materials → Kelvin-Voigt or Burgers model\n\n### Common Pitfalls\n\n1. **Float64 Precision:**\n   - Always use `safe_import_jax()` pattern\n   - NLSQ requires float64 for numerical stability\n   - Automatic via package but verify in custom code\n\n2. **Bayesian Convergence:**\n   - **Never skip diagnostic checks** - R-hat, ESS, divergences\n   - Use warm-start from NLSQ (essential for complex models)\n   - Multiple chains (num_chains=4) recommended for production\n\n3. **Model Selection:**\n   - Check residuals for systematic trends\n   - Maxwell often insufficient for real materials\n   - Use Bayesian model comparison (WAIC, LOO) to compare alternatives\n\n4. **Parameter Bounds:**\n   - Set physically reasonable bounds in ParameterSet\n   - Prevents optimization from exploring unphysical regions\n   - Transforms to priors in Bayesian inference\n\n## Further Reading\n\n### Related Models\n- [**Maxwell Model Handbook**](../../docs/source/models/classical/maxwell.rst) — Comprehensive theoretical foundation, experimental design, fitting guidance, and material interpretation\n- [**Zener (Standard Linear Solid)**](02-zener-fitting.ipynb) — Adds parallel spring for finite equilibrium modulus\n- [**SpringPot (Fractional Element)**](03-springpot-fitting.ipynb) — Power-law relaxation for broad spectra\n- [**Generalized Maxwell**](../../docs/source/models/multi_mode/generalized_maxwell.rst) — Multiple relaxation times via Prony series\n\n### Key References\n- **Ferry, J.D. (1980)**. *Viscoelastic Properties of Polymers*, 3rd ed. Wiley. — Canonical reference for linear viscoelasticity and time-temperature superposition\n- **Macosko, C.W. (1994)**. *Rheology: Principles, Measurements, and Applications*. Wiley-VCH. — Practical guide balancing theory and applications\n- **Doi, M. & Edwards, S.F. (1986)**. *The Theory of Polymer Dynamics*. Oxford. — Connection to reptation theory and molecular dynamics\n\n### Advanced Workflows\n- [**Bayesian Basics**](../bayesian/01-bayesian-basics.ipynb) — Comprehensive NLSQ→NUTS workflow with detailed diagnostics\n- [**Convergence Diagnostics**](../bayesian/03-convergence-diagnostics.ipynb) — Deep dive into all 6 ArviZ plots\n- [**Mastercurve Generation**](../transforms/02-mastercurve-generation.ipynb) — Time-temperature superposition\n- [**Multi-Technique Fitting**](../advanced/01-multi-technique-fitting.ipynb) — Constrained fitting across test modes\n\n## Next Steps\n\n**Continue the Basic Series:**\n1. **[02-zener-fitting.ipynb](02-zener-fitting.ipynb)** — Finite equilibrium modulus (viscoelastic solid)\n2. **[03-springpot-fitting.ipynb](03-springpot-fitting.ipynb)** — Fractional element with power-law relaxation\n3. **[04-bingham-fitting.ipynb](04-bingham-fitting.ipynb)** — Yield stress fluids\n4. **[05-power-law-fitting.ipynb](05-power-law-fitting.ipynb)** — Shear-thinning/thickening flow behavior"
  },
  {
   "cell_type": "markdown",
   "id": "session-info",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Session Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "session-info-code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:10:41.340187Z",
     "iopub.status.busy": "2026-02-09T21:10:41.340102Z",
     "iopub.status.idle": "2026-02-09T21:10:41.342329Z",
     "shell.execute_reply": "2026-02-09T21:10:41.341877Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print session information for reproducibility\n",
    "import sys\n",
    "\n",
    "import arviz as az\n",
    "import rheojax\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Rheo version: {rheojax.__version__}\")\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"ArviZ version: {az.__version__}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rheojax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}