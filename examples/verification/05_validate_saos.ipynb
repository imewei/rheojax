{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAOS Protocol Validation\n",
    "\n",
    "**Validates Small Amplitude Oscillatory Shear data: G'(ω), G''(ω)**\n",
    "\n",
    "## Protocol Description\n",
    "\n",
    "SAOS experiments apply small-amplitude oscillatory strain and measure the in-phase (G') and\n",
    "out-of-phase (G'') stress components. This characterizes the material's linear viscoelastic response.\n",
    "\n",
    "## Validation Checks\n",
    "\n",
    "1. **Schema validation**: Required columns present (frequency, G', G'')\n",
    "2. **Finite values**: No NaN or Inf in data arrays\n",
    "3. **Positive frequency**: ω > 0 (strictly positive)\n",
    "4. **Monotonic frequency**: Frequency monotonically changing\n",
    "5. **Non-negative moduli**: G' ≥ 0, G'' ≥ 0\n",
    "6. **Derived quantities**: |G*|, tan(δ)\n",
    "\n",
    "## Standard Plots\n",
    "\n",
    "- G', G'' vs ω (log-log)\n",
    "- tan(δ) vs ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODE = \"FAST\"  # \"FAST\" or \"FULL\"\n",
    "\n",
    "if MODE == \"FAST\":\n",
    "    MAX_FILES = 2\n",
    "    SKIP_HEAVY_PLOTS = True\n",
    "    SAVE_ARTIFACTS = False\n",
    "else:\n",
    "    MAX_FILES = None\n",
    "    SKIP_HEAVY_PLOTS = False\n",
    "    SAVE_ARTIFACTS = True\n",
    "\n",
    "print(f\"Running in {MODE} mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd()\n",
    "while not (project_root / \"pyproject.toml\").exists() and project_root != project_root.parent:\n",
    "    project_root = project_root.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from examples.verification.utils.validation_utils import (\n",
    "    DatasetValidation,\n",
    "    ValidationResult,\n",
    "    check_finite,\n",
    "    check_monotonic,\n",
    "    check_positive,\n",
    "    compute_saos_derived,\n",
    "    create_output_directories,\n",
    "    discover_files_by_protocol,\n",
    "    get_data_dir,\n",
    "    plot_saos,\n",
    "    print_validation_summary,\n",
    "    write_validation_report,\n",
    ")\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Dataset Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = get_data_dir()\n",
    "files = discover_files_by_protocol(data_dir, \"saos\")\n",
    "\n",
    "# Filter to main oscillation files (not DMA framework files)\n",
    "files = [f for f in files if \"oscillation\" in f.name.lower() or f.suffix == \".csv\"]\n",
    "\n",
    "print(f\"Found {len(files)} SAOS data files:\")\n",
    "for i, f in enumerate(files[:10]):\n",
    "    print(f\"  {i+1}. {f.relative_to(data_dir)}\")\n",
    "if len(files) > 10:\n",
    "    print(f\"  ... and {len(files) - 10} more\")\n",
    "\n",
    "if MAX_FILES is not None:\n",
    "    files = files[:MAX_FILES]\n",
    "    print(f\"\\nProcessing {len(files)} files (FAST mode)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saos_data(file_path: Path) -> tuple[np.ndarray, np.ndarray, np.ndarray, str]:\n",
    "    \"\"\"Load SAOS data with format auto-detection.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (omega, G_prime, G_double_prime, status_message)\n",
    "    \"\"\"\n",
    "    # Try different separators\n",
    "    for sep in [\"\\t\", \",\", \";\"]:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=sep)\n",
    "            if len(df.columns) >= 3:\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "    else:\n",
    "        return None, None, None, \"Could not parse file\"\n",
    "    \n",
    "    # Find frequency column\n",
    "    freq_cols = [c for c in df.columns if \"freq\" in c.lower() or \"omega\" in c.lower() or \"angular\" in c.lower()]\n",
    "    if not freq_cols:\n",
    "        freq_col = df.columns[0]\n",
    "    else:\n",
    "        freq_col = freq_cols[0]\n",
    "    \n",
    "    # Find G' and G'' columns\n",
    "    gp_cols = [c for c in df.columns if \"storage\" in c.lower() or \"g'\" in c.lower() or \"g_prime\" in c.lower()]\n",
    "    gpp_cols = [c for c in df.columns if \"loss\" in c.lower() or \"g''\" in c.lower() or \"g_double\" in c.lower()]\n",
    "    \n",
    "    if not gp_cols:\n",
    "        gp_col = df.columns[1] if len(df.columns) > 1 else None\n",
    "    else:\n",
    "        gp_col = gp_cols[0]\n",
    "    \n",
    "    if not gpp_cols:\n",
    "        gpp_col = df.columns[2] if len(df.columns) > 2 else None\n",
    "    else:\n",
    "        gpp_col = gpp_cols[0]\n",
    "    \n",
    "    if gp_col is None or gpp_col is None:\n",
    "        return None, None, None, \"Missing G' or G'' column\"\n",
    "    \n",
    "    try:\n",
    "        omega = pd.to_numeric(df[freq_col], errors=\"coerce\").values\n",
    "        G_prime = pd.to_numeric(df[gp_col], errors=\"coerce\").values\n",
    "        G_double_prime = pd.to_numeric(df[gpp_col], errors=\"coerce\").values\n",
    "    except Exception as e:\n",
    "        return None, None, None, f\"Numeric conversion failed: {e}\"\n",
    "    \n",
    "    # Remove NaN values\n",
    "    mask = np.isfinite(omega) & np.isfinite(G_prime) & np.isfinite(G_double_prime)\n",
    "    omega = omega[mask]\n",
    "    G_prime = G_prime[mask]\n",
    "    G_double_prime = G_double_prime[mask]\n",
    "    \n",
    "    return omega, G_prime, G_double_prime, f\"Loaded {len(omega)} points from {freq_col}, {gp_col}, {gpp_col}\"\n",
    "\n",
    "# Test loading\n",
    "if files:\n",
    "    test_file = files[0]\n",
    "    omega, Gp, Gpp, msg = load_saos_data(test_file)\n",
    "    print(f\"Test load: {test_file.name}\")\n",
    "    print(f\"  {msg}\")\n",
    "    if omega is not None:\n",
    "        print(f\"  ω range: [{omega.min():.2e}, {omega.max():.2e}] rad/s\")\n",
    "        print(f\"  G' range: [{Gp.min():.2e}, {Gp.max():.2e}] Pa\")\n",
    "        print(f\"  G'' range: [{Gpp.min():.2e}, {Gpp.max():.2e}] Pa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Validation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_saos(file_path: Path) -> DatasetValidation:\n",
    "    \"\"\"Run all validation checks on a SAOS file.\"\"\"\n",
    "    validation = DatasetValidation(\n",
    "        file_path=str(file_path),\n",
    "        protocol=\"saos\",\n",
    "    )\n",
    "    \n",
    "    omega, G_prime, G_double_prime, load_msg = load_saos_data(file_path)\n",
    "    \n",
    "    if omega is None:\n",
    "        validation.results.append(ValidationResult(\n",
    "            check_name=\"data_loading\",\n",
    "            passed=False,\n",
    "            message=load_msg,\n",
    "        ))\n",
    "        return validation\n",
    "    \n",
    "    validation.results.append(ValidationResult(\n",
    "        check_name=\"data_loading\",\n",
    "        passed=True,\n",
    "        message=load_msg,\n",
    "        details={\"n_points\": len(omega)},\n",
    "    ))\n",
    "    \n",
    "    # Check 1: Finite values\n",
    "    validation.results.append(check_finite(omega, \"frequency\"))\n",
    "    validation.results.append(check_finite(G_prime, \"G_prime\"))\n",
    "    validation.results.append(check_finite(G_double_prime, \"G_double_prime\"))\n",
    "    \n",
    "    # Check 2: Positive frequency\n",
    "    validation.results.append(check_positive(omega, \"frequency\", strict=True))\n",
    "    \n",
    "    # Check 3: Monotonic frequency (either direction is fine)\n",
    "    is_increasing = omega[-1] > omega[0] if len(omega) > 1 else True\n",
    "    mono_result = check_monotonic(omega, \"frequency\", increasing=is_increasing, strict=False)\n",
    "    validation.results.append(mono_result)\n",
    "    \n",
    "    # Check 4: Non-negative moduli\n",
    "    validation.results.append(check_positive(G_prime, \"G_prime\", strict=False))\n",
    "    validation.results.append(check_positive(G_double_prime, \"G_double_prime\", strict=False))\n",
    "    \n",
    "    # Compute derived quantities\n",
    "    derived = compute_saos_derived(omega, G_prime, G_double_prime)\n",
    "    \n",
    "    # Check tan(delta) range\n",
    "    tan_delta = derived[\"tan_delta\"]\n",
    "    valid_td = tan_delta[np.isfinite(tan_delta)]\n",
    "    if len(valid_td) > 0:\n",
    "        td_range = f\"[{valid_td.min():.3f}, {valid_td.max():.3f}]\"\n",
    "        # Classify material behavior\n",
    "        mean_td = np.mean(valid_td)\n",
    "        if mean_td < 0.1:\n",
    "            behavior = \"solid-like\"\n",
    "        elif mean_td > 1:\n",
    "            behavior = \"liquid-like\"\n",
    "        else:\n",
    "            behavior = \"viscoelastic\"\n",
    "    else:\n",
    "        td_range = \"N/A\"\n",
    "        behavior = \"unknown\"\n",
    "    \n",
    "    validation.results.append(ValidationResult(\n",
    "        check_name=\"tan_delta_range\",\n",
    "        passed=True,\n",
    "        message=f\"tan(δ) = {td_range} ({behavior})\",\n",
    "        details={\"mean_tan_delta\": float(np.nanmean(tan_delta)), \"behavior\": behavior},\n",
    "    ))\n",
    "    \n",
    "    # Sort by frequency for storage\n",
    "    sort_idx = np.argsort(omega)\n",
    "    validation.derived_quantities = {\n",
    "        \"omega\": omega[sort_idx],\n",
    "        \"G_prime\": G_prime[sort_idx],\n",
    "        \"G_double_prime\": G_double_prime[sort_idx],\n",
    "        \"G_star\": derived[\"G_star\"][sort_idx],\n",
    "        \"tan_delta\": derived[\"tan_delta\"][sort_idx],\n",
    "    }\n",
    "    \n",
    "    return validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation on all files\n",
    "validations = []\n",
    "\n",
    "for file_path in files:\n",
    "    print(f\"\\nValidating: {file_path.name}\")\n",
    "    v = validate_saos(file_path)\n",
    "    validations.append(v)\n",
    "    \n",
    "    for r in v.results:\n",
    "        status = \"PASS\" if r.passed else \"FAIL\"\n",
    "        print(f\"  [{status}] {r.check_name}: {r.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Standard Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_HEAVY_PLOTS:\n",
    "    output_paths = create_output_directories(\"saos\")\n",
    "    \n",
    "    for v in validations:\n",
    "        if v.passed and \"omega\" in v.derived_quantities:\n",
    "            file_name = Path(v.file_path).stem\n",
    "            save_path = output_paths[\"plots\"] / f\"{file_name}_saos.png\" if SAVE_ARTIFACTS else None\n",
    "            \n",
    "            fig = plot_saos(\n",
    "                v.derived_quantities[\"omega\"],\n",
    "                v.derived_quantities[\"G_prime\"],\n",
    "                v.derived_quantities[\"G_double_prime\"],\n",
    "                save_path=save_path,\n",
    "                title=file_name,\n",
    "            )\n",
    "            plt.show()\n",
    "else:\n",
    "    for v in validations:\n",
    "        if v.passed and \"omega\" in v.derived_quantities:\n",
    "            fig = plot_saos(\n",
    "                v.derived_quantities[\"omega\"],\n",
    "                v.derived_quantities[\"G_prime\"],\n",
    "                v.derived_quantities[\"G_double_prime\"],\n",
    "                title=Path(v.file_path).stem,\n",
    "            )\n",
    "            plt.show()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E) Validation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_validation_summary(validations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F) Export Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_ARTIFACTS:\n",
    "    output_paths = create_output_directories(\"saos\")\n",
    "    \n",
    "    report = {\n",
    "        \"protocol\": \"saos\",\n",
    "        \"mode\": MODE,\n",
    "        \"n_files_validated\": len(validations),\n",
    "        \"all_passed\": all(v.passed for v in validations),\n",
    "        \"validations\": validations,\n",
    "    }\n",
    "    \n",
    "    report_path = output_paths[\"plots\"].parent / \"validation_report.json\"\n",
    "    write_validation_report(report, report_path)\n",
    "    print(f\"Validation report saved to: {report_path}\")\n",
    "    \n",
    "    for v in validations:\n",
    "        if v.passed and \"omega\" in v.derived_quantities:\n",
    "            file_name = Path(v.file_path).stem\n",
    "            df = pd.DataFrame({\n",
    "                \"omega\": v.derived_quantities[\"omega\"],\n",
    "                \"G_prime\": v.derived_quantities[\"G_prime\"],\n",
    "                \"G_double_prime\": v.derived_quantities[\"G_double_prime\"],\n",
    "                \"G_star\": v.derived_quantities[\"G_star\"],\n",
    "                \"tan_delta\": v.derived_quantities[\"tan_delta\"],\n",
    "            })\n",
    "            df.to_csv(output_paths[\"derived_quantities\"] / f\"{file_name}_derived.csv\", index=False)\n",
    "    \n",
    "    print(f\"Derived quantities saved to: {output_paths['derived_quantities']}\")\n",
    "else:\n",
    "    print(\"Artifacts not saved (FAST mode). Set MODE='FULL' to save.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
