{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f8349e",
   "metadata": {},
   "source": [
    "# Polystyrene Stress Relaxation\n",
    "\n",
    "Fit polystyrene relaxation at selectable temperature.\n",
    "\n",
    "**Data:** examples/data/relaxation/polymers/stressrelaxation_ps130_data.csv (swap for other temps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ab50b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T23:36:57.289032Z",
     "iopub.status.busy": "2025-12-07T23:36:57.288775Z",
     "iopub.status.idle": "2025-12-07T23:36:57.292899Z",
     "shell.execute_reply": "2025-12-07T23:36:57.292296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Google Colab compatibility - uncomment if running in Colab\n",
    "# !pip install -q rheojax\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f40ebb2",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d5f79a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T23:36:57.295884Z",
     "iopub.status.busy": "2025-12-07T23:36:57.295630Z",
     "iopub.status.idle": "2025-12-07T23:36:58.667879Z",
     "shell.execute_reply": "2025-12-07T23:36:58.667415Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.core.jax_config import safe_import_jax, verify_float64\n",
    "from rheojax.models.fractional_maxwell_model import FractionalMaxwellModel\n",
    "from rheojax.models.generalized_maxwell import GeneralizedMaxwell\n",
    "from rheojax.pipeline.base import Pipeline\n",
    "\n",
    "jax, jnp = safe_import_jax()\n",
    "verify_float64()\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "def r2_complex(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    ss_res = np.sum(np.abs(y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum(np.abs(y_true - np.mean(y_true)) ** 2)\n",
    "    return float(1 - ss_res / ss_tot)\n",
    "\n",
    "def mpe(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return float(np.mean(np.abs(y_true - y_pred) / np.maximum(np.abs(y_true), 1e-12)) * 100)\n",
    "\n",
    "def load_tab_file(path):\n",
    "    df = pd.read_csv(path, sep='\t')\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df = df.dropna()\n",
    "    df.iloc[:,0] = pd.to_numeric(df.iloc[:,0], errors='coerce')\n",
    "    df.iloc[:,1] = pd.to_numeric(df.iloc[:,1], errors='coerce')\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "import arviz as az\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba6d0de",
   "metadata": {},
   "source": [
    "## Load relaxation data (select temperature file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4fe52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T23:36:58.669423Z",
     "iopub.status.busy": "2025-12-07T23:36:58.669252Z",
     "iopub.status.idle": "2025-12-07T23:36:58.675897Z",
     "shell.execute_reply": "2025-12-07T23:36:58.675477Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / 'data' / 'relaxation' / 'polymers'\n",
    "file = DATA_DIR / 'stressrelaxation_ps130_data.csv'  # swap for other temps\n",
    "df = load_tab_file(file)\n",
    "t = df.iloc[:,0].to_numpy()\n",
    "G = df.iloc[:,1].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a596b339",
   "metadata": {},
   "source": [
    "## Fit relaxation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34ab67b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T23:36:58.677384Z",
     "iopub.status.busy": "2025-12-07T23:36:58.677291Z",
     "iopub.status.idle": "2025-12-07T23:37:05.809481Z",
     "shell.execute_reply": "2025-12-07T23:37:05.808940Z"
    }
   },
   "outputs": [],
   "source": [
    "gm = GeneralizedMaxwell(n_modes=5, modulus_type='tensile')\n",
    "gm.fit(t, G, test_mode='relaxation', use_log_residuals=True, use_multi_start=True)\n",
    "gm_pred = gm.predict(t)\n",
    "gm_r2 = gm.score(t, G)\n",
    "\n",
    "fm = FractionalMaxwellModel()\n",
    "fm.fit(t, G, test_mode='relaxation', use_log_residuals=True)\n",
    "fm_pred = fm.predict(t, test_mode='relaxation')\n",
    "fm_r2 = r2_complex(G, fm_pred)\n",
    "\n",
    "print({'gm_r2': gm_r2, 'fm_r2': fm_r2})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db0932b",
   "metadata": {},
   "source": [
    "## Plot relaxation fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d104f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T23:37:05.810932Z",
     "iopub.status.busy": "2025-12-07T23:37:05.810828Z",
     "iopub.status.idle": "2025-12-07T23:37:06.039117Z",
     "shell.execute_reply": "2025-12-07T23:37:06.038690Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "ax.loglog(t, G, 'o', label='Data', alpha=0.5)\n",
    "ax.loglog(t, gm_pred, '-', label=f'GM (R^2={gm_r2:.3f})')\n",
    "ax.loglog(t, fm_pred, '--', label=f'Fractional (R^2={fm_r2:.3f})')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Relaxation modulus (Pa)')\n",
    "ax.grid(True, which='both', ls='--', alpha=0.4)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec84b81",
   "metadata": {},
   "source": [
    "## Bayesian workflow (NLSQ → best model → NUTS diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d8ca91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T23:37:06.041045Z",
     "iopub.status.busy": "2025-12-07T23:37:06.040955Z",
     "iopub.status.idle": "2025-12-07T23:41:31.059926Z",
     "shell.execute_reply": "2025-12-07T23:41:31.059474Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unified workflow: load → NLSQ fits → best by R² → Bayesian → diagnostics\n",
    "\n",
    "# Fallback R² for complex data\n",
    "if 'r2_complex' not in globals():\n",
    "    def r2_complex(y_true, y_pred):\n",
    "        y_true = np.asarray(y_true)\n",
    "        y_pred = np.asarray(y_pred)\n",
    "        ss_res = np.sum(np.abs(y_true - y_pred) ** 2)\n",
    "        ss_tot = np.sum(np.abs(y_true - np.mean(y_true)) ** 2)\n",
    "        return 1 - ss_res / ss_tot\n",
    "\n",
    "\n",
    "\n",
    "# Handle models that return real/imag columns instead of complex numbers\n",
    "if '_coerce_pred' not in globals():\n",
    "    def _coerce_pred(pred):\n",
    "        arr = np.asarray(pred)\n",
    "        if arr.ndim == 2 and arr.shape[1] == 2 and not np.iscomplexobj(arr):\n",
    "            arr = arr[:, 0] + 1j * arr[:, 1]\n",
    "        return arr\n",
    "\n",
    "\n",
    "NUTS_CONFIG = dict(num_chains=4, num_warmup=1000, num_samples=3000, chain_method=\"vectorized\")\n",
    "\n",
    "def _detect_datasets():\n",
    "    datasets = []\n",
    "    if 'G_star' in globals() and 'omega' in globals():\n",
    "        datasets.append({\n",
    "            'X': omega,\n",
    "            'y': G_star,\n",
    "            'test_mode': 'oscillation',\n",
    "            'x_label': 'Angular frequency (rad/s)',\n",
    "            'y_label': 'Complex modulus',\n",
    "        })\n",
    "    elif 'Gp' in globals() and 'Gpp' in globals() and 'omega' in globals():\n",
    "        datasets.append({\n",
    "            'X': omega,\n",
    "            'y': Gp + 1j * Gpp,\n",
    "            'test_mode': 'oscillation',\n",
    "            'x_label': 'Angular frequency (rad/s)',\n",
    "            'y_label': 'Complex modulus',\n",
    "        })\n",
    "    if 'master' in globals() and hasattr(master, 'x') and hasattr(master, 'y'):\n",
    "        datasets.append({\n",
    "            'X': master.x,\n",
    "            'y': master.y,\n",
    "            'test_mode': master.metadata.get('test_mode', 'oscillation') if hasattr(master, 'metadata') else 'oscillation',\n",
    "            'x_label': 'Shifted frequency',\n",
    "            'y_label': 'Mastercurve modulus',\n",
    "        })\n",
    "    if 't' in globals() and 'G' in globals():\n",
    "        datasets.append({\n",
    "            'X': t,\n",
    "            'y': G,\n",
    "            'test_mode': 'relaxation',\n",
    "            'x_label': 'Time (s)',\n",
    "            'y_label': 'Relaxation modulus',\n",
    "        })\n",
    "\n",
    "    if 't' in globals() and 'E_t' in globals():\n",
    "        datasets.append({\n",
    "            'X': t,\n",
    "            'y': E_t,\n",
    "            'test_mode': 'relaxation',\n",
    "            'x_label': 'Time (s)',\n",
    "            'y_label': 'Relaxation modulus',\n",
    "        })\n",
    "    if 't' in globals() and 'sigma' in globals():\n",
    "        datasets.append({\n",
    "            'X': t,\n",
    "            'y': sigma,\n",
    "            'test_mode': 'relaxation',\n",
    "            'x_label': 'Time (s)',\n",
    "            'y_label': 'Stress (Pa)',\n",
    "        })\n",
    "    if 't' in globals() and 'J' in globals():\n",
    "        datasets.append({\n",
    "            'X': t,\n",
    "            'y': J,\n",
    "            'test_mode': 'creep',\n",
    "            'x_label': 'Time (s)',\n",
    "            'y_label': 'Creep compliance',\n",
    "        })\n",
    "    if 'all_df' in globals() and hasattr(all_df, 'columns') and 'phi' in all_df.columns:\n",
    "        for phi, frame in all_df.groupby('phi'):\n",
    "            x_vals = frame.iloc[:, 0].to_numpy()\n",
    "            y_vals = frame.iloc[:, 1].to_numpy()\n",
    "            datasets.append({\n",
    "                'X': x_vals,\n",
    "                'y': y_vals,\n",
    "                'test_mode': 'rotation',\n",
    "                'x_label': f'Shear rate 1/s (phi={phi})',\n",
    "                'y_label': 'Stress (Pa)',\n",
    "                'label': f'phi={phi}',\n",
    "            })\n",
    "    if not datasets:\n",
    "        raise ValueError('No datasets detected; ensure data variables are defined before running this cell.')\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def _collect_candidate_models():\n",
    "    if 'candidates' in globals() and isinstance(candidates, (list, tuple)) and candidates:\n",
    "        return candidates\n",
    "    models = []\n",
    "    for name, obj in globals().items():\n",
    "        if isinstance(obj, type):\n",
    "            continue  # skip classes; require initialized models\n",
    "        if hasattr(obj, 'fit_bayesian') and hasattr(obj, 'predict'):\n",
    "            models.append((name, obj))\n",
    "    if not models:\n",
    "        raise ValueError('No candidate models found; define models before running this cell.')\n",
    "    return models\n",
    "\n",
    "\n",
    "def _plot_data_and_fits(ds, fits):\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    X_plot = ds['X']\n",
    "    y_true = ds['y']\n",
    "    if np.iscomplexobj(y_true):\n",
    "        x_axis = X_plot / (2 * np.pi) if ds['test_mode'] == 'oscillation' else X_plot\n",
    "        ax.loglog(x_axis, np.real(y_true), 'o', label=\"Data real\", alpha=0.6)\n",
    "        ax.loglog(x_axis, np.imag(y_true), 's', label=\"Data imag\", alpha=0.6)\n",
    "        for rec in fits:\n",
    "            pred = _coerce_pred(rec['pred'])\n",
    "            ax.loglog(x_axis, np.real(pred), '-', label=f\"{rec['name']} Re (R²={rec['r2']:.3f})\")\n",
    "            ax.loglog(x_axis, np.imag(pred), '--', label=f\"{rec['name']} Im\")\n",
    "    else:\n",
    "        x_axis = X_plot\n",
    "        ax.loglog(x_axis, y_true, 'o', label='Data', alpha=0.6)\n",
    "        for rec in fits:\n",
    "            ax.loglog(x_axis, rec['pred'], '-', label=f\"{rec['name']} (R²={rec['r2']:.3f})\")\n",
    "    ax.set_xlabel(ds.get('x_label', 'X'))\n",
    "    ax.set_ylabel(ds.get('y_label', 'Response'))\n",
    "    ax.set_title(ds.get('label', f\"test_mode={ds['test_mode']}\"))\n",
    "    ax.grid(True, which='both', ls='--', alpha=0.4)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _plot_diagnostics(idata):\n",
    "    diag_plotters = [\n",
    "        ('pair', lambda: az.plot_pair(idata, divergences=True, kind='kde')),\n",
    "        ('forest', lambda: az.plot_forest(idata, combined=True)),\n",
    "        ('energy', lambda: az.plot_energy(idata)),\n",
    "        ('autocorr', lambda: az.plot_autocorr(idata)),\n",
    "        ('rank', lambda: az.plot_rank(idata)),\n",
    "        ('ess', lambda: az.plot_ess(idata, kind='evolution')),\n",
    "    ]\n",
    "    for name, plot_fn in diag_plotters:\n",
    "        try:\n",
    "            obj = plot_fn()\n",
    "        except Exception as exc:\n",
    "            print(f\"Skipping {name} plot due to: {exc}\")\n",
    "            continue\n",
    "        plt.tight_layout()\n",
    "        display(obj)\n",
    "        plt.close('all')\n",
    "\n",
    "\n",
    "datasets = _detect_datasets()\n",
    "model_entries = _collect_candidate_models()\n",
    "\n",
    "for ds in datasets:\n",
    "    fits = []\n",
    "    for name, model in model_entries:\n",
    "        fitted_model = model\n",
    "        fit_kwargs = {'test_mode': ds['test_mode'], 'use_log_residuals': True}\n",
    "        try:\n",
    "            fitted_model.fit(ds['X'], ds['y'], **fit_kwargs)\n",
    "        except TypeError:\n",
    "            fit_kwargs.pop('use_log_residuals', None)\n",
    "            fitted_model.fit(ds['X'], ds['y'], **fit_kwargs)\n",
    "        except Exception as exc:\n",
    "            print(f\"Skipping {name} due to fit error: {exc}\")\n",
    "            continue\n",
    "        predict_kwargs = {'test_mode': ds['test_mode']} if 'test_mode' in fit_kwargs else {}\n",
    "        try:\n",
    "            pred = _coerce_pred(fitted_model.predict(ds['X'], **predict_kwargs))\n",
    "        except Exception as exc:\n",
    "            print(f\"Skipping {name} due to predict error: {exc}\")\n",
    "            continue\n",
    "        try:\n",
    "            r2_val = r2_complex(ds['y'], pred) if np.iscomplexobj(ds['y']) else fitted_model.score(ds['X'], ds['y'])\n",
    "        except Exception as exc:\n",
    "            print(f\"Skipping {name} due to scoring error: {exc}\")\n",
    "            continue\n",
    "        fits.append({'name': name, 'model': fitted_model, 'pred': pred, 'r2': float(r2_val)})\n",
    "\n",
    "    if not fits:\n",
    "        print('No successful fits for dataset; skipping Bayesian step.')\n",
    "        continue\n",
    "\n",
    "    fits.sort(key=lambda rec: rec['r2'], reverse=True)\n",
    "    best = fits[0]\n",
    "    print(f\"Model ranking (R²): {[ (rec['name'], round(rec['r2'], 3)) for rec in fits ]}\")\n",
    "    _plot_data_and_fits(ds, fits)\n",
    "\n",
    "    try:\n",
    "        bayes_result = best['model'].fit_bayesian(\n",
    "            ds['X'],\n",
    "            ds['y'],\n",
    "            **NUTS_CONFIG,\n",
    "            test_mode=ds['test_mode'],\n",
    "        )\n",
    "        idata = bayes_result.to_inference_data()\n",
    "        _plot_diagnostics(idata)\n",
    "    except Exception as exc:\n",
    "        print(f\"Skipping Bayesian step for {best['name']} due to: {exc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce NUTS progress updates: print every 500 samples instead of each iteration\n",
    "import jax.numpy as jnp\n",
    "import numpyro.util as numpyro_util\n",
    "from jax import lax\n",
    "\n",
    "\n",
    "def progress_bar_factory_every_500(num_samples: int, num_chains: int):\n",
    "    print_rate = max(1, min(500, num_samples))\n",
    "    remainder = num_samples % print_rate\n",
    "\n",
    "    idx_counter = 0\n",
    "    tqdm_bars = {}\n",
    "    lock = numpyro_util.Lock()\n",
    "    for chain in range(num_chains):\n",
    "        tqdm_bars[chain] = numpyro_util.tqdm_auto(range(num_samples), position=chain)\n",
    "        tqdm_bars[chain].set_description(\"Compiling.. \", refresh=True)\n",
    "\n",
    "    def _update_tqdm(increment, chain):\n",
    "        increment = int(increment)\n",
    "        chain = int(chain)\n",
    "        if chain == -1:\n",
    "            nonlocal idx_counter\n",
    "            with lock:\n",
    "                chain = idx_counter\n",
    "                idx_counter += 1\n",
    "        tqdm_bars[chain].set_description(f\"Running chain {chain}\", refresh=False)\n",
    "        tqdm_bars[chain].update(increment)\n",
    "        return chain\n",
    "\n",
    "    def _close_tqdm(increment, chain):\n",
    "        increment = int(increment)\n",
    "        chain = int(chain)\n",
    "        tqdm_bars[chain].update(increment)\n",
    "        tqdm_bars[chain].close()\n",
    "\n",
    "    def _update_progress_bar(iter_num, chain):\n",
    "        chain = lax.cond(\n",
    "            iter_num == 1,\n",
    "            lambda _: numpyro_util.io_callback(_update_tqdm, jnp.array(0), 0, chain),\n",
    "            lambda _: chain,\n",
    "            operand=None,\n",
    "        )\n",
    "        chain = lax.cond(\n",
    "            iter_num % print_rate == 0,\n",
    "            lambda _: numpyro_util.io_callback(_update_tqdm, jnp.array(0), print_rate, chain),\n",
    "            lambda _: chain,\n",
    "            operand=None,\n",
    "        )\n",
    "        _ = lax.cond(\n",
    "            iter_num == num_samples,\n",
    "            lambda _: numpyro_util.io_callback(_close_tqdm, None, remainder, chain),\n",
    "            lambda _: None,\n",
    "            operand=None,\n",
    "        )\n",
    "        return chain\n",
    "\n",
    "    def progress_bar_fori_loop(func):\n",
    "        def wrapper_progress_bar(i, vals):\n",
    "            subvals, chain = vals\n",
    "            result = func(i, subvals)\n",
    "            chain = _update_progress_bar(i + 1, chain)\n",
    "            return (result, chain)\n",
    "\n",
    "        return wrapper_progress_bar\n",
    "\n",
    "    return progress_bar_fori_loop\n",
    "\n",
    "numpyro_util.progress_bar_factory = progress_bar_factory_every_500\n",
    "print(\"Using custom NUTS progress: updates every 500 samples.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rheojax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
