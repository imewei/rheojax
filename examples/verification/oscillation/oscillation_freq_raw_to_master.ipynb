{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2221b236",
   "metadata": {},
   "source": [
    "# Raw Frequency Data → Master Curve\n",
    "\n",
    "Apply manual shift factors to build a mastercurve and fit RheoJAX models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4705ddf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T00:40:21.546659Z",
     "iopub.status.busy": "2026-02-14T00:40:21.546227Z",
     "iopub.status.idle": "2026-02-14T00:40:21.551028Z",
     "shell.execute_reply": "2026-02-14T00:40:21.549689Z"
    }
   },
   "outputs": [],
   "source": [
    "# Google Colab compatibility - uncomment if running in Colab\n",
    "# !pip install -q rheojax\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1319fce7",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "Use raw multi-temperature frequency sweeps and apply RheoJAX mastercurve shifting with PyVisco shift factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a252a7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T00:40:21.554110Z",
     "iopub.status.busy": "2026-02-14T00:40:21.553825Z",
     "iopub.status.idle": "2026-02-14T00:40:26.064772Z",
     "shell.execute_reply": "2026-02-14T00:40:26.063609Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.core.jax_config import safe_import_jax, verify_float64\n",
    "from rheojax.models import FractionalMaxwellModel, GeneralizedMaxwell\n",
    "from rheojax.pipeline.base import Pipeline\n",
    "from rheojax.transforms.mastercurve import Mastercurve\n",
    "\n",
    "jax, jnp = safe_import_jax()\n",
    "verify_float64()\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "def r2_complex(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    ss_res = np.sum(np.abs(y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum(np.abs(y_true - np.mean(y_true)) ** 2)\n",
    "    return float(1 - ss_res / ss_tot)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import arviz as az\n",
    "\n",
    "# Shared plotting utilities\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(\"\")), \"..\"))\n",
    "from utils.plotting_utils import display_arviz_diagnostics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a813ab4",
   "metadata": {},
   "source": [
    "## Load raw sweeps and shift factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4605d525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T00:40:26.139174Z",
     "iopub.status.busy": "2026-02-14T00:40:26.118152Z",
     "iopub.status.idle": "2026-02-14T00:40:26.223156Z",
     "shell.execute_reply": "2026-02-14T00:40:26.218481Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / 'data' / 'mastercurves' / 'freq_raw'\n",
    "raw_df = pd.read_excel(DATA_DIR / 'freq_Eplexor_raw.xls')\n",
    "shift_df = pd.read_csv(DATA_DIR / 'freq_Eplexor_raw__shift_factors.csv')\n",
    "shift_df.columns = shift_df.columns.str.strip()\n",
    "\n",
    "# Drop header row (units) and coerce numeric\n",
    "raw_clean = raw_df[pd.to_numeric(raw_df['Nr'], errors='coerce').notna()].copy()\n",
    "raw_clean['T'] = raw_clean['T'].astype(float)\n",
    "\n",
    "# Build RheoData per temperature\n",
    "datasets = []\n",
    "for temp_c, frame in raw_clean.groupby('T'):\n",
    "    omega = 2 * np.pi * frame['f'].astype(float).to_numpy()\n",
    "    Gp = frame[\"E'\"] .astype(float).to_numpy()\n",
    "    Gpp = frame[\"E''\"].astype(float).to_numpy()\n",
    "    data = RheoData(\n",
    "        x=omega,\n",
    "        y=Gp + 1j * Gpp,\n",
    "        x_units='rad/s',\n",
    "        y_units='MPa',\n",
    "        domain='oscillation',\n",
    "        metadata={'temperature': temp_c + 273.15, 'test_mode': 'oscillation'}\n",
    "    )\n",
    "    datasets.append(data)\n",
    "\n",
    "# Manual shift factors from PyVisco table\n",
    "shift_clean = shift_df.iloc[1:].copy()\n",
    "shift_clean['T'] = shift_clean['T'].astype(float) + 273.15\n",
    "shift_clean['log_aT'] = shift_clean['log_aT'].replace('-', 0).astype(float)\n",
    "manual_shifts = {float(T): float(10 ** log_aT) for T, log_aT in zip(shift_clean['T'], shift_clean['log_aT'])}\n",
    "ref_temp = float(shift_clean['T'].iloc[0])\n",
    "\n",
    "mc = Mastercurve(reference_temp=ref_temp, method='manual', auto_shift=False)\n",
    "mc.set_manual_shifts(manual_shifts)\n",
    "master, shift_factors = mc.create_mastercurve(datasets, return_shifts=True)\n",
    "\n",
    "print(f\"Mastercurve built with {len(datasets)} temperatures → {len(master.x)} points\")\n",
    "shift_factors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f50726",
   "metadata": {},
   "source": [
    "## Plot raw vs shifted curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7492b7b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T00:40:26.227798Z",
     "iopub.status.busy": "2026-02-14T00:40:26.227407Z",
     "iopub.status.idle": "2026-02-14T00:40:28.914783Z",
     "shell.execute_reply": "2026-02-14T00:40:28.912992Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(datasets)))\n",
    "\n",
    "for color, data in zip(colors, datasets):\n",
    "    temp_c = data.metadata['temperature'] - 273.15\n",
    "    axes[0].loglog(data.x / (2*np.pi), np.real(data.y), 'o', color=color, label=f\"{temp_c:.0f}°C E'\")\n",
    "    axes[0].loglog(data.x / (2*np.pi), np.imag(data.y), 's', color=color, alpha=0.6, label=f\"{temp_c:.0f}°C E''\")\n",
    "axes[0].set_xlabel('Frequency (Hz)')\n",
    "axes[0].set_ylabel('Modulus (MPa)')\n",
    "axes[0].set_title('Unshifted raw sweeps')\n",
    "axes[0].grid(True, which='both', ls='--', alpha=0.4)\n",
    "axes[0].legend(ncol=2, fontsize=8)\n",
    "\n",
    "axes[1].loglog(master.x / (2*np.pi), np.real(master.y), 'o', label=\"E' master\", alpha=0.7)\n",
    "axes[1].loglog(master.x / (2*np.pi), np.imag(master.y), 's', label='E\" master', alpha=0.7)\n",
    "axes[1].set_xlabel('Frequency (Hz, shifted)')\n",
    "axes[1].set_title('Shifted mastercurve')\n",
    "axes[1].grid(True, which='both', ls='--', alpha=0.4)\n",
    "axes[1].legend()\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462c5919",
   "metadata": {},
   "source": [
    "## Fit models on mastercurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0645d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T00:40:28.922381Z",
     "iopub.status.busy": "2026-02-14T00:40:28.921016Z",
     "iopub.status.idle": "2026-02-14T00:40:54.618925Z",
     "shell.execute_reply": "2026-02-14T00:40:54.526053Z"
    }
   },
   "outputs": [],
   "source": [
    "omega_master = master.x\n",
    "G_master = master.y\n",
    "\n",
    "# Generalized Maxwell on mastercurve\n",
    "gm = GeneralizedMaxwell(n_modes=6, modulus_type='tensile')\n",
    "gm.fit(omega_master, G_master, test_mode='oscillation', use_log_residuals=True)\n",
    "gm_pred_components = gm.predict(omega_master)\n",
    "gm_pred = gm_pred_components[:, 0] + 1j * gm_pred_components[:, 1]\n",
    "gm_r2 = r2_complex(G_master, gm_pred)\n",
    "\n",
    "fm_pred = np.full_like(G_master, np.nan)\n",
    "fm_r2 = np.nan\n",
    "try:\n",
    "    fm = FractionalMaxwellModel()\n",
    "    fm.fit(omega_master, G_master, test_mode='oscillation', use_log_residuals=True)\n",
    "    fm_pred = fm.predict(omega_master, test_mode='oscillation')\n",
    "    fm_r2 = r2_complex(G_master, fm_pred)\n",
    "except Exception as exc:\n",
    "    print(f\"Fractional Maxwell fit failed: {exc}\")\n",
    "\n",
    "print(f\"Generalized Maxwell R^2: {gm_r2:.4f}\")\n",
    "print(f\"Fractional Maxwell R^2:   {fm_r2 if np.isfinite(fm_r2) else float('nan'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a7775",
   "metadata": {},
   "source": [
    "## Overlay fits on shifted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c5399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T00:40:54.650567Z",
     "iopub.status.busy": "2026-02-14T00:40:54.646776Z",
     "iopub.status.idle": "2026-02-14T00:40:55.049297Z",
     "shell.execute_reply": "2026-02-14T00:40:55.047382Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "ax.loglog(master.x / (2*np.pi), np.real(master.y), 'o', label=\"E' data\", alpha=0.5)\n",
    "ax.loglog(master.x / (2*np.pi), np.imag(master.y), 's', label='E\" data', alpha=0.5)\n",
    "ax.loglog(master.x / (2*np.pi), np.real(gm_pred), '-', label=\"E' GM\")\n",
    "ax.loglog(master.x / (2*np.pi), np.imag(gm_pred), '--', label='E\" GM')\n",
    "\n",
    "if np.isfinite(fm_r2):\n",
    "    ax.loglog(master.x / (2*np.pi), np.real(fm_pred), '-', label=\"E' FM\")\n",
    "    ax.loglog(master.x / (2*np.pi), np.imag(fm_pred), '--', label='E\" FM')\n",
    "else:\n",
    "    ax.text(0.5, 0.1, 'Fractional fit failed', transform=ax.transAxes)\n",
    "\n",
    "ax.set_xlabel('Frequency (Hz, shifted)')\n",
    "ax.set_ylabel('Modulus (MPa)')\n",
    "ax.set_title('Mastercurve fits')\n",
    "ax.grid(True, which='both', ls='--', alpha=0.4)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e486f4",
   "metadata": {},
   "source": [
    "## Bayesian workflow (NLSQ → best model → NUTS diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e13dfd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T00:40:55.052571Z",
     "iopub.status.busy": "2026-02-14T00:40:55.052313Z",
     "iopub.status.idle": "2026-02-14T00:40:55.057124Z",
     "shell.execute_reply": "2026-02-14T00:40:55.055850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions for workflow\n",
    "if 'r2_complex' not in globals():\n",
    "    def r2_complex(y_true, y_pred):\n",
    "        \"\"\"Compute R² for complex-valued data.\"\"\"\n",
    "        y_true = np.asarray(y_true)\n",
    "        y_pred = np.asarray(y_pred)\n",
    "        ss_res = np.sum(np.abs(y_true - y_pred) ** 2)\n",
    "        ss_tot = np.sum(np.abs(y_true - np.mean(y_true)) ** 2)\n",
    "        return 1 - ss_res / ss_tot\n",
    "\n",
    "if '_coerce_pred' not in globals():\n",
    "    def _coerce_pred(pred):\n",
    "        \"\"\"Convert 2-column real array to complex if needed.\"\"\"\n",
    "        arr = np.asarray(pred)\n",
    "        if arr.ndim == 2 and arr.shape[1] == 2 and not np.iscomplexobj(arr):\n",
    "            arr = arr[:, 0] + 1j * arr[:, 1]\n",
    "        return arr\n",
    "\n",
    "NUTS_CONFIG = dict(num_chains=1, num_warmup=200, num_samples=500)  # Fast demo mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9600068",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T00:40:55.062348Z",
     "iopub.status.busy": "2026-02-14T00:40:55.061464Z",
     "iopub.status.idle": "2026-02-14T00:40:55.142019Z",
     "shell.execute_reply": "2026-02-14T00:40:55.107179Z"
    }
   },
   "outputs": [],
   "source": [
    "def _detect_datasets():\n",
    "    \"\"\"Auto-detect datasets from global variables.\"\"\"\n",
    "    datasets = []\n",
    "    if 'G_star' in globals() and 'omega' in globals():\n",
    "        datasets.append({\n",
    "            'X': omega, 'y': G_star, 'test_mode': 'oscillation',\n",
    "            'x_label': 'Angular frequency (rad/s)', 'y_label': 'Complex modulus',\n",
    "        })\n",
    "    elif 'Gp' in globals() and 'Gpp' in globals() and 'omega' in globals():\n",
    "        datasets.append({\n",
    "            'X': omega, 'y': Gp + 1j * Gpp, 'test_mode': 'oscillation',\n",
    "            'x_label': 'Angular frequency (rad/s)', 'y_label': 'Complex modulus',\n",
    "        })\n",
    "    if 'master' in globals() and hasattr(master, 'x') and hasattr(master, 'y'):\n",
    "        test_mode = master.metadata.get('test_mode', 'oscillation') if hasattr(master, 'metadata') else 'oscillation'\n",
    "        datasets.append({\n",
    "            'X': master.x, 'y': master.y, 'test_mode': test_mode,\n",
    "            'x_label': 'Shifted frequency', 'y_label': 'Mastercurve modulus',\n",
    "        })\n",
    "    if 't' in globals() and 'G' in globals():\n",
    "        datasets.append({'X': t, 'y': G, 'test_mode': 'relaxation', 'x_label': 'Time (s)', 'y_label': 'Relaxation modulus'})\n",
    "    if 't' in globals() and 'E_t' in globals():\n",
    "        datasets.append({'X': t, 'y': E_t, 'test_mode': 'relaxation', 'x_label': 'Time (s)', 'y_label': 'Relaxation modulus'})\n",
    "    if 't' in globals() and 'sigma' in globals():\n",
    "        datasets.append({'X': t, 'y': sigma, 'test_mode': 'relaxation', 'x_label': 'Time (s)', 'y_label': 'Stress (Pa)'})\n",
    "    if 't' in globals() and 'J' in globals():\n",
    "        datasets.append({'X': t, 'y': J, 'test_mode': 'creep', 'x_label': 'Time (s)', 'y_label': 'Creep compliance'})\n",
    "    if 'all_df' in globals() and hasattr(all_df, 'columns') and 'phi' in all_df.columns:\n",
    "        for phi, frame in all_df.groupby('phi'):\n",
    "            x_vals = frame.iloc[:, 0].to_numpy()\n",
    "            y_vals = frame.iloc[:, 1].to_numpy()\n",
    "            datasets.append({\n",
    "                'X': x_vals, 'y': y_vals, 'test_mode': 'rotation',\n",
    "                'x_label': f'Shear rate 1/s (phi={phi})', 'y_label': 'Stress (Pa)', 'label': f'phi={phi}',\n",
    "            })\n",
    "    if not datasets:\n",
    "        raise ValueError('No datasets detected; ensure data variables are defined.')\n",
    "    return datasets\n",
    "\n",
    "def _collect_candidate_models():\n",
    "    \"\"\"Collect candidate models from global variables.\"\"\"\n",
    "    if 'candidates' in globals() and isinstance(candidates, (list, tuple)) and candidates:\n",
    "        return candidates\n",
    "    models = []\n",
    "    for name, obj in globals().items():\n",
    "        if isinstance(obj, type):\n",
    "            continue\n",
    "        if hasattr(obj, 'fit_bayesian') and hasattr(obj, 'predict'):\n",
    "            models.append((name, obj))\n",
    "    if not models:\n",
    "        raise ValueError('No candidate models found; define models before running.')\n",
    "    return models\n",
    "\n",
    "datasets = _detect_datasets()\n",
    "model_entries = _collect_candidate_models()\n",
    "print(f\"Found {len(datasets)} dataset(s) and {len(model_entries)} model(s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3948264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T00:40:55.204134Z",
     "iopub.status.busy": "2026-02-14T00:40:55.203449Z",
     "iopub.status.idle": "2026-02-14T00:40:59.976475Z",
     "shell.execute_reply": "2026-02-14T00:40:59.975005Z"
    }
   },
   "outputs": [],
   "source": [
    "# NLSQ fitting loop - fit all models to all datasets\n",
    "all_fits = {}  # {dataset_idx: [fit_records]}\n",
    "\n",
    "for ds_idx, ds in enumerate(datasets):\n",
    "    fits = []\n",
    "    for name, model in model_entries:\n",
    "        fitted_model = model\n",
    "        fit_kwargs = {'test_mode': ds['test_mode'], 'use_log_residuals': True}\n",
    "        try:\n",
    "            fitted_model.fit(ds['X'], ds['y'], **fit_kwargs)\n",
    "        except TypeError:\n",
    "            fit_kwargs.pop('use_log_residuals', None)\n",
    "            try:\n",
    "                fitted_model.fit(ds['X'], ds['y'], **fit_kwargs)\n",
    "            except Exception as exc:\n",
    "                print(f\"Skipping {name} due to fit error: {exc}\")\n",
    "                continue\n",
    "        except Exception as exc:\n",
    "            print(f\"Skipping {name} due to fit error: {exc}\")\n",
    "            continue\n",
    "\n",
    "        predict_kwargs = {'test_mode': ds['test_mode']} if 'test_mode' in fit_kwargs else {}\n",
    "        try:\n",
    "            pred = _coerce_pred(fitted_model.predict(ds['X'], **predict_kwargs))\n",
    "        except Exception as exc:\n",
    "            print(f\"Skipping {name} due to predict error: {exc}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            r2_val = r2_complex(ds['y'], pred) if np.iscomplexobj(ds['y']) else fitted_model.score(ds['X'], ds['y'])\n",
    "        except Exception as exc:\n",
    "            print(f\"Skipping {name} due to scoring error: {exc}\")\n",
    "            continue\n",
    "\n",
    "        fits.append({'name': name, 'model': fitted_model, 'pred': pred, 'r2': float(r2_val)})\n",
    "\n",
    "    fits.sort(key=lambda rec: rec['r2'], reverse=True)\n",
    "    all_fits[ds_idx] = fits\n",
    "    if fits:\n",
    "        print(f\"Dataset {ds_idx} ranking: {[(r['name'], round(r['r2'], 3)) for r in fits]}\")\n",
    "    else:\n",
    "        print(f\"Dataset {ds_idx}: No successful fits\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b9e2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T00:40:59.981791Z",
     "iopub.status.busy": "2026-02-14T00:40:59.980222Z",
     "iopub.status.idle": "2026-02-14T00:41:13.226974Z",
     "shell.execute_reply": "2026-02-14T00:41:13.215758Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bayesian inference on best model per dataset\n",
    "def _plot_data_and_fits(ds, fits):\n",
    "    \"\"\"Plot data with model fits overlay.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    X_plot, y_true = ds['X'], ds['y']\n",
    "    if np.iscomplexobj(y_true):\n",
    "        x_axis = X_plot / (2 * np.pi) if ds['test_mode'] == 'oscillation' else X_plot\n",
    "        ax.loglog(x_axis, np.real(y_true), 'o', label=\"Data real\", alpha=0.6)\n",
    "        ax.loglog(x_axis, np.imag(y_true), 's', label=\"Data imag\", alpha=0.6)\n",
    "        for rec in fits:\n",
    "            pred = _coerce_pred(rec['pred'])\n",
    "            ax.loglog(x_axis, np.real(pred), '-', label=f\"{rec['name']} Re (R²={rec['r2']:.3f})\")\n",
    "            ax.loglog(x_axis, np.imag(pred), '--', label=f\"{rec['name']} Im\")\n",
    "    else:\n",
    "        ax.loglog(X_plot, y_true, 'o', label='Data', alpha=0.6)\n",
    "        for rec in fits:\n",
    "            ax.loglog(X_plot, rec['pred'], '-', label=f\"{rec['name']} (R²={rec['r2']:.3f})\")\n",
    "    ax.set_xlabel(ds.get('x_label', 'X'))\n",
    "    ax.set_ylabel(ds.get('y_label', 'Response'))\n",
    "    ax.set_title(ds.get('label', f\"test_mode={ds['test_mode']}\"))\n",
    "    ax.grid(True, which='both', ls='--', alpha=0.4)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "bayes_results = {}  # {dataset_idx: (bayes_result, param_names)}\n",
    "\n",
    "for ds_idx, ds in enumerate(datasets):\n",
    "    fits = all_fits.get(ds_idx, [])\n",
    "    if not fits:\n",
    "        continue\n",
    "\n",
    "    best = fits[0]\n",
    "    _plot_data_and_fits(ds, fits)\n",
    "\n",
    "    try:\n",
    "        bayes_result = best['model'].fit_bayesian(\n",
    "            ds['X'], ds['y'], **NUTS_CONFIG, test_mode=ds['test_mode'],\n",
    "        )\n",
    "        param_names = list(best['model'].parameters.keys())\n",
    "        bayes_results[ds_idx] = (bayes_result, param_names)\n",
    "        print(f\"Dataset {ds_idx}: Bayesian inference complete for {best['name']}\")\n",
    "    except Exception as exc:\n",
    "        print(f\"Dataset {ds_idx}: Bayesian step failed for {best['name']}: {exc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60234c7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T00:41:13.231846Z",
     "iopub.status.busy": "2026-02-14T00:41:13.231460Z",
     "iopub.status.idle": "2026-02-14T00:41:17.583522Z",
     "shell.execute_reply": "2026-02-14T00:41:17.581936Z"
    }
   },
   "outputs": [],
   "source": [
    "# ArviZ diagnostics for Bayesian results\n",
    "for ds_idx, (bayes_result, param_names) in bayes_results.items():\n",
    "    print(f\"\\n--- Diagnostics for dataset {ds_idx} ---\")\n",
    "    display_arviz_diagnostics(bayes_result, param_names, fast_mode=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
