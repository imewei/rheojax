{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8adac25",
   "metadata": {},
   "source": [
    "# Prony vs Fractional Models\n",
    "\n",
    "Compare PyVisco Prony references to RheoJAX generalized and fractional fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd7f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T23:22:19.474895Z",
     "iopub.status.busy": "2025-12-07T23:22:19.474759Z",
     "iopub.status.idle": "2025-12-07T23:22:19.477775Z",
     "shell.execute_reply": "2025-12-07T23:22:19.477212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Google Colab compatibility - uncomment if running in Colab\n",
    "# !pip install -q rheojax\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e112f",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "Compare Prony-series reference curves against RheoJAX generalized and fractional fits using the time-domain dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deea553",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T23:22:19.479409Z",
     "iopub.status.busy": "2025-12-07T23:22:19.479296Z",
     "iopub.status.idle": "2025-12-07T23:22:20.841515Z",
     "shell.execute_reply": "2025-12-07T23:22:20.840848Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rheojax.models import FractionalMaxwellModel\n",
    "from rheojax.models import GeneralizedMaxwell\n",
    "\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.core.jax_config import safe_import_jax, verify_float64\n",
    "from rheojax.pipeline.base import Pipeline\n",
    "from rheojax.transforms.mastercurve import Mastercurve\n",
    "\n",
    "jax, jnp = safe_import_jax()\n",
    "verify_float64()\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "def r2_complex(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    ss_res = np.sum(np.abs(y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum(np.abs(y_true - np.mean(y_true)) ** 2)\n",
    "    return float(1 - ss_res / ss_tot)\n",
    "import arviz as az\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1342bcdc",
   "metadata": {},
   "source": [
    "## Load data and Prony terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0383f22a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T23:22:20.843111Z",
     "iopub.status.busy": "2025-12-07T23:22:20.842899Z",
     "iopub.status.idle": "2025-12-07T23:22:20.854863Z",
     "shell.execute_reply": "2025-12-07T23:22:20.854355Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / 'data' / 'mastercurves' / 'time_master'\n",
    "relax_df = pd.read_csv(DATA_DIR / 'time_user_master.csv')\n",
    "relax_clean = relax_df.iloc[1:].astype(float)\n",
    "t = relax_clean['t'].to_numpy()\n",
    "E_t = relax_clean['E_relax'].to_numpy()\n",
    "\n",
    "prony_path = DATA_DIR / 'prony_terms_KPf_MD.csv'\n",
    "with open(prony_path) as fh:\n",
    "    lines = [ln.strip() for ln in fh.readlines() if ln.strip()]\n",
    "E0_line = next((ln for ln in lines if ln.startswith('# E0')), '# E0 = 1.0 MPa')\n",
    "E0 = float(E0_line.split('=')[1].split()[0])  # MPa\n",
    "\n",
    "prony_vals = [ln for ln in lines if not ln.startswith('#')]\n",
    "prony_df = pd.DataFrame([list(map(float, row.split(','))) for row in prony_vals], columns=['rel_mod', 'rel_time'])\n",
    "\n",
    "# Build reference relaxation curve from Prony series\n",
    "prony_moduli = E0 * prony_df['rel_mod'].to_numpy()\n",
    "prony_taus = prony_df['rel_time'].to_numpy()\n",
    "\n",
    "E_prony = np.zeros_like(t)\n",
    "for g, tau in zip(prony_moduli, prony_taus):\n",
    "    E_prony += g * np.exp(-t / tau)\n",
    "\n",
    "print(f\"E0 = {E0:.2f} MPa, modes = {len(prony_moduli)}\")\n",
    "prony_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7688217",
   "metadata": {},
   "source": [
    "## Fit RheoJAX models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09235eb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T23:22:20.856287Z",
     "iopub.status.busy": "2025-12-07T23:22:20.856175Z",
     "iopub.status.idle": "2025-12-07T23:22:33.141346Z",
     "shell.execute_reply": "2025-12-07T23:22:33.140870Z"
    }
   },
   "outputs": [],
   "source": [
    "gm = GeneralizedMaxwell(n_modes=6, modulus_type='tensile')\n",
    "gm.fit(t, E_t, test_mode='relaxation', use_log_residuals=True)\n",
    "gm_pred = gm.predict(t)\n",
    "fm = FractionalMaxwellModel()\n",
    "fm.fit(t, E_t, test_mode='relaxation', use_log_residuals=True)\n",
    "fm_pred = fm.predict(t, test_mode='relaxation')\n",
    "\n",
    "metrics = {\n",
    "    'prony_ref_r2': r2_complex(E_t, E_prony),\n",
    "    'gm_r2': gm.score(t, E_t),\n",
    "    'fm_r2': r2_complex(E_t, fm_pred),\n",
    "}\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff108ff",
   "metadata": {},
   "source": [
    "## Overlay reference vs RheoJAX fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737eaa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T23:22:33.142852Z",
     "iopub.status.busy": "2025-12-07T23:22:33.142750Z",
     "iopub.status.idle": "2025-12-07T23:22:33.299546Z",
     "shell.execute_reply": "2025-12-07T23:22:33.298721Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "ax.loglog(t, E_t, 'o', label='Data', alpha=0.5)\n",
    "ax.loglog(t, E_prony, '-', label='Prony reference')\n",
    "ax.loglog(t, gm_pred, '--', label='Generalized Maxwell fit')\n",
    "ax.loglog(t, fm_pred, ':', label='Fractional Maxwell fit')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Relaxation modulus (MPa)')\n",
    "ax.grid(True, which='both', ls='--', alpha=0.4)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a27f47",
   "metadata": {},
   "source": [
    "## Residual summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8172d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T23:22:33.300863Z",
     "iopub.status.busy": "2025-12-07T23:22:33.300770Z",
     "iopub.status.idle": "2025-12-07T23:22:33.304716Z",
     "shell.execute_reply": "2025-12-07T23:22:33.304402Z"
    }
   },
   "outputs": [],
   "source": [
    "def mpe(y_true, y_pred):\n",
    "    return float(np.mean(np.abs(y_true - y_pred) / np.maximum(np.abs(y_true), 1e-12)) * 100)\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {'model': 'Prony reference', 'R2': metrics['prony_ref_r2'], 'MPE_%': mpe(E_t, E_prony)},\n",
    "    {'model': 'Generalized Maxwell', 'R2': metrics['gm_r2'], 'MPE_%': mpe(E_t, gm_pred)},\n",
    "    {'model': 'Fractional Maxwell', 'R2': metrics['fm_r2'], 'MPE_%': mpe(E_t, fm_pred)},\n",
    "])\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f2d64",
   "metadata": {},
   "source": [
    "## Bayesian workflow (NLSQ \u2192 best model \u2192 NUTS diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c91f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T23:22:33.306208Z",
     "iopub.status.busy": "2025-12-07T23:22:33.306135Z",
     "iopub.status.idle": "2025-12-07T23:22:43.566566Z",
     "shell.execute_reply": "2025-12-07T23:22:43.566190Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unified workflow: load \u2192 NLSQ fits \u2192 best by R\u00b2 \u2192 Bayesian \u2192 diagnostics\n",
    "\n",
    "# Fallback R\u00b2 for complex data\n",
    "if 'r2_complex' not in globals():\n",
    "    def r2_complex(y_true, y_pred):\n",
    "        y_true = np.asarray(y_true)\n",
    "        y_pred = np.asarray(y_pred)\n",
    "        ss_res = np.sum(np.abs(y_true - y_pred) ** 2)\n",
    "        ss_tot = np.sum(np.abs(y_true - np.mean(y_true)) ** 2)\n",
    "        return 1 - ss_res / ss_tot\n",
    "\n",
    "\n",
    "\n",
    "# Handle models that return real/imag columns instead of complex numbers\n",
    "if '_coerce_pred' not in globals():\n",
    "    def _coerce_pred(pred):\n",
    "        arr = np.asarray(pred)\n",
    "        if arr.ndim == 2 and arr.shape[1] == 2 and not np.iscomplexobj(arr):\n",
    "            arr = arr[:, 0] + 1j * arr[:, 1]\n",
    "        return arr\n",
    "\n",
    "\n",
    "NUTS_CONFIG = dict(num_chains=4, num_warmup=1000, num_samples=3000)\n",
    "\n",
    "def _detect_datasets():\n",
    "    datasets = []\n",
    "    if 'G_star' in globals() and 'omega' in globals():\n",
    "        datasets.append({\n",
    "            'X': omega,\n",
    "            'y': G_star,\n",
    "            'test_mode': 'oscillation',\n",
    "            'x_label': 'Angular frequency (rad/s)',\n",
    "            'y_label': 'Complex modulus',\n",
    "        })\n",
    "    elif 'Gp' in globals() and 'Gpp' in globals() and 'omega' in globals():\n",
    "        datasets.append({\n",
    "            'X': omega,\n",
    "            'y': Gp + 1j * Gpp,\n",
    "            'test_mode': 'oscillation',\n",
    "            'x_label': 'Angular frequency (rad/s)',\n",
    "            'y_label': 'Complex modulus',\n",
    "        })\n",
    "    if 'master' in globals() and hasattr(master, 'x') and hasattr(master, 'y'):\n",
    "        datasets.append({\n",
    "            'X': master.x,\n",
    "            'y': master.y,\n",
    "            'test_mode': master.metadata.get('test_mode', 'oscillation') if hasattr(master, 'metadata') else 'oscillation',\n",
    "            'x_label': 'Shifted frequency',\n",
    "            'y_label': 'Mastercurve modulus',\n",
    "        })\n",
    "    if 't' in globals() and 'G' in globals():\n",
    "        datasets.append({\n",
    "            'X': t,\n",
    "            'y': G,\n",
    "            'test_mode': 'relaxation',\n",
    "            'x_label': 'Time (s)',\n",
    "            'y_label': 'Relaxation modulus',\n",
    "        })\n",
    "\n",
    "    if 't' in globals() and 'E_t' in globals():\n",
    "        datasets.append({\n",
    "            'X': t,\n",
    "            'y': E_t,\n",
    "            'test_mode': 'relaxation',\n",
    "            'x_label': 'Time (s)',\n",
    "            'y_label': 'Relaxation modulus',\n",
    "        })\n",
    "    if 't' in globals() and 'sigma' in globals():\n",
    "        datasets.append({\n",
    "            'X': t,\n",
    "            'y': sigma,\n",
    "            'test_mode': 'relaxation',\n",
    "            'x_label': 'Time (s)',\n",
    "            'y_label': 'Stress (Pa)',\n",
    "        })\n",
    "    if 't' in globals() and 'J' in globals():\n",
    "        datasets.append({\n",
    "            'X': t,\n",
    "            'y': J,\n",
    "            'test_mode': 'creep',\n",
    "            'x_label': 'Time (s)',\n",
    "            'y_label': 'Creep compliance',\n",
    "        })\n",
    "    if 'all_df' in globals() and hasattr(all_df, 'columns') and 'phi' in all_df.columns:\n",
    "        for phi, frame in all_df.groupby('phi'):\n",
    "            x_vals = frame.iloc[:, 0].to_numpy()\n",
    "            y_vals = frame.iloc[:, 1].to_numpy()\n",
    "            datasets.append({\n",
    "                'X': x_vals,\n",
    "                'y': y_vals,\n",
    "                'test_mode': 'rotation',\n",
    "                'x_label': f'Shear rate 1/s (phi={phi})',\n",
    "                'y_label': 'Stress (Pa)',\n",
    "                'label': f'phi={phi}',\n",
    "            })\n",
    "    if not datasets:\n",
    "        raise ValueError('No datasets detected; ensure data variables are defined before running this cell.')\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def _collect_candidate_models():\n",
    "    if 'candidates' in globals() and isinstance(candidates, (list, tuple)) and candidates:\n",
    "        return candidates\n",
    "    models = []\n",
    "    for name, obj in globals().items():\n",
    "        if isinstance(obj, type):\n",
    "            continue  # skip classes; require initialized models\n",
    "        if hasattr(obj, 'fit_bayesian') and hasattr(obj, 'predict'):\n",
    "            models.append((name, obj))\n",
    "    if not models:\n",
    "        raise ValueError('No candidate models found; define models before running this cell.')\n",
    "    return models\n",
    "\n",
    "\n",
    "def _plot_data_and_fits(ds, fits):\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    X_plot = ds['X']\n",
    "    y_true = ds['y']\n",
    "    if np.iscomplexobj(y_true):\n",
    "        x_axis = X_plot / (2 * np.pi) if ds['test_mode'] == 'oscillation' else X_plot\n",
    "        ax.loglog(x_axis, np.real(y_true), 'o', label=\"Data real\", alpha=0.6)\n",
    "        ax.loglog(x_axis, np.imag(y_true), 's', label=\"Data imag\", alpha=0.6)\n",
    "        for rec in fits:\n",
    "            pred = _coerce_pred(rec['pred'])\n",
    "            ax.loglog(x_axis, np.real(pred), '-', label=f\"{rec['name']} Re (R\u00b2={rec['r2']:.3f})\")\n",
    "            ax.loglog(x_axis, np.imag(pred), '--', label=f\"{rec['name']} Im\")\n",
    "    else:\n",
    "        x_axis = X_plot\n",
    "        ax.loglog(x_axis, y_true, 'o', label='Data', alpha=0.6)\n",
    "        for rec in fits:\n",
    "            ax.loglog(x_axis, rec['pred'], '-', label=f\"{rec['name']} (R\u00b2={rec['r2']:.3f})\")\n",
    "    ax.set_xlabel(ds.get('x_label', 'X'))\n",
    "    ax.set_ylabel(ds.get('y_label', 'Response'))\n",
    "    ax.set_title(ds.get('label', f\"test_mode={ds['test_mode']}\"))\n",
    "    ax.grid(True, which='both', ls='--', alpha=0.4)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _plot_diagnostics(idata):\n",
    "    diag_plotters = [\n",
    "        ('pair', lambda: az.plot_pair(idata, divergences=True, kind='kde')),\n",
    "        ('forest', lambda: az.plot_forest(idata, combined=True)),\n",
    "        ('energy', lambda: az.plot_energy(idata)),\n",
    "        ('autocorr', lambda: az.plot_autocorr(idata)),\n",
    "        ('rank', lambda: az.plot_rank(idata)),\n",
    "        ('ess', lambda: az.plot_ess(idata, kind='evolution')),\n",
    "    ]\n",
    "    for name, plot_fn in diag_plotters:\n",
    "        try:\n",
    "            obj = plot_fn()\n",
    "        except Exception as exc:\n",
    "            print(f\"Skipping {name} plot due to: {exc}\")\n",
    "            continue\n",
    "        plt.tight_layout()\n",
    "        display(obj)\n",
    "        plt.close('all')\n",
    "\n",
    "\n",
    "datasets = _detect_datasets()\n",
    "model_entries = _collect_candidate_models()\n",
    "\n",
    "for ds in datasets:\n",
    "    fits = []\n",
    "    for name, model in model_entries:\n",
    "        fitted_model = model\n",
    "        fit_kwargs = {'test_mode': ds['test_mode'], 'use_log_residuals': True}\n",
    "        try:\n",
    "            fitted_model.fit(ds['X'], ds['y'], **fit_kwargs)\n",
    "        except TypeError:\n",
    "            fit_kwargs.pop('use_log_residuals', None)\n",
    "            fitted_model.fit(ds['X'], ds['y'], **fit_kwargs)\n",
    "        except Exception as exc:\n",
    "            print(f\"Skipping {name} due to fit error: {exc}\")\n",
    "            continue\n",
    "        predict_kwargs = {'test_mode': ds['test_mode']} if 'test_mode' in fit_kwargs else {}\n",
    "        try:\n",
    "            pred = _coerce_pred(fitted_model.predict(ds['X'], **predict_kwargs))\n",
    "        except Exception as exc:\n",
    "            print(f\"Skipping {name} due to predict error: {exc}\")\n",
    "            continue\n",
    "        try:\n",
    "            r2_val = r2_complex(ds['y'], pred) if np.iscomplexobj(ds['y']) else fitted_model.score(ds['X'], ds['y'])\n",
    "        except Exception as exc:\n",
    "            print(f\"Skipping {name} due to scoring error: {exc}\")\n",
    "            continue\n",
    "        fits.append({'name': name, 'model': fitted_model, 'pred': pred, 'r2': float(r2_val)})\n",
    "\n",
    "    if not fits:\n",
    "        print('No successful fits for dataset; skipping Bayesian step.')\n",
    "        continue\n",
    "\n",
    "    fits.sort(key=lambda rec: rec['r2'], reverse=True)\n",
    "    best = fits[0]\n",
    "    print(f\"Model ranking (R\u00b2): {[ (rec['name'], round(rec['r2'], 3)) for rec in fits ]}\")\n",
    "    _plot_data_and_fits(ds, fits)\n",
    "\n",
    "    try:\n",
    "        bayes_result = best['model'].fit_bayesian(\n",
    "            ds['X'],\n",
    "            ds['y'],\n",
    "            **NUTS_CONFIG,\n",
    "            test_mode=ds['test_mode'],\n",
    "        )\n",
    "        idata = bayes_result.to_inference_data()\n",
    "        _plot_diagnostics(idata)\n",
    "    except Exception as exc:\n",
    "        print(f\"Skipping Bayesian step for {best['name']} due to: {exc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}