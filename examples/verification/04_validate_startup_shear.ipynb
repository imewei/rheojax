{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Startup Shear Protocol Validation\n",
    "\n",
    "**Validates startup shear data: σ(t) at constant γ̇ (stress evolution during startup)**\n",
    "\n",
    "## Protocol Description\n",
    "\n",
    "Startup shear experiments apply a constant shear rate and measure the stress response over time.\n",
    "This reveals transient material behavior including stress overshoot (thixotropic signature).\n",
    "\n",
    "## Validation Checks\n",
    "\n",
    "1. **Schema validation**: Required columns present (time, stress)\n",
    "2. **Finite values**: No NaN or Inf in data arrays\n",
    "3. **Positive time**: t ≥ 0 (non-negative)\n",
    "4. **Monotonic time**: Time strictly increasing\n",
    "5. **Positive stress**: σ > 0 after initial ramp\n",
    "6. **Overshoot detection**: Identify σ_max/σ_ss ratio\n",
    "\n",
    "## Standard Plots\n",
    "\n",
    "- σ(t) vs t\n",
    "- σ(t) vs γ(t) = γ̇·t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODE = \"FAST\"  # \"FAST\" or \"FULL\"\n",
    "\n",
    "if MODE == \"FAST\":\n",
    "    MAX_FILES = 2\n",
    "    SKIP_HEAVY_PLOTS = True\n",
    "    SAVE_ARTIFACTS = False\n",
    "else:\n",
    "    MAX_FILES = None\n",
    "    SKIP_HEAVY_PLOTS = False\n",
    "    SAVE_ARTIFACTS = True\n",
    "\n",
    "print(f\"Running in {MODE} mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd()\n",
    "while not (project_root / \"pyproject.toml\").exists() and project_root != project_root.parent:\n",
    "    project_root = project_root.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from examples.verification.utils.validation_utils import (\n",
    "    DatasetValidation,\n",
    "    ValidationResult,\n",
    "    check_finite,\n",
    "    check_monotonic,\n",
    "    check_positive,\n",
    "    create_output_directories,\n",
    "    detect_startup_overshoot,\n",
    "    get_data_dir,\n",
    "    plot_startup,\n",
    "    print_validation_summary,\n",
    "    write_validation_report,\n",
    ")\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Dataset Inventory\n",
    "\n",
    "Startup shear data is in the PNAS_DigitalRheometerTwin_Dataset.xlsx file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = get_data_dir()\n",
    "pnas_path = data_dir / \"ikh\" / \"PNAS_DigitalRheometerTwin_Dataset.xlsx\"\n",
    "\n",
    "if pnas_path.exists():\n",
    "    xl = pd.ExcelFile(pnas_path)\n",
    "    startup_sheets = [s for s in xl.sheet_names if \"StartUp\" in s]\n",
    "    print(f\"Found {len(startup_sheets)} startup shear datasets:\")\n",
    "    for i, sheet in enumerate(startup_sheets):\n",
    "        print(f\"  {i+1}. {sheet}\")\n",
    "else:\n",
    "    print(f\"PNAS dataset not found at: {pnas_path}\")\n",
    "    startup_sheets = []\n",
    "\n",
    "if MAX_FILES is not None and startup_sheets:\n",
    "    startup_sheets = startup_sheets[:MAX_FILES]\n",
    "    print(f\"\\nProcessing {len(startup_sheets)} sheets (FAST mode)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_startup_data(xlsx_path: Path, sheet_name: str) -> tuple[np.ndarray, np.ndarray, float, str]:\n",
    "    \"\"\"Load startup shear data from PNAS Excel file.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (time, stress, gamma_dot, status_message)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(xlsx_path, sheet_name=sheet_name, header=None)\n",
    "    except Exception as e:\n",
    "        return None, None, None, f\"Failed to read sheet: {e}\"\n",
    "    \n",
    "    # Parse shear rate from sheet name (e.g., \"StartUp_0.056\" -> 0.056)\n",
    "    try:\n",
    "        gamma_dot = float(sheet_name.split(\"_\")[1])\n",
    "    except (IndexError, ValueError):\n",
    "        gamma_dot = 1.0  # Default\n",
    "    \n",
    "    # Find header row (contains \"Step time\" or \"time\")\n",
    "    header_row = None\n",
    "    for i in range(min(5, len(df))):\n",
    "        row_str = df.iloc[i].astype(str).str.lower()\n",
    "        if row_str.str.contains(\"step time|time\", regex=True).any():\n",
    "            header_row = i\n",
    "            break\n",
    "    \n",
    "    if header_row is None:\n",
    "        return None, None, None, \"Could not find header row\"\n",
    "    \n",
    "    # Skip header and units rows\n",
    "    data_start = header_row + 2  # Skip header and units\n",
    "    \n",
    "    # Find time and stress columns\n",
    "    headers = df.iloc[header_row].astype(str).str.lower()\n",
    "    time_col = None\n",
    "    stress_col = None\n",
    "    \n",
    "    for i, h in enumerate(headers):\n",
    "        if \"time\" in h:\n",
    "            time_col = i\n",
    "        elif \"stress\" in h:\n",
    "            stress_col = i\n",
    "    \n",
    "    if time_col is None or stress_col is None:\n",
    "        # Default to first two columns\n",
    "        time_col = 0\n",
    "        stress_col = 1\n",
    "    \n",
    "    try:\n",
    "        time = pd.to_numeric(df.iloc[data_start:, time_col], errors=\"coerce\").values\n",
    "        stress = pd.to_numeric(df.iloc[data_start:, stress_col], errors=\"coerce\").values\n",
    "    except Exception as e:\n",
    "        return None, None, None, f\"Numeric conversion failed: {e}\"\n",
    "    \n",
    "    # Remove NaN values\n",
    "    mask = np.isfinite(time) & np.isfinite(stress)\n",
    "    time = time[mask]\n",
    "    stress = stress[mask]\n",
    "    \n",
    "    # Subsample if very large\n",
    "    if len(time) > 500:\n",
    "        indices = np.linspace(0, len(time) - 1, 500, dtype=int)\n",
    "        time = time[indices]\n",
    "        stress = stress[indices]\n",
    "    \n",
    "    return time, stress, gamma_dot, f\"Loaded {len(time)} points at γ̇ = {gamma_dot} 1/s\"\n",
    "\n",
    "# Test loading\n",
    "if startup_sheets and pnas_path.exists():\n",
    "    test_sheet = startup_sheets[0]\n",
    "    time, stress, gamma_dot, msg = load_startup_data(pnas_path, test_sheet)\n",
    "    print(f\"Test load: {test_sheet}\")\n",
    "    print(f\"  {msg}\")\n",
    "    if time is not None:\n",
    "        print(f\"  t range: [{time.min():.2e}, {time.max():.2e}] s\")\n",
    "        print(f\"  σ range: [{stress.min():.2e}, {stress.max():.2e}] Pa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Validation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_startup(xlsx_path: Path, sheet_name: str) -> DatasetValidation:\n",
    "    \"\"\"Run all validation checks on a startup shear dataset.\"\"\"\n",
    "    validation = DatasetValidation(\n",
    "        file_path=f\"{xlsx_path}::{sheet_name}\",\n",
    "        protocol=\"startup_shear\",\n",
    "    )\n",
    "    \n",
    "    time, stress, gamma_dot, load_msg = load_startup_data(xlsx_path, sheet_name)\n",
    "    \n",
    "    if time is None:\n",
    "        validation.results.append(ValidationResult(\n",
    "            check_name=\"data_loading\",\n",
    "            passed=False,\n",
    "            message=load_msg,\n",
    "        ))\n",
    "        return validation\n",
    "    \n",
    "    validation.results.append(ValidationResult(\n",
    "        check_name=\"data_loading\",\n",
    "        passed=True,\n",
    "        message=load_msg,\n",
    "        details={\"n_points\": len(time), \"gamma_dot\": gamma_dot},\n",
    "    ))\n",
    "    \n",
    "    # Check 1: Finite values\n",
    "    validation.results.append(check_finite(time, \"time\"))\n",
    "    validation.results.append(check_finite(stress, \"stress\"))\n",
    "    \n",
    "    # Check 2: Non-negative time (startup can start at t=0)\n",
    "    validation.results.append(check_positive(time, \"time\", strict=False))\n",
    "    \n",
    "    # Check 3: Monotonic time\n",
    "    validation.results.append(check_monotonic(time, \"time\", increasing=True, strict=True))\n",
    "    \n",
    "    # Check 4: Positive stress (after initial points)\n",
    "    n_skip = max(1, len(stress) // 20)  # Skip first 5%\n",
    "    stress_after_ramp = stress[n_skip:]\n",
    "    validation.results.append(check_positive(stress_after_ramp, \"stress_after_ramp\", strict=True))\n",
    "    \n",
    "    # Check 5: Overshoot detection\n",
    "    overshoot_info = detect_startup_overshoot(time, stress)\n",
    "    validation.results.append(ValidationResult(\n",
    "        check_name=\"overshoot_detection\",\n",
    "        passed=True,  # Informational\n",
    "        message=f\"Overshoot ratio = {overshoot_info['overshoot_ratio']:.2f}\" +\n",
    "                (f\" at t = {overshoot_info['t_peak']:.3f} s\" if overshoot_info['has_overshoot'] else \" (no overshoot)\"),\n",
    "        details=overshoot_info,\n",
    "    ))\n",
    "    \n",
    "    validation.derived_quantities = {\n",
    "        \"time\": time,\n",
    "        \"stress\": stress,\n",
    "        \"gamma_dot\": gamma_dot,\n",
    "        \"overshoot_info\": overshoot_info,\n",
    "    }\n",
    "    \n",
    "    return validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation on all sheets\n",
    "validations = []\n",
    "\n",
    "for sheet_name in startup_sheets:\n",
    "    print(f\"\\nValidating: {sheet_name}\")\n",
    "    v = validate_startup(pnas_path, sheet_name)\n",
    "    validations.append(v)\n",
    "    \n",
    "    for r in v.results:\n",
    "        status = \"PASS\" if r.passed else \"FAIL\"\n",
    "        print(f\"  [{status}] {r.check_name}: {r.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Standard Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_HEAVY_PLOTS:\n",
    "    output_paths = create_output_directories(\"startup_shear\")\n",
    "    \n",
    "    for v in validations:\n",
    "        if v.passed and \"time\" in v.derived_quantities:\n",
    "            sheet_name = Path(v.file_path).name.split(\"::\")[1] if \"::\" in v.file_path else \"unknown\"\n",
    "            save_path = output_paths[\"plots\"] / f\"{sheet_name}_startup.png\" if SAVE_ARTIFACTS else None\n",
    "            \n",
    "            fig = plot_startup(\n",
    "                v.derived_quantities[\"time\"],\n",
    "                v.derived_quantities[\"stress\"],\n",
    "                v.derived_quantities[\"overshoot_info\"],\n",
    "                gamma_dot=v.derived_quantities[\"gamma_dot\"],\n",
    "                save_path=save_path,\n",
    "                title=sheet_name,\n",
    "            )\n",
    "            plt.show()\n",
    "else:\n",
    "    for v in validations:\n",
    "        if v.passed and \"time\" in v.derived_quantities:\n",
    "            sheet_name = v.file_path.split(\"::\")[1] if \"::\" in v.file_path else \"unknown\"\n",
    "            fig = plot_startup(\n",
    "                v.derived_quantities[\"time\"],\n",
    "                v.derived_quantities[\"stress\"],\n",
    "                v.derived_quantities[\"overshoot_info\"],\n",
    "                gamma_dot=v.derived_quantities[\"gamma_dot\"],\n",
    "                title=sheet_name,\n",
    "            )\n",
    "            plt.show()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E) Validation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_validation_summary(validations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F) Export Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_ARTIFACTS:\n",
    "    output_paths = create_output_directories(\"startup_shear\")\n",
    "    \n",
    "    report = {\n",
    "        \"protocol\": \"startup_shear\",\n",
    "        \"mode\": MODE,\n",
    "        \"n_files_validated\": len(validations),\n",
    "        \"all_passed\": all(v.passed for v in validations),\n",
    "        \"validations\": validations,\n",
    "    }\n",
    "    \n",
    "    report_path = output_paths[\"plots\"].parent / \"validation_report.json\"\n",
    "    write_validation_report(report, report_path)\n",
    "    print(f\"Validation report saved to: {report_path}\")\n",
    "    \n",
    "    for v in validations:\n",
    "        if v.passed and \"time\" in v.derived_quantities:\n",
    "            sheet_name = v.file_path.split(\"::\")[1] if \"::\" in v.file_path else \"unknown\"\n",
    "            df = pd.DataFrame({\n",
    "                \"time\": v.derived_quantities[\"time\"],\n",
    "                \"stress\": v.derived_quantities[\"stress\"],\n",
    "            })\n",
    "            df.to_csv(output_paths[\"derived_quantities\"] / f\"{sheet_name}_derived.csv\", index=False)\n",
    "    \n",
    "    print(f\"Derived quantities saved to: {output_paths['derived_quantities']}\")\n",
    "else:\n",
    "    print(\"Artifacts not saved (FAST mode). Set MODE='FULL' to save.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
