{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VLB Bayesian Workflow\n",
    "\n",
    "**VLB transient network — Full NLSQ → NUTS inference pipeline**\n",
    "\n",
    "## Context: Bayesian Inference for VLB\n",
    "\n",
    "This notebook demonstrates the **complete Bayesian workflow** for VLB parameter estimation: NLSQ point estimation → NUTS sampling → convergence diagnostics → posterior predictive checks. \n",
    "\n",
    "The VLB model has only **2 fundamental parameters** ($G_0$, $k_d$), making it ideal for Bayesian inference:\n",
    "- Well-defined posterior (no identifiability issues)\n",
    "- NLSQ provides excellent warm-start for MCMC\n",
    "- Fast convergence (R-hat < 1.01 with 1000 warmup samples)\n",
    "- Derived quantities ($t_R = 1/k_d$, $\\eta_0 = G_0/k_d$, $\\Psi_1 = 2G_0/k_d^2$) inherit posterior uncertainty\n",
    "\n",
    "**Why Bayesian?** Beyond point estimates, we obtain:\n",
    "1. **Credible intervals** — quantify parameter uncertainty\n",
    "2. **Derived quantity distributions** — propagate uncertainty through nonlinear transformations\n",
    "3. **Model comparison** — Bayes factors for VLBLocal vs VLBMultiNetwork\n",
    "4. **Posterior predictive checks** — verify model adequacy\n",
    "\n",
    "> **Handbook:** See [VLB Knowledge](../../docs/source/models/vlb/vlb_knowledge.rst) for cross-protocol validation workflow and parameter identifiability discussion.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Complete NLSQ → NUTS Bayesian workflow for VLBLocal\n",
    "- Evaluate convergence diagnostics (R-hat, ESS, divergences)\n",
    "- Construct posterior predictive checks\n",
    "- Compare posteriors from different protocols\n",
    "\n",
    "## Estimated Runtime\n",
    "\n",
    "- Fast demo (1 chain): ~2 min\n",
    "- Full run (4 chains): ~5-10 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:13:12.072208Z",
     "iopub.status.busy": "2026-02-14T04:13:12.072088Z",
     "iopub.status.idle": "2026-02-14T04:13:12.075322Z",
     "shell.execute_reply": "2026-02-14T04:13:12.074847Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    %pip install -q rheojax\n",
    "    import os\n",
    "    os.environ[\"JAX_ENABLE_X64\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:13:12.076741Z",
     "iopub.status.busy": "2026-02-14T04:13:12.076653Z",
     "iopub.status.idle": "2026-02-14T04:13:13.362333Z",
     "shell.execute_reply": "2026-02-14T04:13:13.361812Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from rheojax.core.jax_config import safe_import_jax, verify_float64\n",
    "from rheojax.models import VLBLocal\n",
    "\n",
    "jax, jnp = safe_import_jax()\n",
    "verify_float64()\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # JAX/equinox upstream deprecation churn — not actionable in user notebooks\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(\"\")))\n",
    "from utils.plotting_utils import (\n",
    "    display_arviz_diagnostics,\n",
    "    plot_nlsq_fit,\n",
    "    plot_posterior_predictive,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic SAOS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:13:13.364020Z",
     "iopub.status.busy": "2026-02-14T04:13:13.363825Z",
     "iopub.status.idle": "2026-02-14T04:13:13.367222Z",
     "shell.execute_reply": "2026-02-14T04:13:13.366629Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "G0_true = 5000.0   # Pa\n",
    "kd_true = 2.0      # 1/s\n",
    "tR = 1.0 / kd_true\n",
    "\n",
    "np.random.seed(42)\n",
    "omega = np.logspace(-2, 3, 40)\n",
    "\n",
    "G_prime_true = G0_true * (omega * tR)**2 / (1 + (omega * tR)**2)\n",
    "G_double_prime_true = G0_true * (omega * tR) / (1 + (omega * tR)**2)\n",
    "\n",
    "# 3% noise\n",
    "noise = 0.03\n",
    "G_prime = G_prime_true * (1 + noise * np.random.randn(len(omega)))\n",
    "G_double_prime = G_double_prime_true * (1 + noise * np.random.randn(len(omega)))\n",
    "G_star = G_prime + 1j * G_double_prime\n",
    "\n",
    "print(f\"True: G₀ = {G0_true} Pa, k_d = {kd_true} 1/s\")\n",
    "print(f\"Data: {len(omega)} frequencies, ω = [{omega.min():.3f}, {omega.max():.0f}] rad/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Step 1: NLSQ Point Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:13:13.368989Z",
     "iopub.status.busy": "2026-02-14T04:13:13.368892Z",
     "iopub.status.idle": "2026-02-14T04:13:14.481090Z",
     "shell.execute_reply": "2026-02-14T04:13:14.480496Z"
    }
   },
   "outputs": [],
   "source": [
    "model = VLBLocal()\n",
    "\n",
    "t0 = time.time()\n",
    "model.fit(omega, G_star, test_mode=\"oscillation\")\n",
    "t_nlsq = time.time() - t0\n",
    "\n",
    "print(f\"NLSQ fit time: {t_nlsq:.2f} s\")\n",
    "print(f\"G₀  = {model.G0:.1f} Pa (true: {G0_true})\")\n",
    "print(f\"k_d = {model.k_d:.4f} 1/s (true: {kd_true})\")\n",
    "\n",
    "# Fit quality — use predict_saos for G', G'' and compare with |G*|\n",
    "G_prime_pred, G_double_prime_pred = model.predict_saos(omega)\n",
    "G_star_pred_abs = np.sqrt(np.array(G_prime_pred)**2 + np.array(G_double_prime_pred)**2)\n",
    "G_star_data_abs = np.abs(G_star)\n",
    "ss_res = np.sum((G_star_data_abs - G_star_pred_abs)**2)\n",
    "ss_tot = np.sum((G_star_data_abs - np.mean(G_star_data_abs))**2)\n",
    "r2 = 1 - ss_res / ss_tot\n",
    "print(f\"R² = {r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Step 2: Bayesian Inference with NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:13:14.482798Z",
     "iopub.status.busy": "2026-02-14T04:13:14.482680Z",
     "iopub.status.idle": "2026-02-14T04:13:17.362050Z",
     "shell.execute_reply": "2026-02-14T04:13:17.361319Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Fast demo config ---\n",
    "NUM_WARMUP = 200\n",
    "NUM_SAMPLES = 500\n",
    "NUM_CHAINS = 1\n",
    "# --- Production config (uncomment for full run) ---\n",
    "# NUM_WARMUP = 1000\n",
    "# NUM_SAMPLES = 2000\n",
    "# NUM_CHAINS = 4\n",
    "\n",
    "# Warm-start from NLSQ\n",
    "initial_values = {\"G0\": float(model.G0), \"k_d\": float(model.k_d)}\n",
    "print(f\"Warm-start: {initial_values}\")\n",
    "\n",
    "t0 = time.time()\n",
    "result = model.fit_bayesian(\n",
    "    omega, G_star, test_mode=\"oscillation\",\n",
    "    num_warmup=NUM_WARMUP,\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    num_chains=NUM_CHAINS,\n",
    "    initial_values=initial_values,\n",
    "    seed=42,\n",
    ")\n",
    "t_bayes = time.time() - t0\n",
    "print(f\"\\nBayesian inference time: {t_bayes:.1f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Convergence Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:13:17.363579Z",
     "iopub.status.busy": "2026-02-14T04:13:17.363452Z",
     "iopub.status.idle": "2026-02-14T04:13:17.367039Z",
     "shell.execute_reply": "2026-02-14T04:13:17.366506Z"
    }
   },
   "outputs": [],
   "source": [
    "diag = result.diagnostics\n",
    "param_names = [\"G0\", \"k_d\"]\n",
    "\n",
    "print(\"Convergence Diagnostics\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Parameter':>10s}  {'R-hat':>8s}  {'ESS':>8s}\")\n",
    "print(\"-\" * 50)\n",
    "for p in param_names:\n",
    "    r_hat = diag.get(\"r_hat\", {}).get(p, float(\"nan\"))\n",
    "    ess = diag.get(\"ess\", {}).get(p, float(\"nan\"))\n",
    "    print(f\"{p:>10s}  {r_hat:8.4f}  {ess:8.0f}\")\n",
    "\n",
    "n_div = diag.get(\"divergences\", diag.get(\"num_divergences\", 0))\n",
    "print(f\"\\nDivergences: {n_div}\")\n",
    "\n",
    "r_hat_ok = all(diag.get(\"r_hat\", {}).get(p, 2.0) < 1.05 for p in param_names)\n",
    "ess_ok = all(diag.get(\"ess\", {}).get(p, 0) > 100 for p in param_names)\n",
    "print(f\"\\nConvergence: {'PASSED' if r_hat_ok and ess_ok else 'CHECK REQUIRED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:13:17.368312Z",
     "iopub.status.busy": "2026-02-14T04:13:17.368192Z",
     "iopub.status.idle": "2026-02-14T04:13:18.403800Z",
     "shell.execute_reply": "2026-02-14T04:13:18.403302Z"
    }
   },
   "outputs": [],
   "source": [
    "display_arviz_diagnostics(result, param_names, fast_mode=os.environ.get(\"FAST_MODE\", \"1\") == \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:13:18.405394Z",
     "iopub.status.busy": "2026-02-14T04:13:18.405175Z",
     "iopub.status.idle": "2026-02-14T04:13:18.659604Z",
     "shell.execute_reply": "2026-02-14T04:13:18.659157Z"
    }
   },
   "outputs": [],
   "source": [
    "display_arviz_diagnostics(result, param_names, fast_mode=os.environ.get(\"FAST_MODE\", \"1\") == \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Posterior Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:13:18.660970Z",
     "iopub.status.busy": "2026-02-14T04:13:18.660869Z",
     "iopub.status.idle": "2026-02-14T04:13:18.664056Z",
     "shell.execute_reply": "2026-02-14T04:13:18.663502Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior = result.posterior_samples\n",
    "\n",
    "print(\"Parameter Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Param':>8s}  {'True':>8s}  {'NLSQ':>10s}  {'Bayes (median)':>14s}  {'95% CI':>20s}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "true_vals = {\"G0\": G0_true, \"k_d\": kd_true}\n",
    "nlsq_vals = {\"G0\": model.G0, \"k_d\": model.k_d}\n",
    "\n",
    "for p in param_names:\n",
    "    samples = np.array(posterior[p])\n",
    "    med = np.median(samples)\n",
    "    lo, hi = np.percentile(samples, [2.5, 97.5])\n",
    "    print(f\"{p:>8s}  {true_vals[p]:8.1f}  {nlsq_vals[p]:10.1f}  {med:14.1f}  [{lo:.1f}, {hi:.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Posterior Predictive Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:13:18.665331Z",
     "iopub.status.busy": "2026-02-14T04:13:18.665255Z",
     "iopub.status.idle": "2026-02-14T04:13:19.067158Z",
     "shell.execute_reply": "2026-02-14T04:13:19.066637Z"
    }
   },
   "outputs": [],
   "source": [
    "omega_fine = np.logspace(-2.5, 3.5, 200)\n",
    "n_draws = min(200, len(posterior[\"G0\"]))\n",
    "\n",
    "Gp_samples = []\n",
    "Gdp_samples = []\n",
    "\n",
    "for i in range(n_draws):\n",
    "    model.parameters.set_value(\"G0\", float(posterior[\"G0\"][i]))\n",
    "    model.parameters.set_value(\"k_d\", float(posterior[\"k_d\"][i]))\n",
    "    Gp_i, Gdp_i = model.predict_saos(omega_fine)\n",
    "    Gp_samples.append(np.array(Gp_i))\n",
    "    Gdp_samples.append(np.array(Gdp_i))\n",
    "\n",
    "Gp_arr = np.array(Gp_samples)\n",
    "Gdp_arr = np.array(Gdp_samples)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "# 95% CI bands\n",
    "ax.fill_between(omega_fine, np.percentile(Gp_arr, 2.5, axis=0),\n",
    "                np.percentile(Gp_arr, 97.5, axis=0), alpha=0.2, color=\"C0\")\n",
    "ax.fill_between(omega_fine, np.percentile(Gdp_arr, 2.5, axis=0),\n",
    "                np.percentile(Gdp_arr, 97.5, axis=0), alpha=0.2, color=\"C1\")\n",
    "\n",
    "# Medians\n",
    "ax.loglog(omega_fine, np.median(Gp_arr, axis=0), \"C0-\", lw=2, label=\"G' (posterior median)\")\n",
    "ax.loglog(omega_fine, np.median(Gdp_arr, axis=0), \"C1-\", lw=2, label=\"G'' (posterior median)\")\n",
    "\n",
    "# Data\n",
    "ax.loglog(omega, np.real(G_star), \"ko\", markersize=4, label=\"G' data\")\n",
    "ax.loglog(omega, np.imag(G_star), \"ks\", markersize=4, label=\"G'' data\")\n",
    "\n",
    "ax.set_xlabel(\"ω [rad/s]\")\n",
    "ax.set_ylabel(\"G', G'' [Pa]\")\n",
    "ax.set_title(\"Posterior Predictive Check\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3, which=\"both\")\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Derived Quantities with Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:13:19.068783Z",
     "iopub.status.busy": "2026-02-14T04:13:19.068672Z",
     "iopub.status.idle": "2026-02-14T04:13:19.071726Z",
     "shell.execute_reply": "2026-02-14T04:13:19.071341Z"
    }
   },
   "outputs": [],
   "source": [
    "G0_samples = np.array(posterior[\"G0\"])\n",
    "kd_samples = np.array(posterior[\"k_d\"])\n",
    "\n",
    "tR_samples = 1.0 / kd_samples\n",
    "eta_samples = G0_samples / kd_samples\n",
    "Psi1_samples = 2.0 * G0_samples / kd_samples**2\n",
    "\n",
    "print(\"Derived Quantities (posterior)\")\n",
    "print(\"=\" * 55)\n",
    "for name, samples, true_val in [\n",
    "    (\"t_R [s]\", tR_samples, 1/kd_true),\n",
    "    (\"η₀ [Pa·s]\", eta_samples, G0_true/kd_true),\n",
    "    (\"Ψ₁ [Pa·s²]\", Psi1_samples, 2*G0_true/kd_true**2),\n",
    "]:\n",
    "    med = np.median(samples)\n",
    "    lo, hi = np.percentile(samples, [2.5, 97.5])\n",
    "    print(f\"  {name:12s}: {med:.1f} [{lo:.1f}, {hi:.1f}] (true: {true_val:.1f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T04:13:19.073380Z",
     "iopub.status.busy": "2026-02-14T04:13:19.073275Z",
     "iopub.status.idle": "2026-02-14T04:13:19.077075Z",
     "shell.execute_reply": "2026-02-14T04:13:19.076683Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "output_dir = os.path.join(\"..\", \"outputs\", \"vlb\", \"bayesian\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "posterior_dict = {k: np.array(v).tolist() for k, v in posterior.items()}\n",
    "with open(os.path.join(output_dir, \"posterior_samples.json\"), \"w\") as f:\n",
    "    json.dump(posterior_dict, f)\n",
    "\n",
    "print(f\"Saved to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **NLSQ warm-start is critical** for fast NUTS convergence\n",
    "2. **VLBLocal has only 2 parameters** → well-identified posteriors\n",
    "3. **R-hat < 1.01 and ESS > 400** are the convergence targets\n",
    "4. **Derived quantities** ($t_R$, $\\eta_0$, $\\Psi_1$) inherit uncertainty from the posterior\n",
    "5. **Posterior predictive checks** verify the model captures the data\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [VLB Model Reference](../../docs/source/models/vlb/vlb.rst) — SAOS analytical solutions for posterior predictive\n",
    "- [VLB Knowledge Extraction](../../docs/source/models/vlb/vlb_knowledge.rst) — cross-protocol validation workflow, parameter identifiability\n",
    "- Vernerey, F.J., Long, R. & Brighenti, R. (2017). *J. Mech. Phys. Solids*, 107, 1-20.\n",
    "\n",
    "## Production Tips\n",
    "\n",
    "- Use `num_chains=4` for proper convergence diagnostics\n",
    "- Use `num_warmup=1000, num_samples=2000` for publication-quality results\n",
    "- Check `az.plot_energy()` for sampling efficiency\n",
    "- If divergences appear, increase `num_warmup` or check parameter bounds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
