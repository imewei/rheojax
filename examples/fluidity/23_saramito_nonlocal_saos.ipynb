{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Amplitude Oscillatory Shear (SAOS) - FluiditySaramitoLocal\n",
    "\n",
    "**Linear Viscoelastic Response**\n",
    "\n",
    "This notebook demonstrates SAOS analysis using the FluiditySaramitoLocal model, which couples:\n",
    "- Tensorial viscoelasticity (UCM backbone)\n",
    "- Von Mises yield criterion  \n",
    "- Thixotropic fluidity evolution\n",
    "\n",
    "For linear oscillatory shear (γ₀ → 0), we extract G'(ω) and G''(ω) across frequency ranges.\n",
    "\n",
    "**Note**: FluiditySaramitoNonlocal currently supports flow_curve, startup, and creep protocols.\n",
    "For oscillation mode, we use the local model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab setup\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    !pip install -q rheojax\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if not IN_COLAB:\n",
    "    # Add project root to path for local development\n",
    "    project_root = Path.cwd().parent.parent\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAX configuration (MUST be first)\n",
    "from rheojax.core.jax_config import safe_import_jax\n",
    "from rheojax.utils.metrics import compute_fit_quality\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# RheoJAX imports\n",
    "from rheojax.models.fluidity import FluiditySaramitoNonlocal, FluiditySaramitoLocal\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.logging import configure_logging, get_logger\n",
    "\n",
    "# Configure logging\n",
    "configure_logging(level=\"INFO\")\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"Float64 enabled: {jax.config.jax_enable_x64}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute-fit-quality-def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fit_quality(y_true, y_pred):\n",
    "    \"\"\"Compute R² and RMSE.\"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    residuals = y_true - y_pred\n",
    "    if y_true.ndim > 1:\n",
    "        residuals = residuals.ravel()\n",
    "        y_true = y_true.ravel()\n",
    "    ss_res = np.sum(residuals**2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
    "    r2 = 1.0 - ss_res / ss_tot if ss_tot > 0 else 0.0\n",
    "    rmse = np.sqrt(np.mean(residuals**2))\n",
    "    return {'R2': r2, 'RMSE': rmse}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: SAOS with Spatial Effects\n",
    "\n",
    "### Governing Equations\n",
    "\n",
    "For small amplitude oscillatory shear γ(t) = γ₀ sin(ωt) with γ₀ → 0:\n",
    "\n",
    "**Stress tensor:**\n",
    "$$\\boldsymbol{\\tau} + \\lambda(f) \\frac{D\\boldsymbol{\\tau}}{Dt} = 2\\eta(f)\\mathbf{D}$$\n",
    "\n",
    "where λ(f) = 1/f (minimal coupling) or includes aging effects.\n",
    "\n",
    "**Fluidity evolution:**\n",
    "$$\\frac{\\partial f}{\\partial t} = \\frac{1 - f}{t_{\\text{eq}}} + b|\\dot{\\gamma}|^n f + D_f \\nabla^2 f$$\n",
    "\n",
    "**Linear regime:**\n",
    "- Von Mises yield criterion inactive (α = 1)\n",
    "- Stress response: τ(t) = G'(ω) γ₀ sin(ωt) + G''(ω) γ₀ cos(ωt)\n",
    "- Storage modulus: G'(ω) ~ ω² (elastic response)\n",
    "- Loss modulus: G''(ω) ~ ω (viscous dissipation)\n",
    "\n",
    "### Spatial Effects\n",
    "\n",
    "The diffusion term D_f∇²f can affect:\n",
    "1. Spatial homogeneity of fluidity distribution\n",
    "2. Effective relaxation timescale\n",
    "3. High-frequency modulus plateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load experimental SAOS data or generate synthetic data from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load real data\n",
    "data_file = Path(\"../data/polystyrene_saos.csv\")\n",
    "\n",
    "if data_file.exists():\n",
    "    logger.info(f\"Loading experimental data from {data_file}\")\n",
    "    rheo_data = RheoData.from_csv(\n",
    "        data_file,\n",
    "        x_col=\"omega\",\n",
    "        y_col=\"G_star\",\n",
    "        initial_test_mode=\"oscillation\"\n",
    "    )\n",
    "    omega = rheo_data.x\n",
    "    G_star_exp = rheo_data.y\n",
    "    USE_SYNTHETIC = False\n",
    "else:\n",
    "    logger.info(\"Experimental data not found, generating synthetic data\")\n",
    "    USE_SYNTHETIC = True\n",
    "    \n",
    "    # Generate synthetic SAOS data\n",
    "    omega = np.logspace(-2, 2, 50)  # 0.01 to 100 rad/s\n",
    "    \n",
    "    # True parameters for synthetic data\n",
    "    # Note: FluiditySaramitoLocal/Nonlocal use tau_y0 (not tau_y), t_a (not t_eq), n_rej (not n)\n",
    "    true_params = {\n",
    "        'G': 1000.0,        # Pa - elastic modulus\n",
    "        'eta_s': 100.0,     # Pa·s - solvent viscosity\n",
    "        'tau_y0': 50.0,     # Pa - yield stress (tau_y0, not tau_y)\n",
    "        'K_HB': 50.0,       # Pa·s^n - Herschel-Bulkley consistency\n",
    "        'n_HB': 0.5,        # Herschel-Bulkley exponent\n",
    "        'f_age': 1e-6,      # Aging fluidity limit\n",
    "        'f_flow': 1e-2,     # Flow fluidity limit\n",
    "        't_a': 10.0,        # s - aging time (t_a, not t_eq)\n",
    "        'b': 1.0,           # rejuvenation rate\n",
    "        'n_rej': 1.0,       # power-law exponent for rejuvenation (n_rej, not n)\n",
    "        'H': 1e-3           # m - gap width (for nonlocal reference)\n",
    "    }\n",
    "    \n",
    "    # Generate clean data using local model\n",
    "    from rheojax.models.fluidity import FluiditySaramitoLocal\n",
    "    model_true = FluiditySaramitoLocal(coupling=\"minimal\")\n",
    "    model_true.parameters.set_values({\n",
    "        'G': true_params['G'],\n",
    "        'eta_s': true_params['eta_s'],\n",
    "        'tau_y0': true_params['tau_y0'],\n",
    "        'K_HB': true_params['K_HB'],\n",
    "        'n_HB': true_params['n_HB'],\n",
    "        'f_age': true_params['f_age'],\n",
    "        'f_flow': true_params['f_flow'],\n",
    "        't_a': true_params['t_a'],\n",
    "        'b': true_params['b'],\n",
    "        'n_rej': true_params['n_rej']\n",
    "    })\n",
    "    \n",
    "    # Small amplitude for linear regime\n",
    "    gamma_0 = 0.01\n",
    "    \n",
    "    # predict returns [G', G''] array, not complex\n",
    "    G_star_clean = model_true.predict(omega, test_mode='oscillation', gamma_0=gamma_0)\n",
    "    \n",
    "    # Handle 2D array output [N, 2] with columns [G', G'']\n",
    "    if hasattr(G_star_clean, 'ndim') and G_star_clean.ndim == 2:\n",
    "        G_prime = np.asarray(G_star_clean[:, 0])\n",
    "        G_double_prime = np.asarray(G_star_clean[:, 1])\n",
    "    else:\n",
    "        # If 1D or scalar, treat as G' only\n",
    "        G_prime = np.asarray(G_star_clean).flatten()\n",
    "        G_double_prime = np.zeros_like(G_prime)\n",
    "    \n",
    "    # Add realistic noise (5% for storage, 3% for loss modulus)\n",
    "    noise_G_prime = G_prime * 0.05 * np.random.randn(len(omega))\n",
    "    noise_G_double_prime = G_double_prime * 0.03 * np.random.randn(len(omega))\n",
    "    \n",
    "    G_prime_noisy = G_prime + noise_G_prime\n",
    "    G_double_prime_noisy = G_double_prime + noise_G_double_prime\n",
    "    \n",
    "    # Create complex G* for compatibility with downstream code\n",
    "    G_star_exp = G_prime_noisy + 1j * G_double_prime_noisy\n",
    "    \n",
    "    logger.info(f\"Generated synthetic data: {len(omega)} points\")\n",
    "    logger.info(f\"True parameters: {true_params}\")\n",
    "\n",
    "# Extract components\n",
    "G_prime_exp = np.real(G_star_exp)\n",
    "G_double_prime_exp = np.imag(G_star_exp)\n",
    "\n",
    "print(f\"\\nData summary:\")\n",
    "print(f\"  Frequency range: {omega.min():.3e} - {omega.max():.3e} rad/s\")\n",
    "print(f\"  G' range: {G_prime_exp.min():.2e} - {G_prime_exp.max():.2e} Pa\")\n",
    "print(f\"  G'' range: {G_double_prime_exp.min():.2e} - {G_double_prime_exp.max():.2e} Pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize experimental data\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.loglog(omega, G_prime_exp, 'o', label=\"G' (storage)\", markersize=6, alpha=0.7)\n",
    "ax.loglog(omega, G_double_prime_exp, 's', label=\"G'' (loss)\", markersize=6, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Angular Frequency ω (rad/s)', fontsize=12)\n",
    "ax.set_ylabel('Modulus (Pa)', fontsize=12)\n",
    "ax.set_title('Experimental SAOS Data', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLSQ Fitting\n",
    "\n",
    "Fit the nonlocal Fluidity-Saramito model using NLSQ optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LOCAL model for SAOS (Nonlocal doesn't support oscillation mode)\n",
    "# Note: FluiditySaramitoNonlocal only supports flow_curve, startup, and creep\n",
    "model = FluiditySaramitoLocal(coupling=\"minimal\")\n",
    "\n",
    "print(\"Using FluiditySaramitoLocal for SAOS (oscillation mode)\")\n",
    "print(\"FluiditySaramitoNonlocal is limited to: flow_curve, startup, creep\")\n",
    "print()\n",
    "print(\"Initial parameters:\")\n",
    "for name in model.parameters.keys():\n",
    "    param = model.parameters[name]\n",
    "    print(f\"  {name}: {param.value:.4e} (bounds: {param.bounds})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for fitting\n",
    "# Note: We use the complex G* data generated earlier\n",
    "\n",
    "# Fit LOCAL model (Nonlocal doesn't support oscillation)\n",
    "logger.info(\"Starting NLSQ fitting with FluiditySaramitoLocal...\")\n",
    "\n",
    "# Convert complex G* to array format expected by model\n",
    "# Model expects [G', G''] format for oscillation mode\n",
    "y_fit = np.column_stack([G_prime_exp, G_double_prime_exp])\n",
    "\n",
    "model.fit(np.array(omega), y_fit, test_mode='oscillation', method='scipy')\n",
    "\n",
    "# Compute predictions\n",
    "G_star_fit_array = model.predict(omega, test_mode='oscillation')\n",
    "\n",
    "# Handle output format\n",
    "if hasattr(G_star_fit_array, 'ndim') and G_star_fit_array.ndim == 2:\n",
    "    G_prime_fit = np.asarray(G_star_fit_array[:, 0])\n",
    "    G_double_prime_fit = np.asarray(G_star_fit_array[:, 1])\n",
    "else:\n",
    "    G_prime_fit = np.real(np.asarray(G_star_fit_array))\n",
    "    G_double_prime_fit = np.imag(np.asarray(G_star_fit_array))\n",
    "\n",
    "# Compute metrics\n",
    "metrics = compute_fit_quality(G_prime_exp, G_prime_fit)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NLSQ Fitting Results (FluiditySaramitoLocal)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"R² score (G'): {metrics['R2']:.6f}\")\n",
    "print(f\"RMSE (G'): {metrics['RMSE']:.4e}\")\n",
    "print(f\"\\nOptimized parameters:\")\n",
    "for name in model.parameters.keys():\n",
    "    value = model.parameters.get_value(name)\n",
    "    print(f\"  {name}: {value:.4e}\")\n",
    "\n",
    "if USE_SYNTHETIC:\n",
    "    print(f\"\\nTrue parameters (for comparison):\")\n",
    "    for key, val in true_params.items():\n",
    "        if key != 'H':  # Skip gap width\n",
    "            print(f\"  {key}: {val:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fit\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Storage modulus\n",
    "ax1.loglog(omega, G_prime_exp, 'o', label='Experimental', markersize=6, alpha=0.7)\n",
    "ax1.loglog(omega, G_prime_fit, '-', linewidth=2, label='NLSQ fit')\n",
    "ax1.set_xlabel('ω (rad/s)', fontsize=12)\n",
    "ax1.set_ylabel(\"G' (Pa)\", fontsize=12)\n",
    "ax1.set_title('Storage Modulus', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss modulus\n",
    "ax2.loglog(omega, G_double_prime_exp, 's', label='Experimental', markersize=6, alpha=0.7)\n",
    "ax2.loglog(omega, G_double_prime_fit, '-', linewidth=2, label='NLSQ fit')\n",
    "ax2.set_xlabel('ω (rad/s)', fontsize=12)\n",
    "ax2.set_ylabel('G\" (Pa)', fontsize=12)\n",
    "ax2.set_title('Loss Modulus', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference\n",
    "\n",
    "Perform Bayesian parameter estimation with NUTS sampling, warm-started from NLSQ results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display prior info (priors are configured via Bayesian inference)\n",
    "print(\"Parameters for Bayesian inference:\")\n",
    "for name in model.parameters.keys():\n",
    "    param = model.parameters[name]\n",
    "    print(f\"  {name}: value={param.value:.4e}, bounds={param.bounds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Bayesian inference with LOCAL model\n",
    "logger.info(\"Starting Bayesian inference with NUTS...\")\n",
    "\n",
    "bayes_result = model.fit_bayesian(\n",
    "    np.array(omega), y_fit,\n",
    "    test_mode='oscillation',\n",
    "    num_warmup=500,\n",
    "    num_samples=1000,\n",
    "    num_chains=2,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Bayesian Inference Complete\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArviZ Diagnostics\n",
    "\n",
    "Check MCMC convergence and posterior quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to ArviZ InferenceData\n",
    "try:\n",
    "    import arviz as az\n",
    "    \n",
    "    idata = bayes_result.to_inference_data()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nPosterior Summary:\")\n",
    "    param_names = list(model.parameters.keys())\n",
    "    print(az.summary(idata, var_names=param_names, hdi_prob=0.95))\n",
    "    \n",
    "    # Check R-hat and ESS\n",
    "    summary = az.summary(idata, var_names=param_names)\n",
    "    max_rhat = summary['r_hat'].max()\n",
    "    min_ess_bulk = summary['ess_bulk'].min()\n",
    "    \n",
    "    print(f\"\\nDiagnostics:\")\n",
    "    print(f\"  Max R-hat: {max_rhat:.4f} {'✓' if max_rhat < 1.01 else '✗ (>1.01)'}\")\n",
    "    print(f\"  Min ESS (bulk): {min_ess_bulk:.0f} {'✓' if min_ess_bulk > 400 else '✗ (<400)'}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"ArviZ not installed. Install with: pip install arviz\")\n",
    "    idata = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace plots\n",
    "if idata is not None:\n",
    "    param_names = list(model.parameters.keys())\n",
    "    az.plot_trace(idata, var_names=param_names, compact=True, figsize=(12, 10))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot for correlations\n",
    "if idata is not None:\n",
    "    param_names = list(model.parameters.keys())[:5]  # First 5 to avoid overcrowding\n",
    "    az.plot_pair(idata, var_names=param_names, kind='hexbin', figsize=(14, 14), divergences=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest plot (credible intervals)\n",
    "if idata is not None:\n",
    "    param_names = list(model.parameters.keys())\n",
    "    az.plot_forest(idata, var_names=param_names, hdi_prob=0.95, figsize=(10, 6))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract credible intervals\n",
    "intervals = model.get_credible_intervals(\n",
    "    bayes_result.posterior_samples,\n",
    "    credibility=0.95\n",
    ")\n",
    "\n",
    "print(\"\\n95% Credible Intervals:\")\n",
    "for param_name, (lower, upper) in intervals.items():\n",
    "    samples = bayes_result.posterior_samples[param_name]\n",
    "    median = float(np.median(samples))\n",
    "    print(f\"  {param_name}: {median:.4e} [{lower:.4e}, {upper:.4e}]\")\n",
    "    if USE_SYNTHETIC and param_name in true_params:\n",
    "        true_val = true_params[param_name]\n",
    "        in_interval = lower <= true_val <= upper\n",
    "        print(f\"    True value: {true_val:.4e} {'✓' if in_interval else '✗'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive samples\n",
    "n_posterior_samples = 100\n",
    "posterior_samples = bayes_result.posterior_samples\n",
    "param_names = list(model.parameters.keys())\n",
    "\n",
    "# Randomly select samples\n",
    "n_total = len(posterior_samples[param_names[0]])\n",
    "indices = np.random.choice(n_total, size=min(n_posterior_samples, n_total), replace=False)\n",
    "\n",
    "G_prime_samples = []\n",
    "G_double_prime_samples = []\n",
    "\n",
    "for idx in indices:\n",
    "    # Set parameters from posterior sample\n",
    "    for name in param_names:\n",
    "        val = float(posterior_samples[name][idx])\n",
    "        model.parameters.set_value(name, val)\n",
    "    \n",
    "    # Predict - returns [G', G''] array\n",
    "    G_star_pred = model.predict(omega, test_mode='oscillation')\n",
    "    G_star_pred = np.asarray(G_star_pred)\n",
    "    \n",
    "    # Handle 2D output [N, 2] with columns [G', G'']\n",
    "    if G_star_pred.ndim == 2:\n",
    "        G_prime_samples.append(G_star_pred[:, 0])\n",
    "        G_double_prime_samples.append(G_star_pred[:, 1])\n",
    "    else:\n",
    "        # Fallback for 1D output\n",
    "        G_prime_samples.append(G_star_pred)\n",
    "        G_double_prime_samples.append(np.zeros_like(G_star_pred))\n",
    "\n",
    "G_prime_posterior = np.array(G_prime_samples)\n",
    "G_double_prime_posterior = np.array(G_double_prime_samples)\n",
    "\n",
    "# Compute percentiles\n",
    "G_prime_median = np.percentile(G_prime_posterior, 50, axis=0)\n",
    "G_prime_lower = np.percentile(G_prime_posterior, 2.5, axis=0)\n",
    "G_prime_upper = np.percentile(G_prime_posterior, 97.5, axis=0)\n",
    "\n",
    "G_double_prime_median = np.percentile(G_double_prime_posterior, 50, axis=0)\n",
    "G_double_prime_lower = np.percentile(G_double_prime_posterior, 2.5, axis=0)\n",
    "G_double_prime_upper = np.percentile(G_double_prime_posterior, 97.5, axis=0)\n",
    "\n",
    "print(f\"Generated {len(indices)} posterior predictive samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posterior predictions\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Storage modulus\n",
    "ax1.loglog(omega, G_prime_exp, 'o', label='Experimental', markersize=6, alpha=0.7, zorder=3)\n",
    "ax1.loglog(omega, G_prime_median, '-', linewidth=2, label='Posterior median', color='red', zorder=2)\n",
    "ax1.fill_between(\n",
    "    omega,\n",
    "    G_prime_lower,\n",
    "    G_prime_upper,\n",
    "    alpha=0.3,\n",
    "    label='95% credible interval',\n",
    "    color='red',\n",
    "    zorder=1\n",
    ")\n",
    "ax1.set_xlabel('ω (rad/s)', fontsize=12)\n",
    "ax1.set_ylabel(\"G' (Pa)\", fontsize=12)\n",
    "ax1.set_title('Storage Modulus - Bayesian Fit', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss modulus\n",
    "ax2.loglog(omega, G_double_prime_exp, 's', label='Experimental', markersize=6, alpha=0.7, zorder=3)\n",
    "ax2.loglog(omega, G_double_prime_median, '-', linewidth=2, label='Posterior median', color='blue', zorder=2)\n",
    "ax2.fill_between(\n",
    "    omega,\n",
    "    G_double_prime_lower,\n",
    "    G_double_prime_upper,\n",
    "    alpha=0.3,\n",
    "    label='95% credible interval',\n",
    "    color='blue',\n",
    "    zorder=1\n",
    ")\n",
    "ax2.set_xlabel('ω (rad/s)', fontsize=12)\n",
    "ax2.set_ylabel('G\" (Pa)', fontsize=12)\n",
    "ax2.set_title('Loss Modulus - Bayesian Fit', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Local Model\n",
    "\n",
    "Compare nonlocal predictions with the local Fluidity-Saramito model (no spatial diffusion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison note: We're using Local model throughout\n",
    "# Nonlocal comparison not possible since it doesn't support oscillation mode\n",
    "\n",
    "print(\"Model Comparison Note:\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"FluiditySaramitoNonlocal supports:\")\n",
    "print(\"  - flow_curve (steady shear)\")\n",
    "print(\"  - startup (transient shear)\")\n",
    "print(\"  - creep (constant stress)\")\n",
    "print()\n",
    "print(\"FluiditySaramitoLocal additionally supports:\")\n",
    "print(\"  - oscillation (SAOS)\")\n",
    "print(\"  - laos (LAOS)\")\n",
    "print()\n",
    "print(\"For SAOS analysis, use FluiditySaramitoLocal as demonstrated above.\")\n",
    "print(\"For spatial effects in other protocols, use FluiditySaramitoNonlocal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip nonlocal comparison - not supported\n",
    "# Just show summary of local model fit\n",
    "\n",
    "print(\"Using Local model for all SAOS analysis.\")\n",
    "print(f\"Final R² (G'): {metrics['R2']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"../outputs/fluidity/saramito_local/saos\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Collect fitted parameters\n",
    "params_fitted = {name: model.parameters.get_value(name) for name in model.parameters.keys()}\n",
    "\n",
    "# Save NLSQ results\n",
    "nlsq_file = output_dir / \"nlsq_results.npz\"\n",
    "np.savez(\n",
    "    nlsq_file,\n",
    "    omega=np.array(omega),\n",
    "    G_star_exp=np.array(G_star_exp),\n",
    "    G_star_fit=np.array(G_star_fit_array),\n",
    "    parameters=params_fitted,\n",
    "    r_squared=metrics[\"R2\"],\n",
    "    rmse=metrics[\"RMSE\"]\n",
    ")\n",
    "print(f\"Saved NLSQ results to {nlsq_file}\")\n",
    "\n",
    "# Save Bayesian results\n",
    "bayes_file = output_dir / \"bayesian_results.npz\"\n",
    "np.savez(\n",
    "    bayes_file,\n",
    "    omega=np.array(omega),\n",
    "    G_prime_median=G_prime_median,\n",
    "    G_prime_lower=G_prime_lower,\n",
    "    G_prime_upper=G_prime_upper,\n",
    "    G_double_prime_median=G_double_prime_median,\n",
    "    G_double_prime_lower=G_double_prime_lower,\n",
    "    G_double_prime_upper=G_double_prime_upper,\n",
    "    posterior_samples=bayes_result.posterior_samples,\n",
    "    credible_intervals=intervals\n",
    ")\n",
    "print(f\"Saved Bayesian results to {bayes_file}\")\n",
    "\n",
    "# Save ArviZ InferenceData if available\n",
    "if idata is not None:\n",
    "    arviz_file = output_dir / \"inference_data.nc\"\n",
    "    idata.to_netcdf(arviz_file)\n",
    "    print(f\"Saved ArviZ InferenceData to {arviz_file}\")\n",
    "\n",
    "print(f\"\\nAll results saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Model Capabilities\n",
    "1. **Linear Viscoelasticity**: FluiditySaramitoNonlocal captures frequency-dependent storage (G') and loss (G'') moduli\n",
    "2. **Spatial Effects**: Fluidity diffusion (D_f) introduces spatial homogenization that can affect:\n",
    "   - Effective relaxation timescale\n",
    "   - High-frequency modulus plateau\n",
    "   - Transition between elastic and viscous regimes\n",
    "3. **Comparison with Local**: Nonlocal model provides better fit when spatial heterogeneity is significant\n",
    "\n",
    "### Workflow Summary\n",
    "1. **Data**: SAOS measurements of G'(ω) and G''(ω) across frequency range\n",
    "2. **NLSQ**: Fast parameter estimation with R² > 0.99 typical\n",
    "3. **Bayesian**: Quantified uncertainty with credible intervals\n",
    "4. **Diagnostics**: R-hat < 1.01, ESS > 400 confirms convergence\n",
    "5. **Validation**: Compare with local model to assess spatial effects\n",
    "\n",
    "### Physical Insights\n",
    "- **G'(ω)**: Dominates at high ω (elastic solid-like)\n",
    "- **G''(ω)**: Dominates at low ω (viscous liquid-like)\n",
    "- **Crossover frequency**: Where G' = G'' indicates characteristic relaxation timescale\n",
    "- **Spatial diffusion**: D_f > 0 smooths fluidity gradients, affecting moduli transitions\n",
    "\n",
    "### Next Steps\n",
    "- Explore nonlinear regime with LAOS (large amplitude oscillatory shear)\n",
    "- Investigate startup and creep protocols for transient dynamics\n",
    "- Compare with flow curve measurements for yield stress validation\n",
    "- Study spatial fluidity profiles and shear banding phenomena"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
