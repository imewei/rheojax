{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Amplitude Oscillatory Shear (SAOS) - FluiditySaramitoNonlocal\n",
    "\n",
    "**Linear Viscoelastic Response with Spatial Effects**\n",
    "\n",
    "This notebook demonstrates SAOS analysis using the nonlocal Fluidity-Saramito model, which couples:\n",
    "- Tensorial viscoelasticity (UCM backbone)\n",
    "- Von Mises yield criterion\n",
    "- Thixotropic fluidity evolution\n",
    "- Spatial diffusion effects\n",
    "\n",
    "For linear oscillatory shear (γ₀ → 0), we extract G'(ω) and G''(ω) across frequency ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab setup\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    !pip install -q rheojax\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if not IN_COLAB:\n",
    "    # Add project root to path for local development\n",
    "    project_root = Path.cwd().parent.parent\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAX configuration (MUST be first)\n",
    "from rheojax.core.jax_config import safe_import_jax\n",
    "from rheojax.utils.metrics import compute_fit_quality\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# RheoJAX imports\n",
    "from rheojax.models.fluidity import FluiditySaramitoNonlocal, FluiditySaramitoLocal\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.logging import configure_logging, get_logger\n",
    "\n",
    "# Configure logging\n",
    "configure_logging(level=\"INFO\")\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"Float64 enabled: {jax.config.jax_enable_x64}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: SAOS with Spatial Effects\n",
    "\n",
    "### Governing Equations\n",
    "\n",
    "For small amplitude oscillatory shear γ(t) = γ₀ sin(ωt) with γ₀ → 0:\n",
    "\n",
    "**Stress tensor:**\n",
    "$$\\boldsymbol{\\tau} + \\lambda(f) \\frac{D\\boldsymbol{\\tau}}{Dt} = 2\\eta(f)\\mathbf{D}$$\n",
    "\n",
    "where λ(f) = 1/f (minimal coupling) or includes aging effects.\n",
    "\n",
    "**Fluidity evolution:**\n",
    "$$\\frac{\\partial f}{\\partial t} = \\frac{1 - f}{t_{\\text{eq}}} + b|\\dot{\\gamma}|^n f + D_f \\nabla^2 f$$\n",
    "\n",
    "**Linear regime:**\n",
    "- Von Mises yield criterion inactive (α = 1)\n",
    "- Stress response: τ(t) = G'(ω) γ₀ sin(ωt) + G''(ω) γ₀ cos(ωt)\n",
    "- Storage modulus: G'(ω) ~ ω² (elastic response)\n",
    "- Loss modulus: G''(ω) ~ ω (viscous dissipation)\n",
    "\n",
    "### Spatial Effects\n",
    "\n",
    "The diffusion term D_f∇²f can affect:\n",
    "1. Spatial homogeneity of fluidity distribution\n",
    "2. Effective relaxation timescale\n",
    "3. High-frequency modulus plateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load experimental SAOS data or generate synthetic data from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load real data\n",
    "data_file = Path(\"../data/polystyrene_saos.csv\")\n",
    "\n",
    "if data_file.exists():\n",
    "    logger.info(f\"Loading experimental data from {data_file}\")\n",
    "    rheo_data = RheoData.from_csv(\n",
    "        data_file,\n",
    "        x_col=\"omega\",\n",
    "        y_col=\"G_star\",\n",
    "        test_mode=\"oscillation\"\n",
    "    )\n",
    "    omega = rheo_data.x\n",
    "    G_star_exp = rheo_data.y\n",
    "    USE_SYNTHETIC = False\n",
    "else:\n",
    "    logger.info(\"Experimental data not found, generating synthetic data\")\n",
    "    USE_SYNTHETIC = True\n",
    "    \n",
    "    # Generate synthetic SAOS data\n",
    "    omega = jnp.logspace(-2, 2, 50)  # 0.01 to 100 rad/s\n",
    "    \n",
    "    # True parameters for synthetic data\n",
    "    true_params = {\n",
    "        'G': 1000.0,        # Pa - elastic modulus\n",
    "        'eta_s': 100.0,     # Pa·s - solvent viscosity\n",
    "        'tau_y': 50.0,      # Pa - yield stress\n",
    "        't_eq': 10.0,       # s - equilibration time\n",
    "        'b': 1.0,           # s^(-n) - rejuvenation rate\n",
    "        'n': 1.0,           # dimensionless - power-law exponent\n",
    "        'D_f': 1e-6,        # m²/s - fluidity diffusion\n",
    "        'gap_width': 1e-3   # m - gap width\n",
    "    }\n",
    "    \n",
    "    # Generate clean data\n",
    "    model_true = FluiditySaramitoNonlocal(\n",
    "        coupling=\"minimal\",\n",
    "        n_points=51\n",
    "    )\n",
    "    model_true.G.value = true_params['G']\n",
    "    model_true.eta_s.value = true_params['eta_s']\n",
    "    model_true.tau_y.value = true_params['tau_y']\n",
    "    model_true.t_eq.value = true_params['t_eq']\n",
    "    model_true.b.value = true_params['b']\n",
    "    model_true.n.value = true_params['n']\n",
    "    model_true.D_f.value = true_params['D_f']\n",
    "    model_true.gap_width.value = true_params['gap_width']\n",
    "    \n",
    "    # Small amplitude for linear regime\n",
    "    gamma_0 = 0.01\n",
    "    \n",
    "    G_star_clean = model_true.predict(omega, test_mode='oscillation', gamma_0=gamma_0)\n",
    "    \n",
    "    # Add realistic noise (5% for storage, 3% for loss modulus)\n",
    "    G_prime = jnp.real(G_star_clean)\n",
    "    G_double_prime = jnp.imag(G_star_clean)\n",
    "    \n",
    "    noise_G_prime = G_prime * 0.05 * np.random.randn(len(omega))\n",
    "    noise_G_double_prime = G_double_prime * 0.03 * np.random.randn(len(omega))\n",
    "    \n",
    "    G_star_exp = (G_prime + noise_G_prime) + 1j * (G_double_prime + noise_G_double_prime)\n",
    "    \n",
    "    logger.info(f\"Generated synthetic data: {len(omega)} points\")\n",
    "    logger.info(f\"True parameters: {true_params}\")\n",
    "\n",
    "# Extract components\n",
    "G_prime_exp = jnp.real(G_star_exp)\n",
    "G_double_prime_exp = jnp.imag(G_star_exp)\n",
    "\n",
    "print(f\"\\nData summary:\")\n",
    "print(f\"  Frequency range: {omega.min():.3e} - {omega.max():.3e} rad/s\")\n",
    "print(f\"  G' range: {G_prime_exp.min():.2e} - {G_prime_exp.max():.2e} Pa\")\n",
    "print(f\"  G'' range: {G_double_prime_exp.min():.2e} - {G_double_prime_exp.max():.2e} Pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize experimental data\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.loglog(omega, G_prime_exp, 'o', label=\"G' (storage)\", markersize=6, alpha=0.7)\n",
    "ax.loglog(omega, G_double_prime_exp, 's', label=\"G'' (loss)\", markersize=6, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Angular Frequency ω (rad/s)', fontsize=12)\n",
    "ax.set_ylabel('Modulus (Pa)', fontsize=12)\n",
    "ax.set_title('Experimental SAOS Data', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLSQ Fitting\n",
    "\n",
    "Fit the nonlocal Fluidity-Saramito model using NLSQ optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = FluiditySaramitoNonlocal(\n",
    "    coupling=\"minimal\",  # λ = 1/f only\n",
    "    n_points=51          # Spatial resolution\n",
    ")\n",
    "\n",
    "# Set parameter bounds based on physical constraints\n",
    "model.G.bounds = (1e2, 1e5)          # Elastic modulus (Pa)\n",
    "model.eta_s.bounds = (1.0, 1e4)      # Solvent viscosity (Pa·s)\n",
    "model.tau_y.bounds = (1.0, 500.0)    # Yield stress (Pa)\n",
    "model.t_eq.bounds = (0.1, 100.0)     # Equilibration time (s)\n",
    "model.b.bounds = (0.01, 10.0)        # Rejuvenation rate\n",
    "model.n.bounds = (0.5, 2.0)          # Power-law exponent\n",
    "model.D_f.bounds = (1e-8, 1e-4)      # Fluidity diffusion (m²/s)\n",
    "model.gap_width.bounds = (1e-4, 1e-2)  # Gap width (m)\n",
    "\n",
    "print(\"Initial parameters:\")\n",
    "for param in model.parameters:\n",
    "    print(f\"  {param.name}: {param.value:.4e} (bounds: {param.bounds})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "rheo_data = RheoData(\n",
    "    x=omega,\n",
    "    y=G_star_exp,\n",
    "    test_mode='oscillation'\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "logger.info(\"Starting NLSQ fitting...\")\n",
    "result = model.fit(\n",
    "    rheo_data,\n",
    "    gamma_0=0.01,  # Small amplitude for linear regime\n",
    "    max_iter=2000,\n",
    "    verbose=True\n",
    ", method='scipy')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NLSQ Fitting Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Convergence: {result.success}\")\n",
    "print(f\"R² score: {metrics['R2']:.6f}\")\n",
    "print(f\"RMSE: {metrics['RMSE']:.4e}\")\n",
    "print(f\"Iterations: {result.nit}\")\n",
    "print(f\"\\nOptimized parameters:\")\n",
    "for param in model.parameters:\n",
    "    print(f\"  {param.name}: {param.value:.4e}\")\n",
    "\n",
    "if USE_SYNTHETIC:\n",
    "    print(f\"\\nTrue parameters (for comparison):\")\n",
    "    for key, val in true_params.items():\n",
    "        print(f\"  {key}: {val:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "G_star_fit = model.predict(omega, test_mode='oscillation', gamma_0=0.01)\n",
    "G_prime_fit = jnp.real(G_star_fit)\n",
    "G_double_prime_fit = jnp.imag(G_star_fit)\n",
    "\n",
    "# Plot fit\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Storage modulus\n",
    "ax1.loglog(omega, G_prime_exp, 'o', label='Experimental', markersize=6, alpha=0.7)\n",
    "ax1.loglog(omega, G_prime_fit, '-', linewidth=2, label='NLSQ fit')\n",
    "ax1.set_xlabel('ω (rad/s)', fontsize=12)\n",
    "ax1.set_ylabel(\"G' (Pa)\", fontsize=12)\n",
    "ax1.set_title('Storage Modulus', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss modulus\n",
    "ax2.loglog(omega, G_double_prime_exp, 's', label='Experimental', markersize=6, alpha=0.7)\n",
    "ax2.loglog(omega, G_double_prime_fit, '-', linewidth=2, label='NLSQ fit')\n",
    "ax2.set_xlabel('ω (rad/s)', fontsize=12)\n",
    "ax2.set_ylabel('G\" (Pa)', fontsize=12)\n",
    "ax2.set_title('Loss Modulus', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference\n",
    "\n",
    "Perform Bayesian parameter estimation with NUTS sampling, warm-started from NLSQ results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set priors (log-uniform for scale parameters)\n",
    "model.G.prior = ('LogUniform', 1e2, 1e5)\n",
    "model.eta_s.prior = ('LogUniform', 1.0, 1e4)\n",
    "model.tau_y.prior = ('Uniform', 1.0, 500.0)\n",
    "model.t_eq.prior = ('LogUniform', 0.1, 100.0)\n",
    "model.b.prior = ('LogUniform', 0.01, 10.0)\n",
    "model.n.prior = ('Uniform', 0.5, 2.0)\n",
    "model.D_f.prior = ('LogUniform', 1e-8, 1e-4)\n",
    "model.gap_width.prior = ('LogUniform', 1e-4, 1e-2)\n",
    "\n",
    "print(\"Priors:\")\n",
    "for param in model.parameters:\n",
    "    print(f\"  {param.name}: {param.prior}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Bayesian inference\n",
    "logger.info(\"Starting Bayesian inference with NUTS...\")\n",
    "\n",
    "bayes_result = model.fit_bayesian(\n",
    "    rheo_data,\n",
    "    gamma_0=0.01,\n",
    "    num_warmup=1000,\n",
    "    num_samples=2000,\n",
    "    num_chains=4,\n",
    "    seed=42,\n",
    "    progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Bayesian Inference Complete\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples: {bayes_result.num_samples}\")\n",
    "print(f\"Number of chains: {bayes_result.num_chains}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArviZ Diagnostics\n",
    "\n",
    "Check MCMC convergence and posterior quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to ArviZ InferenceData\n",
    "try:\n",
    "    import arviz as az\n",
    "    \n",
    "    idata = bayes_result.to_inference_data()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nPosterior Summary:\")\n",
    "    print(az.summary(\n",
    "        idata,\n",
    "        var_names=[p.name for p in model.parameters],\n",
    "        hdi_prob=0.95\n",
    "    ))\n",
    "    \n",
    "    # Check R-hat and ESS\n",
    "    summary = az.summary(idata, var_names=[p.name for p in model.parameters])\n",
    "    max_rhat = summary['r_hat'].max()\n",
    "    min_ess_bulk = summary['ess_bulk'].min()\n",
    "    \n",
    "    print(f\"\\nDiagnostics:\")\n",
    "    print(f\"  Max R-hat: {max_rhat:.4f} {'✓' if max_rhat < 1.01 else '✗ (>1.01)'}\")\n",
    "    print(f\"  Min ESS (bulk): {min_ess_bulk:.0f} {'✓' if min_ess_bulk > 400 else '✗ (<400)'}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"ArviZ not installed. Install with: pip install arviz\")\n",
    "    idata = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace plots\n",
    "if idata is not None:\n",
    "    az.plot_trace(\n",
    "        idata,\n",
    "        var_names=[p.name for p in model.parameters],\n",
    "        compact=True,\n",
    "        figsize=(12, 10)\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot for correlations\n",
    "if idata is not None:\n",
    "    az.plot_pair(\n",
    "        idata,\n",
    "        var_names=[p.name for p in model.parameters],\n",
    "        kind='hexbin',\n",
    "        figsize=(14, 14),\n",
    "        divergences=True\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest plot (credible intervals)\n",
    "if idata is not None:\n",
    "    az.plot_forest(\n",
    "        idata,\n",
    "        var_names=[p.name for p in model.parameters],\n",
    "        hdi_prob=0.95,\n",
    "        figsize=(10, 6)\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract credible intervals\n",
    "intervals = model.get_credible_intervals(\n",
    "    bayes_result.posterior_samples,\n",
    "    credibility=0.95\n",
    ")\n",
    "\n",
    "print(\"\\n95% Credible Intervals:\")\n",
    "for param_name, (lower, median, upper) in intervals.items():\n",
    "    print(f\"  {param_name}: {median:.4e} [{lower:.4e}, {upper:.4e}]\")\n",
    "    if USE_SYNTHETIC and param_name in true_params:\n",
    "        true_val = true_params[param_name]\n",
    "        in_interval = lower <= true_val <= upper\n",
    "        print(f\"    True value: {true_val:.4e} {'✓' if in_interval else '✗'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive samples\n",
    "n_posterior_samples = 100\n",
    "posterior_samples = bayes_result.posterior_samples\n",
    "\n",
    "# Randomly select samples\n",
    "indices = np.random.choice(\n",
    "    len(posterior_samples[model.parameters[0].name]),\n",
    "    size=n_posterior_samples,\n",
    "    replace=False\n",
    ")\n",
    "\n",
    "G_star_posterior = []\n",
    "for idx in indices:\n",
    "    # Set parameters from posterior sample\n",
    "    for param in model.parameters:\n",
    "        param.value = float(posterior_samples[param.name][idx])\n",
    "    \n",
    "    # Predict\n",
    "    G_star_pred = model.predict(omega, test_mode='oscillation', gamma_0=0.01)\n",
    "    G_star_posterior.append(G_star_pred)\n",
    "\n",
    "G_star_posterior = jnp.array(G_star_posterior)\n",
    "G_prime_posterior = jnp.real(G_star_posterior)\n",
    "G_double_prime_posterior = jnp.imag(G_star_posterior)\n",
    "\n",
    "# Compute percentiles\n",
    "G_prime_median = jnp.percentile(G_prime_posterior, 50, axis=0)\n",
    "G_prime_lower = jnp.percentile(G_prime_posterior, 2.5, axis=0)\n",
    "G_prime_upper = jnp.percentile(G_prime_posterior, 97.5, axis=0)\n",
    "\n",
    "G_double_prime_median = jnp.percentile(G_double_prime_posterior, 50, axis=0)\n",
    "G_double_prime_lower = jnp.percentile(G_double_prime_posterior, 2.5, axis=0)\n",
    "G_double_prime_upper = jnp.percentile(G_double_prime_posterior, 97.5, axis=0)\n",
    "\n",
    "print(f\"Generated {n_posterior_samples} posterior predictive samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posterior predictions\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Storage modulus\n",
    "ax1.loglog(omega, G_prime_exp, 'o', label='Experimental', markersize=6, alpha=0.7, zorder=3)\n",
    "ax1.loglog(omega, G_prime_median, '-', linewidth=2, label='Posterior median', color='red', zorder=2)\n",
    "ax1.fill_between(\n",
    "    omega,\n",
    "    G_prime_lower,\n",
    "    G_prime_upper,\n",
    "    alpha=0.3,\n",
    "    label='95% credible interval',\n",
    "    color='red',\n",
    "    zorder=1\n",
    ")\n",
    "ax1.set_xlabel('ω (rad/s)', fontsize=12)\n",
    "ax1.set_ylabel(\"G' (Pa)\", fontsize=12)\n",
    "ax1.set_title('Storage Modulus - Bayesian Fit', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss modulus\n",
    "ax2.loglog(omega, G_double_prime_exp, 's', label='Experimental', markersize=6, alpha=0.7, zorder=3)\n",
    "ax2.loglog(omega, G_double_prime_median, '-', linewidth=2, label='Posterior median', color='blue', zorder=2)\n",
    "ax2.fill_between(\n",
    "    omega,\n",
    "    G_double_prime_lower,\n",
    "    G_double_prime_upper,\n",
    "    alpha=0.3,\n",
    "    label='95% credible interval',\n",
    "    color='blue',\n",
    "    zorder=1\n",
    ")\n",
    "ax2.set_xlabel('ω (rad/s)', fontsize=12)\n",
    "ax2.set_ylabel('G\" (Pa)', fontsize=12)\n",
    "ax2.set_title('Loss Modulus - Bayesian Fit', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Local Model\n",
    "\n",
    "Compare nonlocal predictions with the local Fluidity-Saramito model (no spatial diffusion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit local model\n",
    "model_local = FluiditySaramitoLocal(coupling=\"minimal\")\n",
    "\n",
    "# Set same bounds\n",
    "model_local.G.bounds = (1e2, 1e5)\n",
    "model_local.eta_s.bounds = (1.0, 1e4)\n",
    "model_local.tau_y.bounds = (1.0, 500.0)\n",
    "model_local.t_eq.bounds = (0.1, 100.0)\n",
    "model_local.b.bounds = (0.01, 10.0)\n",
    "model_local.n.bounds = (0.5, 2.0)\n",
    "\n",
    "logger.info(\"Fitting local model for comparison...\")\n",
    "result_local = model_local.fit(\n",
    "    rheo_data,\n",
    "    gamma_0=0.01,\n",
    "    max_iter=2000,\n",
    "    verbose=True\n",
    ", method='scipy')\n",
    "\n",
    "print(f\"\\nLocal model R²: {result_local.r_squared:.6f}\")\n",
    "print(f\"Nonlocal model R²: {metrics['R2']:.6f}\")\n",
    "print(f\"Improvement: {(metrics['R2'] - result_local.r_squared)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate local predictions\n",
    "G_star_local = model_local.predict(omega, test_mode='oscillation', gamma_0=0.01)\n",
    "G_prime_local = jnp.real(G_star_local)\n",
    "G_double_prime_local = jnp.imag(G_star_local)\n",
    "\n",
    "# Compare fits\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Storage modulus comparison\n",
    "ax1.loglog(omega, G_prime_exp, 'o', label='Experimental', markersize=6, alpha=0.7)\n",
    "ax1.loglog(omega, G_prime_fit, '-', linewidth=2, label='Nonlocal', color='red')\n",
    "ax1.loglog(omega, G_prime_local, '--', linewidth=2, label='Local', color='green')\n",
    "ax1.set_xlabel('ω (rad/s)', fontsize=12)\n",
    "ax1.set_ylabel(\"G' (Pa)\", fontsize=12)\n",
    "ax1.set_title('Storage Modulus - Model Comparison', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss modulus comparison\n",
    "ax2.loglog(omega, G_double_prime_exp, 's', label='Experimental', markersize=6, alpha=0.7)\n",
    "ax2.loglog(omega, G_double_prime_fit, '-', linewidth=2, label='Nonlocal', color='red')\n",
    "ax2.loglog(omega, G_double_prime_local, '--', linewidth=2, label='Local', color='green')\n",
    "ax2.set_xlabel('ω (rad/s)', fontsize=12)\n",
    "ax2.set_ylabel('G\" (Pa)', fontsize=12)\n",
    "ax2.set_title('Loss Modulus - Model Comparison', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"../outputs/fluidity/saramito_nonlocal/saos\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save NLSQ results\n",
    "nlsq_file = output_dir / \"nlsq_results.npz\"\n",
    "np.savez(\n",
    "    nlsq_file,\n",
    "    omega=np.array(omega),\n",
    "    G_star_exp=np.array(G_star_exp),\n",
    "    G_star_fit=np.array(G_star_fit),\n",
    "    parameters={p.name: p.value for p in model.parameters},\n",
    "    r_squared=metrics[\"R2\"],\n",
    "    rmse=metrics[\"RMSE\"]\n",
    ")\n",
    "print(f\"Saved NLSQ results to {nlsq_file}\")\n",
    "\n",
    "# Save Bayesian results\n",
    "bayes_file = output_dir / \"bayesian_results.npz\"\n",
    "np.savez(\n",
    "    bayes_file,\n",
    "    omega=np.array(omega),\n",
    "    G_prime_median=np.array(G_prime_median),\n",
    "    G_prime_lower=np.array(G_prime_lower),\n",
    "    G_prime_upper=np.array(G_prime_upper),\n",
    "    G_double_prime_median=np.array(G_double_prime_median),\n",
    "    G_double_prime_lower=np.array(G_double_prime_lower),\n",
    "    G_double_prime_upper=np.array(G_double_prime_upper),\n",
    "    posterior_samples=bayes_result.posterior_samples,\n",
    "    credible_intervals=intervals\n",
    ")\n",
    "print(f\"Saved Bayesian results to {bayes_file}\")\n",
    "\n",
    "# Save ArviZ InferenceData if available\n",
    "if idata is not None:\n",
    "    arviz_file = output_dir / \"inference_data.nc\"\n",
    "    idata.to_netcdf(arviz_file)\n",
    "    print(f\"Saved ArviZ InferenceData to {arviz_file}\")\n",
    "\n",
    "# Save comparison with local model\n",
    "comparison_file = output_dir / \"local_comparison.npz\"\n",
    "np.savez(\n",
    "    comparison_file,\n",
    "    omega=np.array(omega),\n",
    "    G_star_nonlocal=np.array(G_star_fit),\n",
    "    G_star_local=np.array(G_star_local),\n",
    "    r_squared_nonlocal=metrics[\"R2\"],\n",
    "    r_squared_local=result_local.r_squared,\n",
    "    parameters_nonlocal={p.name: p.value for p in model.parameters},\n",
    "    parameters_local={p.name: p.value for p in model_local.parameters}\n",
    ")\n",
    "print(f\"Saved local comparison to {comparison_file}\")\n",
    "\n",
    "print(f\"\\nAll results saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Model Capabilities\n",
    "1. **Linear Viscoelasticity**: FluiditySaramitoNonlocal captures frequency-dependent storage (G') and loss (G'') moduli\n",
    "2. **Spatial Effects**: Fluidity diffusion (D_f) introduces spatial homogenization that can affect:\n",
    "   - Effective relaxation timescale\n",
    "   - High-frequency modulus plateau\n",
    "   - Transition between elastic and viscous regimes\n",
    "3. **Comparison with Local**: Nonlocal model provides better fit when spatial heterogeneity is significant\n",
    "\n",
    "### Workflow Summary\n",
    "1. **Data**: SAOS measurements of G'(ω) and G''(ω) across frequency range\n",
    "2. **NLSQ**: Fast parameter estimation with R² > 0.99 typical\n",
    "3. **Bayesian**: Quantified uncertainty with credible intervals\n",
    "4. **Diagnostics**: R-hat < 1.01, ESS > 400 confirms convergence\n",
    "5. **Validation**: Compare with local model to assess spatial effects\n",
    "\n",
    "### Physical Insights\n",
    "- **G'(ω)**: Dominates at high ω (elastic solid-like)\n",
    "- **G''(ω)**: Dominates at low ω (viscous liquid-like)\n",
    "- **Crossover frequency**: Where G' = G'' indicates characteristic relaxation timescale\n",
    "- **Spatial diffusion**: D_f > 0 smooths fluidity gradients, affecting moduli transitions\n",
    "\n",
    "### Next Steps\n",
    "- Explore nonlinear regime with LAOS (large amplitude oscillatory shear)\n",
    "- Investigate startup and creep protocols for transient dynamics\n",
    "- Compare with flow curve measurements for yield stress validation\n",
    "- Study spatial fluidity profiles and shear banding phenomena"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}