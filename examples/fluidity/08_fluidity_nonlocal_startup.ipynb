{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FluidityNonlocal: Startup Shear with Fluidity Profile Evolution\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. **Fluidity Profile Evolution**: Track spatial distribution f(y,t) across gap during startup\n",
    "2. **Shear Banding Onset**: Detect localization and band formation from fluidity gradients\n",
    "3. **1D Couette Flow**: Understand wall boundary conditions and gap-averaged stress\n",
    "4. **Nonlocal Effects**: Quantify diffusion D_f influence on band width and stability\n",
    "5. **NLSQ + Bayesian Pipeline**: Fit startup curves with spatially-resolved fluidity diagnostics\n",
    "\n",
    "**Physical Context**: Startup shear reveals transient localization dynamics that precede steady-state banding. The fluidity profile f(y,t) evolves from homogeneous (high fluidity) to localized (low fluidity in arrested regions), controlled by competition between destructuring (shear) and aging (thixotropy).\n",
    "\n",
    "**Model**: FluidityNonlocal with diffusion term D_f∇²f prevents singular band interfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T21:16:58.737892Z",
     "iopub.status.busy": "2026-02-08T21:16:58.737716Z",
     "iopub.status.idle": "2026-02-08T21:17:00.053743Z",
     "shell.execute_reply": "2026-02-08T21:17:00.052835Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Colab detection and installation\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    !pip install -q rheojax nlsq numpyro arviz\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# JAX with float64 (CRITICAL for numerical stability)\n",
    "from rheojax.core.jax_config import safe_import_jax\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "from rheojax.models.fluidity import FluidityNonlocal\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.logging import configure_logging, get_logger\n",
    "\n",
    "# Configure logging\n",
    "configure_logging(level=\"INFO\")\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Output directory\n",
    "output_dir = Path(\"../outputs/fluidity/nonlocal/startup\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"Float64 enabled: {jax.config.jax_enable_x64}\")\n",
    "# Flag for conditional Bayesian sections\n",
    "bayesian_completed = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: 1D Couette Flow with Fluidity Diffusion\n",
    "\n",
    "### Governing Equations\n",
    "\n",
    "**Stress evolution** (Maxwell backbone):\n",
    "$$\n",
    "\\frac{\\partial \\sigma}{\\partial t} = G \\dot{\\gamma}(y,t) - f(y,t) \\sigma(y,t)\n",
    "$$\n",
    "\n",
    "**Fluidity evolution** (aging-rejuvenation with diffusion):\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial t} = \\frac{1}{\\tau_{\\text{age}}} - \\alpha f + D_f \\nabla^2 f\n",
    "$$\n",
    "- $\\alpha = a |\\dot{\\gamma}|^c / \\tau_{\\text{age}}$: Shear-induced destructuring\n",
    "- $D_f$: Fluidity diffusion coefficient (nonlocal coupling)\n",
    "\n",
    "**Mechanical equilibrium** (1D Couette):\n",
    "$$\n",
    "\\frac{\\partial \\sigma}{\\partial y} = 0 \\quad \\Rightarrow \\quad \\sigma(y,t) = \\sigma(t) \\quad \\text{(uniform stress)}\n",
    "$$\n",
    "\n",
    "**Boundary conditions** (gap width h, top plate velocity V):\n",
    "$$\n",
    "\\dot{\\gamma}(0,t) = 0, \\quad \\int_0^h \\dot{\\gamma}(y,t) \\, dy = V \\quad \\Rightarrow \\quad \\langle \\dot{\\gamma} \\rangle = V/h\n",
    "$$\n",
    "\n",
    "**Startup protocol**:\n",
    "- Initial condition: $f(y,0) = f_0$ (homogeneous, equilibrated)\n",
    "- Applied shear rate: $\\dot{\\gamma}_{\\text{avg}} = V/h$ (constant)\n",
    "- Observe: $\\sigma(t)$ (gap-averaged stress), $f(y,t)$ (spatial profile)\n",
    "\n",
    "### Shear Banding Criterion\n",
    "\n",
    "**Fluidity gradient threshold**:\n",
    "$$\n",
    "\\xi = \\frac{\\max_y f(y) - \\min_y f(y)}{\\langle f(y) \\rangle} > \\xi_{\\text{thresh}} \\quad \\text{(e.g., 0.3)}\n",
    "$$\n",
    "\n",
    "**Band width** (characteristic length from diffusion):\n",
    "$$\n",
    "\\delta \\sim \\sqrt{D_f \\tau_{\\text{age}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Calibrated Parameters or Use Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T21:17:00.072464Z",
     "iopub.status.busy": "2026-02-08T21:17:00.072269Z",
     "iopub.status.idle": "2026-02-08T21:17:00.079796Z",
     "shell.execute_reply": "2026-02-08T21:17:00.078952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Try to load calibrated parameters from flow_curve fitting\n",
    "param_file = output_dir.parent / \"flow_curve\" / \"fluidity_nonlocal_params.npz\"\n",
    "\n",
    "# Default parameters for demonstration\n",
    "default_params = {\n",
    "    'G': 1000.0,          # Elastic modulus (Pa)\n",
    "    'tau_eq': 10.0,       # Aging timescale (s)\n",
    "    'a': 1.0,             # Destructuring coefficient\n",
    "    'c': 1.0,             # Shear rate exponent\n",
    "    'f_eq': 0.1,          # Equilibrium fluidity (1/s)\n",
    "    'D_f': 1e-6,          # Fluidity diffusion (m²/s)\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = FluidityNonlocal(\n",
    "    N_y=51,  # Spatial resolution\n",
    "    gap_width=1e-3  # 1 mm gap\n",
    ")\n",
    "\n",
    "if param_file.exists():\n",
    "    logger.info(f\"Loading calibrated parameters from {param_file}\")\n",
    "    loaded_params = np.load(param_file)\n",
    "    \n",
    "    # Set parameters from file\n",
    "    for key in default_params.keys():\n",
    "        if key in loaded_params:\n",
    "            model.parameters.set_value(key, float(loaded_params[key]))\n",
    "            logger.info(f\"  {key} = {loaded_params[key]:.6e}\")\n",
    "        else:\n",
    "            model.parameters.set_value(key, default_params[key])\n",
    "            logger.info(f\"  {key} = {default_params[key]:.6e} (default)\")\n",
    "else:\n",
    "    logger.warning(\"No calibrated parameters found, using defaults\")\n",
    "    \n",
    "    # Set physically reasonable defaults\n",
    "    for key, value in default_params.items():\n",
    "        try:\n",
    "            model.parameters.set_value(key, value)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not set {key}: {e}\")\n",
    "    \n",
    "    logger.info(\"Using default parameters\")\n",
    "\n",
    "print(f\"\\nModel configuration:\")\n",
    "print(f\"  Spatial points: {model.N_y}\")\n",
    "print(f\"  Gap width: {model.gap_width*1e3:.2f} mm\")\n",
    "print(f\"  Grid spacing: {model.gap_width/(model.N_y-1)*1e6:.2f} μm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Startup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T21:17:00.081435Z",
     "iopub.status.busy": "2026-02-08T21:17:00.081335Z",
     "iopub.status.idle": "2026-02-08T21:17:01.270670Z",
     "shell.execute_reply": "2026-02-08T21:17:01.270053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Startup protocol parameters\n",
    "gamma_dot = 1.0  # Applied shear rate (1/s)\n",
    "t_end = 100.0    # Total time (s) - capture transient and steady state\n",
    "n_points = 200   # Temporal resolution\n",
    "\n",
    "# Generate time array (logarithmic spacing to capture early transient)\n",
    "t_early = np.logspace(-2, 0, 50)  # 0.01 to 1 s\n",
    "t_late = np.linspace(1.0, t_end, 150)  # 1 to 100 s\n",
    "t = np.unique(np.concatenate([t_early, t_late]))\n",
    "\n",
    "logger.info(f\"Simulating startup shear at γ̇ = {gamma_dot} 1/s for {t_end} s\")\n",
    "\n",
    "# Simulate startup (this populates model._f_field_trajectory)\n",
    "sigma_true = model.predict(t, test_mode='startup', gamma_dot=gamma_dot)\n",
    "\n",
    "# Add realistic noise (5% relative error)\n",
    "noise_level = 0.05\n",
    "np.random.seed(42)\n",
    "sigma_noisy = sigma_true + noise_level * np.abs(sigma_true) * np.random.randn(len(sigma_true))\n",
    "\n",
    "# Create RheoData object\n",
    "data = RheoData(\n",
    "    x=t,\n",
    "    y=sigma_noisy,\n",
    "    initial_test_mode='startup',\n",
    "    metadata={'gamma_dot': gamma_dot, 'noise_level': noise_level}\n",
    ")\n",
    "\n",
    "logger.info(f\"Generated {len(t)} data points with {noise_level*100}% noise\")\n",
    "logger.info(f\"Stress range: {sigma_noisy.min():.2f} to {sigma_noisy.max():.2f} Pa\")\n",
    "\n",
    "# Plot synthetic data\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Linear time\n",
    "ax1.plot(t, sigma_true, 'k-', label='True', linewidth=2)\n",
    "ax1.plot(t, sigma_noisy, 'o', markersize=3, alpha=0.5, label='Noisy')\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_ylabel('Stress (Pa)')\n",
    "ax1.set_title('Startup Shear: Linear Time')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Log time (emphasize transient)\n",
    "ax2.plot(t, sigma_true, 'k-', label='True', linewidth=2)\n",
    "ax2.plot(t, sigma_noisy, 'o', markersize=3, alpha=0.5, label='Noisy')\n",
    "ax2.set_xlabel('Time (s)')\n",
    "ax2.set_ylabel('Stress (Pa)')\n",
    "ax2.set_title('Startup Shear: Log Time')\n",
    "ax2.set_xscale('log')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'synthetic_data.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close('all')\n",
    "\n",
    "print(f\"\\nData characteristics:\")\n",
    "print(f\"  Peak stress: {sigma_noisy.max():.2f} Pa at t = {t[np.argmax(sigma_noisy)]:.2f} s\")\n",
    "print(f\"  Steady-state stress: {sigma_noisy[-10:].mean():.2f} Pa\")\n",
    "steady_mean = sigma_noisy[-10:].mean()\n",
    "print(f\"  Overshoot ratio: {sigma_noisy.max() / steady_mean:.2f}\" if steady_mean > 0 else \"  Overshoot ratio: N/A\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLSQ Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T21:17:01.271998Z",
     "iopub.status.busy": "2026-02-08T21:17:01.271886Z",
     "iopub.status.idle": "2026-02-08T21:24:15.581834Z",
     "shell.execute_reply": "2026-02-08T21:24:15.581084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize fresh model for fitting\n",
    "model_fit = FluidityNonlocal(N_y=51, gap_width=1e-3)\n",
    "\n",
    "# Set reasonable initial values (starting points for optimization)\n",
    "initial_params = {\n",
    "    'G': 500.0,\n",
    "    'tau_eq': 5.0,\n",
    "    'a': 0.5,\n",
    "    'c': 1.0,\n",
    "    'f_eq': 0.05,\n",
    "    'D_f': 1e-7\n",
    "}\n",
    "\n",
    "for key, value in initial_params.items():\n",
    "    try:\n",
    "        model_fit.parameters.set_value(key, value)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "logger.info(\"Starting NLSQ fitting...\")\n",
    "\n",
    "# Fit with test_mode='startup' and gamma_dot\n",
    "result = model_fit.fit(\n",
    "    data.x,\n",
    "    data.y,\n",
    "    test_mode='startup',\n",
    "    gamma_dot=gamma_dot,\n",
    "    method='scipy'\n",
    ")\n",
    "\n",
    "# Generate predictions\n",
    "sigma_pred = model_fit.predict(t, test_mode='startup', gamma_dot=gamma_dot)\n",
    "\n",
    "# Compute fit quality\n",
    "from rheojax.utils.metrics import compute_fit_quality\n",
    "metrics = compute_fit_quality(sigma_noisy, sigma_pred)\n",
    "\n",
    "logger.info(f\"NLSQ completed: R² = {metrics['R2']:.6f}\")\n",
    "logger.info(f\"Fitted parameters:\")\n",
    "param_names = ['G', 'tau_eq', 'a', 'c', 'f_eq', 'D_f']\n",
    "for name in param_names:\n",
    "    try:\n",
    "        value = model_fit.parameters.get_value(name)\n",
    "        logger.info(f\"  {name} = {value:.6e}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Plot fit\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(t, sigma_noisy, 'o', markersize=4, alpha=0.5, label='Data')\n",
    "ax.plot(t, sigma_pred, 'r-', linewidth=2, label=f'NLSQ Fit (R² = {metrics[\"R2\"]:.4f})')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Stress (Pa)')\n",
    "ax.set_title(f'NLSQ Fit: Startup Shear at γ̇ = {gamma_dot} 1/s')\n",
    "ax.set_xscale('log')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, which='both')\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'nlsq_fit.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close('all')\n",
    "\n",
    "# Residual analysis\n",
    "residuals = sigma_noisy - sigma_pred\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(t, residuals, 'o', markersize=3)\n",
    "ax1.axhline(0, color='k', linestyle='--', alpha=0.3)\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_ylabel('Residuals (Pa)')\n",
    "ax1.set_title('Residuals vs Time')\n",
    "ax1.set_xscale('log')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.hist(residuals, bins=30, edgecolor='k', alpha=0.7)\n",
    "ax2.set_xlabel('Residuals (Pa)')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title(f'Residual Distribution (σ = {residuals.std():.2f} Pa)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'nlsq_residuals.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference with NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T21:24:15.583773Z",
     "iopub.status.busy": "2026-02-08T21:24:15.583657Z",
     "iopub.status.idle": "2026-02-08T21:24:15.588898Z",
     "shell.execute_reply": "2026-02-08T21:24:15.588356Z"
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"Starting Bayesian inference (NUTS)...\")\n",
    "\n",
    "# Run NUTS (warm-started from NLSQ)\n",
    "\n",
    "# FAST_MODE for CI: set FAST_MODE=1 env var for quick iteration\n",
    "FAST_MODE = os.environ.get('FAST_MODE', '0') == '1'\n",
    "_num_warmup = 50 if FAST_MODE else 200\n",
    "_num_samples = 100 if FAST_MODE else 500\n",
    "_num_chains = 1\n",
    "\n",
    "if FAST_MODE:\n",
    "    print('FAST_MODE: Skipping Bayesian inference (nonlocal ODE+NUTS too memory-intensive)')\n",
    "    bayesian_completed = False\n",
    "else:\n",
    "    bayesian_result = model_fit.fit_bayesian(\n",
    "        data.x,\n",
    "        data.y,\n",
    "        test_mode='startup',\n",
    "        gamma_dot=gamma_dot,\n",
    "        num_warmup=_num_warmup,\n",
    "        num_samples=_num_samples,\n",
    "        num_chains=1,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    logger.info(\"Bayesian inference completed\")\n",
    "\n",
    "    # Extract posterior samples\n",
    "    posterior = bayesian_result.posterior_samples\n",
    "\n",
    "    # Compute credible intervals\n",
    "    intervals = model_fit.get_credible_intervals(posterior, credibility=0.95)\n",
    "\n",
    "    print(\"\\n95% Credible Intervals:\")\n",
    "    for param_name, (lower, upper) in intervals.items():\n",
    "        mean = float(posterior[param_name].mean())\n",
    "        print(f\"  {param_name}: {mean:.6e} [{lower:.6e}, {upper:.6e}]\")\n",
    "\n",
    "    # Diagnostics\n",
    "    try:\n",
    "        import arviz as az\n",
    "\n",
    "        # Convert to ArviZ InferenceData\n",
    "        idata = az.from_dict(posterior={k: np.array(v)[None, :] for k, v in posterior.items()})\n",
    "\n",
    "        # R-hat (should be < 1.01)\n",
    "        rhat = az.rhat(idata)\n",
    "        print(\"\\nR-hat (convergence diagnostic, target < 1.01):\")\n",
    "        for var in rhat.data_vars:\n",
    "            print(f\"  {var}: {float(rhat[var]):.4f}\")\n",
    "\n",
    "        # ESS (should be > 400 for num_samples=2000)\n",
    "        ess = az.ess(idata)\n",
    "        print(\"\\nEffective Sample Size (target > 400):\")\n",
    "        for var in ess.data_vars:\n",
    "            print(f\"  {var}: {float(ess[var]):.0f}\")\n",
    "\n",
    "        # Plot posterior distributions\n",
    "        az.plot_trace(idata, compact=True, figsize=(12, 10))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / 'posterior_trace.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close('all')\n",
    "\n",
    "        # Plot pair plot\n",
    "        az.plot_pair(idata, kind='kde', figsize=(10, 10))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / 'posterior_pair.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close('all')\n",
    "\n",
    "    except ImportError:\n",
    "        logger.warning(\"ArviZ not available, skipping diagnostics\")\n",
    "\n",
    "    bayesian_completed = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluidity Profile Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T21:24:15.590262Z",
     "iopub.status.busy": "2026-02-08T21:24:15.590151Z",
     "iopub.status.idle": "2026-02-08T21:24:15.596454Z",
     "shell.execute_reply": "2026-02-08T21:24:15.595733Z"
    }
   },
   "outputs": [],
   "source": [
    "if (hasattr(model_fit, '_f_field_trajectory') and model_fit._f_field_trajectory is not None\n",
    "        and hasattr(model_fit, '_y_coords') and model_fit._y_coords is not None):\n",
    "    # Access fluidity field trajectory (populated during last predict() call)\n",
    "    f_trajectory = model_fit._f_field_trajectory  # Shape: (n_times, n_points)\n",
    "    y_coords = model_fit._y_coords  # Spatial coordinates (m)\n",
    "\n",
    "    logger.info(f\"Fluidity trajectory shape: {f_trajectory.shape}\")\n",
    "    logger.info(f\"Spatial coordinates: {len(y_coords)} points from 0 to {model_fit.gap_width*1e3:.2f} mm\")\n",
    "\n",
    "    # Select snapshots at different times (early, peak stress, steady state)\n",
    "    t_snapshots = [0.1, 1.0, 10.0, t_end]\n",
    "    snapshot_indices = [np.argmin(np.abs(t - t_snap)) for t_snap in t_snapshots]\n",
    "\n",
    "    # Plot fluidity profiles\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(t_snapshots)))\n",
    "    for i, (idx, t_snap, color) in enumerate(zip(snapshot_indices, t_snapshots, colors)):\n",
    "        f_profile = f_trajectory[idx, :]\n",
    "        ax.plot(y_coords * 1e3, f_profile, '-o', color=color, label=f't = {t_snap:.1f} s', markersize=4)\n",
    "\n",
    "    ax.set_xlabel('Position across gap (mm)')\n",
    "    ax.set_ylabel('Fluidity f (1/s)')\n",
    "    ax.set_title('Fluidity Profile Evolution During Startup')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'fluidity_profiles.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close('all')\n",
    "\n",
    "    # Spatiotemporal heatmap\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Use only subset of times for visualization\n",
    "    t_plot_indices = np.linspace(0, len(t)-1, 100, dtype=int)\n",
    "    t_plot = t[t_plot_indices]\n",
    "    f_plot = f_trajectory[t_plot_indices, :]\n",
    "\n",
    "    im = ax.pcolormesh(y_coords * 1e3, t_plot, f_plot, shading='auto', cmap='plasma')\n",
    "    ax.set_xlabel('Position across gap (mm)')\n",
    "    ax.set_ylabel('Time (s)')\n",
    "    ax.set_title('Fluidity Field f(y,t) Spatiotemporal Evolution')\n",
    "    ax.set_yscale('log')\n",
    "    cbar = plt.colorbar(im, ax=ax, label='Fluidity (1/s)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'fluidity_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close('all')\n",
    "\n",
    "    print(\"\\nFluidity profile statistics:\")\n",
    "    print(f\"  Initial (t=0): f_min = {f_trajectory[0].min():.4f}, f_max = {f_trajectory[0].max():.4f}\")\n",
    "    print(f\"  Final (t={t_end}): f_min = {f_trajectory[-1].min():.4f}, f_max = {f_trajectory[-1].max():.4f}\")\n",
    "    print(f\"  Spatial variation: {(f_trajectory[-1].max() - f_trajectory[-1].min()) / f_trajectory[-1].mean():.2%}\")\n",
    "else:\n",
    "    print('Fluidity trajectory not available (skipped during FAST_MODE)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shear Banding Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T21:24:15.598245Z",
     "iopub.status.busy": "2026-02-08T21:24:15.598135Z",
     "iopub.status.idle": "2026-02-08T21:24:15.604018Z",
     "shell.execute_reply": "2026-02-08T21:24:15.603642Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'f_trajectory' in dir():\n",
    "    def detect_shear_banding(f_profile, threshold=0.3):\n",
    "        \"\"\"\n",
    "        Detect shear banding from fluidity profile.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        f_profile : array\n",
    "            Fluidity profile f(y) across gap\n",
    "        threshold : float\n",
    "            Normalized gradient threshold for banding detection\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Banding diagnostics: is_banded, localization_index, band_ratio\n",
    "        \"\"\"\n",
    "        f_mean = np.mean(f_profile)\n",
    "        f_min = np.min(f_profile)\n",
    "        f_max = np.max(f_profile)\n",
    "\n",
    "        # Localization index (normalized variation)\n",
    "        localization_index = (f_max - f_min) / f_mean if f_mean > 0 else 0.0\n",
    "\n",
    "        # Band ratio (high fluidity / low fluidity)\n",
    "        band_ratio = f_max / f_min if f_min > 0 else np.inf\n",
    "\n",
    "        # Banding detected if localization exceeds threshold\n",
    "        is_banded = localization_index > threshold\n",
    "\n",
    "        return {\n",
    "            'is_banded': is_banded,\n",
    "            'localization_index': localization_index,\n",
    "            'band_ratio': band_ratio,\n",
    "            'f_mean': f_mean,\n",
    "            'f_min': f_min,\n",
    "            'f_max': f_max\n",
    "        }\n",
    "\n",
    "    # Analyze banding evolution\n",
    "    banding_evolution = []\n",
    "    for i, t_val in enumerate(t):\n",
    "        diagnostics = detect_shear_banding(f_trajectory[i, :], threshold=0.3)\n",
    "        diagnostics['time'] = t_val\n",
    "        banding_evolution.append(diagnostics)\n",
    "\n",
    "    # Convert to arrays for plotting\n",
    "    times = np.array([d['time'] for d in banding_evolution])\n",
    "    localization = np.array([d['localization_index'] for d in banding_evolution])\n",
    "    is_banded = np.array([d['is_banded'] for d in banding_evolution])\n",
    "\n",
    "    # Find banding onset time\n",
    "    banding_onset_idx = np.argmax(is_banded)\n",
    "    banding_onset_time = times[banding_onset_idx] if is_banded.any() else None\n",
    "\n",
    "    # Plot localization index evolution\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "    # Localization index\n",
    "    ax1.plot(times, localization, 'b-', linewidth=2)\n",
    "    ax1.axhline(0.3, color='r', linestyle='--', label='Banding threshold')\n",
    "    if banding_onset_time is not None:\n",
    "        ax1.axvline(banding_onset_time, color='g', linestyle=':', label=f'Onset at t={banding_onset_time:.2f} s')\n",
    "    ax1.fill_between(times, 0, localization, where=is_banded, alpha=0.3, color='orange', label='Banded region')\n",
    "    ax1.set_ylabel('Localization Index ξ')\n",
    "    ax1.set_title('Shear Banding Detection')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xscale('log')\n",
    "\n",
    "    # Stress correlation\n",
    "    ax2.plot(times, sigma_pred, 'k-', linewidth=2)\n",
    "    if banding_onset_time is not None:\n",
    "        ax2.axvline(banding_onset_time, color='g', linestyle=':', label=f'Banding onset')\n",
    "    ax2.set_xlabel('Time (s)')\n",
    "    ax2.set_ylabel('Stress (Pa)')\n",
    "    ax2.set_title('Stress Evolution (with banding onset marker)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xscale('log')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'shear_banding_detection.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close('all')\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\nShear Banding Analysis:\")\n",
    "    if banding_onset_time is not None:\n",
    "        print(f\"  Banding detected: YES\")\n",
    "        print(f\"  Onset time: {banding_onset_time:.2f} s\")\n",
    "        print(f\"  Final localization index: {localization[-1]:.3f}\")\n",
    "        print(f\"  Final band ratio (f_max/f_min): {banding_evolution[-1]['band_ratio']:.2f}\")\n",
    "    else:\n",
    "        print(f\"  Banding detected: NO\")\n",
    "        print(f\"  Maximum localization index: {localization.max():.3f}\")\n",
    "\n",
    "    # Estimate band width from diffusion length\n",
    "    D_f = model_fit.parameters.get_value('D_f')\n",
    "    tau_eq = model_fit.parameters.get_value('tau_eq')\n",
    "    band_width = np.sqrt(D_f * tau_eq)\n",
    "    print(f\"\\nEstimated band width (δ ~ √(D_f*τ_eq)): {band_width*1e6:.2f} μm\")\n",
    "    print(f\"  Relative to gap: {band_width/model_fit.gap_width:.2%}\")\n",
    "else:\n",
    "    print('Skipping shear banding analysis (fluidity trajectory not available)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T21:24:15.605650Z",
     "iopub.status.busy": "2026-02-08T21:24:15.605544Z",
     "iopub.status.idle": "2026-02-08T21:24:15.608766Z",
     "shell.execute_reply": "2026-02-08T21:24:15.608084Z"
    }
   },
   "outputs": [],
   "source": [
    "if bayesian_completed:\n",
    "    # Save fitted parameters\n",
    "    param_names = ['G', 'tau_eq', 'a', 'c', 'f_eq', 'D_f']\n",
    "    param_dict = {}\n",
    "    for name in param_names:\n",
    "        try:\n",
    "            param_dict[name] = model_fit.parameters.get_value(name)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    np.savez(\n",
    "        output_dir / 'startup_params.npz',\n",
    "        **param_dict,\n",
    "        gamma_dot=gamma_dot,\n",
    "        r_squared=metrics['R2']\n",
    "    )\n",
    "\n",
    "    # Save fluidity trajectory\n",
    "    np.savez(\n",
    "        output_dir / 'fluidity_trajectory.npz',\n",
    "        t=t,\n",
    "        y=y_coords,\n",
    "        f_trajectory=np.array(f_trajectory),\n",
    "        sigma=sigma_pred\n",
    "    )\n",
    "\n",
    "    # Save banding diagnostics\n",
    "    np.savez(\n",
    "        output_dir / 'banding_diagnostics.npz',\n",
    "        times=times,\n",
    "        localization_index=localization,\n",
    "        is_banded=is_banded,\n",
    "        onset_time=banding_onset_time if banding_onset_time else -1.0\n",
    "    )\n",
    "\n",
    "    # Save posterior samples\n",
    "    if bayesian_result is not None:\n",
    "        np.savez(\n",
    "            output_dir / 'posterior_samples.npz',\n",
    "            **posterior\n",
    "        )\n",
    "\n",
    "    logger.info(f\"Results saved to {output_dir}\")\n",
    "    print(f\"\\nAll results saved to: {output_dir}\")\n",
    "else:\n",
    "    print('Skipping Bayesian diagnostics (inference was skipped)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Fluidity Profile Evolution\n",
    "\n",
    "1. **Initial Homogeneity**: At t=0, fluidity is spatially uniform (f(y,0) = f_eq)\n",
    "2. **Shear-Induced Localization**: Regions with higher shear rate experience faster destructuring (lower fluidity)\n",
    "3. **Diffusion Smoothing**: D_f prevents singular band interfaces, creating finite band width δ ~ √(D_f*τ_age)\n",
    "4. **Steady-State Banding**: At long times, fluidity profile stabilizes with distinct high/low regions\n",
    "\n",
    "### Shear Banding Onset\n",
    "\n",
    "**Criterion**: Localization index ξ = (f_max - f_min)/⟨f⟩ exceeds threshold (~0.3)\n",
    "\n",
    "**Onset Time**: Typically occurs after stress peak, during approach to steady state\n",
    "\n",
    "**Stress Signature**: Banding onset often correlates with stress plateau or slight decrease\n",
    "\n",
    "### Model Parameters from Startup\n",
    "\n",
    "- **G**: Elastic modulus controls initial stress rise (linear regime)\n",
    "- **τ_age**: Aging timescale sets time to stress peak\n",
    "- **a, c**: Destructuring controls peak magnitude and overshoot ratio\n",
    "- **D_f**: Diffusion coefficient determines band width and stability\n",
    "- **f_eq**: Equilibrium fluidity sets steady-state stress level\n",
    "\n",
    "### NLSQ + Bayesian Workflow\n",
    "\n",
    "1. **NLSQ**: Fast point estimation with gap-averaged stress σ(t)\n",
    "2. **NUTS**: Bayesian uncertainty quantification (R-hat < 1.01, ESS > 400)\n",
    "3. **Fluidity Access**: Use `model._f_field_trajectory` for spatially-resolved diagnostics\n",
    "4. **Validation**: Check banding predictions against known SGR/ITT-MCT regimes\n",
    "\n",
    "### Experimental Connections\n",
    "\n",
    "- **Rheo-PIV**: Compare predicted f(y,t) gradients with velocity profiles\n",
    "- **Rheo-NMR**: Validate spatial localization with MRI measurements\n",
    "- **Ultrasonic Velocimetry**: Time-resolved band position from Doppler shifts\n",
    "- **Stress Overshoot**: Magnitude indicates strength of thixotropic memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
