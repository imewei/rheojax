{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FluidityNonlocal: Startup Shear with Fluidity Profile Evolution\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. **Fluidity Profile Evolution**: Track spatial distribution f(y,t) across gap during startup\n",
    "2. **Shear Banding Onset**: Detect localization and band formation from fluidity gradients\n",
    "3. **1D Couette Flow**: Understand wall boundary conditions and gap-averaged stress\n",
    "4. **Nonlocal Effects**: Quantify diffusion D_f influence on band width and stability\n",
    "5. **NLSQ + Bayesian Pipeline**: Fit startup curves with spatially-resolved fluidity diagnostics\n",
    "\n",
    "**Physical Context**: Startup shear reveals transient localization dynamics that precede steady-state banding. The fluidity profile f(y,t) evolves from homogeneous (high fluidity) to localized (low fluidity in arrested regions), controlled by competition between destructuring (shear) and aging (thixotropy).\n",
    "\n",
    "**Model**: FluidityNonlocal with diffusion term D_f\u2207\u00b2f prevents singular band interfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab detection and installation\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    !pip install -q rheojax nlsq numpyro arviz\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# JAX with float64 (CRITICAL for numerical stability)\n",
    "from rheojax.core.jax_config import safe_import_jax\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "from rheojax.models.fluidity import FluidityNonlocal\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.logging import configure_logging, get_logger\n",
    "\n",
    "# Configure logging\n",
    "configure_logging(level=\"INFO\")\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Output directory\n",
    "output_dir = Path(\"../outputs/fluidity/nonlocal/startup\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"Float64 enabled: {jax.config.jax_enable_x64}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: 1D Couette Flow with Fluidity Diffusion\n",
    "\n",
    "### Governing Equations\n",
    "\n",
    "**Stress evolution** (Maxwell backbone):\n",
    "$$\n",
    "\\frac{\\partial \\sigma}{\\partial t} = G \\dot{\\gamma}(y,t) - f(y,t) \\sigma(y,t)\n",
    "$$\n",
    "\n",
    "**Fluidity evolution** (aging-rejuvenation with diffusion):\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial t} = \\frac{1}{\\tau_{\\text{age}}} - \\alpha f + D_f \\nabla^2 f\n",
    "$$\n",
    "- $\\alpha = a |\\dot{\\gamma}|^c / \\tau_{\\text{age}}$: Shear-induced destructuring\n",
    "- $D_f$: Fluidity diffusion coefficient (nonlocal coupling)\n",
    "\n",
    "**Mechanical equilibrium** (1D Couette):\n",
    "$$\n",
    "\\frac{\\partial \\sigma}{\\partial y} = 0 \\quad \\Rightarrow \\quad \\sigma(y,t) = \\sigma(t) \\quad \\text{(uniform stress)}\n",
    "$$\n",
    "\n",
    "**Boundary conditions** (gap width h, top plate velocity V):\n",
    "$$\n",
    "\\dot{\\gamma}(0,t) = 0, \\quad \\int_0^h \\dot{\\gamma}(y,t) \\, dy = V \\quad \\Rightarrow \\quad \\langle \\dot{\\gamma} \\rangle = V/h\n",
    "$$\n",
    "\n",
    "**Startup protocol**:\n",
    "- Initial condition: $f(y,0) = f_0$ (homogeneous, equilibrated)\n",
    "- Applied shear rate: $\\dot{\\gamma}_{\\text{avg}} = V/h$ (constant)\n",
    "- Observe: $\\sigma(t)$ (gap-averaged stress), $f(y,t)$ (spatial profile)\n",
    "\n",
    "### Shear Banding Criterion\n",
    "\n",
    "**Fluidity gradient threshold**:\n",
    "$$\n",
    "\\xi = \\frac{\\max_y f(y) - \\min_y f(y)}{\\langle f(y) \\rangle} > \\xi_{\\text{thresh}} \\quad \\text{(e.g., 0.3)}\n",
    "$$\n",
    "\n",
    "**Band width** (characteristic length from diffusion):\n",
    "$$\n",
    "\\delta \\sim \\sqrt{D_f \\tau_{\\text{age}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Calibrated Parameters or Use Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load calibrated parameters from flow_curve fitting\n",
    "param_file = output_dir.parent / \"flow_curve\" / \"fluidity_nonlocal_params.npz\"\n",
    "\n",
    "if param_file.exists():\n",
    "    logger.info(f\"Loading calibrated parameters from {param_file}\")\n",
    "    params = np.load(param_file)\n",
    "    \n",
    "    # Initialize model with calibrated params\n",
    "    model = FluidityNonlocal(\n",
    "        n_points=51,  # Spatial resolution\n",
    "        gap_width=1e-3  # 1 mm gap\n",
    "    )\n",
    "    \n",
    "    # Set parameters\n",
    "    for key, value in params.items():\n",
    "        if hasattr(model.params, key):\n",
    "            setattr(model.params, key, float(value))\n",
    "    \n",
    "    logger.info(\"Loaded parameters:\")\n",
    "    for key, value in params.items():\n",
    "        logger.info(f\"  {key} = {value:.6e}\")\n",
    "else:\n",
    "    logger.warning(\"No calibrated parameters found, using defaults\")\n",
    "    \n",
    "    # Default parameters for demonstration\n",
    "    model = FluidityNonlocal(\n",
    "        n_points=51,\n",
    "        gap_width=1e-3\n",
    "    )\n",
    "    \n",
    "    # Set physically reasonable defaults\n",
    "    model.params.G = 1000.0          # Elastic modulus (Pa)\n",
    "    model.params.tau_age = 10.0      # Aging timescale (s)\n",
    "    model.params.a = 1.0             # Destructuring coefficient\n",
    "    model.params.c = 1.0             # Shear rate exponent\n",
    "    model.params.f_eq = 0.1          # Equilibrium fluidity (1/s)\n",
    "    model.params.D_f = 1e-6          # Fluidity diffusion (m\u00b2/s)\n",
    "    \n",
    "    logger.info(\"Using default parameters\")\n",
    "\n",
    "print(f\"\\nModel configuration:\")\n",
    "print(f\"  Spatial points: {model.n_points}\")\n",
    "print(f\"  Gap width: {model.gap_width*1e3:.2f} mm\")\n",
    "print(f\"  Grid spacing: {model.gap_width/(model.n_points-1)*1e6:.2f} \u03bcm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Startup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Startup protocol parameters\n",
    "gamma_dot = 1.0  # Applied shear rate (1/s)\n",
    "t_end = 100.0    # Total time (s) - capture transient and steady state\n",
    "n_points = 200   # Temporal resolution\n",
    "\n",
    "# Generate time array (logarithmic spacing to capture early transient)\n",
    "t_early = np.logspace(-2, 0, 50)  # 0.01 to 1 s\n",
    "t_late = np.linspace(1.0, t_end, 150)  # 1 to 100 s\n",
    "t = np.unique(np.concatenate([t_early, t_late]))\n",
    "\n",
    "logger.info(f\"Simulating startup shear at \u03b3\u0307 = {gamma_dot} 1/s for {t_end} s\")\n",
    "\n",
    "# Simulate startup (this populates model._f_field_trajectory)\n",
    "sigma_true = model.predict(t, test_mode='startup', gamma_dot=gamma_dot)\n",
    "\n",
    "# Add realistic noise (5% relative error)\n",
    "noise_level = 0.05\n",
    "np.random.seed(42)\n",
    "sigma_noisy = sigma_true + noise_level * np.abs(sigma_true) * np.random.randn(len(sigma_true))\n",
    "\n",
    "# Create RheoData object\n",
    "data = RheoData(\n",
    "    x=t,\n",
    "    y=sigma_noisy,\n",
    "    test_mode='startup',\n",
    "    metadata={'gamma_dot': gamma_dot, 'noise_level': noise_level}\n",
    ")\n",
    "\n",
    "logger.info(f\"Generated {len(t)} data points with {noise_level*100}% noise\")\n",
    "logger.info(f\"Stress range: {sigma_noisy.min():.2f} to {sigma_noisy.max():.2f} Pa\")\n",
    "\n",
    "# Plot synthetic data\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Linear time\n",
    "ax1.plot(t, sigma_true, 'k-', label='True', linewidth=2)\n",
    "ax1.plot(t, sigma_noisy, 'o', markersize=3, alpha=0.5, label='Noisy')\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_ylabel('Stress (Pa)')\n",
    "ax1.set_title('Startup Shear: Linear Time')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Log time (emphasize transient)\n",
    "ax2.plot(t, sigma_true, 'k-', label='True', linewidth=2)\n",
    "ax2.plot(t, sigma_noisy, 'o', markersize=3, alpha=0.5, label='Noisy')\n",
    "ax2.set_xlabel('Time (s)')\n",
    "ax2.set_ylabel('Stress (Pa)')\n",
    "ax2.set_title('Startup Shear: Log Time')\n",
    "ax2.set_xscale('log')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'synthetic_data.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nData characteristics:\")\n",
    "print(f\"  Peak stress: {sigma_noisy.max():.2f} Pa at t = {t[np.argmax(sigma_noisy)]:.2f} s\")\n",
    "print(f\"  Steady-state stress: {sigma_noisy[-10:].mean():.2f} Pa\")\n",
    "print(f\"  Overshoot ratio: {sigma_noisy.max() / sigma_noisy[-10:].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLSQ Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize fresh model for fitting\n",
    "model_fit = FluidityNonlocal(n_points=51, gap_width=1e-3)\n",
    "\n",
    "# Set reasonable parameter bounds (wider for fitting)\n",
    "model_fit.params.G.bounds = (100.0, 10000.0)\n",
    "model_fit.params.tau_age.bounds = (1.0, 100.0)\n",
    "model_fit.params.a.bounds = (0.1, 10.0)\n",
    "model_fit.params.c.bounds = (0.5, 2.0)\n",
    "model_fit.params.f_eq.bounds = (0.01, 1.0)\n",
    "model_fit.params.D_f.bounds = (1e-8, 1e-5)\n",
    "\n",
    "logger.info(\"Starting NLSQ fitting...\")\n",
    "\n",
    "# Fit with test_mode='startup' and gamma_dot\n",
    "result = model_fit.fit(\n",
    "    data.x,\n",
    "    data.y,\n",
    "    test_mode='startup',\n",
    "    gamma_dot=gamma_dot,\n",
    "    workflow='auto',  # Auto-select NLSQ workflow\n",
    "    compute_diagnostics=True\n",
    ", method='scipy')\n",
    "\n",
    "logger.info(f\"NLSQ completed: R\u00b2 = {metrics['R2']:.6f}\")\n",
    "logger.info(f\"Fitted parameters:\")\n",
    "for param in model_fit.params:\n",
    "    logger.info(f\"  {param.name} = {param.value:.6e}\")\n",
    "\n",
    "# Generate predictions\n",
    "sigma_pred = model_fit.predict(t, test_mode='startup', gamma_dot=gamma_dot)\n",
    "\n",
    "# Plot fit\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(t, sigma_noisy, 'o', markersize=4, alpha=0.5, label='Data')\n",
    "ax.plot(t, sigma_pred, 'r-', linewidth=2, label=f'NLSQ Fit (R\u00b2 = {metrics['R2']:.4f})')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Stress (Pa)')\n",
    "ax.set_title(f'NLSQ Fit: Startup Shear at \u03b3\u0307 = {gamma_dot} 1/s')\n",
    "ax.set_xscale('log')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, which='both')\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'nlsq_fit.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Residual analysis\n",
    "residuals = sigma_noisy - sigma_pred\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(t, residuals, 'o', markersize=3)\n",
    "ax1.axhline(0, color='k', linestyle='--', alpha=0.3)\n",
    "ax1.set_xlabel('Time (s)')\n",
    "ax1.set_ylabel('Residuals (Pa)')\n",
    "ax1.set_title('Residuals vs Time')\n",
    "ax1.set_xscale('log')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.hist(residuals, bins=30, edgecolor='k', alpha=0.7)\n",
    "ax2.set_xlabel('Residuals (Pa)')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title(f'Residual Distribution (\u03c3 = {residuals.std():.2f} Pa)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'nlsq_residuals.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference with NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Starting Bayesian inference (NUTS)...\")\n",
    "\n",
    "# Set priors (weakly informative, centered on NLSQ fit)\n",
    "for param in model_fit.params:\n",
    "    # Use NLSQ fit as prior mean, with 50% coefficient of variation\n",
    "    mean = param.value\n",
    "    std = 0.5 * mean  # 50% CV\n",
    "    param.prior = ('normal', {'loc': mean, 'scale': std})\n",
    "\n",
    "# Run NUTS (warm-started from NLSQ)\n",
    "bayesian_result = model_fit.fit_bayesian(\n",
    "    data.x,\n",
    "    data.y,\n",
    "    test_mode='startup',\n",
    "    gamma_dot=gamma_dot,\n",
    "    num_warmup=1000,\n",
    "    num_samples=2000,\n",
    "    num_chains=4,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "logger.info(\"Bayesian inference completed\")\n",
    "\n",
    "# Extract posterior samples\n",
    "posterior = bayesian_result.posterior_samples\n",
    "\n",
    "# Compute credible intervals\n",
    "intervals = model_fit.get_credible_intervals(posterior, credibility=0.95)\n",
    "\n",
    "print(\"\\n95% Credible Intervals:\")\n",
    "for param_name, (lower, upper) in intervals.items():\n",
    "    mean = posterior[param_name].mean()\n",
    "    print(f\"  {param_name}: {mean:.6e} [{lower:.6e}, {upper:.6e}]\")\n",
    "\n",
    "# Diagnostics\n",
    "try:\n",
    "    import arviz as az\n",
    "    \n",
    "    # Convert to ArviZ InferenceData\n",
    "    idata = az.from_dict(posterior)\n",
    "    \n",
    "    # R-hat (should be < 1.01)\n",
    "    rhat = az.rhat(idata)\n",
    "    print(\"\\nR-hat (convergence diagnostic, target < 1.01):\")\n",
    "    for var in rhat.data_vars:\n",
    "        print(f\"  {var}: {float(rhat[var]):.4f}\")\n",
    "    \n",
    "    # ESS (should be > 400 for num_samples=2000)\n",
    "    ess = az.ess(idata)\n",
    "    print(\"\\nEffective Sample Size (target > 400):\")\n",
    "    for var in ess.data_vars:\n",
    "        print(f\"  {var}: {float(ess[var]):.0f}\")\n",
    "    \n",
    "    # Plot posterior distributions\n",
    "    az.plot_trace(idata, compact=True, figsize=(12, 10))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'posterior_trace.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot pair plot\n",
    "    az.plot_pair(idata, kind='kde', divergences=True, figsize=(10, 10))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'posterior_pair.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    logger.warning(\"ArviZ not available, skipping diagnostics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluidity Profile Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access fluidity field trajectory (populated during last predict() call)\n",
    "f_trajectory = model_fit._f_field_trajectory  # Shape: (n_times, n_points)\n",
    "y_coords = model_fit._y_coords  # Spatial coordinates (m)\n",
    "\n",
    "logger.info(f\"Fluidity trajectory shape: {f_trajectory.shape}\")\n",
    "logger.info(f\"Spatial coordinates: {len(y_coords)} points from 0 to {model_fit.gap_width*1e3:.2f} mm\")\n",
    "\n",
    "# Select snapshots at different times (early, peak stress, steady state)\n",
    "t_snapshots = [0.1, 1.0, 10.0, t_end]\n",
    "snapshot_indices = [np.argmin(np.abs(t - t_snap)) for t_snap in t_snapshots]\n",
    "\n",
    "# Plot fluidity profiles\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(t_snapshots)))\n",
    "for i, (idx, t_snap, color) in enumerate(zip(snapshot_indices, t_snapshots, colors)):\n",
    "    f_profile = f_trajectory[idx, :]\n",
    "    ax.plot(y_coords * 1e3, f_profile, '-o', color=color, label=f't = {t_snap:.1f} s', markersize=4)\n",
    "\n",
    "ax.set_xlabel('Position across gap (mm)')\n",
    "ax.set_ylabel('Fluidity f (1/s)')\n",
    "ax.set_title('Fluidity Profile Evolution During Startup')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'fluidity_profiles.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Spatiotemporal heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Use only subset of times for visualization\n",
    "t_plot_indices = np.linspace(0, len(t)-1, 100, dtype=int)\n",
    "t_plot = t[t_plot_indices]\n",
    "f_plot = f_trajectory[t_plot_indices, :]\n",
    "\n",
    "im = ax.pcolormesh(y_coords * 1e3, t_plot, f_plot, shading='auto', cmap='plasma')\n",
    "ax.set_xlabel('Position across gap (mm)')\n",
    "ax.set_ylabel('Time (s)')\n",
    "ax.set_title('Fluidity Field f(y,t) Spatiotemporal Evolution')\n",
    "ax.set_yscale('log')\n",
    "cbar = plt.colorbar(im, ax=ax, label='Fluidity (1/s)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'fluidity_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFluidity profile statistics:\")\n",
    "print(f\"  Initial (t=0): f_min = {f_trajectory[0].min():.4f}, f_max = {f_trajectory[0].max():.4f}\")\n",
    "print(f\"  Final (t={t_end}): f_min = {f_trajectory[-1].min():.4f}, f_max = {f_trajectory[-1].max():.4f}\")\n",
    "print(f\"  Spatial variation: {(f_trajectory[-1].max() - f_trajectory[-1].min()) / f_trajectory[-1].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shear Banding Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_shear_banding(f_profile, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Detect shear banding from fluidity profile.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f_profile : array\n",
    "        Fluidity profile f(y) across gap\n",
    "    threshold : float\n",
    "        Normalized gradient threshold for banding detection\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Banding diagnostics: is_banded, localization_index, band_ratio\n",
    "    \"\"\"\n",
    "    f_mean = np.mean(f_profile)\n",
    "    f_min = np.min(f_profile)\n",
    "    f_max = np.max(f_profile)\n",
    "    \n",
    "    # Localization index (normalized variation)\n",
    "    localization_index = (f_max - f_min) / f_mean if f_mean > 0 else 0.0\n",
    "    \n",
    "    # Band ratio (high fluidity / low fluidity)\n",
    "    band_ratio = f_max / f_min if f_min > 0 else np.inf\n",
    "    \n",
    "    # Banding detected if localization exceeds threshold\n",
    "    is_banded = localization_index > threshold\n",
    "    \n",
    "    return {\n",
    "        'is_banded': is_banded,\n",
    "        'localization_index': localization_index,\n",
    "        'band_ratio': band_ratio,\n",
    "        'f_mean': f_mean,\n",
    "        'f_min': f_min,\n",
    "        'f_max': f_max\n",
    "    }\n",
    "\n",
    "# Analyze banding evolution\n",
    "banding_evolution = []\n",
    "for i, t_val in enumerate(t):\n",
    "    diagnostics = detect_shear_banding(f_trajectory[i, :], threshold=0.3)\n",
    "    diagnostics['time'] = t_val\n",
    "    banding_evolution.append(diagnostics)\n",
    "\n",
    "# Convert to arrays for plotting\n",
    "times = np.array([d['time'] for d in banding_evolution])\n",
    "localization = np.array([d['localization_index'] for d in banding_evolution])\n",
    "is_banded = np.array([d['is_banded'] for d in banding_evolution])\n",
    "\n",
    "# Find banding onset time\n",
    "banding_onset_idx = np.argmax(is_banded)\n",
    "banding_onset_time = times[banding_onset_idx] if is_banded.any() else None\n",
    "\n",
    "# Plot localization index evolution\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "# Localization index\n",
    "ax1.plot(times, localization, 'b-', linewidth=2)\n",
    "ax1.axhline(0.3, color='r', linestyle='--', label='Banding threshold')\n",
    "if banding_onset_time is not None:\n",
    "    ax1.axvline(banding_onset_time, color='g', linestyle=':', label=f'Onset at t={banding_onset_time:.2f} s')\n",
    "ax1.fill_between(times, 0, localization, where=is_banded, alpha=0.3, color='orange', label='Banded region')\n",
    "ax1.set_ylabel('Localization Index \u03be')\n",
    "ax1.set_title('Shear Banding Detection')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "# Stress correlation\n",
    "ax2.plot(times, sigma_pred, 'k-', linewidth=2)\n",
    "if banding_onset_time is not None:\n",
    "    ax2.axvline(banding_onset_time, color='g', linestyle=':', label=f'Banding onset')\n",
    "ax2.set_xlabel('Time (s)')\n",
    "ax2.set_ylabel('Stress (Pa)')\n",
    "ax2.set_title('Stress Evolution (with banding onset marker)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'shear_banding_detection.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "print(\"\\nShear Banding Analysis:\")\n",
    "if banding_onset_time is not None:\n",
    "    print(f\"  Banding detected: YES\")\n",
    "    print(f\"  Onset time: {banding_onset_time:.2f} s\")\n",
    "    print(f\"  Final localization index: {localization[-1]:.3f}\")\n",
    "    print(f\"  Final band ratio (f_max/f_min): {banding_evolution[-1]['band_ratio']:.2f}\")\n",
    "else:\n",
    "    print(f\"  Banding detected: NO\")\n",
    "    print(f\"  Maximum localization index: {localization.max():.3f}\")\n",
    "\n",
    "# Estimate band width from diffusion length\n",
    "D_f = model_fit.params.D_f.value\n",
    "tau_age = model_fit.params.tau_age.value\n",
    "band_width = np.sqrt(D_f * tau_age)\n",
    "print(f\"\\nEstimated band width (\u03b4 ~ \u221a(D_f*\u03c4_age)): {band_width*1e6:.2f} \u03bcm\")\n",
    "print(f\"  Relative to gap: {band_width/model_fit.gap_width:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fitted parameters\n",
    "param_dict = {param.name: param.value for param in model_fit.params}\n",
    "np.savez(\n",
    "    output_dir / 'startup_params.npz',\n",
    "    **param_dict,\n",
    "    gamma_dot=gamma_dot,\n",
    "    r_squared=metrics['R2']\n",
    ")\n",
    "\n",
    "# Save fluidity trajectory\n",
    "np.savez(\n",
    "    output_dir / 'fluidity_trajectory.npz',\n",
    "    t=t,\n",
    "    y=y_coords,\n",
    "    f_trajectory=np.array(f_trajectory),\n",
    "    sigma=sigma_pred\n",
    ")\n",
    "\n",
    "# Save banding diagnostics\n",
    "np.savez(\n",
    "    output_dir / 'banding_diagnostics.npz',\n",
    "    times=times,\n",
    "    localization_index=localization,\n",
    "    is_banded=is_banded,\n",
    "    onset_time=banding_onset_time if banding_onset_time else -1.0\n",
    ")\n",
    "\n",
    "# Save posterior samples\n",
    "if bayesian_result is not None:\n",
    "    np.savez(\n",
    "        output_dir / 'posterior_samples.npz',\n",
    "        **posterior\n",
    "    )\n",
    "\n",
    "logger.info(f\"Results saved to {output_dir}\")\n",
    "print(f\"\\nAll results saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Fluidity Profile Evolution\n",
    "\n",
    "1. **Initial Homogeneity**: At t=0, fluidity is spatially uniform (f(y,0) = f_eq)\n",
    "2. **Shear-Induced Localization**: Regions with higher shear rate experience faster destructuring (lower fluidity)\n",
    "3. **Diffusion Smoothing**: D_f prevents singular band interfaces, creating finite band width \u03b4 ~ \u221a(D_f*\u03c4_age)\n",
    "4. **Steady-State Banding**: At long times, fluidity profile stabilizes with distinct high/low regions\n",
    "\n",
    "### Shear Banding Onset\n",
    "\n",
    "**Criterion**: Localization index \u03be = (f_max - f_min)/\u27e8f\u27e9 exceeds threshold (~0.3)\n",
    "\n",
    "**Onset Time**: Typically occurs after stress peak, during approach to steady state\n",
    "\n",
    "**Stress Signature**: Banding onset often correlates with stress plateau or slight decrease\n",
    "\n",
    "### Model Parameters from Startup\n",
    "\n",
    "- **G**: Elastic modulus controls initial stress rise (linear regime)\n",
    "- **\u03c4_age**: Aging timescale sets time to stress peak\n",
    "- **a, c**: Destructuring controls peak magnitude and overshoot ratio\n",
    "- **D_f**: Diffusion coefficient determines band width and stability\n",
    "- **f_eq**: Equilibrium fluidity sets steady-state stress level\n",
    "\n",
    "### NLSQ + Bayesian Workflow\n",
    "\n",
    "1. **NLSQ**: Fast point estimation with gap-averaged stress \u03c3(t)\n",
    "2. **NUTS**: Bayesian uncertainty quantification (R-hat < 1.01, ESS > 400)\n",
    "3. **Fluidity Access**: Use `model._f_field_trajectory` for spatially-resolved diagnostics\n",
    "4. **Validation**: Check banding predictions against known SGR/ITT-MCT regimes\n",
    "\n",
    "### Experimental Connections\n",
    "\n",
    "- **Rheo-PIV**: Compare predicted f(y,t) gradients with velocity profiles\n",
    "- **Rheo-NMR**: Validate spatial localization with MRI measurements\n",
    "- **Ultrasonic Velocimetry**: Time-resolved band position from Doppler shifts\n",
    "- **Stress Overshoot**: Magnitude indicates strength of thixotropic memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}