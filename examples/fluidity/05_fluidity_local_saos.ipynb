{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FluidityLocal SAOS: Small Amplitude Oscillatory Shear\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand linear viscoelastic response of fluidity models\n",
    "- Fit FluidityLocal to SAOS data (frequency sweeps) with G' and G'' components\n",
    "- Extract effective Maxwell relaxation time τ_eff = 1/(G·f_eq)\n",
    "- Perform Bayesian inference with NUTS for parameter uncertainty\n",
    "- Visualize posterior predictive distributions for storage (G') and loss (G'') moduli\n",
    "- Create Cole-Cole plots for phase-space analysis\n",
    "\n",
    "**Prerequisites:** Understanding of SAOS (complex modulus, G', G''), Maxwell model\n",
    "\n",
    "**Runtime:** ~3-5 minutes (NLSQ + quick Bayesian with 1 chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab setup\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    %pip install -q rheojax\n",
    "    import os\n",
    "    os.environ[\"JAX_ENABLE_X64\"] = \"true\"\n",
    "    print(\"RheoJAX installed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from rheojax.core.jax_config import safe_import_jax, verify_float64\n",
    "from rheojax.models.fluidity import FluidityLocal\n",
    "\n",
    "# Add utils to path\n",
    "if not IN_COLAB:\n",
    "    sys.path.insert(0, os.path.join(\"..\", \"utils\"))\n",
    "    from fluidity_tutorial_utils import (\n",
    "        load_polymer_saos,\n",
    "        save_fluidity_results,\n",
    "        print_convergence_summary,\n",
    "        print_parameter_comparison,\n",
    "        compute_fit_quality,\n",
    "    )\n",
    "\n",
    "jax, jnp = safe_import_jax()\n",
    "verify_float64()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"Devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theory: SAOS and Linear Viscoelasticity\n",
    "\n",
    "In small-amplitude oscillatory shear (SAOS), the applied strain is:\n",
    "\n",
    "$$\\gamma(t) = \\gamma_0 \\sin(\\omega t)$$\n",
    "\n",
    "where $\\gamma_0 \\ll 1$ (typically < 0.01 for linear regime). The resulting stress is:\n",
    "\n",
    "$$\\sigma(t) = \\gamma_0 [G'(\\omega) \\sin(\\omega t) + G''(\\omega) \\cos(\\omega t)]$$\n",
    "\n",
    "**Complex modulus:**\n",
    "\n",
    "$$G^*(\\omega) = G'(\\omega) + iG''(\\omega)$$\n",
    "\n",
    "- **G'(ω)**: Storage modulus (elastic energy storage)\n",
    "- **G''(ω)**: Loss modulus (viscous dissipation)\n",
    "- **tan δ = G''/G'**: Loss tangent (phase lag)\n",
    "\n",
    "### FluidityLocal in Linear Regime\n",
    "\n",
    "At equilibrium (no flow), the fluidity is frozen at $f = f_{eq}$. The model reduces to a **Maxwell element**:\n",
    "\n",
    "$$\\frac{d\\sigma}{dt} = G\\left(\\dot{\\gamma} - \\sigma f_{eq}\\right)$$\n",
    "\n",
    "This gives the classical Maxwell response:\n",
    "\n",
    "$$G'(\\omega) = G \\frac{(\\omega \\tau_{eff})^2}{1 + (\\omega \\tau_{eff})^2}$$\n",
    "\n",
    "$$G''(\\omega) = G \\frac{\\omega \\tau_{eff}}{1 + (\\omega \\tau_{eff})^2}$$\n",
    "\n",
    "where the **effective relaxation time** is:\n",
    "\n",
    "$$\\tau_{eff} = \\frac{1}{G \\cdot f_{eq}}$$\n",
    "\n",
    "**Key features:**\n",
    "- **Low ω:** G' ~ ω², G'' ~ ω (terminal regime)\n",
    "- **Crossover:** G' = G'' at ω = 1/τ_eff\n",
    "- **High ω:** G' → G (plateau), G'' ~ 1/ω\n",
    "\n",
    "This notebook uses real polystyrene SAOS data to extract G and f_eq from frequency sweeps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load polystyrene SAOS data at 145°C\n",
    "if IN_COLAB:\n",
    "    # Use synthetic data for Colab\n",
    "    print(\"Generating synthetic SAOS data for Colab demo...\")\n",
    "    omega = np.logspace(-1, 2, 30)\n",
    "    # Calibrated parameters from flow_curve fit\n",
    "    G_cal = 5e5\n",
    "    f_eq_cal = 5e-6\n",
    "    tau_eff = 1.0 / (G_cal * f_eq_cal)\n",
    "    \n",
    "    # Maxwell model\n",
    "    omega_tau = omega * tau_eff\n",
    "    G_prime = G_cal * omega_tau**2 / (1 + omega_tau**2)\n",
    "    G_double_prime = G_cal * omega_tau / (1 + omega_tau**2)\n",
    "    \n",
    "    # Add noise\n",
    "    rng = np.random.default_rng(42)\n",
    "    G_prime = G_prime * (1 + rng.normal(0, 0.03, len(omega)))\n",
    "    G_double_prime = G_double_prime * (1 + rng.normal(0, 0.03, len(omega)))\n",
    "else:\n",
    "    # Load real polystyrene data\n",
    "    omega, G_prime, G_double_prime = load_polymer_saos(temp=145)\n",
    "\n",
    "# Sort by frequency\n",
    "sort_idx = np.argsort(omega)\n",
    "omega = omega[sort_idx]\n",
    "G_prime = G_prime[sort_idx]\n",
    "G_double_prime = G_double_prime[sort_idx]\n",
    "\n",
    "# Stack for fitting\n",
    "G_star = np.column_stack([G_prime, G_double_prime])\n",
    "\n",
    "print(f\"Data points: {len(omega)}\")\n",
    "print(f\"Frequency range: {omega.min():.4f} – {omega.max():.1f} rad/s\")\n",
    "print(f\"G' range: {G_prime.min():.2e} – {G_prime.max():.2e} Pa\")\n",
    "print(f\"G'' range: {G_double_prime.min():.2e} – {G_double_prime.max():.2e} Pa\")\n",
    "\n",
    "# Check for crossover\n",
    "tan_delta = G_double_prime / G_prime\n",
    "crossover_mask = np.abs(tan_delta - 1.0) < 0.2\n",
    "if crossover_mask.any():\n",
    "    omega_cross = omega[crossover_mask][0]\n",
    "    tau_est = 1.0 / omega_cross\n",
    "    print(f\"\\nApproximate crossover: ω ≈ {omega_cross:.2f} rad/s\")\n",
    "    print(f\"Estimated relaxation time: τ ≈ {tau_est:.4f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot raw data\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# G' and G'' vs frequency\n",
    "ax1.loglog(omega, G_prime, \"o\", markersize=6, color=\"C0\", label=\"G' (Storage)\")\n",
    "ax1.loglog(omega, G_double_prime, \"s\", markersize=6, color=\"C1\", label=\"G'' (Loss)\")\n",
    "ax1.set_xlabel(\"Angular frequency ω [rad/s]\")\n",
    "ax1.set_ylabel(\"Modulus [Pa]\")\n",
    "ax1.set_title(\"Polystyrene SAOS (145°C)\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, which=\"both\")\n",
    "\n",
    "# tan δ vs frequency\n",
    "ax2.semilogx(omega, tan_delta, \"o-\", markersize=5, color=\"C2\")\n",
    "ax2.axhline(1.0, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"tan δ = 1 (crossover)\")\n",
    "ax2.set_xlabel(\"Angular frequency ω [rad/s]\")\n",
    "ax2.set_ylabel(\"tan δ = G''/G'\")\n",
    "ax2.set_title(\"Loss Tangent\")\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NLSQ Fitting\n",
    "\n",
    "Fit FluidityLocal to SAOS data using NLSQ optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize model\nmodel = FluidityLocal()\n\n# Set reasonable initial guesses (optional - NLSQ has smart defaults)\n# model.parameters.set_value(\"G\", 5e5)\n# model.parameters.set_value(\"f_eq\", 1e-6)\n# model.parameters.set_value(\"theta\", 10.0)\n\nprint(\"Fitting FluidityLocal to SAOS data...\")\nt0 = time.time()\nmodel.fit(omega, G_star, test_mode=\"oscillation\", method='scipy')\nt_nlsq = time.time() - t0\n\n# Compute fit quality using frequency sweep predictions\nG_star_pred = model.predict(omega)\n# Flatten both arrays for comparison\nmetrics = compute_fit_quality(G_star.flatten(), np.array(G_star_pred).flatten())\n\nprint(f\"\\nNLSQ fit time: {t_nlsq:.2f} s\")\nprint(f\"R²: {metrics['R2']:.6f}\")\nprint(f\"RMSE: {metrics['RMSE']:.4g} Pa\")\n\n# Extract parameters\nG_fit = model.parameters.get_value(\"G\")\nf_eq_fit = model.parameters.get_value(\"f_eq\")\ntheta_fit = model.parameters.get_value(\"theta\")\n\n# Compute effective relaxation time\ntau_eff_fit = 1.0 / (G_fit * f_eq_fit)\n\nprint(\"\\nFitted parameters:\")\nprint(f\"  G      = {G_fit:.4e} Pa\")\nprint(f\"  f_eq   = {f_eq_fit:.4e} 1/(Pa·s)\")\nprint(f\"  theta  = {theta_fit:.4f} s\")\nprint(f\"\\nDerived quantities:\")\nprint(f\"  τ_eff  = 1/(G·f_eq) = {tau_eff_fit:.4f} s\")\nprint(f\"  η_eq   = 1/f_eq = {1.0/f_eq_fit:.4e} Pa·s\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "omega_fine = np.logspace(np.log10(omega.min()) - 0.5, np.log10(omega.max()) + 0.5, 200)\n",
    "G_pred = model.predict(omega_fine)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# G' and G'' fit\n",
    "ax1.loglog(omega, G_prime, \"o\", markersize=7, color=\"C0\", label=\"G' data\", alpha=0.7)\n",
    "ax1.loglog(omega, G_double_prime, \"s\", markersize=7, color=\"C1\", label=\"G'' data\", alpha=0.7)\n",
    "ax1.loglog(omega_fine, G_pred[:, 0], \"-\", lw=2.5, color=\"C0\", label=\"G' fit\")\n",
    "ax1.loglog(omega_fine, G_pred[:, 1], \"--\", lw=2.5, color=\"C1\", label=\"G'' fit\")\n",
    "\n",
    "# Mark crossover frequency\n",
    "omega_cross_fit = 1.0 / tau_eff_fit\n",
    "ax1.axvline(omega_cross_fit, color=\"gray\", linestyle=\":\", alpha=0.5)\n",
    "ax1.text(omega_cross_fit * 1.3, G_fit * 0.3, f\"ω* = {omega_cross_fit:.2f} rad/s\", \n",
    "         rotation=90, va=\"center\", fontsize=9, color=\"gray\")\n",
    "\n",
    "ax1.set_xlabel(\"Angular frequency ω [rad/s]\")\n",
    "ax1.set_ylabel(\"Modulus [Pa]\")\n",
    "ax1.set_title(f\"FluidityLocal SAOS Fit (R² = {metrics['R2']:.5f})\")\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(True, alpha=0.3, which=\"both\")\n",
    "\n",
    "# Residuals\n",
    "G_pred_data = model.predict(omega)\n",
    "residuals_Gp = (G_prime - G_pred_data[:, 0]) / G_prime * 100\n",
    "residuals_Gpp = (G_double_prime - G_pred_data[:, 1]) / G_double_prime * 100\n",
    "\n",
    "ax2.semilogx(omega, residuals_Gp, \"o\", markersize=5, color=\"C0\", label=\"G' residuals\")\n",
    "ax2.semilogx(omega, residuals_Gpp, \"s\", markersize=5, color=\"C1\", label=\"G'' residuals\")\n",
    "ax2.axhline(0, color=\"black\", linestyle=\"--\", lw=1, alpha=0.5)\n",
    "ax2.set_xlabel(\"Angular frequency ω [rad/s]\")\n",
    "ax2.set_ylabel(\"Relative error [%]\")\n",
    "ax2.set_title(\"Fit Residuals\")\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Maxwell Model Comparison\n",
    "\n",
    "Compare FluidityLocal prediction with the analytical Maxwell model using fitted τ_eff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytical Maxwell model\n",
    "omega_tau = omega_fine * tau_eff_fit\n",
    "G_maxwell_prime = G_fit * omega_tau**2 / (1 + omega_tau**2)\n",
    "G_maxwell_double_prime = G_fit * omega_tau / (1 + omega_tau**2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "ax.loglog(omega, G_prime, \"o\", markersize=6, color=\"C0\", label=\"G' data\", alpha=0.7)\n",
    "ax.loglog(omega, G_double_prime, \"s\", markersize=6, color=\"C1\", label=\"G'' data\", alpha=0.7)\n",
    "ax.loglog(omega_fine, G_pred[:, 0], \"-\", lw=2, color=\"C0\", label=\"G' FluidityLocal\")\n",
    "ax.loglog(omega_fine, G_pred[:, 1], \"--\", lw=2, color=\"C1\", label=\"G'' FluidityLocal\")\n",
    "ax.loglog(omega_fine, G_maxwell_prime, \":\", lw=2, color=\"C0\", alpha=0.5, label=\"G' Maxwell\")\n",
    "ax.loglog(omega_fine, G_maxwell_double_prime, \":\", lw=2, color=\"C1\", alpha=0.5, label=\"G'' Maxwell\")\n",
    "\n",
    "ax.set_xlabel(\"Angular frequency ω [rad/s]\")\n",
    "ax.set_ylabel(\"Modulus [Pa]\")\n",
    "ax.set_title(\"FluidityLocal vs Analytical Maxwell Model\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3, which=\"both\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')\n",
    "\n",
    "print(\"\\nIn the linear regime (SAOS), FluidityLocal reduces to a Maxwell element.\")\n",
    "print(\"The excellent agreement confirms the model captures viscoelastic relaxation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bayesian Inference with NUTS\n",
    "\n",
    "Use NLSQ parameters as warm-start for Bayesian inference to quantify uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare warm-start values\n",
    "param_names = [\"G\", \"f_eq\", \"theta\"]\n",
    "initial_values = {name: model.parameters.get_value(name) for name in param_names}\n",
    "print(\"Warm-start values:\", initial_values)\n",
    "\n",
    "# Bayesian parameters\n",
    "NUM_WARMUP = 200\n",
    "NUM_SAMPLES = 500\n",
    "NUM_CHAINS = 1\n",
    "# NUM_WARMUP = 1000; NUM_SAMPLES = 2000; NUM_CHAINS = 4  # production\n",
    "\n",
    "print(f\"\\nRunning NUTS (num_warmup={NUM_WARMUP}, num_samples={NUM_SAMPLES}, num_chains={NUM_CHAINS})...\")\n",
    "t0 = time.time()\n",
    "result = model.fit_bayesian(\n",
    "    omega, G_star, test_mode=\"oscillation\",\n",
    "    num_warmup=NUM_WARMUP, num_samples=NUM_SAMPLES, num_chains=NUM_CHAINS,\n",
    "    initial_values=initial_values, seed=42,\n",
    ")\n",
    "t_bayes = time.time() - t0\n",
    "print(f\"Bayesian inference time: {t_bayes:.1f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Convergence Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print convergence summary\n",
    "if not IN_COLAB:\n",
    "    all_pass = print_convergence_summary(result, param_names=param_names)\n",
    "else:\n",
    "    # Manual diagnostics for Colab\n",
    "    diag = result.diagnostics\n",
    "    print(\"Convergence Diagnostics\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"{'Parameter':>10s}  {'R-hat':>8s}  {'ESS':>8s}\")\n",
    "    print(\"-\" * 50)\n",
    "    for p in param_names:\n",
    "        r_hat = diag.get(\"r_hat\", {}).get(p, float(\"nan\"))\n",
    "        ess = diag.get(\"ess\", {}).get(p, float(\"nan\"))\n",
    "        print(f\"{p:>10s}  {r_hat:8.4f}  {ess:8.0f}\")\n",
    "    n_div = diag.get(\"divergences\", diag.get(\"num_divergences\", 0))\n",
    "    print(f\"\\nDivergences: {n_div}\")\n",
    "    all_pass = n_div == 0\n",
    "\n",
    "if not all_pass:\n",
    "    print(\"\\nNote: Single chain (num_chains=1) is for quick demos. Use num_chains=4 for production.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Parameter Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare NLSQ vs Bayesian estimates\n",
    "posterior = result.posterior_samples\n",
    "\n",
    "if not IN_COLAB:\n",
    "    print_parameter_comparison(model, posterior, param_names=param_names)\n",
    "else:\n",
    "    print(\"\\nParameter Comparison: NLSQ vs Bayesian\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Param':>12s}  {'NLSQ':>12s}  {'Median':>12s}  {'95% CI':>28s}\")\n",
    "    print(\"-\" * 70)\n",
    "    for name in param_names:\n",
    "        nlsq_val = model.parameters.get_value(name)\n",
    "        samples = posterior[name]\n",
    "        median = float(np.median(samples))\n",
    "        lo = float(np.percentile(samples, 2.5))\n",
    "        hi = float(np.percentile(samples, 97.5))\n",
    "        print(f\"{name:>12s}  {nlsq_val:12.4g}  {median:12.4g}  [{lo:.4g}, {hi:.4g}]\")\n",
    "\n",
    "# Compute posterior τ_eff\n",
    "tau_eff_posterior = 1.0 / (posterior[\"G\"] * posterior[\"f_eq\"])\n",
    "print(\"\\nDerived quantity:\")\n",
    "print(f\"  τ_eff (NLSQ):   {tau_eff_fit:.4f} s\")\n",
    "print(f\"  τ_eff (median): {np.median(tau_eff_posterior):.4f} s\")\n",
    "print(f\"  τ_eff (95% CI): [{np.percentile(tau_eff_posterior, 2.5):.4f}, {np.percentile(tau_eff_posterior, 97.5):.4f}] s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 ArviZ Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace plots\n",
    "idata = result.to_inference_data()\n",
    "axes = az.plot_trace(idata, var_names=param_names, figsize=(12, 6))\n",
    "fig = axes.ravel()[0].figure\n",
    "fig.suptitle(\"Trace Plots\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot (parameter correlations)\n",
    "axes = az.plot_pair(idata, var_names=param_names, kind=\"scatter\", divergences=True, figsize=(9, 9))\n",
    "fig = axes.ravel()[0].figure\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest plot (credible intervals)\n",
    "axes = az.plot_forest(idata, var_names=param_names, combined=True, hdi_prob=0.95, figsize=(10, 4))\n",
    "fig = axes.ravel()[0].figure\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Posterior Predictive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate posterior predictive with CI bands\n",
    "n_draws = min(200, len(posterior[\"G\"]))\n",
    "omega_pred = np.logspace(np.log10(omega.min()) - 0.5, np.log10(omega.max()) + 0.5, 100)\n",
    "\n",
    "pred_Gp = []\n",
    "pred_Gpp = []\n",
    "for i in range(n_draws):\n",
    "    # Temporarily set parameters\n",
    "    model.parameters.set_value(\"G\", posterior[\"G\"][i])\n",
    "    model.parameters.set_value(\"f_eq\", posterior[\"f_eq\"][i])\n",
    "    model.parameters.set_value(\"theta\", posterior[\"theta\"][i])\n",
    "    \n",
    "    pred_i = model.predict(omega_pred)\n",
    "    pred_Gp.append(np.array(pred_i[:, 0]))\n",
    "    pred_Gpp.append(np.array(pred_i[:, 1]))\n",
    "\n",
    "pred_Gp = np.array(pred_Gp)\n",
    "pred_Gpp = np.array(pred_Gpp)\n",
    "\n",
    "# Restore NLSQ parameters\n",
    "for name in param_names:\n",
    "    model.parameters.set_value(name, initial_values[name])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# CI bands\n",
    "ax.fill_between(omega_pred, np.percentile(pred_Gp, 2.5, axis=0), np.percentile(pred_Gp, 97.5, axis=0),\n",
    "                alpha=0.25, color=\"C0\", label=\"G' 95% CI\")\n",
    "ax.fill_between(omega_pred, np.percentile(pred_Gpp, 2.5, axis=0), np.percentile(pred_Gpp, 97.5, axis=0),\n",
    "                alpha=0.25, color=\"C1\", label=\"G'' 95% CI\")\n",
    "\n",
    "# Median predictions\n",
    "ax.loglog(omega_pred, np.median(pred_Gp, axis=0), \"-\", lw=2.5, color=\"C0\", label=\"G' median\")\n",
    "ax.loglog(omega_pred, np.median(pred_Gpp, axis=0), \"--\", lw=2.5, color=\"C1\", label=\"G'' median\")\n",
    "\n",
    "# Data\n",
    "ax.loglog(omega, G_prime, \"o\", color=\"C0\", markersize=6, alpha=0.8)\n",
    "ax.loglog(omega, G_double_prime, \"s\", color=\"C1\", markersize=6, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel(\"Angular frequency ω [rad/s]\")\n",
    "ax.set_ylabel(\"Modulus [Pa]\")\n",
    "ax.set_title(\"Posterior Predictive Check — SAOS\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3, which=\"both\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')\n",
    "\n",
    "print(\"\\nPosterior predictive check confirms excellent model fit with quantified uncertainty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cole-Cole Plot\n",
    "\n",
    "The Cole-Cole plot (G' vs G'') provides a phase-space view of viscoelastic behavior. For a single Maxwell element, this forms a semicircle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cole-Cole plot\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "\n",
    "# Data\n",
    "ax.plot(G_prime, G_double_prime, \"ko-\", markersize=6, label=\"Data\", alpha=0.7, lw=1.5)\n",
    "\n",
    "# NLSQ fit\n",
    "G_pred_data = model.predict(omega)\n",
    "ax.plot(G_pred_data[:, 0], G_pred_data[:, 1], \"s--\", markersize=5, color=\"C3\", \n",
    "        alpha=0.7, label=\"FluidityLocal fit\")\n",
    "\n",
    "# Maxwell theoretical semicircle\n",
    "omega_circle = np.logspace(-2, 3, 300)\n",
    "omega_tau_circle = omega_circle * tau_eff_fit\n",
    "Gp_maxwell = G_fit * omega_tau_circle**2 / (1 + omega_tau_circle**2)\n",
    "Gpp_maxwell = G_fit * omega_tau_circle / (1 + omega_tau_circle**2)\n",
    "ax.plot(Gp_maxwell, Gpp_maxwell, \":\", lw=2, color=\"gray\", alpha=0.5, label=\"Maxwell semicircle\")\n",
    "\n",
    "# Mark low/high frequency limits\n",
    "ax.scatter([0], [0], s=100, marker=\"x\", color=\"green\", zorder=5, label=\"ω → 0 (terminal)\")\n",
    "ax.scatter([G_fit], [0], s=100, marker=\"x\", color=\"red\", zorder=5, label=\"ω → ∞ (plateau)\")\n",
    "\n",
    "ax.set_xlabel(\"G' [Pa]\")\n",
    "ax.set_ylabel(\"G'' [Pa]\")\n",
    "ax.set_title(\"Cole-Cole Plot (G' vs G'')\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')\n",
    "\n",
    "print(\"\\nCole-Cole plot confirms single-relaxation Maxwell behavior in the linear regime.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    save_fluidity_results(model, result, model_variant=\"local\", protocol=\"saos\", param_names=param_names)\n",
    "else:\n",
    "    # Manual save for Colab\n",
    "    output_dir = os.path.join(\"..\", \"outputs\", \"fluidity\", \"local\", \"saos\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    nlsq_params = {name: float(model.parameters.get_value(name)) for name in param_names}\n",
    "    with open(os.path.join(output_dir, \"nlsq_params_saos.json\"), \"w\") as f:\n",
    "        json.dump(nlsq_params, f, indent=2)\n",
    "    \n",
    "    posterior_dict = {k: np.array(v).tolist() for k, v in posterior.items()}\n",
    "    with open(os.path.join(output_dir, \"posterior_saos.json\"), \"w\") as f:\n",
    "        json.dump(posterior_dict, f)\n",
    "    \n",
    "    print(f\"Results saved to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Linear viscoelasticity:** In SAOS, FluidityLocal reduces to a Maxwell element with τ_eff = 1/(G·f_eq)\n",
    "2. **Parameter extraction:** SAOS is excellent for measuring G and f_eq from frequency-dependent moduli\n",
    "3. **Crossover frequency:** G' = G'' at ω* = 1/τ_eff, marking the transition from viscous to elastic dominance\n",
    "4. **Maxwell scaling:** Low-ω terminal regime (G' ~ ω², G'' ~ ω) and high-ω plateau (G' → G) are captured\n",
    "5. **Cole-Cole semicircle:** Single-relaxation systems trace a semicircle in G'-G'' phase space\n",
    "6. **Bayesian uncertainty:** Posterior distributions quantify measurement noise and parameter correlation\n",
    "7. **Model validation:** Excellent agreement between FluidityLocal and analytical Maxwell confirms correct implementation\n",
    "\n",
    "**Next steps:**\n",
    "- Explore **startup shear** (NB 03) to see stress overshoot from thixotropy\n",
    "- Compare with **creep** (NB 04) for complementary time-domain viscoelasticity\n",
    "- Use **LAOS** (NB 06) to probe nonlinear viscoelasticity at large strains"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}