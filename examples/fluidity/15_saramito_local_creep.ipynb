{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FluiditySaramitoLocal: Creep with Elastic Jump and Viscous Bifurcation\n",
    "\n",
    "This notebook demonstrates creep behavior in the FluiditySaramitoLocal model, showcasing:\n",
    "- Elastic jump at t=0: γ_e(0) = σ₀/G\n",
    "- Viscous bifurcation: below vs above yield stress\n",
    "- Maxwell backbone contribution to transient response\n",
    "- NLSQ and Bayesian parameter inference from creep data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab compatibility\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    !pip install -q rheojax\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if not IN_COLAB:\n",
    "    # Add parent directory to path for local development\n",
    "    notebook_dir = Path.cwd()\n",
    "    project_root = notebook_dir.parent.parent\n",
    "    if project_root not in [Path(p) for p in sys.path]:\n",
    "        sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAX float64 configuration (CRITICAL: must be first)\n",
    "from rheojax.core.jax_config import safe_import_jax\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# RheoJAX imports\n",
    "from rheojax.models.fluidity import FluiditySaramitoLocal\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.logging import configure_logging, get_logger\n",
    "\n",
    "# Configure logging\n",
    "configure_logging(level=\"INFO\")\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theory: Saramito Creep Response\n",
    "\n",
    "### Governing Equations\n",
    "\n",
    "For constant applied stress σ₀, the FluiditySaramitoLocal model exhibits:\n",
    "\n",
    "**Total strain decomposition:**\n",
    "$$\\gamma(t) = \\gamma_e(t) + \\gamma_v(t)$$\n",
    "\n",
    "**Elastic jump (Maxwell backbone):**\n",
    "$$\\gamma_e(0) = \\frac{\\sigma_0}{G}$$\n",
    "\n",
    "**Viscous flow (von Mises + fluidity):**\n",
    "$$\\dot{\\gamma}_v = \\frac{1}{\\eta_f} \\max\\left(0, 1 - \\frac{\\tau_y}{|\\sigma_0|}\\right) \\sigma_0$$\n",
    "\n",
    "where $\\eta_f = \\eta_0/f$ is the fluidity-dependent viscosity.\n",
    "\n",
    "**Fluidity evolution:**\n",
    "$$\\frac{df}{dt} = -\\frac{f - 1}{\\tau_{th}} + b |\\dot{\\gamma}_v|^n$$\n",
    "\n",
    "### Bifurcation Behavior\n",
    "\n",
    "1. **Below yield (σ₀ < τ_y):**\n",
    "   - Elastic jump only: γ(t) ≈ σ₀/G\n",
    "   - No viscous flow: α = 0\n",
    "   - Fluidity decays to 1 (aging)\n",
    "\n",
    "2. **Above yield (σ₀ > τ_y):**\n",
    "   - Elastic jump + viscous flow\n",
    "   - Delayed yielding: fluidity increases, viscosity decreases\n",
    "   - Terminal flow: γ(t) ~ σ₀t/(η_∞)\n",
    "\n",
    "3. **Near yield (σ₀ ≈ τ_y):**\n",
    "   - Competition between aging and rejuvenation\n",
    "   - Possible transient yielding followed by arrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Setup and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "if IN_COLAB:\n",
    "    output_dir = Path('/content/outputs/fluidity/saramito_local/creep')\n",
    "else:\n",
    "    output_dir = Path('../outputs/fluidity/saramito_local/creep')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load calibrated parameters from startup tutorial\n",
    "startup_params_file = output_dir.parent / 'startup' / 'calibrated_params.txt'\n",
    "\n",
    "if startup_params_file.exists():\n",
    "    logger.info(f\"Loading calibrated parameters from {startup_params_file}\")\n",
    "    # Parse parameters (simple key=value format)\n",
    "    params = {}\n",
    "    with open(startup_params_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if '=' in line and not line.strip().startswith('#'):\n",
    "                key, value = line.strip().split('=')\n",
    "                params[key.strip()] = float(value.strip())\n",
    "    \n",
    "    # Create model with calibrated parameters\n",
    "    model = FluiditySaramitoLocal(coupling=\"minimal\")\n",
    "    model.parameters.set_values(\n",
    "        G=params.get('G', 1000.0),\n",
    "        eta_0=params.get('eta_0', 500.0),\n",
    "        tau_y=params.get('tau_y', 50.0),\n",
    "        tau_th=params.get('tau_th', 10.0),\n",
    "        b=params.get('b', 0.1),\n",
    "        n=params.get('n', 1.0)\n",
    "    )\n",
    "    logger.info(\"Using calibrated parameters from startup\")\n",
    "else:\n",
    "    logger.info(\"Using default parameters (startup calibration not found)\")\n",
    "    # Default parameters for demonstration\n",
    "    model = FluiditySaramitoLocal(coupling=\"minimal\")\n",
    "    model.parameters.set_values(\n",
    "        G=1000.0,      # Pa (elastic modulus)\n",
    "        eta_0=500.0,   # Pa·s (reference viscosity)\n",
    "        tau_y=50.0,    # Pa (yield stress)\n",
    "        tau_th=10.0,   # s (thixotropic timescale)\n",
    "        b=0.1,         # s^-1 (rejuvenation rate)\n",
    "        n=1.0          # (-) (shear-rate exponent)\n",
    "    )\n",
    "\n",
    "print(\"\\nModel Parameters:\")\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Synthetic Creep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stress levels relative to yield stress\n",
    "tau_y = model.parameters.get_value('tau_y')\n",
    "G = model.parameters.get_value('G')\n",
    "\n",
    "sigma_levels = {\n",
    "    'below_yield': 0.7 * tau_y,   # 35 Pa (no flow)\n",
    "    'at_yield': 1.0 * tau_y,      # 50 Pa (critical)\n",
    "    'above_yield': 1.5 * tau_y    # 75 Pa (flow)\n",
    "}\n",
    "\n",
    "# Time array (longer to capture steady-state)\n",
    "t_end = 200.0  # s\n",
    "n_points = 500\n",
    "t = np.linspace(0, t_end, n_points)\n",
    "\n",
    "# Initial fluidity (equilibrium state)\n",
    "f_0 = 1.0\n",
    "\n",
    "# Generate creep responses\n",
    "creep_data = {}\n",
    "noise_level = 0.02  # 2% noise\n",
    "\n",
    "for label, sigma in sigma_levels.items():\n",
    "    logger.info(f\"Simulating creep at σ = {sigma:.1f} Pa ({label})\")\n",
    "    \n",
    "    gamma, f = model.simulate_creep(t, sigma, f_0=f_0)\n",
    "    \n",
    "    # Add realistic noise\n",
    "    gamma_noisy = gamma * (1 + noise_level * np.random.randn(len(gamma)))\n",
    "    \n",
    "    # Compute elastic and viscous contributions\n",
    "    gamma_elastic = sigma / G\n",
    "    gamma_viscous = gamma - gamma_elastic\n",
    "    \n",
    "    creep_data[label] = {\n",
    "        't': t,\n",
    "        'gamma': gamma,\n",
    "        'gamma_noisy': gamma_noisy,\n",
    "        'gamma_elastic': gamma_elastic,\n",
    "        'gamma_viscous': gamma_viscous,\n",
    "        'fluidity': f,\n",
    "        'sigma': sigma\n",
    "    }\n",
    "\n",
    "logger.info(\"Synthetic creep data generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all creep responses\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "colors = {'below_yield': 'blue', 'at_yield': 'orange', 'above_yield': 'red'}\n",
    "labels_pretty = {\n",
    "    'below_yield': f'σ = {sigma_levels[\"below_yield\"]:.1f} Pa (0.7τ_y)',\n",
    "    'at_yield': f'σ = {sigma_levels[\"at_yield\"]:.1f} Pa (1.0τ_y)',\n",
    "    'above_yield': f'σ = {sigma_levels[\"above_yield\"]:.1f} Pa (1.5τ_y)'\n",
    "}\n",
    "\n",
    "# Panel 1: Total strain\n",
    "ax = axes[0, 0]\n",
    "for label, data in creep_data.items():\n",
    "    ax.plot(data['t'], data['gamma'], '-', color=colors[label], \n",
    "            label=labels_pretty[label], linewidth=2)\n",
    "    ax.plot(data['t'], data['gamma_noisy'], '.', color=colors[label], \n",
    "            alpha=0.3, markersize=3)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Strain γ (-)')\n",
    "ax.set_title('Total Creep Strain')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Elastic vs viscous (above yield only)\n",
    "ax = axes[0, 1]\n",
    "data = creep_data['above_yield']\n",
    "ax.plot(data['t'], data['gamma'], 'k-', label='Total', linewidth=2)\n",
    "ax.axhline(data['gamma_elastic'], color='green', linestyle='--', \n",
    "           label=f'Elastic (σ/G = {data[\"gamma_elastic\"]:.3f})', linewidth=2)\n",
    "ax.plot(data['t'], data['gamma_viscous'], 'purple', linestyle=':', \n",
    "        label='Viscous', linewidth=2)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Strain γ (-)')\n",
    "ax.set_title('Elastic Jump + Viscous Flow (σ > τ_y)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 3: Fluidity evolution\n",
    "ax = axes[1, 0]\n",
    "for label, data in creep_data.items():\n",
    "    ax.plot(data['t'], data['fluidity'], '-', color=colors[label], \n",
    "            label=labels_pretty[label], linewidth=2)\n",
    "ax.axhline(1.0, color='gray', linestyle='--', alpha=0.5, label='Equilibrium (f=1)')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Fluidity f (-)')\n",
    "ax.set_title('Fluidity Evolution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 4: Log-log strain (identify power-law regime)\n",
    "ax = axes[1, 1]\n",
    "for label, data in creep_data.items():\n",
    "    # Avoid log(0) by starting from t > 0\n",
    "    mask = data['t'] > 1.0\n",
    "    ax.loglog(data['t'][mask], data['gamma'][mask], '-', color=colors[label], \n",
    "              label=labels_pretty[label], linewidth=2)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Strain γ (-)')\n",
    "ax.set_title('Log-Log Creep (identifies power-law regimes)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'synthetic_creep_overview.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "logger.info(f\"Saved overview plot to {output_dir / 'synthetic_creep_overview.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. NLSQ Parameter Fitting\n",
    "\n",
    "Fit the model to the above-yield creep data to recover parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select above-yield data for fitting (most informative)\n",
    "fit_data = creep_data['above_yield']\n",
    "sigma_fit = fit_data['sigma']\n",
    "\n",
    "# Create RheoData object\n",
    "rheo_data = RheoData(\n",
    "    x=fit_data['t'],\n",
    "    y=fit_data['gamma_noisy'],\n",
    "    test_mode='creep'\n",
    ")\n",
    "\n",
    "logger.info(f\"Fitting to creep data at σ = {sigma_fit:.1f} Pa\")\n",
    "print(f\"\\nData points: {len(rheo_data.x)}\")\n",
    "print(f\"Strain range: {rheo_data.y.min():.4f} to {rheo_data.y.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fresh model for fitting\n",
    "model_fit = FluiditySaramitoLocal(coupling=\"minimal\")\n",
    "\n",
    "# Set reasonable parameter bounds\n",
    "model_fit.parameters.set_bounds('G', 100.0, 5000.0)\n",
    "model_fit.parameters.set_bounds('eta_0', 100.0, 2000.0)\n",
    "model_fit.parameters.set_bounds('tau_y', 10.0, 100.0)\n",
    "model_fit.parameters.set_bounds('tau_th', 1.0, 50.0)\n",
    "model_fit.parameters.set_bounds('b', 0.01, 1.0)\n",
    "model_fit.parameters.set_bounds('n', 0.5, 2.0)\n",
    "\n",
    "# Initial guess (perturbed from true values)\n",
    "model_fit.parameters.set_values(\n",
    "    G=800.0,\n",
    "    eta_0=400.0,\n",
    "    tau_y=40.0,\n",
    "    tau_th=8.0,\n",
    "    b=0.08,\n",
    "    n=1.2\n",
    ")\n",
    "\n",
    "print(\"\\nInitial guess:\")\n",
    "print(model_fit.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform NLSQ fit\n",
    "logger.info(\"Starting NLSQ optimization...\")\n",
    "\n",
    "result = model_fit.fit(\n",
    "    rheo_data,\n",
    "    test_mode='creep',\n",
    "    sigma_applied=sigma_fit,\n",
    "    max_iter=5000,\n",
    "    ftol=1e-8,\n",
    "    xtol=1e-8\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NLSQ Fit Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Converged: {result.success}\")\n",
    "print(f\"Iterations: {result.nit}\")\n",
    "print(f\"Final cost: {result.cost:.6e}\")\n",
    "print(f\"R²: {result.r_squared:.6f}\")\n",
    "print(f\"RMSE: {result.rmse:.6e}\")\n",
    "print(\"\\nFitted parameters:\")\n",
    "print(model_fit.parameters)\n",
    "\n",
    "# Compare with true values\n",
    "print(\"\\nTrue vs Fitted:\")\n",
    "for param_name in ['G', 'eta_0', 'tau_y', 'tau_th', 'b', 'n']:\n",
    "    true_val = model.parameters.get_value(param_name)\n",
    "    fit_val = model_fit.parameters.get_value(param_name)\n",
    "    error_pct = 100 * abs(fit_val - true_val) / true_val\n",
    "    print(f\"{param_name:8s}: True={true_val:8.3f}, Fit={fit_val:8.3f}, Error={error_pct:5.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize NLSQ fit\n",
    "gamma_pred = model_fit.predict(rheo_data.x, test_mode='creep', sigma_applied=sigma_fit)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: Fit quality\n",
    "ax = axes[0]\n",
    "ax.plot(fit_data['t'], fit_data['gamma'], 'k-', label='True', linewidth=2, alpha=0.7)\n",
    "ax.plot(fit_data['t'], fit_data['gamma_noisy'], 'o', color='gray', \n",
    "        label='Data (noisy)', markersize=3, alpha=0.5)\n",
    "ax.plot(rheo_data.x, gamma_pred, 'r--', label='NLSQ Fit', linewidth=2)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Strain γ (-)')\n",
    "ax.set_title(f'NLSQ Fit (R² = {result.r_squared:.4f})')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Residuals\n",
    "ax = axes[1]\n",
    "residuals = rheo_data.y - gamma_pred\n",
    "ax.plot(rheo_data.x, residuals, 'o', color='red', markersize=3, alpha=0.6)\n",
    "ax.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "ax.fill_between(rheo_data.x, -2*result.rmse, 2*result.rmse, \n",
    "                alpha=0.2, color='red', label='±2 RMSE')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Residuals')\n",
    "ax.set_title('Fit Residuals')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'nlsq_fit.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "logger.info(f\"Saved NLSQ fit plot to {output_dir / 'nlsq_fit.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bayesian Inference with NUTS\n",
    "\n",
    "Use the NLSQ solution as a warm-start for Bayesian inference to quantify parameter uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set priors (weakly informative around NLSQ solution)\n",
    "nlsq_params = model_fit.parameters.to_dict()\n",
    "\n",
    "model_fit.parameters.set_prior('G', 'normal', loc=nlsq_params['G'], scale=200.0)\n",
    "model_fit.parameters.set_prior('eta_0', 'normal', loc=nlsq_params['eta_0'], scale=100.0)\n",
    "model_fit.parameters.set_prior('tau_y', 'normal', loc=nlsq_params['tau_y'], scale=10.0)\n",
    "model_fit.parameters.set_prior('tau_th', 'normal', loc=nlsq_params['tau_th'], scale=5.0)\n",
    "model_fit.parameters.set_prior('b', 'normal', loc=nlsq_params['b'], scale=0.05)\n",
    "model_fit.parameters.set_prior('n', 'normal', loc=nlsq_params['n'], scale=0.2)\n",
    "\n",
    "print(\"Priors set (centered on NLSQ solution):\")\n",
    "for param_name in ['G', 'eta_0', 'tau_y', 'tau_th', 'b', 'n']:\n",
    "    prior = model_fit.parameters.get_prior(param_name)\n",
    "    print(f\"{param_name:8s}: {prior['type']} (loc={prior['loc']:.3f}, scale={prior['scale']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run NUTS sampling\n",
    "logger.info(\"Starting Bayesian inference (NUTS)...\")\n",
    "\n",
    "# Use moderate sampling for demonstration (increase for production)\n",
    "bayesian_result = model_fit.fit_bayesian(\n",
    "    rheo_data,\n",
    "    test_mode='creep',\n",
    "    sigma_applied=sigma_fit,\n",
    "    num_warmup=1000,\n",
    "    num_samples=2000,\n",
    "    num_chains=4,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "logger.info(\"Bayesian inference complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract posterior summary\n",
    "from rheojax.utils.bayesian import compute_rhat, compute_ess\n",
    "\n",
    "posterior = bayesian_result.posterior_samples\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Bayesian Posterior Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for param_name in ['G', 'eta_0', 'tau_y', 'tau_th', 'b', 'n']:\n",
    "    samples = posterior[param_name]\n",
    "    mean = jnp.mean(samples)\n",
    "    std = jnp.std(samples)\n",
    "    q025 = jnp.percentile(samples, 2.5)\n",
    "    q975 = jnp.percentile(samples, 97.5)\n",
    "    rhat = compute_rhat(samples.reshape(4, -1))  # num_chains=4\n",
    "    ess = compute_ess(samples.reshape(4, -1))\n",
    "    \n",
    "    true_val = model.parameters.get_value(param_name)\n",
    "    \n",
    "    print(f\"\\n{param_name}:\")\n",
    "    print(f\"  Mean ± Std:     {mean:.4f} ± {std:.4f}\")\n",
    "    print(f\"  95% CI:         [{q025:.4f}, {q975:.4f}]\")\n",
    "    print(f\"  True value:     {true_val:.4f}\")\n",
    "    print(f\"  R-hat:          {rhat:.4f}\")\n",
    "    print(f\"  ESS:            {ess:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ArviZ Diagnostics\n",
    "\n",
    "Use ArviZ for comprehensive MCMC diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import arviz as az\n",
    "    ARVIZ_AVAILABLE = True\n",
    "except ImportError:\n",
    "    logger.warning(\"ArviZ not installed. Install with: pip install arviz\")\n",
    "    ARVIZ_AVAILABLE = False\n",
    "\n",
    "if ARVIZ_AVAILABLE:\n",
    "    # Convert to ArviZ InferenceData\n",
    "    idata = az.from_dict(\n",
    "        posterior={k: v.reshape(4, -1) for k, v in posterior.items()}\n",
    "    )\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nArviZ Summary:\")\n",
    "    print(az.summary(idata, hdi_prob=0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ARVIZ_AVAILABLE:\n",
    "    # Trace plot\n",
    "    az.plot_trace(idata, compact=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'trace_plot.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    logger.info(f\"Saved trace plot to {output_dir / 'trace_plot.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ARVIZ_AVAILABLE:\n",
    "    # Pair plot (correlations)\n",
    "    az.plot_pair(\n",
    "        idata,\n",
    "        var_names=['G', 'eta_0', 'tau_y', 'tau_th', 'b', 'n'],\n",
    "        kind='hexbin',\n",
    "        marginals=True,\n",
    "        figsize=(12, 12)\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'pair_plot.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    logger.info(f\"Saved pair plot to {output_dir / 'pair_plot.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ARVIZ_AVAILABLE:\n",
    "    # Forest plot (credible intervals)\n",
    "    az.plot_forest(\n",
    "        idata,\n",
    "        var_names=['G', 'eta_0', 'tau_y', 'tau_th', 'b', 'n'],\n",
    "        combined=True,\n",
    "        hdi_prob=0.95,\n",
    "        figsize=(8, 6)\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'forest_plot.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    logger.info(f\"Saved forest plot to {output_dir / 'forest_plot.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Elastic vs Viscous Strain Analysis\n",
    "\n",
    "Decompose the creep response to understand Maxwell contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use posterior mean for predictions\n",
    "G_post = jnp.mean(posterior['G'])\n",
    "eta_0_post = jnp.mean(posterior['eta_0'])\n",
    "tau_y_post = jnp.mean(posterior['tau_y'])\n",
    "\n",
    "# Simulate with posterior mean parameters\n",
    "model_post = FluiditySaramitoLocal(coupling=\"minimal\")\n",
    "model_post.parameters.set_values(\n",
    "    G=float(G_post),\n",
    "    eta_0=float(eta_0_post),\n",
    "    tau_y=float(tau_y_post),\n",
    "    tau_th=float(jnp.mean(posterior['tau_th'])),\n",
    "    b=float(jnp.mean(posterior['b'])),\n",
    "    n=float(jnp.mean(posterior['n']))\n",
    ")\n",
    "\n",
    "gamma_post, f_post = model_post.simulate_creep(t, sigma_fit)\n",
    "\n",
    "# Decompose strain\n",
    "gamma_elastic_post = sigma_fit / G_post\n",
    "gamma_viscous_post = gamma_post - gamma_elastic_post\n",
    "\n",
    "# Compute effective viscosity\n",
    "eta_eff = eta_0_post / f_post\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Panel 1: Strain decomposition\n",
    "ax = axes[0, 0]\n",
    "ax.plot(t, gamma_post, 'k-', label='Total', linewidth=2)\n",
    "ax.axhline(gamma_elastic_post, color='green', linestyle='--', \n",
    "           label=f'Elastic (σ/G = {gamma_elastic_post:.4f})', linewidth=2)\n",
    "ax.plot(t, gamma_viscous_post, 'purple', linestyle=':', \n",
    "        label='Viscous', linewidth=2)\n",
    "ax.plot(fit_data['t'], fit_data['gamma_noisy'], 'o', color='gray', \n",
    "        markersize=3, alpha=0.3, label='Data')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Strain γ (-)')\n",
    "ax.set_title('Strain Decomposition (Posterior Mean)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Fluidity evolution\n",
    "ax = axes[0, 1]\n",
    "ax.plot(t, f_post, 'b-', linewidth=2)\n",
    "ax.axhline(1.0, color='gray', linestyle='--', alpha=0.5, label='Equilibrium (f=1)')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Fluidity f (-)')\n",
    "ax.set_title('Fluidity Evolution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 3: Effective viscosity\n",
    "ax = axes[1, 0]\n",
    "ax.plot(t, eta_eff, 'r-', linewidth=2)\n",
    "ax.axhline(eta_0_post, color='gray', linestyle='--', alpha=0.5, \n",
    "           label=f'η₀ = {eta_0_post:.1f} Pa·s')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Effective Viscosity η_eff (Pa·s)')\n",
    "ax.set_title('Viscosity Evolution (η_eff = η₀/f)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 4: Strain rate\n",
    "ax = axes[1, 1]\n",
    "gamma_dot_viscous = jnp.gradient(gamma_viscous_post, t)\n",
    "ax.plot(t, gamma_dot_viscous, 'orange', linewidth=2)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Viscous Strain Rate (1/s)')\n",
    "ax.set_title('Viscous Flow Rate')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'strain_decomposition.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "logger.info(f\"Saved strain decomposition to {output_dir / 'strain_decomposition.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save synthetic data\n",
    "for label, data in creep_data.items():\n",
    "    np.savetxt(\n",
    "        output_dir / f'synthetic_creep_{label}.csv',\n",
    "        np.column_stack([data['t'], data['gamma'], data['fluidity']]),\n",
    "        header='time,strain,fluidity',\n",
    "        delimiter=',',\n",
    "        comments=''\n",
    "    )\n",
    "\n",
    "# Save NLSQ results\n",
    "with open(output_dir / 'nlsq_results.txt', 'w') as f:\n",
    "    f.write(\"NLSQ Fit Results\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\")\n",
    "    f.write(f\"Converged: {result.success}\\n\")\n",
    "    f.write(f\"Iterations: {result.nit}\\n\")\n",
    "    f.write(f\"R²: {result.r_squared:.6f}\\n\")\n",
    "    f.write(f\"RMSE: {result.rmse:.6e}\\n\")\n",
    "    f.write(\"\\nFitted Parameters:\\n\")\n",
    "    for param_name in ['G', 'eta_0', 'tau_y', 'tau_th', 'b', 'n']:\n",
    "        val = model_fit.parameters.get_value(param_name)\n",
    "        f.write(f\"{param_name} = {val:.6f}\\n\")\n",
    "\n",
    "# Save Bayesian results\n",
    "if ARVIZ_AVAILABLE:\n",
    "    az.to_netcdf(idata, output_dir / 'bayesian_results.nc')\n",
    "    logger.info(f\"Saved ArviZ InferenceData to {output_dir / 'bayesian_results.nc'}\")\n",
    "\n",
    "# Save posterior samples\n",
    "posterior_df = {k: np.array(v) for k, v in posterior.items()}\n",
    "import pandas as pd\n",
    "pd.DataFrame(posterior_df).to_csv(output_dir / 'posterior_samples.csv', index=False)\n",
    "\n",
    "logger.info(f\"All results saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Takeaways\n",
    "\n",
    "### Maxwell Creep Behavior\n",
    "\n",
    "1. **Elastic Jump (Instantaneous Response):**\n",
    "   - All stress levels exhibit γ_e(0) = σ₀/G at t=0\n",
    "   - This is a signature of the Maxwell viscoelastic backbone\n",
    "   - Measurable in experiments as the initial instrument compliance\n",
    "\n",
    "2. **Viscous Bifurcation (Yield Threshold):**\n",
    "   - **Below yield (σ < τ_y):** Only elastic strain, no flow\n",
    "   - **At yield (σ ≈ τ_y):** Transient competition between aging and rejuvenation\n",
    "   - **Above yield (σ > τ_y):** Delayed yielding → terminal flow\n",
    "\n",
    "3. **Thixotropic Dynamics:**\n",
    "   - Fluidity increases above yield (rejuvenation dominates)\n",
    "   - Effective viscosity η_eff = η₀/f decreases over time\n",
    "   - Flow accelerates: γ̇_v(t) increases even at constant σ₀\n",
    "\n",
    "4. **Parameter Identifiability:**\n",
    "   - **G:** Elastic jump magnitude\n",
    "   - **τ_y:** Bifurcation threshold\n",
    "   - **η₀, τ_th, b, n:** Terminal flow rate and transient dynamics\n",
    "\n",
    "### Practical Implications\n",
    "\n",
    "- **Creep testing** is ideal for measuring yield stress and thixotropic timescales\n",
    "- **Multi-stress protocol** (below/at/above yield) provides comprehensive characterization\n",
    "- **Elastic jump** can be used to independently measure G from creep data\n",
    "- **Bayesian inference** quantifies uncertainty in yield stress determination\n",
    "\n",
    "### Comparison with Other Protocols\n",
    "\n",
    "| Protocol | Best For | Elastic Jump? |\n",
    "|----------|----------|---------------|\n",
    "| **Creep** | Yield stress, thixotropy | Yes (t=0) |\n",
    "| **Startup** | Stress overshoot, flow instabilities | No (controlled strain) |\n",
    "| **SAOS** | Linear viscoelasticity, G'/G'' | Embedded in moduli |\n",
    "| **Flow Curve** | Steady-state rheology, shear-thinning | No (steady state) |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Compare creep-derived parameters with startup and flow curve results\n",
    "- Explore shear banding in nonlocal creep (1D spatial gradients)\n",
    "- Test predictive power: use creep-calibrated model for LAOS simulations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
