{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FluiditySaramitoLocal: Small-Amplitude Oscillatory Shear (SAOS)\n",
    "\n",
    "Linear viscoelastic response of the fluidity-Saramito model in the small-strain limit.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand SAOS behavior of thixotropic elastoviscoplastic materials\n",
    "- Maxwell-like linear response: G'(ω) and G''(ω)\n",
    "- NLSQ + Bayesian parameter inference from frequency sweeps\n",
    "- Cole-Cole analysis for model validation\n",
    "- Diagnostic interpretation (R-hat, ESS, divergences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab setup (uncomment if running on Colab)\n",
    "# !pip install rheojax nlsq numpyro arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# JAX-safe import (critical for float64)\n",
    "from rheojax.core.jax_config import safe_import_jax\n",
    "from rheojax.utils.metrics import compute_fit_quality\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "from rheojax.models.fluidity.saramito import FluiditySaramitoLocal\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.logging import configure_logging, get_logger\n",
    "\n",
    "# Configure logging\n",
    "configure_logging(level=\"INFO\")\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theory: SAOS in the Linear Limit\n",
    "\n",
    "### Governing Equations\n",
    "\n",
    "For small oscillatory strain $\\gamma = \\gamma_0 \\sin(\\omega t)$ with $\\gamma_0 \\ll 1$:\n",
    "\n",
    "**Maxwell backbone (coupling='minimal'):**\n",
    "$$\\tau + \\lambda \\frac{d\\tau}{dt} = G \\gamma$$\n",
    "\n",
    "where $\\lambda = 1/f$ is the fluidity-dependent relaxation time.\n",
    "\n",
    "**Complex modulus:**\n",
    "$$G^*(\\omega) = G' + iG'' = \\frac{G \\omega^2 \\lambda^2}{1 + \\omega^2 \\lambda^2} + i \\frac{G \\omega \\lambda}{1 + \\omega^2 \\lambda^2}$$\n",
    "\n",
    "**Key features:**\n",
    "- Low frequency ($\\omega \\ll 1/\\lambda$): $G' \\sim \\omega^2$, $G'' \\sim \\omega$ (viscous liquid)\n",
    "- High frequency ($\\omega \\gg 1/\\lambda$): $G' \\to G$, $G'' \\sim 1/\\omega$ (elastic solid)\n",
    "- Crossover at $\\omega = 1/\\lambda$: $G' = G'' = G/2$\n",
    "- Cole-Cole plot: $G''$ vs $G'$ forms a semicircle (Maxwell signature)\n",
    "\n",
    "**Thixotropic effects:**\n",
    "- Fluidity evolution: $df/dt = (1-f)/t_{eq} + b|\\dot{\\gamma}|^n$ (rejuvenation term negligible for $\\gamma_0 \\ll 1$)\n",
    "- Steady state: $f \\approx 1$ (fully structured), $\\lambda \\to \\lambda_{min}$\n",
    "- Pre-shearing history affects initial fluidity and transient response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Synthetic SAOS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Frequency sweep (rad/s)\nomega = np.logspace(-2, 2, 30)  # 0.01 to 100 rad/s\n\n# Ground truth parameters (using actual model parameter names with valid bounds)\nparams_true = {\n    'G': 1e5,          # Elastic modulus (Pa) - bounds (10, 1e8)\n    'eta_s': 100.0,    # Solvent viscosity (Pa·s) - bounds (0, 1000)\n    'tau_y0': 50.0,    # Yield stress (Pa) - bounds (0.1, 1e5)\n    'K_HB': 100.0,     # Consistency coefficient - bounds (0.01, 1e5)\n    'n_HB': 0.5,       # Power-law exponent - bounds (0.1, 1.5)\n    't_a': 10.0,       # Aging time (s) - bounds (0.01, 1e5)\n    'b': 0.5,          # Rejuvenation coefficient - bounds (0, 1000)\n    'n_rej': 1.0,      # Rejuvenation exponent - bounds (0.1, 3)\n    'f_age': 1e-4,     # Equilibrium fluidity - bounds (1e-12, 0.01)\n    'f_flow': 0.1,     # Maximum fluidity - bounds (1e-6, 1)\n}\n\n# Create model and generate data\nmodel_true = FluiditySaramitoLocal(coupling='minimal')\n\n# Set parameters (check bounds)\nfor name, value in params_true.items():\n    if name in model_true.parameters.keys():\n        try:\n            model_true.parameters.set_value(name, value)\n        except ValueError as e:\n            logger.warning(f\"Could not set {name}={value}: {e}\")\n\n# Predict complex modulus\nG_pred = model_true.predict(omega, test_mode='oscillation')\n\n# Handle output format\nif hasattr(G_pred, 'ndim') and G_pred.ndim == 2:\n    G_prime_true = np.array(G_pred[:, 0])\n    G_double_prime_true = np.array(G_pred[:, 1])\nelse:\n    # Scalar output (magnitude)\n    G_prime_true = np.abs(np.array(G_pred))\n    G_double_prime_true = G_prime_true * 0.5  # Approximate\n\n# Add 5% noise\nnp.random.seed(42)\nnoise_level = 0.05\nG_prime = G_prime_true * (1 + noise_level * np.random.randn(len(omega)))\nG_double_prime = G_double_prime_true * (1 + noise_level * np.random.randn(len(omega)))\nG_star = np.column_stack([G_prime, G_double_prime])\n\nlogger.info(f\"Generated SAOS data: {len(omega)} frequency points\")\nlogger.info(f\"Frequency range: {omega.min():.2e} to {omega.max():.2e} rad/s\")\nlogger.info(f\"G' range: {G_prime.min():.2e} to {G_prime.max():.2e} Pa\")\nlogger.info(f\"G'' range: {G_double_prime.min():.2e} to {G_double_prime.max():.2e} Pa\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw data\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.loglog(omega, G_prime, 'o', label=\"G' (Storage)\", markersize=8, alpha=0.7)\n",
    "ax.loglog(omega, G_double_prime, 's', label=\"G'' (Loss)\", markersize=8, alpha=0.7)\n",
    "ax.loglog(omega, G_prime_true, '-', color='C0', label='G\\' (True)', linewidth=2, alpha=0.5)\n",
    "ax.loglog(omega, G_double_prime_true, '-', color='C1', label='G\\'\\' (True)', linewidth=2, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Angular Frequency ω (rad/s)', fontsize=12)\n",
    "ax.set_ylabel('Modulus (Pa)', fontsize=12)\n",
    "ax.set_title('SAOS Data: G\\' and G\\'\\' vs Frequency', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, which='both', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Crossover frequency (where G' = G'')\n",
    "idx_cross = np.argmin(np.abs(G_prime - G_double_prime))\n",
    "omega_cross = omega[idx_cross]\n",
    "logger.info(f\"Crossover frequency ω_c ≈ {omega_cross:.3f} rad/s (λ ≈ {1/omega_cross:.3f} s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NLSQ Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize model for fitting\nmodel = FluiditySaramitoLocal(coupling='minimal')\n\n# Print actual parameter names\nlogger.info(\"Model parameters:\")\nfor name in model.parameters.keys():\n    val = model.parameters.get_value(name)\n    logger.info(f\"  {name}: {val:.4e}\")\n\nlogger.info(\"\\nStarting NLSQ optimization...\")\nmodel.fit(omega, G_star, test_mode='oscillation', method='scipy')\n\n# Compute fit quality\nG_fit = model.predict(omega, test_mode='oscillation')\nif G_fit.ndim == 2:\n    G_prime_fit = G_fit[:, 0]\n    G_double_prime_fit = G_fit[:, 1]\n    G_star_fit = np.abs(G_fit[:, 0] + 1j * G_fit[:, 1])\nelse:\n    G_prime_fit = G_fit\n    G_double_prime_fit = G_fit\n    G_star_fit = G_fit\n\nG_star_data = np.abs(G_prime + 1j * G_double_prime)\nmetrics = compute_fit_quality(G_star_data, np.array(G_star_fit).flatten())\n\nlogger.info(f\"\\nNLSQ Results:\")\nlogger.info(f\"R² = {metrics['R2']:.6f}\")\nlogger.info(f\"RMSE = {metrics['RMSE']:.4e} Pa\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare fitted vs true parameters\nprint(\"\\nParameter Comparison:\")\nprint(\"=\" * 70)\nprint(f\"{'Parameter':<15} {'True':<15} {'NLSQ':<15} {'Error (%)':<15}\")\nprint(\"=\" * 70)\n\nfor name in model.parameters.keys():\n    true_val = params_true.get(name, None)\n    fitted_val = model.parameters.get_value(name)\n    if true_val is not None:\n        error_pct = 100 * abs(fitted_val - true_val) / abs(true_val) if true_val != 0 else 0\n        print(f\"{name:<15} {true_val:<15.3e} {fitted_val:<15.3e} {error_pct:<15.2f}\")\n    else:\n        print(f\"{name:<15} {'N/A':<15} {fitted_val:<15.3e} {'N/A':<15}\")\n\nprint(\"=\" * 70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot fit quality\nG_fit_full = model.predict(omega, test_mode='oscillation')\nif G_fit_full.ndim == 2:\n    G_prime_fit = np.array(G_fit_full[:, 0])\n    G_double_prime_fit = np.array(G_fit_full[:, 1])\nelse:\n    G_prime_fit = np.array(G_fit_full)\n    G_double_prime_fit = np.array(G_fit_full)\n\nfig, axes = plt.subplots(2, 1, figsize=(10, 10))\n\n# G' and G''\nax = axes[0]\nax.loglog(omega, G_prime, 'o', label=\"G' (Data)\", markersize=8, alpha=0.7)\nax.loglog(omega, G_double_prime, 's', label=\"G'' (Data)\", markersize=8, alpha=0.7)\nax.loglog(omega, G_prime_fit, '-', color='C0', label=\"G' (NLSQ Fit)\", linewidth=2)\nax.loglog(omega, G_double_prime_fit, '-', color='C1', label=\"G'' (NLSQ Fit)\", linewidth=2)\nax.set_xlabel('Angular Frequency ω (rad/s)', fontsize=12)\nax.set_ylabel('Modulus (Pa)', fontsize=12)\nax.set_title(f\"NLSQ Fit (R² = {metrics['R2']:.6f})\", fontsize=14, fontweight='bold')\nax.legend(fontsize=10)\nax.grid(True, which='both', alpha=0.3)\n\n# Residuals\nax = axes[1]\nresiduals_prime = (G_prime - G_prime_fit) / np.maximum(G_prime_fit, 1e-10) * 100\nresiduals_double_prime = (G_double_prime - G_double_prime_fit) / np.maximum(G_double_prime_fit, 1e-10) * 100\nax.semilogx(omega, residuals_prime, 'o-', label=\"G' Residuals\", markersize=6)\nax.semilogx(omega, residuals_double_prime, 's-', label=\"G'' Residuals\", markersize=6)\nax.axhline(0, color='k', linestyle='--', linewidth=1)\nax.set_xlabel('Angular Frequency ω (rad/s)', fontsize=12)\nax.set_ylabel('Residuals (%)', fontsize=12)\nax.set_title('Fit Residuals', fontsize=14, fontweight='bold')\nax.legend(fontsize=10)\nax.grid(True, which='both', alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bayesian Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Bayesian inference with NLSQ warm-start (critical for convergence)\nlogger.info(\"\\nStarting Bayesian inference (NUTS)...\")\nlogger.info(\"Using NLSQ solution as warm-start\")\n\n# Get initial values from fitted model\ninitial_values = {\n    name: model.parameters.get_value(name)\n    for name in model.parameters.keys()\n}\n\nbayes_result = model.fit_bayesian(\n    omega,\n    G_star,\n    test_mode='oscillation',\n    num_warmup=500,\n    num_samples=1000,\n    num_chains=1,        # Fast demo; use 4 for production\n    seed=42,             # Reproducibility\n    initial_values=initial_values,\n)\n\nlogger.info(\"Bayesian inference complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ArviZ Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import arviz as az\n\n# Convert to ArviZ InferenceData\nidata = bayes_result.to_inference_data()\n\n# Get parameter names from model\nparam_names = list(model.parameters.keys())\n\n# Summary statistics  \nsummary = az.summary(idata, var_names=param_names, hdi_prob=0.95)\nprint(\"\\nBayesian Parameter Estimates (95% HDI):\")\nprint(\"=\" * 80)\nprint(summary)\nprint(\"=\" * 80)\n\n# Check diagnostics\nlogger.info(\"\\nDiagnostic Checks:\")\ndiag = bayes_result.diagnostics\nfor param in param_names:\n    r_hat = diag.get(\"r_hat\", {}).get(param, float(\"nan\"))\n    ess = diag.get(\"ess\", {}).get(param, float(\"nan\"))\n    status = \"PASS\" if (r_hat < 1.01 and ess > 400) else \"WARN\"\n    logger.info(f\"{param:<12} R-hat={r_hat:.4f}, ESS={ess:.0f} [{status}]\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace plots (MCMC convergence)\n",
    "az.plot_trace(idata, compact=True, figsize=(12, 10))\n",
    "plt.suptitle('MCMC Trace Plots', fontsize=16, fontweight='bold', y=1.001)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest plot (credible intervals)\n",
    "az.plot_forest(idata, hdi_prob=0.95, figsize=(8, 6))\n",
    "plt.title('Parameter Credible Intervals (95% HDI)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Pair plot (correlations)\n# Select a subset of key parameters\nkey_params = ['G', 'eta_s', 't_a', 'b']\nkey_params = [p for p in key_params if p in bayes_result.posterior_samples][:4]\n\nif len(key_params) >= 2:\n    az.plot_pair(\n        idata,\n        var_names=key_params,\n        divergences=True,\n        figsize=(10, 10)\n    )\n    plt.suptitle('Parameter Correlations', fontsize=16, fontweight='bold', y=1.001)\n    plt.tight_layout()\n    plt.show()\nelse:\n    logger.info(\"Not enough parameters for pair plot\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Energy plot (HMC diagnostics)\n# Note: Energy plot requires sample_stats with 'energy' field\ntry:\n    az.plot_energy(idata, figsize=(8, 5))\n    plt.title('HMC Energy Diagnostic', fontsize=14, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\nexcept (AttributeError, KeyError) as e:\n    logger.info(f\"Energy plot skipped: {e}\")\n    logger.info(\"Note: Energy diagnostic requires MCMC sample stats with energy field\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cole-Cole Plot Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cole-Cole plot: G'' vs G' (should form semicircle for Maxwell model)\nfig, ax = plt.subplots(figsize=(8, 8))\n\n# Data\nax.plot(G_prime, G_double_prime, 'o', label='Data', markersize=10, alpha=0.7)\n\n# NLSQ fit\nax.plot(G_prime_fit, G_double_prime_fit, '-', label='NLSQ Fit', linewidth=2)\n\n# Theoretical semicircle (Maxwell)\nG_fit_param = model.parameters.get_value('G')\ntheta = np.linspace(0, np.pi, 100)\nG_circle = G_fit_param / 2 * (1 + np.cos(theta))\nG_double_circle = G_fit_param / 2 * np.sin(theta)\nax.plot(G_circle, G_double_circle, '--', color='gray', label='Maxwell Semicircle', linewidth=2, alpha=0.5)\n\nax.set_xlabel(\"G' (Storage Modulus) [Pa]\", fontsize=12)\nax.set_ylabel(\"G'' (Loss Modulus) [Pa]\", fontsize=12)\nax.set_title('Cole-Cole Plot', fontsize=14, fontweight='bold')\nax.legend(fontsize=10)\nax.grid(True, alpha=0.3)\nax.set_aspect('equal', adjustable='box')\n\nplt.tight_layout()\nplt.show()\n\nlogger.info(\"Cole-Cole analysis: Data should follow semicircle for ideal Maxwell behavior\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Posterior Predictive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compute credible intervals from posterior samples\nposterior_samples = bayes_result.posterior_samples\nn_samples = len(list(posterior_samples.values())[0])\n\n# Random subset for efficiency (50 posterior samples for speed)\nnp.random.seed(42)\nn_subsample = min(50, n_samples)\nsample_indices = np.random.choice(n_samples, size=n_subsample, replace=False)\n\nG_posterior_samples = []\nparam_names = list(model.parameters.keys())\n\nfor idx in sample_indices:\n    # Set parameters from posterior sample\n    for name in param_names:\n        if name in posterior_samples:\n            model.parameters.set_value(name, float(posterior_samples[name][idx]))\n    \n    G_pred = model.predict(omega, test_mode='oscillation')\n    G_posterior_samples.append(G_pred)\n\nG_posterior_samples = np.array(G_posterior_samples)\n\nif G_posterior_samples.ndim == 3:\n    G_prime_posterior = G_posterior_samples[:, :, 0]\n    G_double_prime_posterior = G_posterior_samples[:, :, 1]\nelse:\n    G_prime_posterior = G_posterior_samples\n    G_double_prime_posterior = G_posterior_samples\n\n# Compute percentiles\nG_prime_median = np.median(G_prime_posterior, axis=0)\nG_prime_lower = np.percentile(G_prime_posterior, 2.5, axis=0)\nG_prime_upper = np.percentile(G_prime_posterior, 97.5, axis=0)\n\nG_double_prime_median = np.median(G_double_prime_posterior, axis=0)\nG_double_prime_lower = np.percentile(G_double_prime_posterior, 2.5, axis=0)\nG_double_prime_upper = np.percentile(G_double_prime_posterior, 97.5, axis=0)\n\nlogger.info(\"Posterior predictive credible intervals computed\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with credible intervals\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Data\n",
    "ax.loglog(omega, G_prime, 'o', label=\"G' (Data)\", markersize=8, alpha=0.7, color='C0')\n",
    "ax.loglog(omega, G_double_prime, 's', label=\"G'' (Data)\", markersize=8, alpha=0.7, color='C1')\n",
    "\n",
    "# Posterior median\n",
    "ax.loglog(omega, G_prime_median, '-', label=\"G' (Posterior Median)\", linewidth=2, color='C0')\n",
    "ax.loglog(omega, G_double_prime_median, '-', label=\"G'' (Posterior Median)\", linewidth=2, color='C1')\n",
    "\n",
    "# 95% credible intervals\n",
    "ax.fill_between(omega, G_prime_lower, G_prime_upper, alpha=0.3, color='C0', label=\"G' 95% CI\")\n",
    "ax.fill_between(omega, G_double_prime_lower, G_double_prime_upper, alpha=0.3, color='C1', label=\"G'' 95% CI\")\n",
    "\n",
    "ax.set_xlabel('Angular Frequency ω (rad/s)', fontsize=12)\n",
    "ax.set_ylabel('Modulus (Pa)', fontsize=12)\n",
    "ax.set_title('Bayesian Posterior Predictive (95% Credible Intervals)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=9, loc='best')\n",
    "ax.grid(True, which='both', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create output directory\nimport json\noutput_dir = Path('../outputs/fluidity/saramito_local/saos')\noutput_dir.mkdir(parents=True, exist_ok=True)\n\n# Save NLSQ results\nnlsq_results = {\n    'parameters': {name: float(model.parameters.get_value(name)) for name in model.parameters.keys()},\n    'r_squared': float(metrics['R2']),\n    'rmse': float(metrics['RMSE']),\n}\n\nwith open(output_dir / 'nlsq_results.json', 'w') as f:\n    json.dump(nlsq_results, f, indent=2)\n\n# Save posterior samples\nposterior_dict = {k: np.array(v).tolist() for k, v in posterior_samples.items()}\nwith open(output_dir / 'posterior_samples.json', 'w') as f:\n    json.dump(posterior_dict, f)\n\n# Save summary\nsummary.to_csv(output_dir / 'bayesian_summary.csv')\n\nlogger.info(f\"Results saved to {output_dir}\")\nprint(f\"\\nOutput files:\")\nprint(f\"  - nlsq_results.json\")\nprint(f\"  - posterior_samples.json\")\nprint(f\"  - bayesian_summary.csv\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Takeaways\n",
    "\n",
    "### Physical Insights\n",
    "\n",
    "1. **Maxwell-like SAOS behavior:**\n",
    "   - Storage modulus G'(ω) transitions from ω² (viscous) to plateau (elastic)\n",
    "   - Loss modulus G''(ω) exhibits peak at crossover frequency ω_c = 1/λ\n",
    "   - Cole-Cole plot forms semicircle (characteristic of single relaxation time)\n",
    "\n",
    "2. **Thixotropic signatures:**\n",
    "   - Initial fluidity f_0 affects transient approach to steady oscillation\n",
    "   - Equilibrium time t_eq controls structural recovery during rest periods\n",
    "   - Yield stress τ_y has minimal effect in linear regime (γ_0 ≪ 1)\n",
    "\n",
    "3. **Parameter identifiability:**\n",
    "   - Elastic modulus G well-constrained by high-frequency plateau\n",
    "   - Viscosity η_∞ (via fluidity) from low-frequency slope G'' ~ ω\n",
    "   - Relaxation time λ from crossover frequency ω_c\n",
    "   - Thixotropic parameters (b, n, t_eq) weakly identifiable from SAOS alone\n",
    "\n",
    "### Computational Best Practices\n",
    "\n",
    "4. **NLSQ warm-start critical:**\n",
    "   - Bayesian inference requires good initialization (use `.fit()` first)\n",
    "   - Multi-start optimization recommended for complex models\n",
    "   - Check R² > 0.95 before proceeding to Bayesian\n",
    "\n",
    "5. **Diagnostic interpretation:**\n",
    "   - R-hat < 1.01: chains converged\n",
    "   - ESS > 400: sufficient effective samples\n",
    "   - Energy plot: marginal/conditional distributions should match\n",
    "   - Divergences: indicate problematic geometry (reparameterize or increase warmup)\n",
    "\n",
    "6. **Model validation:**\n",
    "   - Cole-Cole semicircle confirms Maxwell backbone\n",
    "   - Residuals < 5% indicate good fit\n",
    "   - Posterior predictive intervals should encompass data\n",
    "\n",
    "### Experimental Design\n",
    "\n",
    "7. **Frequency sweep strategy:**\n",
    "   - Log-spaced frequencies spanning 3-4 decades\n",
    "   - Include both low (viscous) and high (elastic) frequency limits\n",
    "   - Strain amplitude γ_0 < 1% to ensure linear regime\n",
    "\n",
    "8. **Pre-shearing protocol:**\n",
    "   - Control initial fluidity f_0 via rest time after pre-shear\n",
    "   - Long rest (t ≫ t_eq): fully structured (f → f_min)\n",
    "   - Short rest (t ≪ t_eq): partially rejuvenated (f > f_min)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **LAOS (Large-Amplitude Oscillatory Shear):** Nonlinear viscoelasticity and yield transition\n",
    "- **Startup flows:** Stress overshoot and thixotropic kinetics\n",
    "- **Step-strain relaxation:** Direct probe of relaxation time spectrum\n",
    "- **Combined protocols:** Simultaneous fitting of SAOS + flow curves for full parameter identification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}