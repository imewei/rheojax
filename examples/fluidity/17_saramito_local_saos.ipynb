{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FluiditySaramitoLocal: Small-Amplitude Oscillatory Shear (SAOS)\n",
    "\n",
    "Linear viscoelastic response of the fluidity-Saramito model in the small-strain limit.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand SAOS behavior of thixotropic elastoviscoplastic materials\n",
    "- Maxwell-like linear response: G'(ω) and G''(ω)\n",
    "- NLSQ + Bayesian parameter inference from frequency sweeps\n",
    "- Cole-Cole analysis for model validation\n",
    "- Diagnostic interpretation (R-hat, ESS, divergences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab setup (uncomment if running on Colab)\n",
    "# !pip install rheojax nlsq numpyro arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# JAX-safe import (critical for float64)\n",
    "from rheojax.core.jax_config import safe_import_jax\n",
    "from rheojax.utils.metrics import compute_fit_quality\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "from rheojax.models.fluidity.saramito import FluiditySaramitoLocal\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.logging import configure_logging, get_logger\n",
    "\n",
    "# Configure logging\n",
    "configure_logging(level=\"INFO\")\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Theory: SAOS in the Linear Limit\n",
    "\n",
    "### Governing Equations\n",
    "\n",
    "For small oscillatory strain $\\gamma = \\gamma_0 \\sin(\\omega t)$ with $\\gamma_0 \\ll 1$:\n",
    "\n",
    "**Maxwell backbone (coupling='minimal'):**\n",
    "$$\\tau + \\lambda \\frac{d\\tau}{dt} = G \\gamma$$\n",
    "\n",
    "where $\\lambda = 1/f$ is the fluidity-dependent relaxation time.\n",
    "\n",
    "**Complex modulus:**\n",
    "$$G^*(\\omega) = G' + iG'' = \\frac{G \\omega^2 \\lambda^2}{1 + \\omega^2 \\lambda^2} + i \\frac{G \\omega \\lambda}{1 + \\omega^2 \\lambda^2}$$\n",
    "\n",
    "**Key features:**\n",
    "- Low frequency ($\\omega \\ll 1/\\lambda$): $G' \\sim \\omega^2$, $G'' \\sim \\omega$ (viscous liquid)\n",
    "- High frequency ($\\omega \\gg 1/\\lambda$): $G' \\to G$, $G'' \\sim 1/\\omega$ (elastic solid)\n",
    "- Crossover at $\\omega = 1/\\lambda$: $G' = G'' = G/2$\n",
    "- Cole-Cole plot: $G''$ vs $G'$ forms a semicircle (Maxwell signature)\n",
    "\n",
    "**Thixotropic effects:**\n",
    "- Fluidity evolution: $df/dt = (1-f)/t_{eq} + b|\\dot{\\gamma}|^n$ (rejuvenation term negligible for $\\gamma_0 \\ll 1$)\n",
    "- Steady state: $f \\approx 1$ (fully structured), $\\lambda \\to \\lambda_{min}$\n",
    "- Pre-shearing history affects initial fluidity and transient response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Synthetic SAOS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency sweep (rad/s)\n",
    "omega = np.logspace(-2, 2, 30)  # 0.01 to 100 rad/s\n",
    "\n",
    "# Ground truth parameters (polystyrene-like)\n",
    "params_true = {\n",
    "    'G': 1e5,          # Elastic modulus (Pa)\n",
    "    'eta_inf': 1e3,    # Infinite-shear viscosity (Pa·s)\n",
    "    'tau_y': 50.0,     # Yield stress (Pa) - minimal effect in SAOS\n",
    "    't_eq': 10.0,      # Equilibrium time (s)\n",
    "    'b': 0.5,          # Rejuvenation coefficient\n",
    "    'n': 1.0,          # Shear-rate exponent\n",
    "    'f_0': 0.8         # Initial fluidity (partially structured)\n",
    "}\n",
    "\n",
    "# Create model and generate data\n",
    "model_true = FluiditySaramitoLocal(coupling='minimal')\n",
    "model_true.set_params(**params_true)\n",
    "\n",
    "# Predict complex modulus\n",
    "G_complex_true = model_true.predict(omega, test_mode='oscillation', return_components=True)\n",
    "G_prime_true = G_complex_true.real\n",
    "G_double_prime_true = G_complex_true.imag\n",
    "\n",
    "# Add 5% noise\n",
    "np.random.seed(42)\n",
    "noise_level = 0.05\n",
    "G_prime = G_prime_true * (1 + noise_level * np.random.randn(len(omega)))\n",
    "G_double_prime = G_double_prime_true * (1 + noise_level * np.random.randn(len(omega)))\n",
    "G_complex = G_prime + 1j * G_double_prime\n",
    "\n",
    "logger.info(f\"Generated SAOS data: {len(omega)} frequency points\")\n",
    "logger.info(f\"Frequency range: {omega.min():.2e} to {omega.max():.2e} rad/s\")\n",
    "logger.info(f\"G' range: {G_prime.min():.2e} to {G_prime.max():.2e} Pa\")\n",
    "logger.info(f\"G'' range: {G_double_prime.min():.2e} to {G_double_prime.max():.2e} Pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw data\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.loglog(omega, G_prime, 'o', label=\"G' (Storage)\", markersize=8, alpha=0.7)\n",
    "ax.loglog(omega, G_double_prime, 's', label=\"G'' (Loss)\", markersize=8, alpha=0.7)\n",
    "ax.loglog(omega, G_prime_true, '-', color='C0', label='G\\' (True)', linewidth=2, alpha=0.5)\n",
    "ax.loglog(omega, G_double_prime_true, '-', color='C1', label='G\\'\\' (True)', linewidth=2, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Angular Frequency ω (rad/s)', fontsize=12)\n",
    "ax.set_ylabel('Modulus (Pa)', fontsize=12)\n",
    "ax.set_title('SAOS Data: G\\' and G\\'\\' vs Frequency', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, which='both', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Crossover frequency (where G' = G'')\n",
    "idx_cross = np.argmin(np.abs(G_prime - G_double_prime))\n",
    "omega_cross = omega[idx_cross]\n",
    "logger.info(f\"Crossover frequency ω_c ≈ {omega_cross:.3f} rad/s (λ ≈ {1/omega_cross:.3f} s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NLSQ Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RheoData object\n",
    "rheo_data = RheoData(x=omega, y=G_complex, test_mode='oscillation')\n",
    "\n",
    "# Initialize model\n",
    "model = FluiditySaramitoLocal(coupling='minimal')\n",
    "\n",
    "# Set initial guesses (deliberately off to test optimization)\n",
    "model.set_params(\n",
    "    G=5e4,          # 2x lower\n",
    "    eta_inf=5e2,    # 2x lower\n",
    "    tau_y=100.0,    # 2x higher (minimal effect in SAOS)\n",
    "    t_eq=5.0,       # 2x lower\n",
    "    b=1.0,          # 2x higher\n",
    "    n=0.8,          # Lower\n",
    "    f_0=0.5         # Lower\n",
    ")\n",
    "\n",
    "logger.info(\"Starting NLSQ optimization...\")\n",
    "result = model.fit(rheo_data, method='scipy')\n",
    "\n",
    "logger.info(f\"\\nNLSQ Results:\")\n",
    "logger.info(f\"R² = {metrics['R2']:.6f}\")\n",
    "logger.info(f\"RMSE = {np.sqrt(result.cost):.2e}\")\n",
    "logger.info(f\"Iterations = {result.nit}\")\n",
    "logger.info(f\"Success = {result.success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare fitted vs true parameters\n",
    "print(\"\\nParameter Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Parameter':<15} {'True':<15} {'NLSQ':<15} {'Error (%)':<15}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fitted_params = model.get_params()\n",
    "for key in params_true.keys():\n",
    "    true_val = params_true[key]\n",
    "    fitted_val = fitted_params[key]\n",
    "    error_pct = 100 * abs(fitted_val - true_val) / true_val\n",
    "    print(f\"{key:<15} {true_val:<15.3e} {fitted_val:<15.3e} {error_pct:<15.2f}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fit quality\n",
    "G_fit = model.predict(omega, test_mode='oscillation', return_components=True)\n",
    "G_prime_fit = G_fit.real\n",
    "G_double_prime_fit = G_fit.imag\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "# G' and G''\n",
    "ax = axes[0]\n",
    "ax.loglog(omega, G_prime, 'o', label=\"G' (Data)\", markersize=8, alpha=0.7)\n",
    "ax.loglog(omega, G_double_prime, 's', label=\"G'' (Data)\", markersize=8, alpha=0.7)\n",
    "ax.loglog(omega, G_prime_fit, '-', color='C0', label='G\\' (NLSQ Fit)', linewidth=2)\n",
    "ax.loglog(omega, G_double_prime_fit, '-', color='C1', label='G\\'\\' (NLSQ Fit)', linewidth=2)\n",
    "ax.set_xlabel('Angular Frequency ω (rad/s)', fontsize=12)\n",
    "ax.set_ylabel('Modulus (Pa)', fontsize=12)\n",
    "ax.set_title(f'NLSQ Fit (R² = {metrics['R2']:.6f})', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, which='both', alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "ax = axes[1]\n",
    "residuals_prime = (G_prime - G_prime_fit) / G_prime_fit * 100\n",
    "residuals_double_prime = (G_double_prime - G_double_prime_fit) / G_double_prime_fit * 100\n",
    "ax.semilogx(omega, residuals_prime, 'o-', label=\"G' Residuals\", markersize=6)\n",
    "ax.semilogx(omega, residuals_double_prime, 's-', label=\"G'' Residuals\", markersize=6)\n",
    "ax.axhline(0, color='k', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel('Angular Frequency ω (rad/s)', fontsize=12)\n",
    "ax.set_ylabel('Residuals (%)', fontsize=12)\n",
    "ax.set_title('Fit Residuals', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, which='both', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bayesian Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian inference with NLSQ warm-start (critical for convergence)\n",
    "logger.info(\"\\nStarting Bayesian inference (NUTS)...\")\n",
    "logger.info(\"Using NLSQ solution as warm-start\")\n",
    "\n",
    "bayes_result = model.fit_bayesian(\n",
    "    rheo_data,\n",
    "    num_warmup=1000,\n",
    "    num_samples=2000,\n",
    "    num_chains=4,        # Production-ready diagnostics\n",
    "    seed=42,             # Reproducibility\n",
    "    progress_bar=True\n",
    ")\n",
    "\n",
    "logger.info(\"Bayesian inference complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ArviZ Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "# Convert to ArviZ InferenceData\n",
    "idata = az.from_numpyro(bayes_result.mcmc)\n",
    "\n",
    "# Summary statistics\n",
    "summary = az.summary(idata, hdi_prob=0.95)\n",
    "print(\"\\nBayesian Parameter Estimates (95% HDI):\")\n",
    "print(\"=\" * 80)\n",
    "print(summary)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check diagnostics\n",
    "logger.info(\"\\nDiagnostic Checks:\")\n",
    "for param in summary.index:\n",
    "    r_hat = summary.loc[param, 'r_hat']\n",
    "    ess_bulk = summary.loc[param, 'ess_bulk']\n",
    "    ess_tail = summary.loc[param, 'ess_tail']\n",
    "    \n",
    "    status = \"PASS\" if (r_hat < 1.01 and ess_bulk > 400 and ess_tail > 400) else \"WARN\"\n",
    "    logger.info(f\"{param:<10} R-hat={r_hat:.4f}, ESS_bulk={ess_bulk:.0f}, ESS_tail={ess_tail:.0f} [{status}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace plots (MCMC convergence)\n",
    "az.plot_trace(idata, compact=True, figsize=(12, 10))\n",
    "plt.suptitle('MCMC Trace Plots', fontsize=16, fontweight='bold', y=1.001)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest plot (credible intervals)\n",
    "az.plot_forest(idata, hdi_prob=0.95, figsize=(8, 6))\n",
    "plt.title('Parameter Credible Intervals (95% HDI)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot (correlations)\n",
    "az.plot_pair(\n",
    "    idata,\n",
    "    var_names=['G', 'eta_inf', 't_eq', 'f_0'],  # Focus on key parameters\n",
    "    divergences=True,\n",
    "    figsize=(10, 10)\n",
    ")\n",
    "plt.suptitle('Parameter Correlations', fontsize=16, fontweight='bold', y=1.001)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy plot (HMC diagnostics)\n",
    "az.plot_energy(idata, figsize=(8, 5))\n",
    "plt.title('HMC Energy Diagnostic', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cole-Cole Plot Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cole-Cole plot: G'' vs G' (should form semicircle for Maxwell model)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Data\n",
    "ax.plot(G_prime, G_double_prime, 'o', label='Data', markersize=10, alpha=0.7)\n",
    "\n",
    "# NLSQ fit\n",
    "ax.plot(G_prime_fit, G_double_prime_fit, '-', label='NLSQ Fit', linewidth=2)\n",
    "\n",
    "# Theoretical semicircle (Maxwell)\n",
    "G_fit_param = fitted_params['G']\n",
    "theta = np.linspace(0, np.pi, 100)\n",
    "G_circle = G_fit_param / 2 * (1 + np.cos(theta))\n",
    "G_double_circle = G_fit_param / 2 * np.sin(theta)\n",
    "ax.plot(G_circle, G_double_circle, '--', color='gray', label='Maxwell Semicircle', linewidth=2, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel(\"G' (Storage Modulus) [Pa]\", fontsize=12)\n",
    "ax.set_ylabel(\"G'' (Loss Modulus) [Pa]\", fontsize=12)\n",
    "ax.set_title('Cole-Cole Plot', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "logger.info(\"Cole-Cole analysis: Data should follow semicircle for ideal Maxwell behavior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Posterior Predictive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute credible intervals from posterior samples\n",
    "posterior_samples = bayes_result.posterior_samples\n",
    "n_samples = len(posterior_samples['G'])\n",
    "\n",
    "# Random subset for efficiency (100 posterior samples)\n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(n_samples, size=min(100, n_samples), replace=False)\n",
    "\n",
    "G_posterior_samples = []\n",
    "for idx in sample_indices:\n",
    "    # Set parameters from posterior sample\n",
    "    model.set_params(**{k: v[idx] for k, v in posterior_samples.items()})\n",
    "    G_pred = model.predict(omega, test_mode='oscillation', return_components=True)\n",
    "    G_posterior_samples.append(G_pred)\n",
    "\n",
    "G_posterior_samples = np.array(G_posterior_samples)\n",
    "G_prime_posterior = G_posterior_samples.real\n",
    "G_double_prime_posterior = G_posterior_samples.imag\n",
    "\n",
    "# Compute percentiles\n",
    "G_prime_median = np.median(G_prime_posterior, axis=0)\n",
    "G_prime_lower = np.percentile(G_prime_posterior, 2.5, axis=0)\n",
    "G_prime_upper = np.percentile(G_prime_posterior, 97.5, axis=0)\n",
    "\n",
    "G_double_prime_median = np.median(G_double_prime_posterior, axis=0)\n",
    "G_double_prime_lower = np.percentile(G_double_prime_posterior, 2.5, axis=0)\n",
    "G_double_prime_upper = np.percentile(G_double_prime_posterior, 97.5, axis=0)\n",
    "\n",
    "logger.info(\"Posterior predictive credible intervals computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with credible intervals\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Data\n",
    "ax.loglog(omega, G_prime, 'o', label=\"G' (Data)\", markersize=8, alpha=0.7, color='C0')\n",
    "ax.loglog(omega, G_double_prime, 's', label=\"G'' (Data)\", markersize=8, alpha=0.7, color='C1')\n",
    "\n",
    "# Posterior median\n",
    "ax.loglog(omega, G_prime_median, '-', label=\"G' (Posterior Median)\", linewidth=2, color='C0')\n",
    "ax.loglog(omega, G_double_prime_median, '-', label=\"G'' (Posterior Median)\", linewidth=2, color='C1')\n",
    "\n",
    "# 95% credible intervals\n",
    "ax.fill_between(omega, G_prime_lower, G_prime_upper, alpha=0.3, color='C0', label=\"G' 95% CI\")\n",
    "ax.fill_between(omega, G_double_prime_lower, G_double_prime_upper, alpha=0.3, color='C1', label=\"G'' 95% CI\")\n",
    "\n",
    "ax.set_xlabel('Angular Frequency ω (rad/s)', fontsize=12)\n",
    "ax.set_ylabel('Modulus (Pa)', fontsize=12)\n",
    "ax.set_title('Bayesian Posterior Predictive (95% Credible Intervals)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=9, loc='best')\n",
    "ax.grid(True, which='both', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path('../outputs/fluidity/saramito_local/saos')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save NLSQ results\n",
    "nlsq_results = {\n",
    "    'parameters': fitted_params,\n",
    "    'r_squared': metrics[\"R2\"],\n",
    "    'rmse': float(np.sqrt(result.cost)),\n",
    "    'iterations': result.nit,\n",
    "    'success': result.success\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(output_dir / 'nlsq_results.json', 'w') as f:\n",
    "    json.dump(nlsq_results, f, indent=2)\n",
    "\n",
    "# Save posterior samples\n",
    "np.savez(\n",
    "    output_dir / 'posterior_samples.npz',\n",
    "    **posterior_samples\n",
    ")\n",
    "\n",
    "# Save summary statistics\n",
    "summary.to_csv(output_dir / 'bayesian_summary.csv')\n",
    "\n",
    "# Save ArviZ InferenceData\n",
    "idata.to_netcdf(output_dir / 'inference_data.nc')\n",
    "\n",
    "logger.info(f\"Results saved to {output_dir}\")\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  - nlsq_results.json\")\n",
    "print(f\"  - posterior_samples.npz\")\n",
    "print(f\"  - bayesian_summary.csv\")\n",
    "print(f\"  - inference_data.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Takeaways\n",
    "\n",
    "### Physical Insights\n",
    "\n",
    "1. **Maxwell-like SAOS behavior:**\n",
    "   - Storage modulus G'(ω) transitions from ω² (viscous) to plateau (elastic)\n",
    "   - Loss modulus G''(ω) exhibits peak at crossover frequency ω_c = 1/λ\n",
    "   - Cole-Cole plot forms semicircle (characteristic of single relaxation time)\n",
    "\n",
    "2. **Thixotropic signatures:**\n",
    "   - Initial fluidity f_0 affects transient approach to steady oscillation\n",
    "   - Equilibrium time t_eq controls structural recovery during rest periods\n",
    "   - Yield stress τ_y has minimal effect in linear regime (γ_0 ≪ 1)\n",
    "\n",
    "3. **Parameter identifiability:**\n",
    "   - Elastic modulus G well-constrained by high-frequency plateau\n",
    "   - Viscosity η_∞ (via fluidity) from low-frequency slope G'' ~ ω\n",
    "   - Relaxation time λ from crossover frequency ω_c\n",
    "   - Thixotropic parameters (b, n, t_eq) weakly identifiable from SAOS alone\n",
    "\n",
    "### Computational Best Practices\n",
    "\n",
    "4. **NLSQ warm-start critical:**\n",
    "   - Bayesian inference requires good initialization (use `.fit()` first)\n",
    "   - Multi-start optimization recommended for complex models\n",
    "   - Check R² > 0.95 before proceeding to Bayesian\n",
    "\n",
    "5. **Diagnostic interpretation:**\n",
    "   - R-hat < 1.01: chains converged\n",
    "   - ESS > 400: sufficient effective samples\n",
    "   - Energy plot: marginal/conditional distributions should match\n",
    "   - Divergences: indicate problematic geometry (reparameterize or increase warmup)\n",
    "\n",
    "6. **Model validation:**\n",
    "   - Cole-Cole semicircle confirms Maxwell backbone\n",
    "   - Residuals < 5% indicate good fit\n",
    "   - Posterior predictive intervals should encompass data\n",
    "\n",
    "### Experimental Design\n",
    "\n",
    "7. **Frequency sweep strategy:**\n",
    "   - Log-spaced frequencies spanning 3-4 decades\n",
    "   - Include both low (viscous) and high (elastic) frequency limits\n",
    "   - Strain amplitude γ_0 < 1% to ensure linear regime\n",
    "\n",
    "8. **Pre-shearing protocol:**\n",
    "   - Control initial fluidity f_0 via rest time after pre-shear\n",
    "   - Long rest (t ≫ t_eq): fully structured (f → f_min)\n",
    "   - Short rest (t ≪ t_eq): partially rejuvenated (f > f_min)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **LAOS (Large-Amplitude Oscillatory Shear):** Nonlinear viscoelasticity and yield transition\n",
    "- **Startup flows:** Stress overshoot and thixotropic kinetics\n",
    "- **Step-strain relaxation:** Direct probe of relaxation time spectrum\n",
    "- **Combined protocols:** Simultaneous fitting of SAOS + flow curves for full parameter identification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}