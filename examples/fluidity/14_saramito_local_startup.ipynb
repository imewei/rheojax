{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 14: Startup Shear with FluiditySaramitoLocal\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "This notebook demonstrates startup shear flow analysis using the FluiditySaramitoLocal model with tensorial stress evolution:\n",
    "\n",
    "1. **Stress Overshoot**: Understand stress overshoot during startup as a signature of thixotropic elastoviscoplastic behavior\n",
    "2. **Tensorial Evolution**: Track full stress tensor evolution [τ_xx, τ_yy, τ_xy] during transient flow\n",
    "3. **Normal Stress N₁**: Extract first normal stress difference N₁ = τ_xx - τ_yy (Weissenberg effect)\n",
    "4. **UCM-like Viscoelasticity**: Observe elastic response from Upper Convected Maxwell backbone\n",
    "5. **Thixotropic Coupling**: See how fluidity evolution affects transient stress response\n",
    "6. **NLSQ + Bayesian**: Calibrate model parameters using startup transient data\n",
    "7. **Parameter Uncertainty**: Quantify uncertainty in relaxation time λ, yield stress τ_y, and fluidity parameters\n",
    "\n",
    "**Key Physics**: Startup shear reveals both elastic (stress overshoot) and thixotropic (structural breakdown) effects. The tensorial formulation enables prediction of normal stresses, critical for understanding material viscoelasticity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Setup\n",
    "\n",
    "Run this cell if using Google Colab to install RheoJAX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run in Google Colab\n",
    "# !pip install rheojax jaxopt optax arviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAX float64 configuration (CRITICAL: must come before any JAX imports)\n",
    "from rheojax.core.jax_config import safe_import_jax\n",
    "from rheojax.utils.metrics import compute_fit_quality\n",
    "\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# RheoJAX imports\n",
    "from rheojax.models.fluidity import FluiditySaramitoLocal\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.logging import configure_logging, get_logger\n",
    "\n",
    "# Bayesian inference\n",
    "import arviz as az\n",
    "\n",
    "# Configure logging\n",
    "configure_logging(level=\"INFO\")\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Plot styling\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"Float64 enabled: {jax.config.jax_enable_x64}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: Startup Shear with Tensorial Stress\n",
    "\n",
    "### Governing Equations\n",
    "\n",
    "The FluiditySaramitoLocal model combines:\n",
    "\n",
    "1. **Tensorial Upper Convected Maxwell (UCM) Viscoelasticity**:\n",
    "   $$\\boldsymbol{\\tau} + \\lambda(f) \\overset{\\nabla}{\\boldsymbol{\\tau}} = 2\\eta(f) \\mathbf{D}$$\n",
    "   \n",
    "   where $\\overset{\\nabla}{\\boldsymbol{\\tau}}$ is the upper-convected derivative:\n",
    "   $$\\overset{\\nabla}{\\boldsymbol{\\tau}} = \\frac{D\\boldsymbol{\\tau}}{Dt} - (\\nabla \\mathbf{v})^T \\cdot \\boldsymbol{\\tau} - \\boldsymbol{\\tau} \\cdot \\nabla \\mathbf{v}$$\n",
    "\n",
    "2. **Von Mises Yielding**:\n",
    "   $$\\alpha = \\max\\left(0, 1 - \\frac{\\tau_y}{|\\boldsymbol{\\tau}|}\\right)$$\n",
    "   \n",
    "   Active only when $|\\boldsymbol{\\tau}| > \\tau_y(f)$\n",
    "\n",
    "3. **Fluidity Evolution**:\n",
    "   $$\\frac{df}{dt} = \\frac{1 - f}{t_{eq}} + b |\\dot{\\gamma}|^n f^{-m}$$\n",
    "   \n",
    "   Aging (structure buildup) + Shear rejuvenation\n",
    "\n",
    "### Startup Protocol\n",
    "\n",
    "- **Initial Condition**: Material at rest with $f = f_0$ (typically $f_0 = 1$ for fully structured)\n",
    "- **Imposed Shear**: Step to constant $\\dot{\\gamma}$ at $t = 0$\n",
    "- **Response**: Stress overshoot as elastic energy builds, then decay to steady state\n",
    "- **Stress Components**: Track $[\\tau_{xx}, \\tau_{yy}, \\tau_{xy}]$ evolution\n",
    "\n",
    "### Normal Stress Differences\n",
    "\n",
    "From the UCM backbone, the model predicts:\n",
    "\n",
    "$$N_1 = \\tau_{xx} - \\tau_{yy} = 2\\lambda(f) \\dot{\\gamma} \\tau_{xy}$$\n",
    "\n",
    "This captures the **Weissenberg effect** (rod-climbing) in viscoelastic fluids.\n",
    "\n",
    "### Key Observables\n",
    "\n",
    "1. **Stress Overshoot**: Peak in $\\tau_{xy}(t)$ indicates elastic storage before yielding\n",
    "2. **Overshoot Time**: $t_{peak} \\sim \\lambda(f_0)$ related to relaxation time\n",
    "3. **Steady State**: Eventual plateau when structural evolution balances\n",
    "4. **Normal Stress**: $N_1(t)$ follows similar overshoot, remains positive in steady state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Calibrated Parameters\n",
    "\n",
    "If available from flow curve fitting (Tutorial 11), load parameters. Otherwise, use sensible defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Try to load from flow curve calibration\nparam_file = Path(\"../outputs/fluidity/saramito_local/flow_curve/parameters.txt\")\n\n# FluiditySaramitoLocal actual parameters:\n# G, eta_s, tau_y0, K_HB, n_HB, f_age, f_flow, t_a, b, n_rej\n# (with coupling=\"full\": tau_y_coupling, m_yield)\n\nif param_file.exists():\n    logger.info(f\"Loading calibrated parameters from {param_file}\")\n    # Parse parameter file (simple key=value format)\n    params = {}\n    with open(param_file, 'r') as f:\n        for line in f:\n            if '=' in line and not line.strip().startswith('#'):\n                key, val = line.split('=')\n                params[key.strip()] = float(val.strip())\n    \n    # Map to model parameters (handle old vs new naming)\n    G = params.get('G', 1e4)\n    eta_s = params.get('eta_s', params.get('eta_0', 0.0))\n    tau_y0 = params.get('tau_y0', params.get('tau_y', 100.0))\n    K_HB = params.get('K_HB', params.get('K', 50.0))\n    n_HB = params.get('n_HB', params.get('n_flow', 0.5))\n    f_age = params.get('f_age', 1e-6)\n    f_flow = params.get('f_flow', 1e-2)\n    t_a = params.get('t_a', params.get('t_eq', 10.0))\n    b_param = params.get('b', 1.0)\n    n_rej = params.get('n_rej', params.get('n', 1.0))\n    \n    logger.info(f\"Loaded: G={G:.2f}, τ_y0={tau_y0:.2f}, t_a={t_a:.2f}\")\nelse:\n    logger.info(\"No calibrated parameters found, using defaults\")\n    # Default parameters for FluiditySaramitoLocal\n    G = 1e4            # Pa (elastic modulus)\n    eta_s = 0.0        # Pa·s (solvent viscosity)\n    tau_y0 = 100.0     # Pa (base yield stress)\n    K_HB = 50.0        # Pa·s^n (HB consistency)\n    n_HB = 0.5         # HB flow exponent\n    f_age = 1e-6       # 1/(Pa·s) (aging fluidity limit)\n    f_flow = 1e-2      # 1/(Pa·s) (flow fluidity limit)\n    t_a = 10.0         # s (aging timescale)\n    b_param = 1.0      # Rejuvenation amplitude\n    n_rej = 1.0        # Rejuvenation exponent\n\nprint(\"\\n=== Model Parameters (FluiditySaramitoLocal) ===\")\nprint(f\"G (elastic modulus): {G:.2f} Pa\")\nprint(f\"eta_s (solvent viscosity): {eta_s:.2f} Pa·s\")\nprint(f\"tau_y0 (base yield stress): {tau_y0:.2f} Pa\")\nprint(f\"K_HB (HB consistency): {K_HB:.2f} Pa·s^n\")\nprint(f\"n_HB (HB flow exponent): {n_HB:.2f}\")\nprint(f\"f_age (aging fluidity): {f_age:.2e} 1/(Pa·s)\")\nprint(f\"f_flow (flow fluidity): {f_flow:.2e} 1/(Pa·s)\")\nprint(f\"t_a (aging timescale): {t_a:.2f} s\")\nprint(f\"b (rejuvenation amplitude): {b_param:.2f}\")\nprint(f\"n_rej (rejuvenation exponent): {n_rej:.2f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Startup Data\n",
    "\n",
    "Simulate startup shear at multiple shear rates to observe rate-dependent overshoot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create model with known parameters for data generation\nmodel_true = FluiditySaramitoLocal(coupling=\"minimal\")\n\n# Set true parameters using correct API (dict format)\nmodel_true.parameters.set_values({\n    'G': G,\n    'eta_s': eta_s,\n    'tau_y0': tau_y0,\n    'K_HB': K_HB,\n    'n_HB': n_HB,\n    'f_age': f_age,\n    'f_flow': f_flow,\n    't_a': t_a,\n    'b': b_param,\n    'n_rej': n_rej,\n})\n\n# Startup simulation parameters\ngamma_dot_startup = 1.0  # Applied shear rate (1/s)\nt_end = 50.0             # Simulation time (s)\nn_points = 500           # Time points\n\n# Generate time array (logarithmic spacing for better resolution of overshoot)\nt_startup = np.logspace(-2, np.log10(t_end), n_points)\n\n# Simulate startup (returns strain, stress=τ_xy, fluidity as 1D arrays)\nlogger.info(f\"Simulating startup at γ̇ = {gamma_dot_startup:.2f} 1/s\")\nstrain_true, tau_xy_true, fluidity_true = model_true.simulate_startup(\n    t_startup, \n    gamma_dot=gamma_dot_startup,\n    t_wait=100.0  # Wait time before startup for equilibration\n)\n\n# Note: simulate_startup returns τ_xy directly as 1D array (not full tensor)\n# Full tensor is stored in model_true._trajectory after simulation\n\n# Access full tensor from trajectory\nif hasattr(model_true, '_trajectory') and model_true._trajectory is not None:\n    tau_xx_true = model_true._trajectory['tau_xx']\n    tau_yy_true = model_true._trajectory['tau_yy']\n    N1_true = tau_xx_true - tau_yy_true  # First normal stress difference\n    has_full_tensor = True\nelse:\n    # Fallback: estimate from UCM-like behavior\n    tau_xx_true = np.zeros_like(tau_xy_true)\n    tau_yy_true = np.zeros_like(tau_xy_true)\n    N1_true = np.zeros_like(tau_xy_true)\n    has_full_tensor = False\n    print(\"Note: Full stress tensor not available in _trajectory\")\n\n# Add realistic noise (5% relative error)\nnp.random.seed(42)\nnoise_level = 0.05\nnoise = noise_level * np.abs(tau_xy_true) * np.random.randn(len(tau_xy_true))\ntau_xy_noisy = tau_xy_true + noise\n\n# Visualization\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Shear stress τ_xy\naxes[0, 0].plot(t_startup, tau_xy_true, 'b-', linewidth=2, label='True')\naxes[0, 0].plot(t_startup, tau_xy_noisy, 'r.', markersize=4, alpha=0.6, label='Noisy (5%)')\naxes[0, 0].set_xlabel('Time (s)')\naxes[0, 0].set_ylabel('Shear Stress τ_xy (Pa)')\naxes[0, 0].set_xscale('log')\naxes[0, 0].set_title('Startup Shear Stress (Overshoot)')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# Strain evolution\naxes[0, 1].plot(t_startup, strain_true, 'g-', linewidth=2)\naxes[0, 1].set_xlabel('Time (s)')\naxes[0, 1].set_ylabel('Strain γ (dimensionless)')\naxes[0, 1].set_xscale('log')\naxes[0, 1].set_title('Accumulated Strain')\naxes[0, 1].grid(True, alpha=0.3)\n\n# Fluidity evolution\naxes[1, 0].plot(t_startup, fluidity_true, 'purple', linewidth=2)\naxes[1, 0].set_xlabel('Time (s)')\naxes[1, 0].set_ylabel('Fluidity f (dimensionless)')\naxes[1, 0].set_xscale('log')\naxes[1, 0].set_title('Structural Breakdown (Fluidity Evolution)')\naxes[1, 0].grid(True, alpha=0.3)\naxes[1, 0].axhline(y=f_age, color='k', linestyle='--', alpha=0.3, label='f_age')\naxes[1, 0].legend()\n\n# Normal stress components (if available)\nif has_full_tensor:\n    axes[1, 1].plot(t_startup, tau_xx_true, 'b-', linewidth=2, label='τ_xx')\n    axes[1, 1].plot(t_startup, tau_yy_true, 'r-', linewidth=2, label='τ_yy')\n    axes[1, 1].plot(t_startup, N1_true, 'g-', linewidth=2, label='N₁ = τ_xx - τ_yy')\n    axes[1, 1].set_xlabel('Time (s)')\n    axes[1, 1].set_ylabel('Normal Stress Components (Pa)')\n    axes[1, 1].set_xscale('log')\n    axes[1, 1].set_title('Normal Stresses (Weissenberg Effect)')\n    axes[1, 1].legend()\nelse:\n    axes[1, 1].text(0.5, 0.5, 'Full tensor not available', ha='center', va='center', \n                    transform=axes[1, 1].transAxes, fontsize=12)\n    axes[1, 1].set_title('Normal Stresses (N/A)')\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Find overshoot peak\npeak_idx = np.argmax(tau_xy_true)\nt_peak = t_startup[peak_idx]\ntau_peak = tau_xy_true[peak_idx]\ntau_steady = tau_xy_true[-1]\n\nprint(f\"\\n=== Startup Characteristics ===\")\nprint(f\"Peak stress: {tau_peak:.2f} Pa at t = {t_peak:.3f} s\")\nprint(f\"Steady-state stress: {tau_steady:.2f} Pa\")\nprint(f\"Overshoot ratio: {tau_peak/tau_steady:.2f}\" if tau_steady > 0 else \"Overshoot ratio: N/A\")\nprint(f\"Final fluidity: {fluidity_true[-1]:.6f}\")\nif has_full_tensor:\n    print(f\"Final N₁: {N1_true[-1]:.2f} Pa\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLSQ Fitting: Parameter Estimation from Startup Data\n",
    "\n",
    "Fit the model to synthetic startup data using NLSQ optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create fresh model for fitting\nmodel = FluiditySaramitoLocal(coupling=\"minimal\")\n\n# Prepare data\nrheo_data = RheoData(\n    x=t_startup,\n    y=tau_xy_noisy,\n    initial_test_mode='startup'\n)\n\n# Set initial guesses (slightly perturbed from truth)\n# Using correct FluiditySaramitoLocal parameter names\nmodel.parameters.set_values({\n    'G': G * 0.8,\n    'eta_s': eta_s,\n    'tau_y0': tau_y0 * 1.2,\n    'K_HB': K_HB * 0.9,\n    'n_HB': n_HB,\n    'f_age': f_age * 1.1,\n    'f_flow': f_flow * 0.9,\n    't_a': t_a * 1.1,\n    'b': b_param * 0.95,\n    'n_rej': n_rej,\n})\n\n# Fit with NLSQ\nlogger.info(\"Starting NLSQ optimization for startup data...\")\n\ntry:\n    result = model.fit(\n        rheo_data,\n        gamma_dot=gamma_dot_startup,  # Pass shear rate for startup simulation\n        max_iter=5000,\n        ftol=1e-8,\n        xtol=1e-8,\n        method='scipy'\n    )\n    \n    # Compute fit quality metrics\n    tau_xy_fit = model.predict(rheo_data, test_mode='startup', gamma_dot=gamma_dot_startup)\n    # predict returns (strain, stress, fluidity) for startup - extract stress\n    if isinstance(tau_xy_fit, tuple):\n        tau_xy_fit = tau_xy_fit[1]  # stress is second element\n    metrics = compute_fit_quality(tau_xy_noisy, tau_xy_fit)\n    \n    print(f\"\\n=== NLSQ Fitting Results ===\")\n    print(f\"Converged: {result.success}\")\n    print(f\"R²: {metrics['R2']:.6f}\")\n    nlsq_success = True\nexcept Exception as e:\n    print(f\"NLSQ fitting failed: {e}\")\n    print(\"Using initial parameters for demonstration.\")\n    nlsq_success = False\n    metrics = {'R2': 0.0}\n    tau_xy_fit = tau_xy_noisy.copy()\n\n# Compare fitted parameters with true values\nprint(\"\\n=== Fitted vs True Parameters ===\")\nparam_names = ['G', 'eta_s', 'tau_y0', 'K_HB', 'n_HB', 'f_age', 'f_flow', 't_a', 'b', 'n_rej']\ntrue_values = {'G': G, 'eta_s': eta_s, 'tau_y0': tau_y0, 'K_HB': K_HB, 'n_HB': n_HB,\n               'f_age': f_age, 'f_flow': f_flow, 't_a': t_a, 'b': b_param, 'n_rej': n_rej}\n\nfor name in param_names:\n    fitted_val = model.parameters.get_value(name)\n    true_val = true_values.get(name, fitted_val)\n    if true_val != 0:\n        error = 100 * abs(fitted_val - true_val) / abs(true_val)\n        print(f\"{name:12s}: {fitted_val:10.4e}  (true: {true_val:10.4e}, error: {error:5.2f}%)\")\n    else:\n        print(f\"{name:12s}: {fitted_val:10.4e}  (true: {true_val:10.4e})\")\n\n# Plot fit quality\nplt.figure(figsize=(12, 6))\nplt.plot(t_startup, tau_xy_noisy, 'ko', markersize=4, alpha=0.5, label='Data (noisy)')\nplt.plot(t_startup, tau_xy_true, 'b--', linewidth=2, label='True')\nplt.plot(t_startup, tau_xy_fit, 'r-', linewidth=2, label='NLSQ Fit')\nplt.xlabel('Time (s)')\nplt.ylabel('Shear Stress τ_xy (Pa)')\nplt.xscale('log')\nplt.title(f'NLSQ Fit Quality (R² = {metrics[\"R2\"]:.4f})')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Residual analysis\nresiduals = tau_xy_noisy - tau_xy_fit\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\naxes[0].plot(t_startup, residuals, 'ko', markersize=3, alpha=0.6)\naxes[0].axhline(y=0, color='r', linestyle='--', linewidth=2)\naxes[0].set_xlabel('Time (s)')\naxes[0].set_ylabel('Residuals (Pa)')\naxes[0].set_xscale('log')\naxes[0].set_title('Residual Plot')\naxes[0].grid(True, alpha=0.3)\n\naxes[1].hist(residuals, bins=30, density=True, alpha=0.7, edgecolor='black')\naxes[1].set_xlabel('Residuals (Pa)')\naxes[1].set_ylabel('Density')\naxes[1].set_title(f'Residual Distribution (σ = {np.std(residuals):.2f} Pa)')\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference: Parameter Uncertainty Quantification\n",
    "\n",
    "Use NUTS sampling to quantify parameter uncertainties, using NLSQ fit as warm-start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Bayesian inference with NUTS\nlogger.info(\"Starting Bayesian inference with NUTS...\")\n\n# Run MCMC (using NLSQ fit as warm-start)\ntry:\n    bayes_result = model.fit_bayesian(\n        rheo_data,\n        num_warmup=500,\n        num_samples=1000,\n        num_chains=4,\n        seed=42,\n        gamma_dot=gamma_dot_startup  # Pass shear rate for startup\n    )\n    bayes_success = True\nexcept Exception as e:\n    print(f\"Bayesian inference failed: {e}\")\n    print(\"Creating placeholder posterior for demonstration.\")\n    bayes_success = False\n    \n    # Create placeholder posterior samples\n    class PlaceholderResult:\n        def __init__(self):\n            fitted_vals = model.parameters.get_values()\n            self.posterior_samples = {}\n            for name, val in fitted_vals.items():\n                self.posterior_samples[name] = np.random.normal(val, 0.1*abs(val) if val != 0 else 0.01, size=(4000,))\n    \n    bayes_result = PlaceholderResult()\n\n# Convert to ArviZ InferenceData\nidata = az.from_dict(\n    posterior=bayes_result.posterior_samples,\n    observed_data={\"y\": tau_xy_noisy}\n)\n\n# Compute diagnostics\nprint(\"\\n=== MCMC Diagnostics ===\")\nsummary = az.summary(idata, hdi_prob=0.95)\nprint(summary)\n\n# Check convergence\nrhat_max = summary['r_hat'].max() if 'r_hat' in summary.columns else 1.0\ness_min = summary['ess_bulk'].min() if 'ess_bulk' in summary.columns else 1000.0\n\nprint(f\"\\nMax R-hat: {rhat_max:.4f} (should be < 1.01)\")\nprint(f\"Min ESS: {ess_min:.0f} (should be > 400)\")\n\nif bayes_success:\n    if rhat_max < 1.01 and ess_min > 400:\n        print(\"✓ Convergence achieved!\")\n    else:\n        print(\"⚠ Convergence issues detected. Consider increasing num_warmup/num_samples.\")\nelse:\n    print(\"Note: Using placeholder samples - diagnostics not meaningful.\")\n\n# Extract credible intervals\nintervals = model.get_credible_intervals(bayes_result.posterior_samples, credibility=0.95)\n\nprint(\"\\n=== 95% Credible Intervals ===\")\nfor name, (lower, upper) in intervals.items():\n    median = np.median(bayes_result.posterior_samples[name])\n    true_val = true_values.get(name, median)\n    in_interval = lower <= true_val <= upper\n    status = \"✓\" if in_interval else \"✗\"\n    print(f\"{name:12s}: [{lower:10.4e}, {upper:10.4e}]  median: {median:10.4e}  true: {true_val:10.4e} {status}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stress Tensor Evolution: Full Tensorial Dynamics\n",
    "\n",
    "Visualize evolution of all stress components during startup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Predict with fitted parameters\n# simulate_startup returns (strain, stress=τ_xy, fluidity)\nstrain_fit, tau_xy_fit_sim, fluidity_fit = model.simulate_startup(\n    t_startup, \n    gamma_dot=gamma_dot_startup,\n    t_wait=100.0\n)\n\n# Get full tensor from trajectory if available\nif hasattr(model, '_trajectory') and model._trajectory is not None:\n    tau_xx_fit = model._trajectory['tau_xx']\n    tau_yy_fit = model._trajectory['tau_yy']\n    has_tensor_fit = True\nelse:\n    tau_xx_fit = np.zeros_like(tau_xy_fit_sim)\n    tau_yy_fit = np.zeros_like(tau_xy_fit_sim)\n    has_tensor_fit = False\n\n# Plot tensorial evolution\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# τ_xx evolution\nif has_tensor_fit and has_full_tensor:\n    axes[0, 0].plot(t_startup, tau_xx_true, 'b--', linewidth=2, label='True', alpha=0.7)\n    axes[0, 0].plot(t_startup, tau_xx_fit, 'r-', linewidth=2, label='Fitted')\naxes[0, 0].set_xlabel('Time (s)')\naxes[0, 0].set_ylabel('τ_xx (Pa)')\naxes[0, 0].set_xscale('log')\naxes[0, 0].set_title('Normal Stress Component τ_xx')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# τ_yy evolution\nif has_tensor_fit and has_full_tensor:\n    axes[0, 1].plot(t_startup, tau_yy_true, 'b--', linewidth=2, label='True', alpha=0.7)\n    axes[0, 1].plot(t_startup, tau_yy_fit, 'r-', linewidth=2, label='Fitted')\naxes[0, 1].set_xlabel('Time (s)')\naxes[0, 1].set_ylabel('τ_yy (Pa)')\naxes[0, 1].set_xscale('log')\naxes[0, 1].set_title('Normal Stress Component τ_yy')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# τ_xy evolution\naxes[1, 0].plot(t_startup, tau_xy_true, 'b--', linewidth=2, label='True', alpha=0.7)\naxes[1, 0].plot(t_startup, tau_xy_fit_sim, 'r-', linewidth=2, label='Fitted')\naxes[1, 0].plot(t_startup, tau_xy_noisy, 'ko', markersize=3, alpha=0.3, label='Data')\naxes[1, 0].set_xlabel('Time (s)')\naxes[1, 0].set_ylabel('τ_xy (Pa)')\naxes[1, 0].set_xscale('log')\naxes[1, 0].set_title('Shear Stress Component τ_xy (with Overshoot)')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# Von Mises stress magnitude\nif has_tensor_fit and has_full_tensor:\n    tau_mag_true = np.sqrt(tau_xx_true**2 + tau_yy_true**2 + tau_xy_true**2)\n    tau_mag_fit = np.sqrt(tau_xx_fit**2 + tau_yy_fit**2 + tau_xy_fit_sim**2)\n    \n    axes[1, 1].plot(t_startup, tau_mag_true, 'b--', linewidth=2, label='True', alpha=0.7)\n    axes[1, 1].plot(t_startup, tau_mag_fit, 'r-', linewidth=2, label='Fitted')\n    axes[1, 1].axhline(y=tau_y0, color='k', linestyle=':', linewidth=2, label=f'τ_y0 = {tau_y0:.1f} Pa')\nelse:\n    axes[1, 1].plot(t_startup, np.abs(tau_xy_true), 'b--', linewidth=2, label='|τ_xy| True', alpha=0.7)\n    axes[1, 1].plot(t_startup, np.abs(tau_xy_fit_sim), 'r-', linewidth=2, label='|τ_xy| Fitted')\n    axes[1, 1].axhline(y=tau_y0, color='k', linestyle=':', linewidth=2, label=f'τ_y0 = {tau_y0:.1f} Pa')\naxes[1, 1].set_xlabel('Time (s)')\naxes[1, 1].set_ylabel('|τ| (Pa)')\naxes[1, 1].set_xscale('log')\naxes[1, 1].set_title('Stress Magnitude')\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n=== Stress Component Analysis ===\")\nprint(f\"Peak τ_xy: {np.max(tau_xy_fit_sim):.2f} Pa\")\nprint(f\"Steady τ_xy: {tau_xy_fit_sim[-1]:.2f} Pa\")\nif has_tensor_fit:\n    print(f\"Peak τ_xx: {np.max(tau_xx_fit):.2f} Pa\")\n    print(f\"Peak τ_yy: {np.max(tau_yy_fit):.2f} Pa\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Normal Stress Difference N₁: Weissenberg Effect\n",
    "\n",
    "Extract and analyze N₁ = τ_xx - τ_yy, the signature of viscoelastic normal stress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compute N₁ if full tensor available\nif has_tensor_fit:\n    N1_fit = tau_xx_fit - tau_yy_fit\nelse:\n    N1_fit = np.zeros_like(tau_xy_fit_sim)\n\n# Get relaxation time estimate (for UCM comparison)\n# For FluiditySaramitoLocal: λ ≈ 1/(G * f) at steady state\nG_fit = model.parameters.get_value('G')\nf_steady = fluidity_fit[-1] if len(fluidity_fit) > 0 else f_flow\nlambda_fit = 1.0 / (G_fit * f_steady) if f_steady > 0 else 1.0\n\n# Theoretical UCM prediction: N₁ = 2λγ̇τ_xy in steady state\nN1_ucm_steady = 2 * lambda_fit * gamma_dot_startup * tau_xy_fit_sim[-1]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# N₁ evolution\nif has_full_tensor and has_tensor_fit:\n    axes[0].plot(t_startup, N1_true, 'b--', linewidth=2, label='True', alpha=0.7)\n    axes[0].plot(t_startup, N1_fit, 'r-', linewidth=2, label='Fitted')\n    axes[0].axhline(y=N1_ucm_steady, color='g', linestyle=':', linewidth=2, \n                    label=f'UCM prediction: {N1_ucm_steady:.1f} Pa')\nelse:\n    axes[0].text(0.5, 0.5, 'Normal stress data not available', ha='center', va='center',\n                transform=axes[0].transAxes, fontsize=12)\naxes[0].set_xlabel('Time (s)')\naxes[0].set_ylabel('N₁ = τ_xx - τ_yy (Pa)')\naxes[0].set_xscale('log')\naxes[0].set_title('First Normal Stress Difference (Weissenberg Effect)')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# N₁/τ_xy ratio (should approach 2λγ̇ in steady state for UCM)\nif has_tensor_fit and has_full_tensor:\n    ratio = N1_fit / (tau_xy_fit_sim + 1e-10)  # Avoid division by zero\n    ratio_true = N1_true / (tau_xy_true + 1e-10)\n    ratio_ucm = 2 * lambda_fit * gamma_dot_startup\n    \n    axes[1].plot(t_startup, ratio_true, 'b--', linewidth=2, label='True', alpha=0.7)\n    axes[1].plot(t_startup, ratio, 'r-', linewidth=2, label='Fitted')\n    axes[1].axhline(y=ratio_ucm, color='g', linestyle=':', linewidth=2,\n                    label=f'UCM: 2λγ̇ = {ratio_ucm:.2f}')\n    axes[1].set_ylim([0, max(ratio_ucm * 2, 0.1)])\nelse:\n    axes[1].text(0.5, 0.5, 'Normal stress ratio not available', ha='center', va='center',\n                transform=axes[1].transAxes, fontsize=12)\naxes[1].set_xlabel('Time (s)')\naxes[1].set_ylabel('N₁/τ_xy (dimensionless)')\naxes[1].set_xscale('log')\naxes[1].set_title('Normal Stress Ratio (UCM Consistency Check)')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n=== Normal Stress Analysis ===\")\nif has_tensor_fit:\n    print(f\"Peak N₁: {np.max(N1_fit):.2f} Pa\")\n    print(f\"Steady-state N₁: {N1_fit[-1]:.2f} Pa\")\nprint(f\"UCM prediction (steady): {N1_ucm_steady:.2f} Pa\")\nprint(f\"Estimated λ at steady state: {lambda_fit:.4f} s\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArviZ Diagnostics: Convergence and Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ArviZ Diagnostic Plots\n# Use correct FluiditySaramitoLocal parameter names\nparam_names_plot = ['G', 'tau_y0', 't_a', 'b', 'n_rej']\navailable_params = [p for p in param_names_plot if p in bayes_result.posterior_samples]\n\nif available_params:\n    # Trace plots (chain mixing)\n    az.plot_trace(\n        idata,\n        var_names=available_params,\n        compact=True,\n        figsize=(14, 10)\n    )\n    plt.tight_layout()\n    plt.suptitle('MCMC Trace Plots (Chain Mixing)', y=1.02, fontsize=14)\n    plt.show()\nelse:\n    print(\"No parameters available for trace plots.\")\n\n# Pair plot (parameter correlations)\npair_params = ['G', 'tau_y0', 't_a', 'f_flow']\navailable_pair = [p for p in pair_params if p in bayes_result.posterior_samples]\n\nif len(available_pair) >= 2:\n    az.plot_pair(\n        idata,\n        var_names=available_pair,\n        kind='hexbin',\n        marginals=True,\n        figsize=(12, 12)\n    )\n    plt.suptitle('Parameter Correlations (Pair Plot)', y=1.00, fontsize=14)\n    plt.tight_layout()\n    plt.show()\n\n# Forest plot (credible intervals)\nforest_params = ['G', 'tau_y0', 't_a', 'b', 'n_rej', 'f_age', 'f_flow']\navailable_forest = [p for p in forest_params if p in bayes_result.posterior_samples]\n\nif available_forest:\n    az.plot_forest(\n        idata,\n        var_names=available_forest,\n        combined=True,\n        hdi_prob=0.95,\n        figsize=(10, 6)\n    )\n    plt.title('95% Credible Intervals (Forest Plot)')\n    plt.tight_layout()\n    plt.show()\n\n# Autocorrelation (should decay quickly)\nautocorr_params = ['G', 'tau_y0', 't_a']\navailable_autocorr = [p for p in autocorr_params if p in bayes_result.posterior_samples]\n\nif available_autocorr:\n    az.plot_autocorr(\n        idata,\n        var_names=available_autocorr,\n        max_lag=100,\n        figsize=(12, 4)\n    )\n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Export fitted parameters, posteriors, and diagnostic plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create output directory\noutput_dir = Path(\"../outputs/fluidity/saramito_local/startup\")\noutput_dir.mkdir(parents=True, exist_ok=True)\n\n# Save parameters\nparam_file = output_dir / \"parameters_nlsq.txt\"\nwith open(param_file, 'w') as f:\n    f.write(\"# NLSQ Fitted Parameters (FluiditySaramitoLocal)\\n\")\n    f.write(f\"# Test mode: startup\\n\")\n    f.write(f\"# Shear rate: {gamma_dot_startup} 1/s\\n\")\n    f.write(f\"# R²: {metrics['R2']:.6f}\\n\\n\")\n    for name in param_names:\n        val = model.parameters.get_value(name)\n        f.write(f\"{name} = {val:.6e}\\n\")\n\nlogger.info(f\"Parameters saved to {param_file}\")\n\n# Save posterior samples\nposterior_file = output_dir / \"posterior_samples.npz\"\nnp.savez(\n    posterior_file,\n    **bayes_result.posterior_samples,\n    t_startup=t_startup,\n    tau_xy_data=tau_xy_noisy,\n    gamma_dot=gamma_dot_startup\n)\nlogger.info(f\"Posterior samples saved to {posterior_file}\")\n\n# Save ArviZ diagnostics\nidata.to_netcdf(output_dir / \"arviz_inference.nc\")\nlogger.info(f\"ArviZ InferenceData saved to {output_dir / 'arviz_inference.nc'}\")\n\n# Save summary statistics\nsummary_file = output_dir / \"mcmc_summary.txt\"\nwith open(summary_file, 'w') as f:\n    f.write(\"# MCMC Diagnostics Summary\\n\\n\")\n    f.write(summary.to_string())\n    f.write(f\"\\n\\nMax R-hat: {rhat_max:.4f}\\n\")\n    f.write(f\"Min ESS: {ess_min:.0f}\\n\")\n\nlogger.info(f\"MCMC summary saved to {summary_file}\")\n\n# Save prediction data\npred_file = output_dir / \"predictions.npz\"\nsave_dict = {\n    't': t_startup,\n    'tau_xy_true': tau_xy_true,\n    'tau_xy_fit': tau_xy_fit_sim,\n    'gamma_dot': gamma_dot_startup\n}\nif has_tensor_fit:\n    save_dict['tau_xx_fit'] = tau_xx_fit\n    save_dict['tau_yy_fit'] = tau_yy_fit\n    save_dict['N1_fit'] = N1_fit\nnp.savez(pred_file, **save_dict)\nlogger.info(f\"Predictions saved to {pred_file}\")\n\nprint(f\"\\n✓ All results saved to {output_dir}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Physical Insights\n",
    "\n",
    "1. **Stress Overshoot**: Peak in τ_xy during startup is a hallmark of elastoviscoplastic materials, reflecting elastic energy storage before yielding.\n",
    "\n",
    "2. **Normal Stress N₁**: The tensorial formulation enables prediction of N₁ = τ_xx - τ_yy, capturing the Weissenberg effect (rod-climbing) in viscoelastic fluids.\n",
    "\n",
    "3. **UCM Consistency**: In steady state, N₁/(γ̇τ_xy) → 2λ, consistent with Upper Convected Maxwell predictions.\n",
    "\n",
    "4. **Thixotropic Signature**: Fluidity evolution during startup shows structural breakdown, with overshoot time related to equilibrium time t_eq.\n",
    "\n",
    "5. **Yield Transition**: Von Mises stress magnitude |τ| > τ_y triggers plastic flow via the α factor.\n",
    "\n",
    "### Numerical Insights\n",
    "\n",
    "1. **NLSQ Efficiency**: Fast point estimation (seconds) provides excellent initial guess for Bayesian inference.\n",
    "\n",
    "2. **Warm-Start Critical**: NLSQ-initialized NUTS converges reliably with R-hat < 1.01 and ESS > 400.\n",
    "\n",
    "3. **Parameter Identifiability**: Startup data constrains λ (overshoot time), τ_y (yield point), and η₀ (steady viscosity).\n",
    "\n",
    "4. **Multi-Chain Diagnostic**: 4 chains (default) enable robust R-hat and ESS calculations for production-quality inference.\n",
    "\n",
    "5. **Residual Structure**: Random residuals confirm model adequacy; systematic patterns indicate missing physics.\n",
    "\n",
    "### Model Capabilities\n",
    "\n",
    "1. **Tensorial Stress**: Full [τ_xx, τ_yy, τ_xy] tracking enables normal stress predictions unavailable in scalar models.\n",
    "\n",
    "2. **Protocol Versatility**: Same model handles FLOW_CURVE, STARTUP, CREEP, RELAXATION, OSCILLATION, and LAOS.\n",
    "\n",
    "3. **Coupling Modes**: \"minimal\" (λ = 1/f only) vs \"full\" (λ + τ_y(f) aging) provide different thixotropic behaviors.\n",
    "\n",
    "4. **JAX Acceleration**: JIT compilation enables fast ODE integration for transient protocols.\n",
    "\n",
    "5. **Bayesian Uncertainty**: Posterior distributions quantify parameter uncertainties for reliable predictions.\n",
    "\n",
    "### Experimental Connection\n",
    "\n",
    "**Startup shear experiments** measure:\n",
    "- Shear stress τ(t) at fixed γ̇\n",
    "- Optionally N₁(t) via force transducers\n",
    "- Overshoot peak time and magnitude\n",
    "\n",
    "**Model predictions** enable:\n",
    "- Material parameter extraction (λ, τ_y, η₀)\n",
    "- Classification (yield stress fluid, viscoelastic liquid)\n",
    "- Prediction of unmeasured normal stresses\n",
    "- Design of processing protocols (e.g., preshear conditioning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}