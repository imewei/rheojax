{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 14: Startup Shear with FluiditySaramitoLocal\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "This notebook demonstrates startup shear flow analysis using the FluiditySaramitoLocal model with tensorial stress evolution:\n",
    "\n",
    "1. **Stress Overshoot**: Understand stress overshoot during startup as a signature of thixotropic elastoviscoplastic behavior\n",
    "2. **Tensorial Evolution**: Track full stress tensor evolution [τ_xx, τ_yy, τ_xy] during transient flow\n",
    "3. **Normal Stress N₁**: Extract first normal stress difference N₁ = τ_xx - τ_yy (Weissenberg effect)\n",
    "4. **UCM-like Viscoelasticity**: Observe elastic response from Upper Convected Maxwell backbone\n",
    "5. **Thixotropic Coupling**: See how fluidity evolution affects transient stress response\n",
    "6. **NLSQ + Bayesian**: Calibrate model parameters using startup transient data\n",
    "7. **Parameter Uncertainty**: Quantify uncertainty in relaxation time λ, yield stress τ_y, and fluidity parameters\n",
    "\n",
    "**Key Physics**: Startup shear reveals both elastic (stress overshoot) and thixotropic (structural breakdown) effects. The tensorial formulation enables prediction of normal stresses, critical for understanding material viscoelasticity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Setup\n",
    "\n",
    "Run this cell if using Google Colab to install RheoJAX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run in Google Colab\n",
    "# !pip install rheojax jaxopt optax arviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAX float64 configuration (CRITICAL: must come before any JAX imports)\n",
    "from rheojax.core.jax_config import safe_import_jax\n",
    "\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# RheoJAX imports\n",
    "from rheojax.models.fluidity import FluiditySaramitoLocal\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.logging import configure_logging, get_logger\n",
    "\n",
    "# Bayesian inference\n",
    "import arviz as az\n",
    "\n",
    "# Configure logging\n",
    "configure_logging(level=\"INFO\")\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Plot styling\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"Float64 enabled: {jax.config.jax_enable_x64}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: Startup Shear with Tensorial Stress\n",
    "\n",
    "### Governing Equations\n",
    "\n",
    "The FluiditySaramitoLocal model combines:\n",
    "\n",
    "1. **Tensorial Upper Convected Maxwell (UCM) Viscoelasticity**:\n",
    "   $$\\boldsymbol{\\tau} + \\lambda(f) \\overset{\\nabla}{\\boldsymbol{\\tau}} = 2\\eta(f) \\mathbf{D}$$\n",
    "   \n",
    "   where $\\overset{\\nabla}{\\boldsymbol{\\tau}}$ is the upper-convected derivative:\n",
    "   $$\\overset{\\nabla}{\\boldsymbol{\\tau}} = \\frac{D\\boldsymbol{\\tau}}{Dt} - (\\nabla \\mathbf{v})^T \\cdot \\boldsymbol{\\tau} - \\boldsymbol{\\tau} \\cdot \\nabla \\mathbf{v}$$\n",
    "\n",
    "2. **Von Mises Yielding**:\n",
    "   $$\\alpha = \\max\\left(0, 1 - \\frac{\\tau_y}{|\\boldsymbol{\\tau}|}\\right)$$\n",
    "   \n",
    "   Active only when $|\\boldsymbol{\\tau}| > \\tau_y(f)$\n",
    "\n",
    "3. **Fluidity Evolution**:\n",
    "   $$\\frac{df}{dt} = \\frac{1 - f}{t_{eq}} + b |\\dot{\\gamma}|^n f^{-m}$$\n",
    "   \n",
    "   Aging (structure buildup) + Shear rejuvenation\n",
    "\n",
    "### Startup Protocol\n",
    "\n",
    "- **Initial Condition**: Material at rest with $f = f_0$ (typically $f_0 = 1$ for fully structured)\n",
    "- **Imposed Shear**: Step to constant $\\dot{\\gamma}$ at $t = 0$\n",
    "- **Response**: Stress overshoot as elastic energy builds, then decay to steady state\n",
    "- **Stress Components**: Track $[\\tau_{xx}, \\tau_{yy}, \\tau_{xy}]$ evolution\n",
    "\n",
    "### Normal Stress Differences\n",
    "\n",
    "From the UCM backbone, the model predicts:\n",
    "\n",
    "$$N_1 = \\tau_{xx} - \\tau_{yy} = 2\\lambda(f) \\dot{\\gamma} \\tau_{xy}$$\n",
    "\n",
    "This captures the **Weissenberg effect** (rod-climbing) in viscoelastic fluids.\n",
    "\n",
    "### Key Observables\n",
    "\n",
    "1. **Stress Overshoot**: Peak in $\\tau_{xy}(t)$ indicates elastic storage before yielding\n",
    "2. **Overshoot Time**: $t_{peak} \\sim \\lambda(f_0)$ related to relaxation time\n",
    "3. **Steady State**: Eventual plateau when structural evolution balances\n",
    "4. **Normal Stress**: $N_1(t)$ follows similar overshoot, remains positive in steady state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Calibrated Parameters\n",
    "\n",
    "If available from flow curve fitting (Tutorial 11), load parameters. Otherwise, use sensible defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load from flow curve calibration\n",
    "param_file = Path(\"../outputs/fluidity/saramito_local/flow_curve/parameters.txt\")\n",
    "\n",
    "if param_file.exists():\n",
    "    logger.info(f\"Loading calibrated parameters from {param_file}\")\n",
    "    # Parse parameter file (simple key=value format)\n",
    "    params = {}\n",
    "    with open(param_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if '=' in line and not line.strip().startswith('#'):\n",
    "                key, val = line.split('=')\n",
    "                params[key.strip()] = float(val.strip())\n",
    "    \n",
    "    # Extract relevant parameters\n",
    "    eta_0 = params.get('eta_0', 100.0)\n",
    "    tau_y = params.get('tau_y', 50.0)\n",
    "    lambda_0 = params.get('lambda_0', 1.0)\n",
    "    t_eq = params.get('t_eq', 10.0)\n",
    "    b = params.get('b', 0.5)\n",
    "    n = params.get('n', 1.0)\n",
    "    m = params.get('m', 0.0)\n",
    "    \n",
    "    logger.info(f\"Loaded: η₀={eta_0:.2f}, τ_y={tau_y:.2f}, λ₀={lambda_0:.2f}, t_eq={t_eq:.2f}\")\n",
    "else:\n",
    "    logger.info(\"No calibrated parameters found, using defaults\")\n",
    "    # Default parameters for demonstration\n",
    "    eta_0 = 100.0      # Zero-shear viscosity (Pa·s)\n",
    "    tau_y = 50.0       # Yield stress (Pa)\n",
    "    lambda_0 = 1.0     # Relaxation time at f=1 (s)\n",
    "    t_eq = 10.0        # Equilibrium aging time (s)\n",
    "    b = 0.5            # Rejuvenation coefficient\n",
    "    n = 1.0            # Shear-rate exponent\n",
    "    m = 0.0            # Fluidity exponent\n",
    "\n",
    "print(\"\\n=== Model Parameters ===\")\n",
    "print(f\"η₀ (zero-shear viscosity): {eta_0:.2f} Pa·s\")\n",
    "print(f\"τ_y (yield stress): {tau_y:.2f} Pa\")\n",
    "print(f\"λ₀ (relaxation time): {lambda_0:.2f} s\")\n",
    "print(f\"t_eq (aging time): {t_eq:.2f} s\")\n",
    "print(f\"b (rejuvenation): {b:.2f}\")\n",
    "print(f\"n (shear exponent): {n:.2f}\")\n",
    "print(f\"m (fluidity exponent): {m:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Startup Data\n",
    "\n",
    "Simulate startup shear at multiple shear rates to observe rate-dependent overshoot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with known parameters for data generation\n",
    "model_true = FluiditySaramitoLocal(coupling=\"full\")\n",
    "\n",
    "# Set true parameters\n",
    "model_true.parameters['eta_0'].value = eta_0\n",
    "model_true.parameters['tau_y'].value = tau_y\n",
    "model_true.parameters['lambda_0'].value = lambda_0\n",
    "model_true.parameters['t_eq'].value = t_eq\n",
    "model_true.parameters['b'].value = b\n",
    "model_true.parameters['n'].value = n\n",
    "model_true.parameters['m'].value = m\n",
    "\n",
    "# Startup simulation parameters\n",
    "gamma_dot_startup = 1.0  # Applied shear rate (1/s)\n",
    "t_end = 50.0             # Simulation time (s)\n",
    "n_points = 500           # Time points\n",
    "\n",
    "# Generate time array (logarithmic spacing for better resolution of overshoot)\n",
    "t_startup = np.logspace(-2, np.log10(t_end), n_points)\n",
    "\n",
    "# Simulate startup (returns strain, stress, fluidity)\n",
    "logger.info(f\"Simulating startup at γ̇ = {gamma_dot_startup:.2f} 1/s\")\n",
    "strain_true, stress_true, fluidity_true = model_true.simulate_startup(\n",
    "    t_startup, \n",
    "    gamma_dot=gamma_dot_startup,\n",
    "    t_wait=100.0  # Wait time before startup for equilibration\n",
    ")\n",
    "\n",
    "# Extract shear stress component (τ_xy)\n",
    "tau_xy_true = stress_true[:, 2]  # Third component is τ_xy\n",
    "\n",
    "# Add realistic noise (5% relative error)\n",
    "np.random.seed(42)\n",
    "noise_level = 0.05\n",
    "noise = noise_level * np.abs(tau_xy_true) * np.random.randn(len(tau_xy_true))\n",
    "tau_xy_noisy = tau_xy_true + noise\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Shear stress τ_xy\n",
    "axes[0, 0].plot(t_startup, tau_xy_true, 'b-', linewidth=2, label='True')\n",
    "axes[0, 0].plot(t_startup, tau_xy_noisy, 'r.', markersize=4, alpha=0.6, label='Noisy (5%)')\n",
    "axes[0, 0].set_xlabel('Time (s)')\n",
    "axes[0, 0].set_ylabel('Shear Stress τ_xy (Pa)')\n",
    "axes[0, 0].set_xscale('log')\n",
    "axes[0, 0].set_title('Startup Shear Stress (Overshoot)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Strain evolution\n",
    "axes[0, 1].plot(t_startup, strain_true, 'g-', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Time (s)')\n",
    "axes[0, 1].set_ylabel('Strain γ (dimensionless)')\n",
    "axes[0, 1].set_xscale('log')\n",
    "axes[0, 1].set_title('Accumulated Strain')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Fluidity evolution\n",
    "axes[1, 0].plot(t_startup, fluidity_true, 'purple', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Time (s)')\n",
    "axes[1, 0].set_ylabel('Fluidity f (dimensionless)')\n",
    "axes[1, 0].set_xscale('log')\n",
    "axes[1, 0].set_title('Structural Breakdown (Fluidity Evolution)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].axhline(y=1.0, color='k', linestyle='--', alpha=0.3, label='Initial')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Normal stress components\n",
    "tau_xx_true = stress_true[:, 0]\n",
    "tau_yy_true = stress_true[:, 1]\n",
    "N1_true = tau_xx_true - tau_yy_true  # First normal stress difference\n",
    "\n",
    "axes[1, 1].plot(t_startup, tau_xx_true, 'b-', linewidth=2, label='τ_xx')\n",
    "axes[1, 1].plot(t_startup, tau_yy_true, 'r-', linewidth=2, label='τ_yy')\n",
    "axes[1, 1].plot(t_startup, N1_true, 'g-', linewidth=2, label='N₁ = τ_xx - τ_yy')\n",
    "axes[1, 1].set_xlabel('Time (s)')\n",
    "axes[1, 1].set_ylabel('Normal Stress Components (Pa)')\n",
    "axes[1, 1].set_xscale('log')\n",
    "axes[1, 1].set_title('Normal Stresses (Weissenberg Effect)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find overshoot peak\n",
    "peak_idx = np.argmax(tau_xy_true)\n",
    "t_peak = t_startup[peak_idx]\n",
    "tau_peak = tau_xy_true[peak_idx]\n",
    "tau_steady = tau_xy_true[-1]\n",
    "\n",
    "print(f\"\\n=== Startup Characteristics ===\")\n",
    "print(f\"Peak stress: {tau_peak:.2f} Pa at t = {t_peak:.3f} s\")\n",
    "print(f\"Steady-state stress: {tau_steady:.2f} Pa\")\n",
    "print(f\"Overshoot ratio: {tau_peak/tau_steady:.2f}\")\n",
    "print(f\"Final fluidity: {fluidity_true[-1]:.3f}\")\n",
    "print(f\"Final N₁: {N1_true[-1]:.2f} Pa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLSQ Fitting: Parameter Estimation from Startup Data\n",
    "\n",
    "Fit the model to synthetic startup data using NLSQ optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fresh model for fitting\n",
    "model = FluiditySaramitoLocal(coupling=\"full\")\n",
    "\n",
    "# Prepare data\n",
    "rheo_data = RheoData(\n",
    "    x=t_startup,\n",
    "    y=tau_xy_noisy,\n",
    "    test_mode='startup'\n",
    ")\n",
    "\n",
    "# Set initial guesses (slightly perturbed from truth)\n",
    "model.parameters['eta_0'].value = eta_0 * 0.8\n",
    "model.parameters['tau_y'].value = tau_y * 1.2\n",
    "model.parameters['lambda_0'].value = lambda_0 * 0.9\n",
    "model.parameters['t_eq'].value = t_eq * 1.1\n",
    "model.parameters['b'].value = b * 0.95\n",
    "model.parameters['n'].value = n\n",
    "model.parameters['m'].value = m\n",
    "\n",
    "# Fit with NLSQ\n",
    "logger.info(\"Starting NLSQ optimization for startup data...\")\n",
    "result = model.fit(\n",
    "    rheo_data,\n",
    "    gamma_dot=gamma_dot_startup,  # Pass shear rate for startup simulation\n",
    "    max_iter=5000,\n",
    "    ftol=1e-8,\n",
    "    xtol=1e-8\n",
    ")\n",
    "\n",
    "print(f\"\\n=== NLSQ Fitting Results ===\")\n",
    "print(f\"Converged: {result.success}\")\n",
    "print(f\"Iterations: {result.nit}\")\n",
    "print(f\"Final cost: {result.cost:.6e}\")\n",
    "print(f\"R²: {result.r_squared:.6f}\")\n",
    "\n",
    "print(\"\\n=== Fitted Parameters ===\")\n",
    "for name, param in model.parameters.items():\n",
    "    true_val = model_true.parameters[name].value\n",
    "    error = 100 * abs(param.value - true_val) / true_val\n",
    "    print(f\"{name:12s}: {param.value:10.4f}  (true: {true_val:10.4f}, error: {error:5.2f}%)\")\n",
    "\n",
    "# Plot fit quality\n",
    "tau_xy_fit = model.predict(t_startup, test_mode='startup', gamma_dot=gamma_dot_startup)[:, 2]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(t_startup, tau_xy_noisy, 'ko', markersize=4, alpha=0.5, label='Data (noisy)')\n",
    "plt.plot(t_startup, tau_xy_true, 'b--', linewidth=2, label='True')\n",
    "plt.plot(t_startup, tau_xy_fit, 'r-', linewidth=2, label='NLSQ Fit')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Shear Stress τ_xy (Pa)')\n",
    "plt.xscale('log')\n",
    "plt.title(f'NLSQ Fit Quality (R² = {result.r_squared:.4f})')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residual analysis\n",
    "residuals = tau_xy_noisy - tau_xy_fit\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(t_startup, residuals, 'ko', markersize=3, alpha=0.6)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Time (s)')\n",
    "axes[0].set_ylabel('Residuals (Pa)')\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_title('Residual Plot')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].hist(residuals, bins=30, density=True, alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xlabel('Residuals (Pa)')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].set_title(f'Residual Distribution (σ = {np.std(residuals):.2f} Pa)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference: Parameter Uncertainty Quantification\n",
    "\n",
    "Use NUTS sampling to quantify parameter uncertainties, using NLSQ fit as warm-start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian inference with NUTS\n",
    "logger.info(\"Starting Bayesian inference with NUTS...\")\n",
    "\n",
    "# Run MCMC (using NLSQ fit as warm-start)\n",
    "bayes_result = model.fit_bayesian(\n",
    "    rheo_data,\n",
    "    num_warmup=1000,\n",
    "    num_samples=2000,\n",
    "    num_chains=4,\n",
    "    seed=42,\n",
    "    gamma_dot=gamma_dot_startup  # Pass shear rate for startup\n",
    ")\n",
    "\n",
    "# Convert to ArviZ InferenceData\n",
    "idata = az.from_dict(\n",
    "    posterior=bayes_result.posterior_samples,\n",
    "    observed_data={\"y\": tau_xy_noisy}\n",
    ")\n",
    "\n",
    "# Compute diagnostics\n",
    "print(\"\\n=== MCMC Diagnostics ===\")\n",
    "summary = az.summary(idata, hdi_prob=0.95)\n",
    "print(summary)\n",
    "\n",
    "# Check convergence\n",
    "rhat_max = summary['r_hat'].max()\n",
    "ess_min = summary['ess_bulk'].min()\n",
    "\n",
    "print(f\"\\nMax R-hat: {rhat_max:.4f} (should be < 1.01)\")\n",
    "print(f\"Min ESS: {ess_min:.0f} (should be > 400)\")\n",
    "\n",
    "if rhat_max < 1.01 and ess_min > 400:\n",
    "    print(\"✓ Convergence achieved!\")\n",
    "else:\n",
    "    print(\"⚠ Convergence issues detected. Consider increasing num_warmup/num_samples.\")\n",
    "\n",
    "# Extract credible intervals\n",
    "intervals = model.get_credible_intervals(bayes_result.posterior_samples, credibility=0.95)\n",
    "\n",
    "print(\"\\n=== 95% Credible Intervals ===\")\n",
    "for name, (lower, upper) in intervals.items():\n",
    "    median = np.median(bayes_result.posterior_samples[name])\n",
    "    true_val = model_true.parameters[name].value\n",
    "    in_interval = lower <= true_val <= upper\n",
    "    status = \"✓\" if in_interval else \"✗\"\n",
    "    print(f\"{name:12s}: [{lower:8.4f}, {upper:8.4f}]  median: {median:8.4f}  true: {true_val:8.4f} {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stress Tensor Evolution: Full Tensorial Dynamics\n",
    "\n",
    "Visualize evolution of all stress components during startup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with fitted parameters\n",
    "stress_fit = model.predict(t_startup, test_mode='startup', gamma_dot=gamma_dot_startup)\n",
    "\n",
    "# Extract components\n",
    "tau_xx_fit = stress_fit[:, 0]\n",
    "tau_yy_fit = stress_fit[:, 1]\n",
    "tau_xy_fit = stress_fit[:, 2]\n",
    "\n",
    "# Plot tensorial evolution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# τ_xx evolution\n",
    "axes[0, 0].plot(t_startup, tau_xx_true, 'b--', linewidth=2, label='True', alpha=0.7)\n",
    "axes[0, 0].plot(t_startup, tau_xx_fit, 'r-', linewidth=2, label='Fitted')\n",
    "axes[0, 0].set_xlabel('Time (s)')\n",
    "axes[0, 0].set_ylabel('τ_xx (Pa)')\n",
    "axes[0, 0].set_xscale('log')\n",
    "axes[0, 0].set_title('Normal Stress Component τ_xx')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# τ_yy evolution\n",
    "axes[0, 1].plot(t_startup, tau_yy_true, 'b--', linewidth=2, label='True', alpha=0.7)\n",
    "axes[0, 1].plot(t_startup, tau_yy_fit, 'r-', linewidth=2, label='Fitted')\n",
    "axes[0, 1].set_xlabel('Time (s)')\n",
    "axes[0, 1].set_ylabel('τ_yy (Pa)')\n",
    "axes[0, 1].set_xscale('log')\n",
    "axes[0, 1].set_title('Normal Stress Component τ_yy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# τ_xy evolution\n",
    "axes[1, 0].plot(t_startup, tau_xy_true, 'b--', linewidth=2, label='True', alpha=0.7)\n",
    "axes[1, 0].plot(t_startup, tau_xy_fit, 'r-', linewidth=2, label='Fitted')\n",
    "axes[1, 0].plot(t_startup, tau_xy_noisy, 'ko', markersize=3, alpha=0.3, label='Data')\n",
    "axes[1, 0].set_xlabel('Time (s)')\n",
    "axes[1, 0].set_ylabel('τ_xy (Pa)')\n",
    "axes[1, 0].set_xscale('log')\n",
    "axes[1, 0].set_title('Shear Stress Component τ_xy (with Overshoot)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Von Mises stress magnitude\n",
    "tau_mag_true = np.sqrt(tau_xx_true**2 + tau_yy_true**2 + tau_xy_true**2)\n",
    "tau_mag_fit = np.sqrt(tau_xx_fit**2 + tau_yy_fit**2 + tau_xy_fit**2)\n",
    "\n",
    "axes[1, 1].plot(t_startup, tau_mag_true, 'b--', linewidth=2, label='True', alpha=0.7)\n",
    "axes[1, 1].plot(t_startup, tau_mag_fit, 'r-', linewidth=2, label='Fitted')\n",
    "axes[1, 1].axhline(y=tau_y, color='k', linestyle=':', linewidth=2, label=f'τ_y = {tau_y:.1f} Pa')\n",
    "axes[1, 1].set_xlabel('Time (s)')\n",
    "axes[1, 1].set_ylabel('|τ| (Pa)')\n",
    "axes[1, 1].set_xscale('log')\n",
    "axes[1, 1].set_title('Von Mises Stress Magnitude (for Yielding)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Stress Component Analysis ===\")\n",
    "print(f\"Peak τ_xx: {np.max(tau_xx_fit):.2f} Pa\")\n",
    "print(f\"Peak τ_yy: {np.max(tau_yy_fit):.2f} Pa\")\n",
    "print(f\"Peak τ_xy: {np.max(tau_xy_fit):.2f} Pa\")\n",
    "print(f\"Steady τ_xx: {tau_xx_fit[-1]:.2f} Pa\")\n",
    "print(f\"Steady τ_yy: {tau_yy_fit[-1]:.2f} Pa\")\n",
    "print(f\"Steady τ_xy: {tau_xy_fit[-1]:.2f} Pa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Normal Stress Difference N₁: Weissenberg Effect\n",
    "\n",
    "Extract and analyze N₁ = τ_xx - τ_yy, the signature of viscoelastic normal stress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute N₁\n",
    "N1_fit = tau_xx_fit - tau_yy_fit\n",
    "\n",
    "# Theoretical prediction from UCM: N₁ = 2λγ̇τ_xy in steady state\n",
    "lambda_fit = model.parameters['lambda_0'].value\n",
    "N1_ucm_steady = 2 * lambda_fit * gamma_dot_startup * tau_xy_fit[-1]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# N₁ evolution\n",
    "axes[0].plot(t_startup, N1_true, 'b--', linewidth=2, label='True', alpha=0.7)\n",
    "axes[0].plot(t_startup, N1_fit, 'r-', linewidth=2, label='Fitted')\n",
    "axes[0].axhline(y=N1_ucm_steady, color='g', linestyle=':', linewidth=2, \n",
    "                label=f'UCM prediction: {N1_ucm_steady:.1f} Pa')\n",
    "axes[0].set_xlabel('Time (s)')\n",
    "axes[0].set_ylabel('N₁ = τ_xx - τ_yy (Pa)')\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_title('First Normal Stress Difference (Weissenberg Effect)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# N₁/τ_xy ratio (should approach 2λγ̇ in steady state for UCM)\n",
    "ratio = N1_fit / (tau_xy_fit + 1e-10)  # Avoid division by zero\n",
    "ratio_true = N1_true / (tau_xy_true + 1e-10)\n",
    "ratio_ucm = 2 * lambda_fit * gamma_dot_startup\n",
    "\n",
    "axes[1].plot(t_startup, ratio_true, 'b--', linewidth=2, label='True', alpha=0.7)\n",
    "axes[1].plot(t_startup, ratio, 'r-', linewidth=2, label='Fitted')\n",
    "axes[1].axhline(y=ratio_ucm, color='g', linestyle=':', linewidth=2,\n",
    "                label=f'UCM: 2λγ̇ = {ratio_ucm:.2f}')\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "axes[1].set_ylabel('N₁/τ_xy (dimensionless)')\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_title('Normal Stress Ratio (UCM Consistency Check)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim([0, ratio_ucm * 2])  # Reasonable y-axis limits\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Normal Stress Analysis ===\")\n",
    "print(f\"Peak N₁: {np.max(N1_fit):.2f} Pa\")\n",
    "print(f\"Steady-state N₁: {N1_fit[-1]:.2f} Pa\")\n",
    "print(f\"UCM prediction (steady): {N1_ucm_steady:.2f} Pa\")\n",
    "print(f\"Prediction accuracy: {100*(1 - abs(N1_fit[-1] - N1_ucm_steady)/N1_ucm_steady):.1f}%\")\n",
    "print(f\"\\nN₁/τ_xy steady ratio: {ratio[-1]:.3f}\")\n",
    "print(f\"UCM ratio (2λγ̇): {ratio_ucm:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArviZ Diagnostics: Convergence and Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace plots (chain mixing)\n",
    "az.plot_trace(\n",
    "    idata,\n",
    "    var_names=['eta_0', 'tau_y', 'lambda_0', 't_eq', 'b'],\n",
    "    compact=True,\n",
    "    figsize=(14, 10)\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.suptitle('MCMC Trace Plots (Chain Mixing)', y=1.02, fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Pair plot (parameter correlations)\n",
    "az.plot_pair(\n",
    "    idata,\n",
    "    var_names=['eta_0', 'tau_y', 'lambda_0', 't_eq'],\n",
    "    kind='hexbin',\n",
    "    marginals=True,\n",
    "    figsize=(12, 12)\n",
    ")\n",
    "plt.suptitle('Parameter Correlations (Pair Plot)', y=1.00, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Forest plot (credible intervals)\n",
    "az.plot_forest(\n",
    "    idata,\n",
    "    var_names=['eta_0', 'tau_y', 'lambda_0', 't_eq', 'b', 'n', 'm'],\n",
    "    combined=True,\n",
    "    hdi_prob=0.95,\n",
    "    figsize=(10, 6)\n",
    ")\n",
    "plt.title('95% Credible Intervals (Forest Plot)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Autocorrelation (should decay quickly)\n",
    "az.plot_autocorr(\n",
    "    idata,\n",
    "    var_names=['eta_0', 'tau_y', 'lambda_0'],\n",
    "    max_lag=100,\n",
    "    figsize=(12, 4)\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Rank plots (uniform if well-mixed)\n",
    "az.plot_rank(\n",
    "    idata,\n",
    "    var_names=['eta_0', 'tau_y', 'lambda_0', 't_eq'],\n",
    "    figsize=(12, 8)\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Export fitted parameters, posteriors, and diagnostic plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"../outputs/fluidity/saramito_local/startup\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save parameters\n",
    "param_file = output_dir / \"parameters_nlsq.txt\"\n",
    "with open(param_file, 'w') as f:\n",
    "    f.write(\"# NLSQ Fitted Parameters\\n\")\n",
    "    f.write(f\"# Test mode: startup\\n\")\n",
    "    f.write(f\"# Shear rate: {gamma_dot_startup} 1/s\\n\")\n",
    "    f.write(f\"# R²: {result.r_squared:.6f}\\n\\n\")\n",
    "    for name, param in model.parameters.items():\n",
    "        f.write(f\"{name} = {param.value:.6e}\\n\")\n",
    "\n",
    "logger.info(f\"Parameters saved to {param_file}\")\n",
    "\n",
    "# Save posterior samples\n",
    "posterior_file = output_dir / \"posterior_samples.npz\"\n",
    "np.savez(\n",
    "    posterior_file,\n",
    "    **bayes_result.posterior_samples,\n",
    "    t_startup=t_startup,\n",
    "    tau_xy_data=tau_xy_noisy,\n",
    "    gamma_dot=gamma_dot_startup\n",
    ")\n",
    "logger.info(f\"Posterior samples saved to {posterior_file}\")\n",
    "\n",
    "# Save ArviZ diagnostics\n",
    "idata.to_netcdf(output_dir / \"arviz_inference.nc\")\n",
    "logger.info(f\"ArviZ InferenceData saved to {output_dir / 'arviz_inference.nc'}\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_file = output_dir / \"mcmc_summary.txt\"\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(\"# MCMC Diagnostics Summary\\n\\n\")\n",
    "    f.write(summary.to_string())\n",
    "    f.write(f\"\\n\\nMax R-hat: {rhat_max:.4f}\\n\")\n",
    "    f.write(f\"Min ESS: {ess_min:.0f}\\n\")\n",
    "\n",
    "logger.info(f\"MCMC summary saved to {summary_file}\")\n",
    "\n",
    "# Save prediction data\n",
    "pred_file = output_dir / \"predictions.npz\"\n",
    "np.savez(\n",
    "    pred_file,\n",
    "    t=t_startup,\n",
    "    tau_xy_true=tau_xy_true,\n",
    "    tau_xy_fit=tau_xy_fit,\n",
    "    tau_xx_fit=tau_xx_fit,\n",
    "    tau_yy_fit=tau_yy_fit,\n",
    "    N1_fit=N1_fit,\n",
    "    gamma_dot=gamma_dot_startup\n",
    ")\n",
    "logger.info(f\"Predictions saved to {pred_file}\")\n",
    "\n",
    "print(f\"\\n✓ All results saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Physical Insights\n",
    "\n",
    "1. **Stress Overshoot**: Peak in τ_xy during startup is a hallmark of elastoviscoplastic materials, reflecting elastic energy storage before yielding.\n",
    "\n",
    "2. **Normal Stress N₁**: The tensorial formulation enables prediction of N₁ = τ_xx - τ_yy, capturing the Weissenberg effect (rod-climbing) in viscoelastic fluids.\n",
    "\n",
    "3. **UCM Consistency**: In steady state, N₁/(γ̇τ_xy) → 2λ, consistent with Upper Convected Maxwell predictions.\n",
    "\n",
    "4. **Thixotropic Signature**: Fluidity evolution during startup shows structural breakdown, with overshoot time related to equilibrium time t_eq.\n",
    "\n",
    "5. **Yield Transition**: Von Mises stress magnitude |τ| > τ_y triggers plastic flow via the α factor.\n",
    "\n",
    "### Numerical Insights\n",
    "\n",
    "1. **NLSQ Efficiency**: Fast point estimation (seconds) provides excellent initial guess for Bayesian inference.\n",
    "\n",
    "2. **Warm-Start Critical**: NLSQ-initialized NUTS converges reliably with R-hat < 1.01 and ESS > 400.\n",
    "\n",
    "3. **Parameter Identifiability**: Startup data constrains λ (overshoot time), τ_y (yield point), and η₀ (steady viscosity).\n",
    "\n",
    "4. **Multi-Chain Diagnostic**: 4 chains (default) enable robust R-hat and ESS calculations for production-quality inference.\n",
    "\n",
    "5. **Residual Structure**: Random residuals confirm model adequacy; systematic patterns indicate missing physics.\n",
    "\n",
    "### Model Capabilities\n",
    "\n",
    "1. **Tensorial Stress**: Full [τ_xx, τ_yy, τ_xy] tracking enables normal stress predictions unavailable in scalar models.\n",
    "\n",
    "2. **Protocol Versatility**: Same model handles FLOW_CURVE, STARTUP, CREEP, RELAXATION, OSCILLATION, and LAOS.\n",
    "\n",
    "3. **Coupling Modes**: \"minimal\" (λ = 1/f only) vs \"full\" (λ + τ_y(f) aging) provide different thixotropic behaviors.\n",
    "\n",
    "4. **JAX Acceleration**: JIT compilation enables fast ODE integration for transient protocols.\n",
    "\n",
    "5. **Bayesian Uncertainty**: Posterior distributions quantify parameter uncertainties for reliable predictions.\n",
    "\n",
    "### Experimental Connection\n",
    "\n",
    "**Startup shear experiments** measure:\n",
    "- Shear stress τ(t) at fixed γ̇\n",
    "- Optionally N₁(t) via force transducers\n",
    "- Overshoot peak time and magnitude\n",
    "\n",
    "**Model predictions** enable:\n",
    "- Material parameter extraction (λ, τ_y, η₀)\n",
    "- Classification (yield stress fluid, viscoelastic liquid)\n",
    "- Prediction of unmeasured normal stresses\n",
    "- Design of processing protocols (e.g., preshear conditioning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
