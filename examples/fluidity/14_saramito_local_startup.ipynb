{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 14: Startup Shear with FluiditySaramitoLocal\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "This notebook demonstrates startup shear flow analysis using the FluiditySaramitoLocal model with tensorial stress evolution:\n",
    "\n",
    "1. **Stress Overshoot**: Understand stress overshoot during startup as a signature of thixotropic elastoviscoplastic behavior\n",
    "2. **Tensorial Evolution**: Track full stress tensor evolution [τ_xx, τ_yy, τ_xy] during transient flow\n",
    "3. **Normal Stress N₁**: Extract first normal stress difference N₁ = τ_xx - τ_yy (Weissenberg effect)\n",
    "4. **UCM-like Viscoelasticity**: Observe elastic response from Upper Convected Maxwell backbone\n",
    "5. **Thixotropic Coupling**: See how fluidity evolution affects transient stress response\n",
    "6. **NLSQ + Bayesian**: Calibrate model parameters using startup transient data\n",
    "7. **Parameter Uncertainty**: Quantify uncertainty in relaxation time λ, yield stress τ_y, and fluidity parameters\n",
    "\n",
    "**Key Physics**: Startup shear reveals both elastic (stress overshoot) and thixotropic (structural breakdown) effects. The tensorial formulation enables prediction of normal stresses, critical for understanding material viscoelasticity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Setup\n",
    "\n",
    "Run this cell if using Google Colab to install RheoJAX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T19:49:41.763583Z",
     "iopub.status.busy": "2026-02-09T19:49:41.763366Z",
     "iopub.status.idle": "2026-02-09T19:49:41.767931Z",
     "shell.execute_reply": "2026-02-09T19:49:41.767082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment and run in Google Colab\n",
    "# !pip install rheojax jaxopt optax arviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T19:49:41.770279Z",
     "iopub.status.busy": "2026-02-09T19:49:41.770138Z",
     "iopub.status.idle": "2026-02-09T19:49:42.980229Z",
     "shell.execute_reply": "2026-02-09T19:49:42.979820Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "# JAX float64 configuration (CRITICAL: must come before any JAX imports)\n",
    "# Add examples root to path for shared utilities\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(\"\")))\n",
    "from utils.plotting_utils import (\n",
    "    display_arviz_diagnostics,\n",
    "    plot_nlsq_fit,\n",
    "    plot_posterior_predictive,\n",
    ")\n",
    "\n",
    "from rheojax.core.jax_config import safe_import_jax\n",
    "from rheojax.utils.metrics import compute_fit_quality\n",
    "\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "# Standard imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.logging import configure_logging, get_logger\n",
    "\n",
    "# RheoJAX imports\n",
    "from rheojax.models.fluidity import FluiditySaramitoLocal\n",
    "\n",
    "# Bayesian inference\n",
    "\n",
    "# Configure logging\n",
    "configure_logging(level=\"INFO\")\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Plot styling\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"Float64 enabled: {jax.config.jax_enable_x64}\")\n",
    "# Flag for conditional Bayesian sections\n",
    "bayesian_completed = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: Startup Shear with Tensorial Stress\n",
    "\n",
    "### Governing Equations\n",
    "\n",
    "The FluiditySaramitoLocal model combines:\n",
    "\n",
    "1. **Tensorial Upper Convected Maxwell (UCM) Viscoelasticity**:\n",
    "   $$\\boldsymbol{\\tau} + \\lambda(f) \\overset{\\nabla}{\\boldsymbol{\\tau}} = 2\\eta(f) \\mathbf{D}$$\n",
    "   \n",
    "   where $\\overset{\\nabla}{\\boldsymbol{\\tau}}$ is the upper-convected derivative:\n",
    "   $$\\overset{\\nabla}{\\boldsymbol{\\tau}} = \\frac{D\\boldsymbol{\\tau}}{Dt} - (\\nabla \\mathbf{v})^T \\cdot \\boldsymbol{\\tau} - \\boldsymbol{\\tau} \\cdot \\nabla \\mathbf{v}$$\n",
    "\n",
    "2. **Von Mises Yielding**:\n",
    "   $$\\alpha = \\max\\left(0, 1 - \\frac{\\tau_y}{|\\boldsymbol{\\tau}|}\\right)$$\n",
    "   \n",
    "   Active only when $|\\boldsymbol{\\tau}| > \\tau_y(f)$\n",
    "\n",
    "3. **Fluidity Evolution**:\n",
    "   $$\\frac{df}{dt} = \\frac{1 - f}{t_{eq}} + b |\\dot{\\gamma}|^n f^{-m}$$\n",
    "   \n",
    "   Aging (structure buildup) + Shear rejuvenation\n",
    "\n",
    "### Startup Protocol\n",
    "\n",
    "- **Initial Condition**: Material at rest with $f = f_0$ (typically $f_0 = 1$ for fully structured)\n",
    "- **Imposed Shear**: Step to constant $\\dot{\\gamma}$ at $t = 0$\n",
    "- **Response**: Stress overshoot as elastic energy builds, then decay to steady state\n",
    "- **Stress Components**: Track $[\\tau_{xx}, \\tau_{yy}, \\tau_{xy}]$ evolution\n",
    "\n",
    "### Normal Stress Differences\n",
    "\n",
    "From the UCM backbone, the model predicts:\n",
    "\n",
    "$$N_1 = \\tau_{xx} - \\tau_{yy} = 2\\lambda(f) \\dot{\\gamma} \\tau_{xy}$$\n",
    "\n",
    "This captures the **Weissenberg effect** (rod-climbing) in viscoelastic fluids.\n",
    "\n",
    "### Key Observables\n",
    "\n",
    "1. **Stress Overshoot**: Peak in $\\tau_{xy}(t)$ indicates elastic storage before yielding\n",
    "2. **Overshoot Time**: $t_{peak} \\sim \\lambda(f_0)$ related to relaxation time\n",
    "3. **Steady State**: Eventual plateau when structural evolution balances\n",
    "4. **Normal Stress**: $N_1(t)$ follows similar overshoot, remains positive in steady state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Calibrated Parameters\n",
    "\n",
    "If available from flow curve fitting (Tutorial 11), load parameters. Otherwise, use sensible defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T19:49:42.981700Z",
     "iopub.status.busy": "2026-02-09T19:49:42.981572Z",
     "iopub.status.idle": "2026-02-09T19:49:42.985741Z",
     "shell.execute_reply": "2026-02-09T19:49:42.985309Z"
    }
   },
   "outputs": [],
   "source": [
    "# Try to load from flow curve calibration\n",
    "param_file = Path(\"../outputs/fluidity/saramito_local/flow_curve/parameters.txt\")\n",
    "\n",
    "# FluiditySaramitoLocal actual parameters:\n",
    "# G, eta_s, tau_y0, K_HB, n_HB, f_age, f_flow, t_a, b, n_rej\n",
    "# (with coupling=\"full\": tau_y_coupling, m_yield)\n",
    "\n",
    "if param_file.exists():\n",
    "    logger.info(f\"Loading calibrated parameters from {param_file}\")\n",
    "    # Parse parameter file (simple key=value format)\n",
    "    params = {}\n",
    "    with open(param_file) as f:\n",
    "        for line in f:\n",
    "            if '=' in line and not line.strip().startswith('#'):\n",
    "                key, val = line.split('=')\n",
    "                params[key.strip()] = float(val.strip())\n",
    "    \n",
    "    # Map to model parameters (handle old vs new naming)\n",
    "    G = params.get('G', 1e4)\n",
    "    eta_s = params.get('eta_s', params.get('eta_0', 0.0))\n",
    "    tau_y0 = params.get('tau_y0', params.get('tau_y', 100.0))\n",
    "    K_HB = params.get('K_HB', params.get('K', 50.0))\n",
    "    n_HB = params.get('n_HB', params.get('n_flow', 0.5))\n",
    "    f_age = params.get('f_age', 1e-6)\n",
    "    f_flow = params.get('f_flow', 1e-2)\n",
    "    t_a = params.get('t_a', params.get('t_eq', 10.0))\n",
    "    b_param = params.get('b', 1.0)\n",
    "    n_rej = params.get('n_rej', params.get('n', 1.0))\n",
    "    \n",
    "    logger.info(f\"Loaded: G={G:.2f}, τ_y0={tau_y0:.2f}, t_a={t_a:.2f}\")\n",
    "else:\n",
    "    logger.info(\"No calibrated parameters found, using defaults\")\n",
    "    # Default parameters for FluiditySaramitoLocal\n",
    "    G = 1e4            # Pa (elastic modulus)\n",
    "    eta_s = 0.0        # Pa·s (solvent viscosity)\n",
    "    tau_y0 = 100.0     # Pa (base yield stress)\n",
    "    K_HB = 50.0        # Pa·s^n (HB consistency)\n",
    "    n_HB = 0.5         # HB flow exponent\n",
    "    f_age = 1e-6       # 1/(Pa·s) (aging fluidity limit)\n",
    "    f_flow = 1e-2      # 1/(Pa·s) (flow fluidity limit)\n",
    "    t_a = 10.0         # s (aging timescale)\n",
    "    b_param = 1.0      # Rejuvenation amplitude\n",
    "    n_rej = 1.0        # Rejuvenation exponent\n",
    "\n",
    "print(\"\\n=== Model Parameters (FluiditySaramitoLocal) ===\")\n",
    "print(f\"G (elastic modulus): {G:.2f} Pa\")\n",
    "print(f\"eta_s (solvent viscosity): {eta_s:.2f} Pa·s\")\n",
    "print(f\"tau_y0 (base yield stress): {tau_y0:.2f} Pa\")\n",
    "print(f\"K_HB (HB consistency): {K_HB:.2f} Pa·s^n\")\n",
    "print(f\"n_HB (HB flow exponent): {n_HB:.2f}\")\n",
    "print(f\"f_age (aging fluidity): {f_age:.2e} 1/(Pa·s)\")\n",
    "print(f\"f_flow (flow fluidity): {f_flow:.2e} 1/(Pa·s)\")\n",
    "print(f\"t_a (aging timescale): {t_a:.2f} s\")\n",
    "print(f\"b (rejuvenation amplitude): {b_param:.2f}\")\n",
    "print(f\"n_rej (rejuvenation exponent): {n_rej:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Startup Data\n",
    "\n",
    "Simulate startup shear at multiple shear rates to observe rate-dependent overshoot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T19:49:42.987031Z",
     "iopub.status.busy": "2026-02-09T19:49:42.986954Z",
     "iopub.status.idle": "2026-02-09T19:49:44.015293Z",
     "shell.execute_reply": "2026-02-09T19:49:44.014861Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create model with known parameters for data generation\n",
    "model_true = FluiditySaramitoLocal(coupling=\"minimal\")\n",
    "\n",
    "# Set true parameters using correct API (dict format)\n",
    "model_true.parameters.set_values({\n",
    "    'G': G,\n",
    "    'eta_s': eta_s,\n",
    "    'tau_y0': tau_y0,\n",
    "    'K_HB': K_HB,\n",
    "    'n_HB': n_HB,\n",
    "    'f_age': f_age,\n",
    "    'f_flow': f_flow,\n",
    "    't_a': t_a,\n",
    "    'b': b_param,\n",
    "    'n_rej': n_rej,\n",
    "})\n",
    "\n",
    "# Startup simulation parameters\n",
    "gamma_dot_startup = 1.0  # Applied shear rate (1/s)\n",
    "t_end = 50.0             # Simulation time (s)\n",
    "n_points = 500           # Time points\n",
    "\n",
    "# Generate time array (logarithmic spacing for better resolution of overshoot)\n",
    "t_startup = np.logspace(-2, np.log10(t_end), n_points)\n",
    "\n",
    "# Simulate startup (returns strain, stress=τ_xy, fluidity as 1D arrays)\n",
    "logger.info(f\"Simulating startup at γ̇ = {gamma_dot_startup:.2f} 1/s\")\n",
    "strain_true, tau_xy_true, fluidity_true = model_true.simulate_startup(\n",
    "    t_startup, \n",
    "    gamma_dot=gamma_dot_startup,\n",
    "    t_wait=100.0  # Wait time before startup for equilibration\n",
    ")\n",
    "\n",
    "# Note: simulate_startup returns τ_xy directly as 1D array (not full tensor)\n",
    "# Full tensor is stored in model_true._trajectory after simulation\n",
    "\n",
    "# Access full tensor from trajectory\n",
    "if hasattr(model_true, '_trajectory') and model_true._trajectory is not None:\n",
    "    tau_xx_true = model_true._trajectory['tau_xx']\n",
    "    tau_yy_true = model_true._trajectory['tau_yy']\n",
    "    N1_true = tau_xx_true - tau_yy_true  # First normal stress difference\n",
    "    has_full_tensor = True\n",
    "else:\n",
    "    # Fallback: estimate from UCM-like behavior\n",
    "    tau_xx_true = np.zeros_like(tau_xy_true)\n",
    "    tau_yy_true = np.zeros_like(tau_xy_true)\n",
    "    N1_true = np.zeros_like(tau_xy_true)\n",
    "    has_full_tensor = False\n",
    "    print(\"Note: Full stress tensor not available in _trajectory\")\n",
    "\n",
    "# Add realistic noise (5% relative error)\n",
    "np.random.seed(42)\n",
    "noise_level = 0.05\n",
    "noise = noise_level * np.abs(tau_xy_true) * np.random.randn(len(tau_xy_true))\n",
    "tau_xy_noisy = tau_xy_true + noise\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Shear stress τ_xy\n",
    "axes[0, 0].plot(t_startup, tau_xy_true, 'b-', linewidth=2, label='True')\n",
    "axes[0, 0].plot(t_startup, tau_xy_noisy, 'r.', markersize=4, alpha=0.6, label='Noisy (5%)')\n",
    "axes[0, 0].set_xlabel('Time (s)')\n",
    "axes[0, 0].set_ylabel('Shear Stress τ_xy (Pa)')\n",
    "axes[0, 0].set_xscale('log')\n",
    "axes[0, 0].set_title('Startup Shear Stress (Overshoot)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Strain evolution\n",
    "axes[0, 1].plot(t_startup, strain_true, 'g-', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Time (s)')\n",
    "axes[0, 1].set_ylabel('Strain γ (dimensionless)')\n",
    "axes[0, 1].set_xscale('log')\n",
    "axes[0, 1].set_title('Accumulated Strain')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Fluidity evolution\n",
    "axes[1, 0].plot(t_startup, fluidity_true, 'purple', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Time (s)')\n",
    "axes[1, 0].set_ylabel('Fluidity f (dimensionless)')\n",
    "axes[1, 0].set_xscale('log')\n",
    "axes[1, 0].set_title('Structural Breakdown (Fluidity Evolution)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].axhline(y=f_age, color='k', linestyle='--', alpha=0.3, label='f_age')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Normal stress components (if available)\n",
    "if has_full_tensor:\n",
    "    axes[1, 1].plot(t_startup, tau_xx_true, 'b-', linewidth=2, label='τ_xx')\n",
    "    axes[1, 1].plot(t_startup, tau_yy_true, 'r-', linewidth=2, label='τ_yy')\n",
    "    axes[1, 1].plot(t_startup, N1_true, 'g-', linewidth=2, label='N₁ = τ_xx - τ_yy')\n",
    "    axes[1, 1].set_xlabel('Time (s)')\n",
    "    axes[1, 1].set_ylabel('Normal Stress Components (Pa)')\n",
    "    axes[1, 1].set_xscale('log')\n",
    "    axes[1, 1].set_title('Normal Stresses (Weissenberg Effect)')\n",
    "    axes[1, 1].legend()\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'Full tensor not available', ha='center', va='center', \n",
    "                    transform=axes[1, 1].transAxes, fontsize=12)\n",
    "    axes[1, 1].set_title('Normal Stresses (N/A)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')\n",
    "\n",
    "# Find overshoot peak\n",
    "peak_idx = np.argmax(tau_xy_true)\n",
    "t_peak = t_startup[peak_idx]\n",
    "tau_peak = tau_xy_true[peak_idx]\n",
    "tau_steady = tau_xy_true[-1]\n",
    "\n",
    "print(f\"\\n=== Startup Characteristics ===\")\n",
    "print(f\"Peak stress: {tau_peak:.2f} Pa at t = {t_peak:.3f} s\")\n",
    "print(f\"Steady-state stress: {tau_steady:.2f} Pa\")\n",
    "print(f\"Overshoot ratio: {tau_peak/tau_steady:.2f}\" if tau_steady > 0 else \"Overshoot ratio: N/A\")\n",
    "print(f\"Final fluidity: {fluidity_true[-1]:.6f}\")\n",
    "if has_full_tensor:\n",
    "    print(f\"Final N₁: {N1_true[-1]:.2f} Pa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLSQ Fitting: Parameter Estimation from Startup Data\n",
    "\n",
    "Fit the model to synthetic startup data using NLSQ optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T19:49:44.017146Z",
     "iopub.status.busy": "2026-02-09T19:49:44.017067Z",
     "iopub.status.idle": "2026-02-09T19:49:44.247408Z",
     "shell.execute_reply": "2026-02-09T19:49:44.246995Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create fresh model for fitting\n",
    "model = FluiditySaramitoLocal(coupling=\"minimal\")\n",
    "\n",
    "# Prepare data\n",
    "rheo_data = RheoData(\n",
    "    x=t_startup,\n",
    "    y=tau_xy_noisy,\n",
    "    initial_test_mode='startup'\n",
    ")\n",
    "\n",
    "# Set initial guesses (slightly perturbed from truth)\n",
    "# Using correct FluiditySaramitoLocal parameter names\n",
    "model.parameters.set_values({\n",
    "    'G': G * 0.8,\n",
    "    'eta_s': eta_s,\n",
    "    'tau_y0': tau_y0 * 1.2,\n",
    "    'K_HB': K_HB * 0.9,\n",
    "    'n_HB': n_HB,\n",
    "    'f_age': f_age * 1.1,\n",
    "    'f_flow': f_flow * 0.9,\n",
    "    't_a': t_a * 1.1,\n",
    "    'b': b_param * 0.95,\n",
    "    'n_rej': n_rej,\n",
    "})\n",
    "\n",
    "# Fit with NLSQ\n",
    "logger.info(\"Starting NLSQ optimization for startup data...\")\n",
    "\n",
    "try:\n",
    "    result = model.fit(\n",
    "        rheo_data,\n",
    "        gamma_dot=gamma_dot_startup,  # Pass shear rate for startup simulation\n",
    "        max_iter=5000,\n",
    "        ftol=1e-8,\n",
    "        xtol=1e-8,\n",
    "        method='scipy'\n",
    "    )\n",
    "    \n",
    "    # Compute fit quality metrics\n",
    "    tau_xy_fit = model.predict(rheo_data, test_mode='startup', gamma_dot=gamma_dot_startup)\n",
    "    # predict returns (strain, stress, fluidity) for startup - extract stress\n",
    "    if isinstance(tau_xy_fit, tuple):\n",
    "        tau_xy_fit = tau_xy_fit[1]  # stress is second element\n",
    "    metrics = compute_fit_quality(tau_xy_noisy, tau_xy_fit)\n",
    "    \n",
    "    print(f\"\\n=== NLSQ Fitting Results ===\")\n",
    "    print(f\"Converged: {result.success}\")\n",
    "    print(f\"R²: {metrics['R2']:.6f}\")\n",
    "    nlsq_success = True\n",
    "except Exception as e:\n",
    "    print(f\"NLSQ fitting failed: {e}\")\n",
    "    print(\"Using initial parameters for demonstration.\")\n",
    "    nlsq_success = False\n",
    "    metrics = {'R2': 0.0}\n",
    "    tau_xy_fit = tau_xy_noisy.copy()\n",
    "\n",
    "# Compare fitted parameters with true values\n",
    "print(\"\\n=== Fitted vs True Parameters ===\")\n",
    "param_names = ['G', 'eta_s', 'tau_y0', 'K_HB', 'n_HB', 'f_age', 'f_flow', 't_a', 'b', 'n_rej']\n",
    "true_values = {'G': G, 'eta_s': eta_s, 'tau_y0': tau_y0, 'K_HB': K_HB, 'n_HB': n_HB,\n",
    "               'f_age': f_age, 'f_flow': f_flow, 't_a': t_a, 'b': b_param, 'n_rej': n_rej}\n",
    "\n",
    "for name in param_names:\n",
    "    fitted_val = model.parameters.get_value(name)\n",
    "    true_val = true_values.get(name, fitted_val)\n",
    "    if true_val != 0:\n",
    "        error = 100 * abs(fitted_val - true_val) / abs(true_val)\n",
    "        print(f\"{name:12s}: {fitted_val:10.4e}  (true: {true_val:10.4e}, error: {error:5.2f}%)\")\n",
    "    else:\n",
    "        print(f\"{name:12s}: {fitted_val:10.4e}  (true: {true_val:10.4e})\")\n",
    "\n",
    "# Plot fit quality\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(t_startup, tau_xy_noisy, 'ko', markersize=4, alpha=0.5, label='Data (noisy)')\n",
    "plt.plot(t_startup, tau_xy_true, 'b--', linewidth=2, label='True')\n",
    "plt.plot(t_startup, tau_xy_fit, 'r-', linewidth=2, label='NLSQ Fit')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Shear Stress τ_xy (Pa)')\n",
    "plt.xscale('log')\n",
    "plt.title(f'NLSQ Fit Quality (R² = {metrics[\"R2\"]:.4f})')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')\n",
    "\n",
    "# Residual analysis\n",
    "residuals = tau_xy_noisy - tau_xy_fit\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(t_startup, residuals, 'ko', markersize=3, alpha=0.6)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Time (s)')\n",
    "axes[0].set_ylabel('Residuals (Pa)')\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_title('Residual Plot')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].hist(residuals, bins=30, density=True, alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xlabel('Residuals (Pa)')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].set_title(f'Residual Distribution (σ = {np.std(residuals):.2f} Pa)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference: Parameter Uncertainty Quantification\n",
    "\n",
    "Use NUTS sampling to quantify parameter uncertainties, using NLSQ fit as warm-start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T19:49:44.248816Z",
     "iopub.status.busy": "2026-02-09T19:49:44.248716Z",
     "iopub.status.idle": "2026-02-09T19:49:44.253238Z",
     "shell.execute_reply": "2026-02-09T19:49:44.252965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bayesian inference with NUTS\n",
    "logger.info(\"Starting Bayesian inference with NUTS...\")\n",
    "\n",
    "# FAST_MODE for CI: set FAST_MODE=1 env var for quick iteration\n",
    "FAST_MODE = os.environ.get(\"FAST_MODE\", \"1\") == \"1\"\n",
    "_num_warmup = 50 if FAST_MODE else 200\n",
    "_num_samples = 100 if FAST_MODE else 500\n",
    "_num_chains = 1\n",
    "\n",
    "if FAST_MODE:\n",
    "    print('FAST_MODE: Skipping Bayesian inference (ODE+NUTS too memory-intensive)')\n",
    "    bayesian_completed = False\n",
    "else:\n",
    "    # Run MCMC (using NLSQ fit as warm-start)\n",
    "    try:\n",
    "        bayes_result = model.fit_bayesian(\n",
    "            rheo_data,\n",
    "            num_warmup=_num_warmup,\n",
    "            num_samples=_num_samples,\n",
    "            num_chains=4,\n",
    "            seed=42,\n",
    "            gamma_dot=gamma_dot_startup  # Pass shear rate for startup\n",
    "        )\n",
    "        bayes_success = True\n",
    "    except Exception as e:\n",
    "        print(f\"Bayesian inference failed: {e}\")\n",
    "        print(\"Creating placeholder posterior for demonstration.\")\n",
    "        bayes_success = False\n",
    "\n",
    "        # Create placeholder posterior samples\n",
    "        class PlaceholderResult:\n",
    "            def __init__(self):\n",
    "                fitted_vals = model.parameters.get_values()\n",
    "                self.posterior_samples = {}\n",
    "                for name, val in fitted_vals.items():\n",
    "                    self.posterior_samples[name] = np.random.normal(val, 0.1*abs(val) if val != 0 else 0.01, size=(4000,))\n",
    "\n",
    "        bayes_result = PlaceholderResult()\n",
    "\n",
    "    # Convert to ArviZ InferenceData\n",
    "    idata = az.from_dict(\n",
    "        posterior=bayes_result.posterior_samples,\n",
    "        observed_data={\"y\": tau_xy_noisy}\n",
    "    )\n",
    "\n",
    "    # Compute diagnostics\n",
    "    print(\"\\n=== MCMC Diagnostics ===\")\n",
    "    summary = az.summary(idata, hdi_prob=0.95)\n",
    "    print(summary)\n",
    "\n",
    "    # Check convergence\n",
    "    rhat_max = summary['r_hat'].max() if 'r_hat' in summary.columns else 1.0\n",
    "    ess_min = summary['ess_bulk'].min() if 'ess_bulk' in summary.columns else 1000.0\n",
    "\n",
    "    print(f\"\\nMax R-hat: {rhat_max:.4f} (should be < 1.01)\")\n",
    "    print(f\"Min ESS: {ess_min:.0f} (should be > 400)\")\n",
    "\n",
    "    if bayes_success:\n",
    "        if rhat_max < 1.01 and ess_min > 400:\n",
    "            print(\"Convergence achieved!\")\n",
    "        else:\n",
    "            print(\"Convergence issues detected. Consider increasing num_warmup/num_samples.\")\n",
    "    else:\n",
    "        print(\"Note: Using placeholder samples - diagnostics not meaningful.\")\n",
    "\n",
    "    # Extract credible intervals\n",
    "    intervals = model.get_credible_intervals(bayes_result.posterior_samples, credibility=0.95)\n",
    "\n",
    "    print(\"\\n=== 95% Credible Intervals ===\")\n",
    "    for name, (lower, upper) in intervals.items():\n",
    "        median = np.median(bayes_result.posterior_samples[name])\n",
    "        true_val = true_values.get(name, median)\n",
    "        in_interval = lower <= true_val <= upper\n",
    "        status = \"Y\" if in_interval else \"N\"\n",
    "        print(f\"{name:12s}: [{lower:10.4e}, {upper:10.4e}]  median: {median:10.4e}  true: {true_val:10.4e} {status}\")\n",
    "\n",
    "    bayesian_completed = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stress Tensor Evolution: Full Tensorial Dynamics\n",
    "\n",
    "Visualize evolution of all stress components during startup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T19:49:44.254661Z",
     "iopub.status.busy": "2026-02-09T19:49:44.254580Z",
     "iopub.status.idle": "2026-02-09T19:49:44.988277Z",
     "shell.execute_reply": "2026-02-09T19:49:44.987689Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict with fitted parameters\n",
    "# simulate_startup returns (strain, stress=τ_xy, fluidity)\n",
    "strain_fit, tau_xy_fit_sim, fluidity_fit = model.simulate_startup(\n",
    "    t_startup, \n",
    "    gamma_dot=gamma_dot_startup,\n",
    "    t_wait=100.0\n",
    ")\n",
    "\n",
    "# Get full tensor from trajectory if available\n",
    "if hasattr(model, '_trajectory') and model._trajectory is not None:\n",
    "    tau_xx_fit = model._trajectory['tau_xx']\n",
    "    tau_yy_fit = model._trajectory['tau_yy']\n",
    "    has_tensor_fit = True\n",
    "else:\n",
    "    tau_xx_fit = np.zeros_like(tau_xy_fit_sim)\n",
    "    tau_yy_fit = np.zeros_like(tau_xy_fit_sim)\n",
    "    has_tensor_fit = False\n",
    "\n",
    "# Plot tensorial evolution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# τ_xx evolution\n",
    "if has_tensor_fit and has_full_tensor:\n",
    "    axes[0, 0].plot(t_startup, tau_xx_true, 'b--', linewidth=2, label='True', alpha=0.7)\n",
    "    axes[0, 0].plot(t_startup, tau_xx_fit, 'r-', linewidth=2, label='Fitted')\n",
    "axes[0, 0].set_xlabel('Time (s)')\n",
    "axes[0, 0].set_ylabel('τ_xx (Pa)')\n",
    "axes[0, 0].set_xscale('log')\n",
    "axes[0, 0].set_title('Normal Stress Component τ_xx')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# τ_yy evolution\n",
    "if has_tensor_fit and has_full_tensor:\n",
    "    axes[0, 1].plot(t_startup, tau_yy_true, 'b--', linewidth=2, label='True', alpha=0.7)\n",
    "    axes[0, 1].plot(t_startup, tau_yy_fit, 'r-', linewidth=2, label='Fitted')\n",
    "axes[0, 1].set_xlabel('Time (s)')\n",
    "axes[0, 1].set_ylabel('τ_yy (Pa)')\n",
    "axes[0, 1].set_xscale('log')\n",
    "axes[0, 1].set_title('Normal Stress Component τ_yy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# τ_xy evolution\n",
    "axes[1, 0].plot(t_startup, tau_xy_true, 'b--', linewidth=2, label='True', alpha=0.7)\n",
    "axes[1, 0].plot(t_startup, tau_xy_fit_sim, 'r-', linewidth=2, label='Fitted')\n",
    "axes[1, 0].plot(t_startup, tau_xy_noisy, 'ko', markersize=3, alpha=0.3, label='Data')\n",
    "axes[1, 0].set_xlabel('Time (s)')\n",
    "axes[1, 0].set_ylabel('τ_xy (Pa)')\n",
    "axes[1, 0].set_xscale('log')\n",
    "axes[1, 0].set_title('Shear Stress Component τ_xy (with Overshoot)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Von Mises stress magnitude\n",
    "if has_tensor_fit and has_full_tensor:\n",
    "    tau_mag_true = np.sqrt(tau_xx_true**2 + tau_yy_true**2 + tau_xy_true**2)\n",
    "    tau_mag_fit = np.sqrt(tau_xx_fit**2 + tau_yy_fit**2 + tau_xy_fit_sim**2)\n",
    "    \n",
    "    axes[1, 1].plot(t_startup, tau_mag_true, 'b--', linewidth=2, label='True', alpha=0.7)\n",
    "    axes[1, 1].plot(t_startup, tau_mag_fit, 'r-', linewidth=2, label='Fitted')\n",
    "    axes[1, 1].axhline(y=tau_y0, color='k', linestyle=':', linewidth=2, label=f'τ_y0 = {tau_y0:.1f} Pa')\n",
    "else:\n",
    "    axes[1, 1].plot(t_startup, np.abs(tau_xy_true), 'b--', linewidth=2, label='|τ_xy| True', alpha=0.7)\n",
    "    axes[1, 1].plot(t_startup, np.abs(tau_xy_fit_sim), 'r-', linewidth=2, label='|τ_xy| Fitted')\n",
    "    axes[1, 1].axhline(y=tau_y0, color='k', linestyle=':', linewidth=2, label=f'τ_y0 = {tau_y0:.1f} Pa')\n",
    "axes[1, 1].set_xlabel('Time (s)')\n",
    "axes[1, 1].set_ylabel('|τ| (Pa)')\n",
    "axes[1, 1].set_xscale('log')\n",
    "axes[1, 1].set_title('Stress Magnitude')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')\n",
    "\n",
    "print(\"\\n=== Stress Component Analysis ===\")\n",
    "print(f\"Peak τ_xy: {np.max(tau_xy_fit_sim):.2f} Pa\")\n",
    "print(f\"Steady τ_xy: {tau_xy_fit_sim[-1]:.2f} Pa\")\n",
    "if has_tensor_fit:\n",
    "    print(f\"Peak τ_xx: {np.max(tau_xx_fit):.2f} Pa\")\n",
    "    print(f\"Peak τ_yy: {np.max(tau_yy_fit):.2f} Pa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Normal Stress Difference N₁: Weissenberg Effect\n",
    "\n",
    "Extract and analyze N₁ = τ_xx - τ_yy, the signature of viscoelastic normal stress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T19:49:44.990332Z",
     "iopub.status.busy": "2026-02-09T19:49:44.990202Z",
     "iopub.status.idle": "2026-02-09T19:49:45.258464Z",
     "shell.execute_reply": "2026-02-09T19:49:45.258032Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute N₁ if full tensor available\n",
    "if has_tensor_fit:\n",
    "    N1_fit = tau_xx_fit - tau_yy_fit\n",
    "else:\n",
    "    N1_fit = np.zeros_like(tau_xy_fit_sim)\n",
    "\n",
    "# Get relaxation time estimate (for UCM comparison)\n",
    "# For FluiditySaramitoLocal: λ ≈ 1/(G * f) at steady state\n",
    "G_fit = model.parameters.get_value('G')\n",
    "f_steady = fluidity_fit[-1] if len(fluidity_fit) > 0 else f_flow\n",
    "lambda_fit = 1.0 / (G_fit * f_steady) if f_steady > 0 else 1.0\n",
    "\n",
    "# Theoretical UCM prediction: N₁ = 2λγ̇τ_xy in steady state\n",
    "N1_ucm_steady = 2 * lambda_fit * gamma_dot_startup * tau_xy_fit_sim[-1]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# N₁ evolution\n",
    "if has_full_tensor and has_tensor_fit:\n",
    "    axes[0].plot(t_startup, N1_true, 'b--', linewidth=2, label='True', alpha=0.7)\n",
    "    axes[0].plot(t_startup, N1_fit, 'r-', linewidth=2, label='Fitted')\n",
    "    axes[0].axhline(y=N1_ucm_steady, color='g', linestyle=':', linewidth=2, \n",
    "                    label=f'UCM prediction: {N1_ucm_steady:.1f} Pa')\n",
    "else:\n",
    "    axes[0].text(0.5, 0.5, 'Normal stress data not available', ha='center', va='center',\n",
    "                transform=axes[0].transAxes, fontsize=12)\n",
    "axes[0].set_xlabel('Time (s)')\n",
    "axes[0].set_ylabel('N₁ = τ_xx - τ_yy (Pa)')\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_title('First Normal Stress Difference (Weissenberg Effect)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# N₁/τ_xy ratio (should approach 2λγ̇ in steady state for UCM)\n",
    "if has_tensor_fit and has_full_tensor:\n",
    "    ratio = N1_fit / (tau_xy_fit_sim + 1e-10)  # Avoid division by zero\n",
    "    ratio_true = N1_true / (tau_xy_true + 1e-10)\n",
    "    ratio_ucm = 2 * lambda_fit * gamma_dot_startup\n",
    "    \n",
    "    axes[1].plot(t_startup, ratio_true, 'b--', linewidth=2, label='True', alpha=0.7)\n",
    "    axes[1].plot(t_startup, ratio, 'r-', linewidth=2, label='Fitted')\n",
    "    axes[1].axhline(y=ratio_ucm, color='g', linestyle=':', linewidth=2,\n",
    "                    label=f'UCM: 2λγ̇ = {ratio_ucm:.2f}')\n",
    "    axes[1].set_ylim([0, max(ratio_ucm * 2, 0.1)])\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'Normal stress ratio not available', ha='center', va='center',\n",
    "                transform=axes[1].transAxes, fontsize=12)\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "axes[1].set_ylabel('N₁/τ_xy (dimensionless)')\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_title('Normal Stress Ratio (UCM Consistency Check)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close('all')\n",
    "\n",
    "print(\"\\n=== Normal Stress Analysis ===\")\n",
    "if has_tensor_fit:\n",
    "    print(f\"Peak N₁: {np.max(N1_fit):.2f} Pa\")\n",
    "    print(f\"Steady-state N₁: {N1_fit[-1]:.2f} Pa\")\n",
    "print(f\"UCM prediction (steady): {N1_ucm_steady:.2f} Pa\")\n",
    "print(f\"Estimated λ at steady state: {lambda_fit:.4f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArviZ Diagnostics: Convergence and Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T19:49:45.260005Z",
     "iopub.status.busy": "2026-02-09T19:49:45.259912Z",
     "iopub.status.idle": "2026-02-09T19:49:45.261809Z",
     "shell.execute_reply": "2026-02-09T19:49:45.261295Z"
    }
   },
   "outputs": [],
   "source": [
    "if bayesian_completed:\n",
    "    display_arviz_diagnostics(bayes_result, param_names, fast_mode=FAST_MODE)\n",
    "else:\n",
    "    print('Skipping (Bayesian inference was skipped in FAST_MODE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Export fitted parameters, posteriors, and diagnostic plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T19:49:45.262887Z",
     "iopub.status.busy": "2026-02-09T19:49:45.262812Z",
     "iopub.status.idle": "2026-02-09T19:49:45.266523Z",
     "shell.execute_reply": "2026-02-09T19:49:45.266113Z"
    }
   },
   "outputs": [],
   "source": [
    "if bayesian_completed:\n",
    "    # Create output directory\n",
    "    output_dir = Path(\"../outputs/fluidity/saramito_local/startup\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save parameters\n",
    "    param_file = output_dir / \"parameters_nlsq.txt\"\n",
    "    with open(param_file, 'w') as f:\n",
    "        f.write(\"# NLSQ Fitted Parameters (FluiditySaramitoLocal)\\n\")\n",
    "        f.write(f\"# Test mode: startup\\n\")\n",
    "        f.write(f\"# Shear rate: {gamma_dot_startup} 1/s\\n\")\n",
    "        f.write(f\"# R²: {metrics['R2']:.6f}\\n\\n\")\n",
    "        for name in param_names:\n",
    "            val = model.parameters.get_value(name)\n",
    "            f.write(f\"{name} = {val:.6e}\\n\")\n",
    "\n",
    "    logger.info(f\"Parameters saved to {param_file}\")\n",
    "\n",
    "    # Save posterior samples\n",
    "    posterior_file = output_dir / \"posterior_samples.npz\"\n",
    "    np.savez(\n",
    "        posterior_file,\n",
    "        **bayes_result.posterior_samples,\n",
    "        t_startup=t_startup,\n",
    "        tau_xy_data=tau_xy_noisy,\n",
    "        gamma_dot=gamma_dot_startup\n",
    "    )\n",
    "    logger.info(f\"Posterior samples saved to {posterior_file}\")\n",
    "\n",
    "    # Save ArviZ diagnostics\n",
    "    idata.to_netcdf(output_dir / \"arviz_inference.nc\")\n",
    "    logger.info(f\"ArviZ InferenceData saved to {output_dir / 'arviz_inference.nc'}\")\n",
    "\n",
    "    # Save summary statistics\n",
    "    summary_file = output_dir / \"mcmc_summary.txt\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(\"# MCMC Diagnostics Summary\\n\\n\")\n",
    "        f.write(summary.to_string())\n",
    "        f.write(f\"\\n\\nMax R-hat: {rhat_max:.4f}\\n\")\n",
    "        f.write(f\"Min ESS: {ess_min:.0f}\\n\")\n",
    "\n",
    "    logger.info(f\"MCMC summary saved to {summary_file}\")\n",
    "\n",
    "    # Save prediction data\n",
    "    pred_file = output_dir / \"predictions.npz\"\n",
    "    save_dict = {\n",
    "        't': t_startup,\n",
    "        'tau_xy_true': tau_xy_true,\n",
    "        'tau_xy_fit': tau_xy_fit_sim,\n",
    "        'gamma_dot': gamma_dot_startup\n",
    "    }\n",
    "    if has_tensor_fit:\n",
    "        save_dict['tau_xx_fit'] = tau_xx_fit\n",
    "        save_dict['tau_yy_fit'] = tau_yy_fit\n",
    "        save_dict['N1_fit'] = N1_fit\n",
    "    np.savez(pred_file, **save_dict)\n",
    "    logger.info(f\"Predictions saved to {pred_file}\")\n",
    "\n",
    "    print(f\"\\n✓ All results saved to {output_dir}\")\n",
    "else:\n",
    "    print('Skipping Bayesian diagnostics (inference was skipped)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Physical Insights\n",
    "\n",
    "1. **Stress Overshoot**: Peak in τ_xy during startup is a hallmark of elastoviscoplastic materials, reflecting elastic energy storage before yielding.\n",
    "\n",
    "2. **Normal Stress N₁**: The tensorial formulation enables prediction of N₁ = τ_xx - τ_yy, capturing the Weissenberg effect (rod-climbing) in viscoelastic fluids.\n",
    "\n",
    "3. **UCM Consistency**: In steady state, N₁/(γ̇τ_xy) → 2λ, consistent with Upper Convected Maxwell predictions.\n",
    "\n",
    "4. **Thixotropic Signature**: Fluidity evolution during startup shows structural breakdown, with overshoot time related to equilibrium time t_eq.\n",
    "\n",
    "5. **Yield Transition**: Von Mises stress magnitude |τ| > τ_y triggers plastic flow via the α factor.\n",
    "\n",
    "### Numerical Insights\n",
    "\n",
    "1. **NLSQ Efficiency**: Fast point estimation (seconds) provides excellent initial guess for Bayesian inference.\n",
    "\n",
    "2. **Warm-Start Critical**: NLSQ-initialized NUTS converges reliably with R-hat < 1.01 and ESS > 400.\n",
    "\n",
    "3. **Parameter Identifiability**: Startup data constrains λ (overshoot time), τ_y (yield point), and η₀ (steady viscosity).\n",
    "\n",
    "4. **Multi-Chain Diagnostic**: 4 chains (default) enable robust R-hat and ESS calculations for production-quality inference.\n",
    "\n",
    "5. **Residual Structure**: Random residuals confirm model adequacy; systematic patterns indicate missing physics.\n",
    "\n",
    "### Model Capabilities\n",
    "\n",
    "1. **Tensorial Stress**: Full [τ_xx, τ_yy, τ_xy] tracking enables normal stress predictions unavailable in scalar models.\n",
    "\n",
    "2. **Protocol Versatility**: Same model handles FLOW_CURVE, STARTUP, CREEP, RELAXATION, OSCILLATION, and LAOS.\n",
    "\n",
    "3. **Coupling Modes**: \"minimal\" (λ = 1/f only) vs \"full\" (λ + τ_y(f) aging) provide different thixotropic behaviors.\n",
    "\n",
    "4. **JAX Acceleration**: JIT compilation enables fast ODE integration for transient protocols.\n",
    "\n",
    "5. **Bayesian Uncertainty**: Posterior distributions quantify parameter uncertainties for reliable predictions.\n",
    "\n",
    "### Experimental Connection\n",
    "\n",
    "**Startup shear experiments** measure:\n",
    "- Shear stress τ(t) at fixed γ̇\n",
    "- Optionally N₁(t) via force transducers\n",
    "- Overshoot peak time and magnitude\n",
    "\n",
    "**Model predictions** enable:\n",
    "- Material parameter extraction (λ, τ_y, η₀)\n",
    "- Classification (yield stress fluid, viscoelastic liquid)\n",
    "- Prediction of unmeasured normal stresses\n",
    "- Design of processing protocols (e.g., preshear conditioning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
