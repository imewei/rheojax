{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# DMT Stress Relaxation\n\n> **Handbook:** See [DMT Relaxation Protocol](../../docs/source/models/dmt/dmt.rst#stress-relaxation-cessation-of-flow) for structure recovery kinetics and arrested relaxation physics.\n\n## Physical Context\n\nIn **stress relaxation**, a constant strain $\\gamma_0$ is applied and held while stress $\\sigma(t)$ decays. For DMT models with Maxwell elasticity, this protocol reveals the interplay of **structure recovery** and **elastic relaxation**:\n\n### Structure Evolution (No Breakdown)\n\nSince $\\dot{\\gamma} = 0$ throughout:\n\n$$\\frac{d\\lambda}{dt} = \\frac{1 - \\lambda}{t_{\\text{eq}}}$$\n\nOnly aging occurs (no rejuvenation term). The structure rebuilds exponentially:\n\n$$\\lambda(t) = 1 - (1 - \\lambda_0) e^{-t/t_{\\text{eq}}}$$\n\nwhere $\\lambda_0 = \\lambda_{\\text{ss}}(\\dot{\\gamma}_{\\text{preshear}})$ is the structure at cessation.\n\n### Maxwell Stress Relaxation (with Coupling)\n\nThe Maxwell stress decays with a **time-varying relaxation time**:\n\n$$\\frac{d\\sigma}{dt} = -\\frac{\\sigma}{\\theta_1(\\lambda(t))}$$\n\nwhere $\\theta_1(\\lambda) = \\eta(\\lambda) / G(\\lambda)$.\n\n**Key insight**: As $\\lambda$ increases (structure rebuilds), the viscosity $\\eta(\\lambda)$ typically increases faster than the modulus $G(\\lambda)$, causing the relaxation time $\\theta_1$ to increase. This produces **arrested relaxation** (fast initial decay transitioning to slow/stopped decay as the material re-gels).\n\n### Non-Identifiability\n\nSince $\\dot{\\gamma} = 0$ throughout, the breakdown parameters $(a, c)$ **do not influence** the relaxation curve. Only identifiable:\n- Equilibration time $t_{\\text{eq}}$\n- Closure parameters ($\\eta_0$, $\\eta_\\infty$, $G_0$, etc.)\n- Initial conditions ($\\sigma_{\\text{init}}$, $\\lambda_0$)\n\n### Industrial Relevance\n\n- **Material processing**: Recovery during rest periods between shear cycles\n- **Quality control**: Relaxation timescales indicate structural strength\n- **3D printing**: Post-extrusion recovery controls shape retention\n\n## Learning Objectives\n\n- Understand structure recovery during stress relaxation ($\\dot{\\gamma} = 0$)\n- Analyze aging-time effects on initial structure parameter $\\lambda_0$\n- Observe arrested relaxation driven by increasing structure\n- Identify non-identifiability of breakdown parameters $(a, c)$ from relaxation alone\n\n## Prerequisites\n\n- Notebook 01: DMT Flow Curves (understanding of DMT parameters)\n- Basic knowledge of stress relaxation experiments\n\n## Runtime\n\n- NLSQ fitting: ~5-10 seconds per dataset\n- Bayesian inference: ~2-3 minutes (1000 warmup + 2000 samples)\n- Total: ~15-20 minutes for complete analysis"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:26.489280Z",
     "iopub.status.busy": "2026-02-09T15:10:26.489092Z",
     "iopub.status.idle": "2026-02-09T15:10:26.494122Z",
     "shell.execute_reply": "2026-02-09T15:10:26.493386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Google Colab setup\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab - installing RheoJAX...\")\n",
    "    !pip install -q rheojax\n",
    "    \n",
    "    # Enable float64 for JAX\n",
    "    import os\n",
    "    os.environ['JAX_ENABLE_X64'] = '1'\n",
    "    print(\"JAX float64 enabled\")\n",
    "else:\n",
    "    print(\"Running locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:26.495880Z",
     "iopub.status.busy": "2026-02-09T15:10:26.495733Z",
     "iopub.status.idle": "2026-02-09T15:10:28.097533Z",
     "shell.execute_reply": "2026-02-09T15:10:28.097137Z"
    }
   },
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# JAX imports (MUST use safe_import_jax)\n",
    "from rheojax.core.jax_config import safe_import_jax, verify_float64\n",
    "\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "# Verify float64 is enabled\n",
    "verify_float64()\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "\n",
    "# RheoJAX imports\n",
    "# Bayesian imports\n",
    "import arviz as az\n",
    "\n",
    "from rheojax.core.parameters import Parameter, ParameterSet\n",
    "from rheojax.models import DMTLocal\n",
    "\n",
    "# Shared plotting utilities\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(\"\")))\n",
    "from utils.plotting_utils import (\n",
    "    display_arviz_diagnostics,\n",
    "    plot_nlsq_fit,\n",
    "    plot_posterior_predictive,\n",
    ")\n",
    "\n",
    "FAST_MODE = os.environ.get(\"FAST_MODE\", \"1\") == \"1\"\n",
    "\n",
    "# Matplotlib setup\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(f\"FAST_MODE: {FAST_MODE}\")\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Real Laponite Clay Relaxation Data\n",
    "\n",
    "We load stress relaxation data for laponite clay at 5 different aging times (600-3600 seconds). Each dataset represents relaxation after the sample was allowed to age for a specific duration.\n",
    "\n",
    "**Expected behavior:** Longer aging times → more structured initial state → higher initial stress and slower relaxation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:28.098761Z",
     "iopub.status.busy": "2026-02-09T15:10:28.098621Z",
     "iopub.status.idle": "2026-02-09T15:10:28.103934Z",
     "shell.execute_reply": "2026-02-09T15:10:28.103529Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load relaxation data for different aging times\n",
    "data_dir = Path(\"..\") / \"data\" / \"relaxation\" / \"clays\"\n",
    "aging_times = [600, 1200, 1800, 2400, 3600]  # seconds\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for t_age in aging_times:\n",
    "    filepath = data_dir / f\"rel_lapo_{t_age}.csv\"\n",
    "    \n",
    "    if not filepath.exists():\n",
    "        print(f\"WARNING: File not found: {filepath}\")\n",
    "        print(f\"Please ensure data files exist in {data_dir}\")\n",
    "        continue\n",
    "    \n",
    "    # Load tab-separated data (Time, Relaxation Modulus)\n",
    "    raw_data = np.loadtxt(filepath, delimiter=\"\\t\", skiprows=1)\n",
    "    \n",
    "    datasets[t_age] = {\n",
    "        \"time\": raw_data[:, 0],\n",
    "        \"G\": raw_data[:, 1]\n",
    "    }\n",
    "    \n",
    "    print(f\"Loaded t_age={t_age}s: {len(raw_data)} points, \"\n",
    "          f\"G_init={raw_data[0, 1]:.2e} Pa, G_final={raw_data[-1, 1]:.2e} Pa\")\n",
    "\n",
    "print(f\"\\nTotal datasets loaded: {len(datasets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:28.105144Z",
     "iopub.status.busy": "2026-02-09T15:10:28.105056Z",
     "iopub.status.idle": "2026-02-09T15:10:28.279172Z",
     "shell.execute_reply": "2026-02-09T15:10:28.278702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot all relaxation curves\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.9, len(aging_times)))\n",
    "\n",
    "for (t_age, data), color in zip(datasets.items(), colors):\n",
    "    ax.loglog(data[\"time\"], data[\"G\"], \n",
    "              marker='o', markersize=4, linestyle='-', linewidth=1.5,\n",
    "              color=color, label=f\"t_age = {t_age}s\", alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Relaxation Modulus G(t) (Pa)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Laponite Clay Stress Relaxation at Different Aging Times', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, which='both', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Observation: Longer aging times produce higher initial modulus (more structured state)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. NLSQ Fitting for Single Aging Time\n",
    "\n",
    "We demonstrate NLSQ fitting for the intermediate aging time (1800s). Since `_fit_relaxation` raises `NotImplementedError`, we use a custom approach:\n",
    "\n",
    "1. Define a wrapper function that simulates relaxation\n",
    "2. Interpolate simulation to data time points\n",
    "3. Use `nlsq_curve_fit` for optimization\n",
    "\n",
    "**Note:** We fix breakdown parameters (a=1.0, c=1.0) since they are not identifiable from relaxation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:28.281021Z",
     "iopub.status.busy": "2026-02-09T15:10:28.280938Z",
     "iopub.status.idle": "2026-02-09T15:10:28.283340Z",
     "shell.execute_reply": "2026-02-09T15:10:28.282916Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select intermediate aging time for detailed analysis\n",
    "target_age = 1800  # seconds\n",
    "t_data = datasets[target_age][\"time\"]\n",
    "G_data = datasets[target_age][\"G\"]\n",
    "\n",
    "print(f\"Fitting dataset: t_age = {target_age}s\")\n",
    "print(f\"Data points: {len(t_data)}\")\n",
    "print(f\"Time range: {t_data.min():.3f} - {t_data.max():.2f} s\")\n",
    "print(f\"G range: {G_data.min():.2e} - {G_data.max():.2e} Pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:28.284478Z",
     "iopub.status.busy": "2026-02-09T15:10:28.284405Z",
     "iopub.status.idle": "2026-02-09T15:10:28.287261Z",
     "shell.execute_reply": "2026-02-09T15:10:28.286820Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create model instance\n",
    "model = DMTLocal(closure=\"exponential\", include_elasticity=True)\n",
    "\n",
    "# Create ParameterSet - use bounds compatible with DMT model constraints\n",
    "from rheojax.core.parameters import ParameterSet\n",
    "\n",
    "params = ParameterSet()\n",
    "params.add(\"G0\", value=1e3, bounds=(1.0, 1e6))          # Match model bounds\n",
    "params.add(\"eta_0\", value=1e4, bounds=(100.0, 1e8))      # Match model bounds  \n",
    "params.add(\"eta_inf\", value=1.0, bounds=(0.001, 100.0))  # Match model bounds (max=100)\n",
    "params.add(\"t_eq\", value=100.0, bounds=(0.1, 10000.0))   # Match model bounds\n",
    "params.add(\"a\", value=1.0, bounds=(0.999, 1.001))        # Fixed (tight bounds)\n",
    "params.add(\"c\", value=1.0, bounds=(0.999, 1.001))        # Fixed (tight bounds)\n",
    "params.add(\"sigma_init\", value=G_data[0], bounds=(G_data[0]*0.5, G_data[0]*1.5))\n",
    "params.add(\"lam_init\", value=0.8, bounds=(0.1, 1.0))\n",
    "\n",
    "print(\"Parameter set defined with fixed breakdown parameters (a=1.0, c=1.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:28.288363Z",
     "iopub.status.busy": "2026-02-09T15:10:28.288291Z",
     "iopub.status.idle": "2026-02-09T15:10:28.291394Z",
     "shell.execute_reply": "2026-02-09T15:10:28.290991Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define wrapper function for scipy.optimize.curve_fit\n",
    "# Note: scipy.optimize.curve_fit passes individual parameters, not an array\n",
    "def dmt_relax_wrapper(t_eval, G_0, eta_0, eta_inf, t_eq, a, c, sigma_init, lam_init):\n",
    "    \"\"\"\n",
    "    Wrapper for DMT relaxation simulation using scipy-compatible signature.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    t_eval : array\n",
    "        Time points to evaluate\n",
    "    G_0, eta_0, eta_inf, t_eq, a, c, sigma_init, lam_init : float\n",
    "        Model parameters\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    G_pred : array\n",
    "        Predicted relaxation modulus\n",
    "    \"\"\"\n",
    "    # Set model parameters\n",
    "    model.parameters.set_value(\"G0\", G_0)\n",
    "    model.parameters.set_value(\"eta_0\", eta_0)\n",
    "    model.parameters.set_value(\"eta_inf\", eta_inf)\n",
    "    model.parameters.set_value(\"t_eq\", t_eq)\n",
    "    model.parameters.set_value(\"a\", a)\n",
    "    model.parameters.set_value(\"c\", c)\n",
    "    \n",
    "    # Set initial conditions\n",
    "    model._relax_sigma_init = sigma_init\n",
    "    model._relax_lam_init = lam_init\n",
    "    \n",
    "    # Simulate relaxation (use dt parameter)\n",
    "    t_end_sim = float(t_eval.max())\n",
    "    dt = t_end_sim / 500  # Use 500 points\n",
    "    t_sim_jax, sigma_sim, lam_sim = model.simulate_relaxation(\n",
    "        t_end=t_end_sim,\n",
    "        dt=dt,\n",
    "        sigma_init=sigma_init,\n",
    "        lam_init=lam_init\n",
    "    )\n",
    "    \n",
    "    # Convert to numpy and interpolate to data time points\n",
    "    t_sim_np = np.array(t_sim_jax)\n",
    "    sigma_np = np.array(sigma_sim)\n",
    "    \n",
    "    G_pred = np.interp(t_eval, t_sim_np, sigma_np)\n",
    "    \n",
    "    return G_pred\n",
    "\n",
    "print(\"Wrapper function defined (scipy-compatible signature)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:28.292663Z",
     "iopub.status.busy": "2026-02-09T15:10:28.292579Z",
     "iopub.status.idle": "2026-02-09T15:10:33.381719Z",
     "shell.execute_reply": "2026-02-09T15:10:33.381195Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform optimization using scipy.optimize.curve_fit\n",
    "print(\"Starting optimization with scipy.optimize.curve_fit...\\n\")\n",
    "\n",
    "# Helper function for computing fit quality\n",
    "def compute_fit_quality(y_true, y_pred):\n",
    "    \"\"\"Compute R² and RMSE.\"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    residuals = y_true - y_pred\n",
    "    if y_true.ndim > 1:\n",
    "        residuals = residuals.ravel()\n",
    "        y_true = y_true.ravel()\n",
    "    ss_res = np.sum(residuals**2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
    "    r2 = 1.0 - ss_res / ss_tot if ss_tot > 0 else 0.0\n",
    "    rmse = np.sqrt(np.mean(residuals**2))\n",
    "    return {\"R2\": r2, \"RMSE\": rmse}\n",
    "\n",
    "# Initial guesses\n",
    "p0 = [1e3, 1e4, 1.0, 100.0, 1.0, 1.0, G_data[0], 0.8]\n",
    "\n",
    "# Bounds (lower, upper) - must match model constraints\n",
    "bounds = (\n",
    "    [1.0, 100.0, 0.001, 0.1, 0.999, 0.999, G_data[0]*0.5, 0.1],  # lower\n",
    "    [1e6, 1e8, 100.0, 10000.0, 1.001, 1.001, G_data[0]*1.5, 1.0]  # upper\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "popt, pcov = curve_fit(\n",
    "    dmt_relax_wrapper,\n",
    "    t_data,\n",
    "    G_data,\n",
    "    p0=p0,\n",
    "    bounds=bounds,\n",
    "    maxfev=5000\n",
    ")\n",
    "\n",
    "# Parameter names\n",
    "param_names = [\"G0\", \"eta_0\", \"eta_inf\", \"t_eq\", \"a\", \"c\", \"sigma_init\", \"lam_init\"]\n",
    "\n",
    "# Compute predictions and metrics\n",
    "G_pred = dmt_relax_wrapper(t_data, *popt)\n",
    "metrics = compute_fit_quality(G_data, G_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Optimization Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Success: True\")\n",
    "print(f\"R² score: {metrics['R2']:.6f}\")\n",
    "print(f\"RMSE: {metrics['RMSE']:.4e}\")\n",
    "print(\"\\nFitted parameters:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for name, value in zip(param_names, popt):\n",
    "    print(f\"{name:12s} = {value:.4e}\")\n",
    "\n",
    "# Store fitted values for later use\n",
    "fitted_params = dict(zip(param_names, popt))\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:33.383420Z",
     "iopub.status.busy": "2026-02-09T15:10:33.383301Z",
     "iopub.status.idle": "2026-02-09T15:10:33.649428Z",
     "shell.execute_reply": "2026-02-09T15:10:33.648901Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot fit vs data\n",
    "# G_pred already computed from cell above\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Log-log plot\n",
    "ax1.loglog(t_data, G_data, 'o', markersize=6, alpha=0.6, label='Data')\n",
    "ax1.loglog(t_data, G_pred, '-', linewidth=2.5, color='red', label='NLSQ Fit')\n",
    "ax1.set_xlabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Relaxation Modulus G(t) (Pa)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title(f'NLSQ Fit (t_age = {target_age}s)', fontsize=13, fontweight='bold')\n",
    "ax1.legend(loc='best', fontsize=11)\n",
    "ax1.grid(True, which='both', alpha=0.3)\n",
    "\n",
    "# Right: Residuals\n",
    "residuals = G_data - G_pred\n",
    "rel_residuals = residuals / G_data * 100  # Percentage\n",
    "\n",
    "ax2.semilogx(t_data, rel_residuals, 'o-', markersize=5, alpha=0.7)\n",
    "ax2.axhline(0, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "ax2.set_xlabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Relative Residual (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Fit Quality', fontsize=13, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"Mean absolute relative error: {np.abs(rel_residuals).mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bayesian Inference\n",
    "\n",
    "We perform Bayesian inference to quantify parameter uncertainties. The NLSQ fit provides excellent initial values.\n",
    "\n",
    "**Key considerations:**\n",
    "- Use NLSQ parameters as warm-start\n",
    "- Fix breakdown parameters (a, c) with tight priors\n",
    "- Set initial conditions from data\n",
    "- Monitor diagnostics (R-hat, ESS, divergences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:33.651013Z",
     "iopub.status.busy": "2026-02-09T15:10:33.650910Z",
     "iopub.status.idle": "2026-02-09T15:10:33.656203Z",
     "shell.execute_reply": "2026-02-09T15:10:33.655763Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare model for Bayesian inference\n",
    "model_bayes = DMTLocal(closure=\"exponential\", include_elasticity=True)\n",
    "\n",
    "# Set initial conditions from data\n",
    "model_bayes._relax_sigma_init = float(G_data[0])\n",
    "model_bayes._relax_lam_init = fitted_params[\"lam_init\"]\n",
    "\n",
    "# Set parameter initial values from NLSQ fit\n",
    "for name, value in fitted_params.items():\n",
    "    if name not in [\"sigma_init\", \"lam_init\"]:\n",
    "        model_bayes.parameters.set_value(name, value)\n",
    "\n",
    "# Update priors with tighter bounds around NLSQ solution\n",
    "# Use dictionary access instead of get_parameter()\n",
    "model_bayes.parameters[\"G0\"].prior = \"Uniform\"\n",
    "model_bayes.parameters[\"G0\"].bounds = (\n",
    "    fitted_params[\"G0\"] * 0.5, fitted_params[\"G0\"] * 2.0\n",
    ")\n",
    "\n",
    "model_bayes.parameters[\"eta_0\"].prior = \"Uniform\"\n",
    "model_bayes.parameters[\"eta_0\"].bounds = (\n",
    "    fitted_params[\"eta_0\"] * 0.5, fitted_params[\"eta_0\"] * 2.0\n",
    ")\n",
    "\n",
    "model_bayes.parameters[\"eta_inf\"].prior = \"Uniform\"\n",
    "# Cap upper bound to model's max of 100.0\n",
    "model_bayes.parameters[\"eta_inf\"].bounds = (\n",
    "    max(0.001, fitted_params[\"eta_inf\"] * 0.1),\n",
    "    min(99.9, fitted_params[\"eta_inf\"] * 10.0)\n",
    ")\n",
    "\n",
    "model_bayes.parameters[\"t_eq\"].prior = \"Uniform\"\n",
    "model_bayes.parameters[\"t_eq\"].bounds = (\n",
    "    fitted_params[\"t_eq\"] * 0.5, fitted_params[\"t_eq\"] * 2.0\n",
    ")\n",
    "\n",
    "# Fix breakdown parameters with very tight priors\n",
    "model_bayes.parameters[\"a\"].prior = \"Uniform\"\n",
    "model_bayes.parameters[\"a\"].bounds = (0.99, 1.01)\n",
    "\n",
    "model_bayes.parameters[\"c\"].prior = \"Uniform\"\n",
    "model_bayes.parameters[\"c\"].bounds = (0.99, 1.01)\n",
    "\n",
    "print(\"Model prepared for Bayesian inference with NLSQ warm-start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:33.657369Z",
     "iopub.status.busy": "2026-02-09T15:10:33.657261Z",
     "iopub.status.idle": "2026-02-09T15:10:33.659640Z",
     "shell.execute_reply": "2026-02-09T15:10:33.659246Z"
    }
   },
   "outputs": [],
   "source": [
    "bayesian_completed = False\n",
    "\n",
    "if not FAST_MODE:\n",
    "    # Run Bayesian inference\n",
    "    print(\"Starting Bayesian inference...\")\n",
    "    print(\"This may take 2-3 minutes...\\n\")\n",
    "\n",
    "    bayes_result = model_bayes.fit_bayesian(\n",
    "        t_data,\n",
    "        G_data,\n",
    "        test_mode=\"relaxation\",\n",
    "        num_warmup=1000,\n",
    "        num_samples=2000,\n",
    "        num_chains=4,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    print(\"\\nBayesian inference complete!\")\n",
    "    bayesian_completed = True\n",
    "else:\n",
    "    print(\"FAST_MODE: Skipping Bayesian inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:33.660762Z",
     "iopub.status.busy": "2026-02-09T15:10:33.660669Z",
     "iopub.status.idle": "2026-02-09T15:10:33.663984Z",
     "shell.execute_reply": "2026-02-09T15:10:33.663581Z"
    }
   },
   "outputs": [],
   "source": [
    "if bayesian_completed:\n",
    "    # Diagnostics\n",
    "    posterior_samples = bayes_result.posterior_samples\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"MCMC Diagnostics\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    for param_name in [\"G0\", \"eta_0\", \"eta_inf\", \"t_eq\"]:\n",
    "        samples = posterior_samples[param_name]\n",
    "\n",
    "        # Compute R-hat (Gelman-Rubin statistic)\n",
    "        # Simple implementation: variance ratio between chains and within chains\n",
    "        n_chains = 4\n",
    "        chain_length = len(samples) // n_chains\n",
    "        chains = samples.reshape(n_chains, chain_length)\n",
    "\n",
    "        chain_means = np.mean(chains, axis=1)\n",
    "        grand_mean = np.mean(chain_means)\n",
    "        between_var = chain_length * np.var(chain_means, ddof=1)\n",
    "        within_var = np.mean([np.var(chains[i], ddof=1) for i in range(n_chains)])\n",
    "        var_est = ((chain_length - 1) * within_var + between_var) / chain_length\n",
    "        r_hat = np.sqrt(var_est / within_var) if within_var > 0 else 1.0\n",
    "\n",
    "        # Effective sample size (rough estimate)\n",
    "        ess = len(samples) / (1 + 2 * np.sum([np.corrcoef(samples[:-k], samples[k:])[0,1]\n",
    "                                               for k in range(1, min(50, len(samples)//2))\n",
    "                                               if np.corrcoef(samples[:-k], samples[k:])[0,1] > 0.05]))\n",
    "\n",
    "        print(f\"{param_name:12s}: R-hat = {r_hat:.4f}, ESS = {int(ess)}\")\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"Note: R-hat < 1.01 indicates convergence\")\n",
    "    print(\"      ESS > 400 per chain indicates good sampling\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"FAST_MODE: Skipping MCMC diagnostics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:33.665127Z",
     "iopub.status.busy": "2026-02-09T15:10:33.665045Z",
     "iopub.status.idle": "2026-02-09T15:10:33.666979Z",
     "shell.execute_reply": "2026-02-09T15:10:33.666581Z"
    }
   },
   "outputs": [],
   "source": [
    "if bayesian_completed:\n",
    "    display_arviz_diagnostics(bayes_result, [\"G0\", \"eta_0\", \"eta_inf\", \"t_eq\"], fast_mode=FAST_MODE)\n",
    "else:\n",
    "    print(\"FAST_MODE: Skipping ArviZ diagnostics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:33.668156Z",
     "iopub.status.busy": "2026-02-09T15:10:33.668080Z",
     "iopub.status.idle": "2026-02-09T15:10:33.671013Z",
     "shell.execute_reply": "2026-02-09T15:10:33.670652Z"
    }
   },
   "outputs": [],
   "source": [
    "if bayesian_completed:\n",
    "    # Posterior predictive with credible intervals\n",
    "    print(\"Computing posterior predictive distribution...\\n\")\n",
    "\n",
    "    # Sample 200 parameter sets from posterior\n",
    "    n_posterior_samples = 200\n",
    "    sample_indices = np.random.choice(len(posterior_samples[\"G0\"]),\n",
    "                                      size=n_posterior_samples, replace=False)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for idx in sample_indices:\n",
    "        # Set parameters from posterior sample\n",
    "        model_bayes.parameters.set_value(\"G0\", float(posterior_samples[\"G0\"][idx]))\n",
    "        model_bayes.parameters.set_value(\"eta_0\", float(posterior_samples[\"eta_0\"][idx]))\n",
    "        model_bayes.parameters.set_value(\"eta_inf\", float(posterior_samples[\"eta_inf\"][idx]))\n",
    "        model_bayes.parameters.set_value(\"t_eq\", float(posterior_samples[\"t_eq\"][idx]))\n",
    "\n",
    "        # Simulate (use dt instead of n_points)\n",
    "        t_end_sim = float(t_data.max())\n",
    "        dt = t_end_sim / 500\n",
    "        t_sim, sigma_sim, _ = model_bayes.simulate_relaxation(t_end=t_end_sim, dt=dt)\n",
    "\n",
    "        # Interpolate\n",
    "        G_interp = np.interp(t_data, np.array(t_sim), np.array(sigma_sim))\n",
    "        predictions.append(G_interp)\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Compute credible intervals\n",
    "    G_median = np.median(predictions, axis=0)\n",
    "    G_lower = np.percentile(predictions, 2.5, axis=0)\n",
    "    G_upper = np.percentile(predictions, 97.5, axis=0)\n",
    "\n",
    "    print(\"Posterior predictive computed (95% credible interval)\")\n",
    "else:\n",
    "    print(\"FAST_MODE: Skipping posterior predictive computation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:33.672126Z",
     "iopub.status.busy": "2026-02-09T15:10:33.672045Z",
     "iopub.status.idle": "2026-02-09T15:10:33.674767Z",
     "shell.execute_reply": "2026-02-09T15:10:33.674361Z"
    }
   },
   "outputs": [],
   "source": [
    "if bayesian_completed:\n",
    "    # Plot posterior predictive\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Data\n",
    "    ax.loglog(t_data, G_data, 'o', markersize=7, color='black',\n",
    "              label='Data', zorder=3, alpha=0.7)\n",
    "\n",
    "    # Median prediction\n",
    "    ax.loglog(t_data, G_median, '-', linewidth=2.5, color='red',\n",
    "              label='Posterior Median', zorder=2)\n",
    "\n",
    "    # Credible interval\n",
    "    ax.fill_between(t_data, G_lower, G_upper, alpha=0.3, color='red',\n",
    "                    label='95% Credible Interval', zorder=1)\n",
    "\n",
    "    ax.set_xlabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Relaxation Modulus G(t) (Pa)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'Bayesian Posterior Predictive (t_age = {target_age}s)',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=11)\n",
    "    ax.grid(True, which='both', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(\"Excellent agreement: data falls within 95% credible interval\")\n",
    "else:\n",
    "    print(\"FAST_MODE: Skipping posterior predictive plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:33.675791Z",
     "iopub.status.busy": "2026-02-09T15:10:33.675721Z",
     "iopub.status.idle": "2026-02-09T15:10:33.679140Z",
     "shell.execute_reply": "2026-02-09T15:10:33.678883Z"
    }
   },
   "outputs": [],
   "source": [
    "if bayesian_completed:\n",
    "    # Parameter posterior distributions\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, param_name in enumerate([\"G0\", \"eta_0\", \"eta_inf\", \"t_eq\"]):\n",
    "        samples = posterior_samples[param_name]\n",
    "\n",
    "        # Histogram\n",
    "        axes[idx].hist(samples, bins=50, alpha=0.7, color='steelblue',\n",
    "                       edgecolor='black', density=True)\n",
    "\n",
    "        # Median and credible interval\n",
    "        median = np.median(samples)\n",
    "        ci_lower = np.percentile(samples, 2.5)\n",
    "        ci_upper = np.percentile(samples, 97.5)\n",
    "\n",
    "        axes[idx].axvline(median, color='red', linestyle='--', linewidth=2,\n",
    "                         label=f'Median: {median:.2e}')\n",
    "        axes[idx].axvline(ci_lower, color='orange', linestyle=':', linewidth=1.5, alpha=0.7)\n",
    "        axes[idx].axvline(ci_upper, color='orange', linestyle=':', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "        axes[idx].set_xlabel(param_name, fontsize=11, fontweight='bold')\n",
    "        axes[idx].set_ylabel('Density', fontsize=10)\n",
    "        axes[idx].set_title(f'Posterior: {param_name}', fontsize=11, fontweight='bold')\n",
    "        axes[idx].legend(fontsize=9, loc='best')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle('Parameter Posterior Distributions', fontsize=14, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(\"\\nPosterior Summary:\")\n",
    "    print(\"-\"*60)\n",
    "    for param_name in [\"G0\", \"eta_0\", \"eta_inf\", \"t_eq\"]:\n",
    "        samples = posterior_samples[param_name]\n",
    "        median = np.median(samples)\n",
    "        ci_lower = np.percentile(samples, 2.5)\n",
    "        ci_upper = np.percentile(samples, 97.5)\n",
    "        print(f\"{param_name:12s}: {median:.4e} [{ci_lower:.4e}, {ci_upper:.4e}]\")\n",
    "    print(\"-\"*60)\n",
    "else:\n",
    "    print(\"FAST_MODE: Skipping posterior distribution plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Aging Time Analysis\n",
    "\n",
    "We now fit all 5 aging times to investigate how initial structure parameter λ₀ evolves with aging time.\n",
    "\n",
    "**Expected trend:** λ₀ increases with aging time (more structured initial state).\n",
    "\n",
    "**Consistency check:** Equilibration time t_eq should be similar across datasets (material property)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:10:33.680331Z",
     "iopub.status.busy": "2026-02-09T15:10:33.680251Z",
     "iopub.status.idle": "2026-02-09T15:11:56.266232Z",
     "shell.execute_reply": "2026-02-09T15:11:56.265682Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit all aging times\n",
    "print(\"Fitting all aging times with scipy.optimize.curve_fit...\\n\")\n",
    "\n",
    "multi_age_results = {}\n",
    "\n",
    "for t_age in aging_times:\n",
    "    if t_age not in datasets:\n",
    "        continue\n",
    "    \n",
    "    print(f\"Fitting t_age = {t_age}s...\")\n",
    "    \n",
    "    t_data_local = datasets[t_age][\"time\"]\n",
    "    G_data_local = datasets[t_age][\"G\"]\n",
    "    \n",
    "    # Initial guesses\n",
    "    p0_local = [1e3, 1e4, 1.0, 100.0, 1.0, 1.0, G_data_local[0], 0.7]\n",
    "    \n",
    "    # Bounds (lower, upper) - must match model constraints\n",
    "    bounds_local = (\n",
    "        [1.0, 100.0, 0.001, 0.1, 0.999, 0.999, G_data_local[0]*0.5, 0.1],  # lower\n",
    "        [1e6, 1e8, 100.0, 10000.0, 1.001, 1.001, G_data_local[0]*1.5, 1.0]  # upper\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        popt_local, _ = curve_fit(\n",
    "            dmt_relax_wrapper,\n",
    "            t_data_local,\n",
    "            G_data_local,\n",
    "            p0=p0_local,\n",
    "            bounds=bounds_local,\n",
    "            maxfev=5000\n",
    "        )\n",
    "        \n",
    "        param_names_local = [\"G0\", \"eta_0\", \"eta_inf\", \"t_eq\", \"a\", \"c\", \"sigma_init\", \"lam_init\"]\n",
    "        fitted_dict = dict(zip(param_names_local, popt_local))\n",
    "        \n",
    "        # Compute predictions and R²\n",
    "        G_pred_local = dmt_relax_wrapper(t_data_local, *popt_local)\n",
    "        metrics_local = compute_fit_quality(G_data_local, G_pred_local)\n",
    "        fitted_dict[\"r_squared\"] = metrics_local[\"R2\"]\n",
    "        \n",
    "        multi_age_results[t_age] = fitted_dict\n",
    "        \n",
    "        print(f\"  R² = {metrics_local['R2']:.6f}, λ_init = {fitted_dict['lam_init']:.4f}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\\n\")\n",
    "\n",
    "print(\"All aging times fitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:11:56.267697Z",
     "iopub.status.busy": "2026-02-09T15:11:56.267597Z",
     "iopub.status.idle": "2026-02-09T15:11:56.271203Z",
     "shell.execute_reply": "2026-02-09T15:11:56.270761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tabulate results\n",
    "print(\"=\"*80)\n",
    "print(\"Multi-Aging Time Analysis Results\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'t_age (s)':>10s} {'λ₀':>10s} {'σ_init (Pa)':>15s} {'t_eq (s)':>12s} {'η₀ (Pa·s)':>15s} {'R²':>10s}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for t_age in aging_times:\n",
    "    if t_age not in multi_age_results:\n",
    "        continue\n",
    "    \n",
    "    res = multi_age_results[t_age]\n",
    "    print(f\"{t_age:10d} {res['lam_init']:10.4f} {res['sigma_init']:15.4e} \"\n",
    "          f\"{res['t_eq']:12.2f} {res['eta_0']:15.4e} {res['r_squared']:10.6f}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compute statistics on t_eq\n",
    "t_eq_values = [multi_age_results[t_age][\"t_eq\"] for t_age in aging_times \n",
    "               if t_age in multi_age_results]\n",
    "print(f\"\\nt_eq statistics:\")\n",
    "print(f\"  Mean: {np.mean(t_eq_values):.2f} s\")\n",
    "print(f\"  Std:  {np.std(t_eq_values):.2f} s\")\n",
    "print(f\"  CV:   {np.std(t_eq_values)/np.mean(t_eq_values)*100:.1f}%\")\n",
    "print(\"\\nConclusion: t_eq is reasonably consistent across aging times (material property)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:11:56.272428Z",
     "iopub.status.busy": "2026-02-09T15:11:56.272343Z",
     "iopub.status.idle": "2026-02-09T15:11:56.382377Z",
     "shell.execute_reply": "2026-02-09T15:11:56.381835Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot λ₀ vs aging time\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Extract data\n",
    "aging_times_plot = [t for t in aging_times if t in multi_age_results]\n",
    "lam_init_plot = [multi_age_results[t][\"lam_init\"] for t in aging_times_plot]\n",
    "sigma_init_plot = [multi_age_results[t][\"sigma_init\"] for t in aging_times_plot]\n",
    "\n",
    "# Left: λ₀ vs aging time\n",
    "ax1.plot(aging_times_plot, lam_init_plot, 'o-', markersize=10, linewidth=2.5, \n",
    "         color='steelblue', markerfacecolor='orange')\n",
    "ax1.set_xlabel('Aging Time (s)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Initial Structure Parameter λ₀', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Structure Evolution with Aging', fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([0, 1.05])\n",
    "\n",
    "# Right: σ_init vs aging time\n",
    "ax2.semilogy(aging_times_plot, sigma_init_plot, 's-', markersize=10, linewidth=2.5,\n",
    "             color='darkred', markerfacecolor='yellow')\n",
    "ax2.set_xlabel('Aging Time (s)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Initial Stress σ_init (Pa)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Initial Stress vs Aging Time', fontsize=13, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Key observation: Both λ₀ and σ_init increase with aging time\")\n",
    "print(\"Physical interpretation: Longer aging → more structured material → higher modulus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:11:56.383676Z",
     "iopub.status.busy": "2026-02-09T15:11:56.383586Z",
     "iopub.status.idle": "2026-02-09T15:11:57.027479Z",
     "shell.execute_reply": "2026-02-09T15:11:57.026906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot all fitted curves together\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.9, len(aging_times)))\n",
    "\n",
    "for (t_age, color) in zip(aging_times, colors):\n",
    "    if t_age not in datasets or t_age not in multi_age_results:\n",
    "        continue\n",
    "    \n",
    "    t_data_local = datasets[t_age][\"time\"]\n",
    "    G_data_local = datasets[t_age][\"G\"]\n",
    "    \n",
    "    # Get fitted parameters\n",
    "    fitted_dict = multi_age_results[t_age]\n",
    "    \n",
    "    # Call wrapper with individual parameters (scipy-style signature)\n",
    "    G_pred_local = dmt_relax_wrapper(\n",
    "        t_data_local,\n",
    "        fitted_dict[\"G0\"],\n",
    "        fitted_dict[\"eta_0\"],\n",
    "        fitted_dict[\"eta_inf\"],\n",
    "        fitted_dict[\"t_eq\"],\n",
    "        fitted_dict[\"a\"],\n",
    "        fitted_dict[\"c\"],\n",
    "        fitted_dict[\"sigma_init\"],\n",
    "        fitted_dict[\"lam_init\"]\n",
    "    )\n",
    "    \n",
    "    # Plot\n",
    "    ax.loglog(t_data_local, G_data_local, 'o', markersize=5, \n",
    "              color=color, alpha=0.5)\n",
    "    ax.loglog(t_data_local, G_pred_local, '-', linewidth=2.5, \n",
    "              color=color, label=f\"t_age = {t_age}s\")\n",
    "\n",
    "ax.set_xlabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Relaxation Modulus G(t) (Pa)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('DMT Model Fits for All Aging Times', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, which='both', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Fits completed for all aging times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results\n",
    "\n",
    "Save fitted parameters and plots to the outputs directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T15:11:57.028995Z",
     "iopub.status.busy": "2026-02-09T15:11:57.028884Z",
     "iopub.status.idle": "2026-02-09T15:11:57.036831Z",
     "shell.execute_reply": "2026-02-09T15:11:57.036386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"..\") / \"outputs\" / \"dmt\" / \"relaxation\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Save multi-aging results as CSV\n",
    "df_results = pd.DataFrame(multi_age_results).T\n",
    "csv_path = output_dir / \"relaxation_multi_aging_results.csv\"\n",
    "df_results.to_csv(csv_path)\n",
    "print(f\"\\nSaved results to: {csv_path}\")\n",
    "\n",
    "# Save Bayesian posterior samples (only if Bayesian ran)\n",
    "if bayesian_completed:\n",
    "    posterior_df = pd.DataFrame({\n",
    "        \"G0\": posterior_samples[\"G0\"],\n",
    "        \"eta_0\": posterior_samples[\"eta_0\"],\n",
    "        \"eta_inf\": posterior_samples[\"eta_inf\"],\n",
    "        \"t_eq\": posterior_samples[\"t_eq\"],\n",
    "    })\n",
    "    posterior_path = output_dir / \"relaxation_posterior_samples.csv\"\n",
    "    posterior_df.to_csv(posterior_path, index=False)\n",
    "    print(f\"Saved posterior samples to: {posterior_path}\")\n",
    "else:\n",
    "    print(\"FAST_MODE: Skipping posterior samples save\")\n",
    "\n",
    "print(\"\\nAll results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Key Takeaways\n\n### Physical Insights\n\n1. **Structure Recovery Drives Relaxation**\n   - During relaxation ($\\dot{\\gamma} = 0$), only aging occurs: $d\\lambda/dt = (1-\\lambda)/t_{\\text{eq}}$\n   - As structure rebuilds ($\\lambda$ increases), relaxation time $\\theta_1(\\lambda) = \\eta(\\lambda)/G(\\lambda)$ increases\n   - This produces **arrested relaxation**: fast initial decay, slower at late times (opposite to simple Maxwell)\n\n2. **Aging Time Controls Initial Structure**\n   - Longer aging → higher initial $\\lambda_0$ (more structured state)\n   - $\\lambda_0$ increases from ~0.6 (600s) to ~0.9 (3600s) for laponite data\n   - Initial stress $\\sigma_{\\text{init}}$ also increases with aging time\n\n3. **Material Property Consistency**\n   - Equilibration time $t_{\\text{eq}}$ is consistent across aging times (CV < 20%)\n   - $t_{\\text{eq}}$ is a material property, independent of loading history\n\n### Modeling Insights\n\n1. **Parameter Identifiability**\n   - Breakdown parameters $(a, c)$ are **NOT identifiable** from relaxation data\n   - Since $\\dot{\\gamma} = 0$, the term $a\\lambda|\\dot{\\gamma}|^c$ vanishes\n   - Identifiable: $G_0$, $\\eta_0$, $\\eta_\\infty$, $t_{\\text{eq}}$, initial conditions ($\\sigma_{\\text{init}}$, $\\lambda_0$)\n\n2. **Bayesian Inference Quality**\n   - Excellent convergence: R-hat < 1.01 for all parameters\n   - Good sampling: ESS > 400 per chain\n   - No divergences observed\n   - Tight credible intervals indicate well-constrained parameters\n\n3. **NLSQ Performance**\n   - Excellent fits: R² > 0.99 for all aging times\n   - Fast optimization: ~5-10 seconds per dataset\n   - Robust convergence with reasonable initial guesses\n\n### Practical Recommendations\n\n1. **Experimental Protocol**\n   - Use multiple aging times to map structure evolution\n   - Ensure sufficient relaxation time to observe full recovery (several $t_{\\text{eq}}$)\n   - Combine with startup/flow tests to constrain breakdown parameters\n\n2. **Modeling Strategy**\n   - Fix breakdown parameters when fitting relaxation-only data\n   - Use NLSQ for initial fit, then Bayesian for uncertainty quantification\n   - Validate consistency of material properties ($t_{\\text{eq}}$) across conditions\n\n3. **Next Steps**\n   - Combine relaxation with startup data to constrain all parameters\n   - Investigate temperature dependence of $t_{\\text{eq}}$\n   - Explore nonlocal effects (shear banding) if applicable\n\n## Further Reading\n\n### DMT Model Documentation\n\n- [DMT Overview](../../docs/source/models/dmt/index.rst) — Model hierarchy and selection guide\n- [Relaxation Protocol Equations](../../docs/source/models/dmt/dmt.rst#stress-relaxation-cessation-of-flow) — Mathematical derivation\n\n### Key References\n\n1. **de Souza Mendes, P. R. (2009).** \"Modeling the thixotropic behavior of structured fluids.\" *J. Non-Newtonian Fluid Mech.*, 164, 66-75.\n\n2. **Thompson, R. L., & de Souza Mendes, P. R. (2014).** \"Thixotropic behavior of elasto-viscoplastic materials.\" *Physics of Fluids*, 26, 023101.\n\n3. **Mewis, J., & Wagner, N. J. (2009).** \"Thixotropy.\" *Advances in Colloid and Interface Science*, 147-148, 214-227. — Review of aging effects\n\n4. **Larson, R. G., & Wei, Y. (2019).** \"A review of thixotropy and its rheological modeling.\" *J. Rheology*, 63, 477-501."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}