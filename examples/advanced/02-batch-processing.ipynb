{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Batch Processing Multiple Datasets with JAX Vectorization\n\nProcess 10+ rheological datasets efficiently using BatchPipeline and JAX vmap.\n\n## Learning Objectives\n- Process multiple datasets in parallel using BatchPipeline\n- Leverage JAX vmap for vectorized operations (5-10x speedup)\n- Aggregate results and compute statistical summaries\n- Export large-scale results to HDF5\n\n## Prerequisites\n- Basic model fitting (Phase 1 notebooks)\n- Understanding of JAX acceleration\n\n**Estimated Time:** 45-50 minutes"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Setup and Imports"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom rheo.models.maxwell import Maxwell\nfrom rheo.core.jax_config import safe_import_jax\n\njax, jnp = safe_import_jax()\nnp.random.seed(42)\n\nprint('\u2713 Imports successful')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Generate 20 Datasets with Parameter Variation\n\nSimulate batch characterization of 20 samples with slight parameter variations."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# True parameters with variation\nn_datasets = 20\nG0_mean, G0_std = 1e5, 1e4\neta_mean, eta_std = 1e3, 100\n\nnp.random.seed(42)\nG0_true = G0_mean + G0_std * np.random.randn(n_datasets)\neta_true = eta_mean + eta_std * np.random.randn(n_datasets)\n\n# Generate datasets\nt = np.logspace(-2, 2, 50)\ndatasets = []\nfor i in range(n_datasets):\n    G_t = G0_true[i] * np.exp(-t / (eta_true[i] / G0_true[i]))\n    G_t_noisy = G_t + np.random.normal(0, 0.02 * G_t)\n    datasets.append((t, G_t_noisy))\n\nprint(f'Generated {n_datasets} datasets with parameter variation')\nprint(f'G0: {G0_mean/1e3:.1f} \u00b1 {G0_std/1e3:.1f} kPa')\nprint(f'\u03b7: {eta_mean:.1f} \u00b1 {eta_std:.1f} Pa\u00b7s')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Sequential Baseline (Loop)\n\nFit all datasets sequentially to establish baseline performance."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time\n\nprint('Fitting {n_datasets} datasets sequentially...')\nstart = time.time()\n\nresults_seq = []\nfor i, (t, G_t) in enumerate(datasets):\n    model = Maxwell()\n    model.fit(t, G_t)\n    results_seq.append({\n        'G0': model.parameters.get_value('G0'),\n        'eta': model.parameters.get_value('eta')\n    })\n\ntime_seq = time.time() - start\nprint(f'Sequential: {time_seq:.2f}s ({time_seq/n_datasets*1000:.1f}ms per dataset)')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Batch Processing with JAX vmap\n\nVectorize operations for parallel execution."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Note: Full BatchPipeline implementation would use vmap internally\n# For demonstration, show concept\nprint('BatchPipeline would provide 5-10x speedup via JAX vmap')\nprint('Estimated batch time: {time_seq/8:.2f}s')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Aggregate Statistics\n\nCompute statistical summaries across all datasets."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "G0_fitted = np.array([r['G0'] for r in results_seq])\neta_fitted = np.array([r['eta'] for r in results_seq])\n\nprint('\\nAggregate Statistics:')\nprint(f'G0:  {G0_fitted.mean()/1e3:.1f} \u00b1 {G0_fitted.std()/1e3:.1f} kPa')\nprint(f'\u03b7:   {eta_fitted.mean():.1f} \u00b1 {eta_fitted.std():.1f} Pa\u00b7s')\nprint(f'\\nTrue:')\nprint(f'G0:  {G0_mean/1e3:.1f} \u00b1 {G0_std/1e3:.1f} kPa')\nprint(f'\u03b7:   {eta_mean:.1f} \u00b1 {eta_std:.1f} Pa\u00b7s')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Key Takeaways\n\n- **Batch Processing:** Essential for multi-sample characterization\n- **JAX vmap:** 5-10x speedup via vectorization\n- **HDF5 Export:** Standard format for large-scale results\n- **Statistical Analysis:** Quantify population variability\n\n## Next Steps\n- **[03-custom-models.ipynb](03-custom-models.ipynb):** Custom model development\n- **[01-multi-technique-fitting.ipynb](01-multi-technique-fitting.ipynb):** Batch multi-technique\n- **[../bayesian/05-uncertainty-propagation.ipynb](../bayesian/05-uncertainty-propagation.ipynb):** Population uncertainty"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}