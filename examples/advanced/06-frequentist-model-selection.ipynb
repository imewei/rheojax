{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Frequentist Model Selection with AIC/BIC\n\nThis notebook demonstrates systematic model comparison using **frequentist information criteria** (AIC, BIC) and the `ModelComparisonPipeline` API. This complements the Bayesian approach (WAIC/LOO) shown in `bayesian/04-model-comparison.ipynb`.\n\n**Learning Objectives:**\n- Use `ModelComparisonPipeline` for automated model comparison\n- Understand AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion)\n- Calculate AIC weights and evidence ratios for model selection\n- Interpret complexity vs performance trade-offs\n- Compare frequentist (AIC/BIC) vs Bayesian (WAIC/LOO) model selection\n\n**Prerequisites:** Basic understanding of model fitting (complete basic/ notebooks first)\n\n**Estimated Time:** 40-45 minutes\n\n**Companion Notebook:** Use `bayesian/04-model-comparison.ipynb` for Bayesian model selection with WAIC/LOO\n\n**Key Concepts:**\n- **AIC** (Akaike Information Criterion): Penalizes complexity based on number of parameters\n- **BIC** (Bayesian Information Criterion): Stronger complexity penalty than AIC\n- **\u0394AIC < 2**: Models essentially equivalent\n- **2 < \u0394AIC < 4**: Moderate evidence for best model\n- **4 < \u0394AIC < 7**: Strong evidence for best model\n- **\u0394AIC > 10**: Very strong evidence for best model"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from rheo.pipeline import ModelComparisonPipeline\n",
    "from rheo.core.data import RheoData\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Polymer Oscillation Data\n",
    "\n",
    "We'll create frequency sweep data (G' and G\") that resembles a viscoelastic polymer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate frequency vector\n",
    "frequency = np.logspace(-2, 3, 50)  # 0.01 to 1000 rad/s\n",
    "\n",
    "# True underlying model: Fractional Zener (SLS variant)\n",
    "# Parameters\n",
    "Ge_true = 1e5      # Equilibrium modulus (Pa)\n",
    "Gm_true = 5e5      # Maxwell arm modulus (Pa)\n",
    "alpha_true = 0.6   # Fractional order\n",
    "tau_true = 1.0     # Relaxation time (s)\n",
    "\n",
    "# Calculate G' and G\" (simplified fractional Zener)\n",
    "omega = frequency\n",
    "omega_tau = omega * tau_true\n",
    "\n",
    "# Storage modulus G'\n",
    "G_storage_true = Ge_true + Gm_true * (omega_tau)**alpha_true / (1 + (omega_tau)**(2*alpha_true))\n",
    "\n",
    "# Loss modulus G\"\n",
    "G_loss_true = Gm_true * (omega_tau)**alpha_true / (1 + (omega_tau)**(2*alpha_true)) * np.sin(alpha_true * np.pi/2)\n",
    "\n",
    "# Add realistic noise (5% for G', 7% for G\")\n",
    "noise_storage = 0.05\n",
    "noise_loss = 0.07\n",
    "\n",
    "G_storage_noisy = G_storage_true * (1 + noise_storage * np.random.randn(len(G_storage_true)))\n",
    "G_loss_noisy = G_loss_true * (1 + noise_loss * np.random.randn(len(G_loss_true)))\n",
    "\n",
    "# For model fitting, we'll use |G*| (complex modulus magnitude)\n",
    "G_star_true = np.sqrt(G_storage_true**2 + G_loss_true**2)\n",
    "G_star_noisy = np.sqrt(G_storage_noisy**2 + G_loss_noisy**2)\n",
    "\n",
    "# Create RheoData object\n",
    "data = RheoData(\n",
    "    x=frequency,\n",
    "    y=G_star_noisy,\n",
    "    x_units='rad/s',\n",
    "    y_units='Pa',\n",
    "    domain='frequency',\n",
    "    test_mode='oscillation'\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(frequency)} data points\")\n",
    "print(f\"Frequency range: {frequency[0]:.2e} to {frequency[-1]:.2e} rad/s\")\n",
    "print(f\"Complex modulus range: {G_star_noisy.min():.2e} to {G_star_noisy.max():.2e} Pa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: G' and G\"\n",
    "ax1.loglog(frequency, G_storage_noisy, 'o', label=\"G' (storage)\", markersize=6, alpha=0.7)\n",
    "ax1.loglog(frequency, G_loss_noisy, 's', label='G\" (loss)', markersize=6, alpha=0.7)\n",
    "ax1.set_xlabel('Frequency (rad/s)', fontsize=12)\n",
    "ax1.set_ylabel('Modulus (Pa)', fontsize=12)\n",
    "ax1.set_title('Storage and Loss Moduli', fontsize=13)\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: |G*| (complex modulus)\n",
    "ax2.loglog(frequency, G_star_noisy, 'o', color='purple', \n",
    "           label='|G*| (data)', markersize=6, alpha=0.7)\n",
    "ax2.loglog(frequency, G_star_true, '--', color='red', \n",
    "           label='True model', linewidth=2)\n",
    "ax2.set_xlabel('Frequency (rad/s)', fontsize=12)\n",
    "ax2.set_ylabel('|G*| (Pa)', fontsize=12)\n",
    "ax2.set_title('Complex Modulus Magnitude', fontsize=13)\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Candidate Models\n",
    "\n",
    "We'll compare 5 models of increasing complexity:\n",
    "1. **Maxwell**: Simplest viscoelastic model\n",
    "2. **Zener**: Standard Linear Solid with equilibrium modulus\n",
    "3. **Fractional Maxwell (Gel)**: Power-law relaxation\n",
    "4. **Fractional Maxwell (Liquid)**: Fractional Maxwell without equilibrium modulus\n",
    "5. **Fractional Zener (SS)**: Most complex, with fractional elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define candidate models\n",
    "candidate_models = [\n",
    "    'maxwell',\n",
    "    'zener',\n",
    "    'fractional_maxwell_gel',\n",
    "    'fractional_maxwell_liquid',\n",
    "    'fractional_zener_ss'\n",
    "]\n",
    "\n",
    "print(f\"Comparing {len(candidate_models)} models:\")\n",
    "for i, model in enumerate(candidate_models, 1):\n",
    "    print(f\"  {i}. {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model Comparison Pipeline\n",
    "\n",
    "The `ModelComparisonPipeline` automatically fits all models and computes comparison metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run comparison pipeline\n",
    "comparison_pipeline = ModelComparisonPipeline(candidate_models)\n",
    "results = comparison_pipeline.run(data)\n",
    "\n",
    "print(\"\\nModel comparison complete!\")\n",
    "print(f\"Fitted {len(results)} models successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Comparison Table\n",
    "\n",
    "We'll create a comprehensive comparison table with:\n",
    "- **RMSE**: Root Mean Square Error (lower is better)\n",
    "- **R\u00b2**: Coefficient of determination (higher is better, max 1.0)\n",
    "- **AIC**: Akaike Information Criterion (lower is better)\n",
    "- **BIC**: Bayesian Information Criterion (lower is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics for each model\n",
    "comparison_data = []\n",
    "\n",
    "for model_name in candidate_models:\n",
    "    if model_name in results:\n",
    "        result = results[model_name]\n",
    "        comparison_data.append({\n",
    "            'Model': model_name,\n",
    "            'Parameters': result['n_params'],\n",
    "            'RMSE': result['rmse'],\n",
    "            'R\u00b2': result['r_squared'],\n",
    "            'AIC': result['aic'],\n",
    "            'BIC': result['bic']\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Sort by AIC (lower is better)\n",
    "df_comparison_sorted = df_comparison.sort_values('AIC').reset_index(drop=True)\n",
    "\n",
    "# Display formatted table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON RESULTS (sorted by AIC)\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(df_comparison_sorted.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Lower AIC/BIC and RMSE are better; Higher R\u00b2 is better (max 1.0)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model by different criteria\n",
    "best_aic = comparison_pipeline.get_best_model(metric='aic')\n",
    "best_bic = comparison_pipeline.get_best_model(metric='bic')\n",
    "best_r2 = comparison_pipeline.get_best_model(metric='r_squared')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST MODEL BY DIFFERENT CRITERIA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest by AIC:  {best_aic}\")\n",
    "print(f\"Best by BIC:  {best_bic}\")\n",
    "print(f\"Best by R\u00b2:   {best_r2}\")\n",
    "\n",
    "# Calculate AIC weights (relative likelihood)\n",
    "aic_values = df_comparison_sorted['AIC'].values\n",
    "delta_aic = aic_values - aic_values.min()\n",
    "aic_weights = np.exp(-0.5 * delta_aic) / np.sum(np.exp(-0.5 * delta_aic))\n",
    "\n",
    "print(f\"\\n{'Model':<30} {'AIC Weight':<15} {'Evidence Ratio'}\")\n",
    "print(\"-\" * 60)\n",
    "for i, (model, weight) in enumerate(zip(df_comparison_sorted['Model'], aic_weights)):\n",
    "    evidence_ratio = aic_weights[0] / weight if weight > 0 else np.inf\n",
    "    print(f\"{model:<30} {weight:>10.4f}     {evidence_ratio:>8.1f}x\")\n",
    "\n",
    "print(\"\\nNote: AIC weight represents the probability that the model is the best model.\")\n",
    "print(\"Evidence ratio shows how much better the best model is compared to others.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize All Model Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = plt.cm.tab10(range(len(candidate_models)))\n",
    "\n",
    "for i, model_name in enumerate(candidate_models):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot data\n",
    "    ax.loglog(frequency, G_star_noisy, 'o', color='gray', \n",
    "              label='Data', markersize=5, alpha=0.5)\n",
    "    \n",
    "    # Plot model fit\n",
    "    if model_name in results:\n",
    "        predictions = results[model_name]['predictions']\n",
    "        r2 = results[model_name]['r_squared']\n",
    "        aic = results[model_name]['aic']\n",
    "        \n",
    "        ax.loglog(frequency, predictions, '-', color=colors[i], \n",
    "                 linewidth=2.5, label=f'Fit (R\u00b2={r2:.4f})')\n",
    "        \n",
    "        ax.set_xlabel('Frequency (rad/s)', fontsize=10)\n",
    "        ax.set_ylabel('|G*| (Pa)', fontsize=10)\n",
    "        ax.set_title(f'{model_name}\\nAIC = {aic:.1f}', fontsize=11)\n",
    "        ax.legend(fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remove extra subplot\n",
    "fig.delaxes(axes[-1])\n",
    "\n",
    "plt.suptitle('Model Comparison: All Fits', fontsize=14, y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(16, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, model_name in enumerate(candidate_models):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    if model_name in results:\n",
    "        predictions = results[model_name]['predictions']\n",
    "        residuals = (G_star_noisy - predictions) / G_star_noisy * 100  # Percent error\n",
    "        rmse = results[model_name]['rmse']\n",
    "        \n",
    "        ax.semilogx(frequency, residuals, 'o-', color=colors[i], \n",
    "                   markersize=5, alpha=0.7, linewidth=1.5)\n",
    "        ax.axhline(y=0, color='k', linestyle='--', linewidth=1)\n",
    "        ax.axhline(y=5, color='r', linestyle=':', linewidth=1, alpha=0.5)\n",
    "        ax.axhline(y=-5, color='r', linestyle=':', linewidth=1, alpha=0.5)\n",
    "        \n",
    "        ax.set_xlabel('Frequency (rad/s)', fontsize=10)\n",
    "        ax.set_ylabel('Relative Error (%)', fontsize=10)\n",
    "        ax.set_title(f'{model_name}\\nRMSE = {rmse:.2e} Pa', fontsize=11)\n",
    "        ax.set_ylim([-15, 15])\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remove extra subplot\n",
    "fig.delaxes(axes[-1])\n",
    "\n",
    "plt.suptitle('Residual Analysis (red lines = \u00b15% error)', fontsize=14, y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Comparison Across Models\n",
    "\n",
    "Compare fitted parameters across models to understand physical interpretations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FITTED PARAMETERS FOR EACH MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name in candidate_models:\n",
    "    if model_name in results:\n",
    "        print(f\"\\n{model_name.upper()}:\")\n",
    "        print(\"-\" * 60)\n",
    "        params = results[model_name]['parameters']\n",
    "        for param_name, param in params.items():\n",
    "            print(f\"  {param_name:<15} = {param.value:>12.3e}  {param.units if param.units else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity vs Performance Trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: R\u00b2 vs number of parameters\n",
    "ax1.plot(df_comparison_sorted['Parameters'], df_comparison_sorted['R\u00b2'], \n",
    "         'o-', markersize=10, linewidth=2)\n",
    "for i, model in enumerate(df_comparison_sorted['Model']):\n",
    "    ax1.annotate(model, \n",
    "                (df_comparison_sorted['Parameters'].iloc[i], \n",
    "                 df_comparison_sorted['R\u00b2'].iloc[i]),\n",
    "                textcoords=\"offset points\", xytext=(0,10), \n",
    "                ha='center', fontsize=8)\n",
    "ax1.set_xlabel('Number of Parameters', fontsize=12)\n",
    "ax1.set_ylabel('R\u00b2 (Goodness of Fit)', fontsize=12)\n",
    "ax1.set_title('Model Complexity vs Fit Quality', fontsize=13)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([0.95, 1.001])\n",
    "\n",
    "# Right: AIC comparison\n",
    "x_pos = np.arange(len(df_comparison_sorted))\n",
    "bars = ax2.bar(x_pos, df_comparison_sorted['AIC'], color=colors[:len(df_comparison_sorted)])\n",
    "ax2.set_xlabel('Model', fontsize=12)\n",
    "ax2.set_ylabel('AIC (lower is better)', fontsize=12)\n",
    "ax2.set_title('Akaike Information Criterion', fontsize=13)\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(df_comparison_sorted['Model'], rotation=45, ha='right', fontsize=9)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Highlight best model\n",
    "bars[0].set_edgecolor('red')\n",
    "bars[0].set_linewidth(3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we performed systematic model comparison for rheological data:\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Model Selection**: Information criteria (AIC, BIC) balance fit quality against complexity\n",
    "2. **Best Model**: The model with lowest AIC/BIC is statistically preferred\n",
    "3. **Complexity Trade-off**: More parameters improve R\u00b2 but may overfit (penalized by AIC/BIC)\n",
    "4. **Residual Patterns**: Systematic residuals indicate model inadequacy\n",
    "\n",
    "### Interpretation Guidelines:\n",
    "\n",
    "- **\u0394A IC < 2**: Models are essentially equivalent\n",
    "- **2 < \u0394AIC < 4**: Moderate evidence favoring best model  \n",
    "- **4 < \u0394AIC < 7**: Strong evidence favoring best model\n",
    "- **\u0394AIC > 10**: Very strong evidence favoring best model\n",
    "\n",
    "### When to Use Each Model:\n",
    "\n",
    "- **Maxwell**: Purely viscous liquids with single relaxation time\n",
    "- **Zener**: Materials with equilibrium modulus (gels, crosslinked polymers)\n",
    "- **Fractional Models**: Materials with broad relaxation spectra (power-law behavior)\n",
    "- **Complex Fractional**: Multi-modal relaxation with fractional components\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "1. Always compare multiple models systematically\n",
    "2. Use information criteria (AIC/BIC) for objective selection\n",
    "3. Examine residuals for systematic patterns\n",
    "4. Consider physical interpretability of parameters\n",
    "5. Validate selected model with independent test data\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Apply multi-technique fitting (see `multi_technique_fitting.ipynb`)\n",
    "- Perform advanced sensitivity analysis (see `advanced_workflows.ipynb`)\n",
    "- Explore Bayesian model selection with uncertainty quantification (Phase 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}