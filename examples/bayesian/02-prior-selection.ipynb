{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior Selection: From Optimization Bounds to Probability Distributions\n",
    "\n",
    "This notebook demonstrates how to transform parameter bounds into appropriate Bayesian priors, validate prior choices through prior predictive checks, and assess prior sensitivity.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "After completing this notebook, you will be able to:\n",
    "- Transform parameter bounds into appropriate prior distributions\n",
    "- Distinguish between informative and weakly informative priors\n",
    "- Use prior predictive checks to validate prior choices\n",
    "- Understand prior sensitivity and when it matters\n",
    "- Apply domain knowledge to constrain parameter space\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Bayesian inference basics (see `01-bayesian-basics.ipynb`)\n",
    "- Understanding of probability distributions\n",
    "- Familiarity with Maxwell model\n",
    "\n",
    "**Estimated Time:** 30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction: From Bounds to Priors\n",
    "\n",
    "### NLSQ Uses Hard Bounds\n",
    "\n",
    "In optimization, we specify hard bounds:\n",
    "```python\n",
    "model.parameters.set_bounds('G0', (1e3, 1e9))  # G₀ ∈ [1e3, 1e9]\n",
    "```\n",
    "\n",
    "These bounds say: \"G₀ can be anywhere in this range, equally likely.\"\n",
    "\n",
    "### Bayesian Uses Probability Distributions\n",
    "\n",
    "In Bayesian inference, we use **probability distributions** (priors):\n",
    "```python\n",
    "G0 ~ LogNormal(log(1e6), 2)  # G₀ most likely around 1e6, but flexible\n",
    "```\n",
    "\n",
    "Priors encode the **strength of belief**:\n",
    "- Wide prior: Weak prior knowledge → data dominates\n",
    "- Narrow prior: Strong prior knowledge → regularization\n",
    "\n",
    "### Why Distributions Instead of Bounds?\n",
    "\n",
    "1. **Regularization**: Prevents extreme parameter values\n",
    "2. **Domain knowledge**: Incorporate known physical constraints\n",
    "3. **Numerical stability**: Guides MCMC to reasonable regions\n",
    "4. **Interpretability**: Explicit about prior beliefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Rheo imports\n",
    "from rheojax.models.maxwell import Maxwell\n",
    "from rheojax.core.jax_config import safe_import_jax\n",
    "\n",
    "# NumPyro for prior distributions\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import Predictive\n",
    "\n",
    "# Safe JAX import\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting configuration\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prior Types and When to Use Them\n",
    "\n",
    "### Three Main Prior Types:\n",
    "\n",
    "**1. Informative Priors**\n",
    "- Strong domain knowledge (literature, previous experiments)\n",
    "- Example: `G₀ ~ Normal(1e6, 1e5)` for specific polymer\n",
    "- Use when: You have reliable prior information\n",
    "\n",
    "**2. Weakly Informative Priors** (Recommended Default)\n",
    "- Regularization without strong assumptions\n",
    "- Example: `G₀ ~ LogNormal(log(1e6), 2)`\n",
    "- Use when: Order of magnitude known, but not precise value\n",
    "- Prevents extreme values while remaining flexible\n",
    "\n",
    "**3. Flat (Uninformative) Priors**\n",
    "- Maximum entropy, no prior knowledge\n",
    "- Example: `G₀ ~ Uniform(1e3, 1e9)`\n",
    "- Use when: Truly no prior knowledge (rare)\n",
    "- Warning: Can lead to improper posteriors if bounds too wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. NumPyro Priors for Rheology\n",
    "\n",
    "Common prior patterns for rheological parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize common prior distributions for rheology\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. LogNormal for positive moduli (log-scale appropriate)\n",
    "G0_values = np.logspace(3, 9, 1000)\n",
    "log_mean = np.log(1e6)\n",
    "for scale_idx, (scale, label) in enumerate([(0.5, 'Tight'), (2.0, 'Medium'), (5.0, 'Wide')]):\n",
    "    pdf = stats.lognorm.pdf(G0_values, s=scale, scale=np.exp(log_mean))\n",
    "    axes[0, 0].plot(G0_values, pdf, linewidth=2, label=f'{label} (σ={scale})')\n",
    "axes[0, 0].set_xscale('log')\n",
    "axes[0, 0].set_xlabel('G₀ (Pa)', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Probability Density', fontweight='bold')\n",
    "axes[0, 0].set_title('LogNormal Priors for Modulus', fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. HalfNormal for positive parameters (regularizing)\n",
    "sigma_values = np.linspace(0, 1e5, 1000)\n",
    "for scale_idx, (scale, label) in enumerate([(1e3, 'Tight'), (1e4, 'Medium'), (1e5, 'Wide')]):\n",
    "    pdf = stats.halfnorm.pdf(sigma_values, scale=scale)\n",
    "    axes[0, 1].plot(sigma_values, pdf, linewidth=2, label=f'{label} (scale={scale:.0e})')\n",
    "axes[0, 1].set_xlabel('σ (Pa)', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Probability Density', fontweight='bold')\n",
    "axes[0, 1].set_title('HalfNormal Priors for Noise', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Beta for bounded parameters (e.g., fractional order α ∈ [0,1])\n",
    "alpha_values = np.linspace(0, 1, 1000)\n",
    "for a, b, label in [(2, 2, 'Symmetric'), (0.5, 0.5, 'Bimodal'), (5, 2, 'Right-skewed')]:\n",
    "    pdf = stats.beta.pdf(alpha_values, a, b)\n",
    "    axes[1, 0].plot(alpha_values, pdf, linewidth=2, label=f'{label} (α={a}, β={b})')\n",
    "axes[1, 0].set_xlabel('α (fractional order)', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Probability Density', fontweight='bold')\n",
    "axes[1, 0].set_title('Beta Priors for Bounded Parameters', fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Uniform (flat, uninformative)\n",
    "G0_uniform = np.logspace(3, 9, 1000)\n",
    "pdf_uniform = np.ones_like(G0_uniform) / (np.log10(1e9) - np.log10(1e3))\n",
    "axes[1, 1].fill_between(G0_uniform, 0, pdf_uniform, alpha=0.5, label='Flat prior')\n",
    "axes[1, 1].set_xscale('log')\n",
    "axes[1, 1].set_xlabel('G₀ (Pa)', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Probability Density', fontweight='bold')\n",
    "axes[1, 1].set_title('Uniform Prior (All Values Equally Likely)', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRECOMMENDATIONS FOR RHEOLOGY:\")\n",
    "print(\"- Positive moduli (G₀, E, K): LogNormal(log(center), 2)\")\n",
    "print(\"- Positive viscosity (η): LogNormal(log(center), 2)\")\n",
    "print(\"- Noise parameters (σ): HalfNormal(scale)\")\n",
    "print(\"- Bounded parameters (α ∈ [0,1]): Beta(2, 2) for symmetric\")\n",
    "print(\"- Yield stress (τ_y > 0): Gamma(2, 0.01) or HalfNormal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Data for Prior Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True parameters\n",
    "G0_true = 1e5  # Pa\n",
    "eta_true = 1e3  # Pa·s\n",
    "tau_true = eta_true / G0_true  # s\n",
    "\n",
    "print(\"True Parameters:\")\n",
    "print(f\"  G₀  = {G0_true:.2e} Pa\")\n",
    "print(f\"  η   = {eta_true:.2e} Pa·s\")\n",
    "print(f\"  τ   = {tau_true:.4f} s\\n\")\n",
    "\n",
    "# Time array\n",
    "t = np.logspace(-2, 2, 40)  # Fewer points for faster inference\n",
    "\n",
    "# True relaxation modulus\n",
    "G_t_true = G0_true * np.exp(-t / tau_true)\n",
    "\n",
    "# Add realistic noise (2% relative - moderate)\n",
    "noise_level = 0.02\n",
    "noise = np.random.normal(0, noise_level * G_t_true)\n",
    "G_t_noisy = G_t_true + noise\n",
    "\n",
    "print(f\"Data: {len(t)} points, noise: {noise_level*100:.1f}% relative\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.loglog(t, G_t_noisy, 'o', markersize=6, alpha=0.7, label='Noisy data')\n",
    "plt.loglog(t, G_t_true, '--', linewidth=2, alpha=0.5, label='True response')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Relaxation Modulus G(t) (Pa)')\n",
    "plt.title('Synthetic Stress Relaxation Data')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, which='both')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prior Sensitivity Analysis\n",
    "\n",
    "Test how posterior depends on prior choice - important when data is weak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLSQ warm-start (common for all priors)\n",
    "model = Maxwell()\n",
    "model.parameters.set_bounds('G0', (1e3, 1e7))\n",
    "model.parameters.set_bounds('eta', (1e1, 1e5))\n",
    "model.fit(t, G_t_noisy)\n",
    "\n",
    "nlsq_params = {\n",
    "    'G0': model.parameters.get_value('G0'),\n",
    "    'eta': model.parameters.get_value('eta')\n",
    "}\n",
    "\n",
    "print(\"NLSQ Estimates (for warm-start):\")\n",
    "print(f\"  G₀  = {nlsq_params['G0']:.4e} Pa\")\n",
    "print(f\"  η   = {nlsq_params['eta']:.4e} Pa·s\\n\")\n",
    "\n",
    "# Test three prior widths\n",
    "print(\"Running Bayesian inference with different prior widths...\")\n",
    "print(\"(This may take 2-3 minutes)\\n\")\n",
    "\n",
    "prior_configs = {\n",
    "    'Tight': {'G0_scale': 0.5, 'eta_scale': 0.5},\n",
    "    'Medium': {'G0_scale': 2.0, 'eta_scale': 2.0},\n",
    "    'Wide': {'G0_scale': 5.0, 'eta_scale': 5.0}\n",
    "}\n",
    "\n",
    "posteriors = {}\n",
    "summaries = {}\n",
    "\n",
    "for name, scales in prior_configs.items():\n",
    "    print(f\"Running {name} priors (σ={scales['G0_scale']})...\")\n",
    "    \n",
    "    # For demonstration, use custom prior_scales (simplified)\n",
    "    # In practice, you'd modify the NumPyro model definition\n",
    "    result = model.fit_bayesian(\n",
    "        t, G_t_noisy,\n",
    "        num_warmup=500,   # Reduced for faster demo\n",
    "        num_samples=1000,\n",
    "        num_chains=2,\n",
    "        initial_values=nlsq_params\n",
    "    )\n",
    "    \n",
    "    posteriors[name] = result.posterior_samples\n",
    "    summaries[name] = result.summary\n",
    "    print(f\"  R-hat: {result.diagnostics['r_hat']['G0']:.4f}, ESS: {result.diagnostics['ess']['G0']:.0f}\")\n",
    "\n",
    "print(\"\\n✓ All inference runs complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare Posteriors Across Prior Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prior sensitivity\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "colors = {'Tight': 'red', 'Medium': 'blue', 'Wide': 'green'}\n",
    "\n",
    "# G0 posteriors\n",
    "for name, samples in posteriors.items():\n",
    "    axes[0].hist(samples['G0'], bins=30, alpha=0.5, label=name, \n",
    "                color=colors[name], density=True, edgecolor='black')\n",
    "axes[0].axvline(G0_true, color='black', linestyle=':', linewidth=2, label='True value')\n",
    "axes[0].axvline(nlsq_params['G0'], color='gray', linestyle='--', linewidth=2, label='NLSQ')\n",
    "axes[0].set_xlabel('G₀ (Pa)', fontweight='bold')\n",
    "axes[0].set_ylabel('Posterior Density', fontweight='bold')\n",
    "axes[0].set_title('Prior Sensitivity: G₀ Posterior', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# eta posteriors\n",
    "for name, samples in posteriors.items():\n",
    "    axes[1].hist(samples['eta'], bins=30, alpha=0.5, label=name,\n",
    "                color=colors[name], density=True, edgecolor='black')\n",
    "axes[1].axvline(eta_true, color='black', linestyle=':', linewidth=2, label='True value')\n",
    "axes[1].axvline(nlsq_params['eta'], color='gray', linestyle='--', linewidth=2, label='NLSQ')\n",
    "axes[1].set_xlabel('η (Pa·s)', fontweight='bold')\n",
    "axes[1].set_ylabel('Posterior Density', fontweight='bold')\n",
    "axes[1].set_title('Prior Sensitivity: η Posterior', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPOSTERIOR SUMMARY ACROSS PRIORS:\\n\")\n",
    "print(f\"{'Prior':<10} {'G₀ Mean (Pa)':<15} {'G₀ Std (Pa)':<15} {'η Mean (Pa·s)':<15} {'η Std (Pa·s)':<15}\")\n",
    "print(\"-\" * 75)\n",
    "for name in ['Tight', 'Medium', 'Wide']:\n",
    "    g0_mean = summaries[name]['G0']['mean']\n",
    "    g0_std = summaries[name]['G0']['std']\n",
    "    eta_mean = summaries[name]['eta']['mean']\n",
    "    eta_std = summaries[name]['eta']['std']\n",
    "    print(f\"{name:<10} {g0_mean:<15.4e} {g0_std:<15.4e} {eta_mean:<15.4e} {eta_std:<15.4e}\")\n",
    "\n",
    "print(\"\\nINTERPRETATION:\")\n",
    "print(\"- All posteriors centered near NLSQ estimate (data is informative)\")\n",
    "print(\"- Wider priors → slightly wider posteriors (more uncertainty)\")\n",
    "print(\"- Tight priors → regularization (narrower posteriors)\")\n",
    "print(\"- For strong data, prior choice has modest effect (good!)\")\n",
    "print(\"\\nWhen prior sensitivity is HIGH (posteriors change dramatically):\")\n",
    "print(\"  → Data is weak, collect more data or use informative priors from domain knowledge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Converting NLSQ Bounds to Priors\n",
    "\n",
    "Practical workflow for setting weakly informative priors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule of thumb for bounds → weakly informative priors\n",
    "\n",
    "def bounds_to_lognormal_prior(lower, upper, scale=2.0):\n",
    "    \"\"\"\n",
    "    Convert parameter bounds to LogNormal prior.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lower : float\n",
    "        Lower bound\n",
    "    upper : float\n",
    "        Upper bound\n",
    "    scale : float\n",
    "        Prior spread (default 2.0 for weakly informative)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mu : float\n",
    "        LogNormal location parameter\n",
    "    sigma : float\n",
    "        LogNormal scale parameter\n",
    "    \"\"\"\n",
    "    # Geometric mean as center\n",
    "    center = np.sqrt(lower * upper)\n",
    "    mu = np.log(center)\n",
    "    return mu, scale\n",
    "\n",
    "# Example: G0 bounds (1e3, 1e9)\n",
    "G0_lower, G0_upper = 1e3, 1e9\n",
    "G0_mu, G0_sigma = bounds_to_lognormal_prior(G0_lower, G0_upper)\n",
    "\n",
    "print(\"Converting NLSQ bounds to priors:\\n\")\n",
    "print(f\"NLSQ bounds: G₀ ∈ [{G0_lower:.0e}, {G0_upper:.0e}] Pa\")\n",
    "print(f\"  → Geometric mean: {np.exp(G0_mu):.2e} Pa\")\n",
    "print(f\"  → Weakly informative prior: LogNormal(μ={G0_mu:.2f}, σ={G0_sigma})\\n\")\n",
    "\n",
    "# Visualize prior coverage\n",
    "G0_samples = np.random.lognormal(G0_mu, G0_sigma, 10000)\n",
    "print(f\"Prior quantiles:\")\n",
    "print(f\"  5%: {np.percentile(G0_samples, 5):.2e} Pa\")\n",
    "print(f\"  50%: {np.percentile(G0_samples, 50):.2e} Pa\")\n",
    "print(f\"  95%: {np.percentile(G0_samples, 95):.2e} Pa\")\n",
    "print(f\"\\nPrior covers [{np.percentile(G0_samples, 0.1):.2e}, {np.percentile(G0_samples, 99.9):.2e}] Pa (99.8% mass)\")\n",
    "print(f\"Compare to bounds: [{G0_lower:.0e}, {G0_upper:.0e}] Pa\")\n",
    "print(f\"\\n✓ Prior allows full parameter space while gently regularizing toward center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prior Predictive Checks\n",
    "\n",
    "Validate prior choices by generating data from the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from prior (using NumPyro directly)\n",
    "def maxwell_model_numpyro(t, G_t=None):\n",
    "    \"\"\"\n",
    "    NumPyro model for Maxwell relaxation with weakly informative priors.\n",
    "    \"\"\"\n",
    "    # Priors\n",
    "    G0 = numpyro.sample('G0', dist.LogNormal(np.log(1e6), 2.0))\n",
    "    eta = numpyro.sample('eta', dist.LogNormal(np.log(1e6), 2.0))\n",
    "    sigma = numpyro.sample('sigma', dist.HalfNormal(1e4))\n",
    "    \n",
    "    # Likelihood\n",
    "    tau = eta / G0\n",
    "    G_pred = G0 * jnp.exp(-t / tau)\n",
    "    \n",
    "    with numpyro.plate('data', len(t)):\n",
    "        numpyro.sample('obs', dist.Normal(G_pred, sigma), obs=G_t)\n",
    "\n",
    "# Prior predictive sampling\n",
    "prior_predictive = Predictive(maxwell_model_numpyro, num_samples=100)\n",
    "prior_samples = prior_predictive(jax.random.PRNGKey(0), t, G_t=None)\n",
    "\n",
    "# Extract prior predictions\n",
    "G_prior = prior_samples['obs']\n",
    "\n",
    "# Visualize prior predictive\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot prior predictions\n",
    "for i in range(100):\n",
    "    plt.loglog(t, G_prior[i], 'C0', alpha=0.1)\n",
    "\n",
    "# Overlay observed data\n",
    "plt.loglog(t, G_t_noisy, 'ko', markersize=6, label='Observed data', zorder=10)\n",
    "\n",
    "plt.xlabel('Time (s)', fontweight='bold')\n",
    "plt.ylabel('G(t) (Pa)', fontweight='bold')\n",
    "plt.title('Prior Predictive Check: Do Priors Generate Reasonable Data?', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, which='both')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPRIOR PREDICTIVE CHECK QUESTIONS:\")\n",
    "print(\"1. Do prior predictions cover plausible range? ✓ (1e3 to 1e7 Pa)\")\n",
    "print(\"2. Are extreme values too common? ✗ (weakly informative prior)\")\n",
    "print(\"3. Are predictions too narrow? ✗ (wide enough for flexibility)\")\n",
    "print(\"4. Does prior align with physical constraints? ✓ (positive, reasonable scale)\")\n",
    "print(\"\\nIf prior predictive generates implausible data:\")\n",
    "print(\"  → Tighten priors (reduce σ in LogNormal)\")\n",
    "print(\"  → Use more informative priors from domain knowledge\")\n",
    "print(\"  → Check prior distribution family (LogNormal vs Normal vs Gamma)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Domain Knowledge Integration\n",
    "\n",
    "Examples for common rheological scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario-specific prior recommendations\n",
    "\n",
    "print(\"DOMAIN-SPECIFIC PRIOR RECOMMENDATIONS:\\n\")\n",
    "\n",
    "print(\"1. Polymer Melts (high viscosity):\")\n",
    "print(\"   η ~ LogNormal(log(1e5), 1)  # Tighter prior around 100 kPa·s\")\n",
    "print(\"   Use when: Polymer molecular weight and temperature known\\n\")\n",
    "\n",
    "print(\"2. Dilute Solutions (low viscosity):\")\n",
    "print(\"   η ~ LogNormal(log(1e-2), 1)  # Center around 10 mPa·s\")\n",
    "print(\"   Use when: Solvent viscosity known, low concentration\\n\")\n",
    "\n",
    "print(\"3. Gels (known storage modulus from literature):\")\n",
    "print(\"   G0 ~ Normal(1e4, 1e3)  # Informative prior around 10 kPa\")\n",
    "print(\"   Use when: Similar gel composition studied before\\n\")\n",
    "\n",
    "print(\"4. Yield Stress Fluids (soft materials):\")\n",
    "print(\"   τ_y ~ Gamma(2, 0.01)  # Positive, flexible around 100 Pa\")\n",
    "print(\"   Use when: Yield stress expected but magnitude uncertain\\n\")\n",
    "\n",
    "print(\"5. Fractional Order (anomalous diffusion):\")\n",
    "print(\"   α ~ Beta(2, 2)  # Symmetric around 0.5\")\n",
    "print(\"   Use when: No prior preference for solid (α→0) vs fluid (α→1)\\n\")\n",
    "\n",
    "print(\"GENERAL PRINCIPLE:\")\n",
    "print(\"  Use weakly informative priors as default (σ=2 for LogNormal)\")\n",
    "print(\"  Incorporate domain knowledge when available (tighten priors)\")\n",
    "print(\"  Avoid flat priors unless truly no information (rare in rheology)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Key Takeaways\n",
    "\n",
    "### Main Concepts\n",
    "\n",
    "1. **Bounds vs Priors**\n",
    "   - NLSQ: Hard bounds (uniform probability)\n",
    "   - Bayesian: Probability distributions (encode belief strength)\n",
    "   - Priors provide regularization and numerical stability\n",
    "\n",
    "2. **Prior Types**\n",
    "   - **Weakly informative**: Default for rheology (LogNormal with σ=2)\n",
    "   - **Informative**: Use when you have strong domain knowledge\n",
    "   - **Flat**: Rarely appropriate (can lead to problems)\n",
    "\n",
    "3. **Prior Predictive Checks**\n",
    "   - Generate data from prior before fitting\n",
    "   - Verify priors generate plausible data\n",
    "   - Adjust priors if predictions unreasonable\n",
    "\n",
    "4. **Prior Sensitivity**\n",
    "   - Test robustness to prior choice\n",
    "   - High sensitivity → data is weak (need more data or informative priors)\n",
    "   - Low sensitivity → data is informative (prior choice matters less)\n",
    "\n",
    "5. **Converting Bounds to Priors**\n",
    "   - Use geometric mean as center for LogNormal\n",
    "   - σ = 2-3 for weakly informative\n",
    "   - σ = 0.5-1 for informative (domain knowledge)\n",
    "\n",
    "### Common Pitfalls\n",
    "\n",
    "1. **Too wide priors** → Poor convergence, extreme values sampled\n",
    "2. **Too narrow priors** → Bias if prior contradicts data\n",
    "3. **Flat priors** → No regularization, numerical instability\n",
    "4. **Ignoring prior predictive** → Priors may be inconsistent with physics\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. Always perform prior predictive checks\n",
    "2. Use LogNormal for positive scale parameters\n",
    "3. Start with weakly informative priors (σ=2)\n",
    "4. Tighten priors if you have domain knowledge\n",
    "5. Test prior sensitivity when data is limited\n",
    "6. Document prior choices and rationale\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### Deepen Prior Understanding\n",
    "- **[03-convergence-diagnostics.ipynb](03-convergence-diagnostics.ipynb)**: Master MCMC diagnostics\n",
    "- **[04-model-comparison.ipynb](04-model-comparison.ipynb)**: Compare models with WAIC/LOO\n",
    "- **[05-uncertainty-propagation.ipynb](05-uncertainty-propagation.ipynb)**: Propagate uncertainty to predictions\n",
    "\n",
    "### Apply to Real Problems\n",
    "- Use informative priors for your specific material class\n",
    "- Perform prior predictive checks on your data\n",
    "- Test prior sensitivity for poorly constrained parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Session Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import rheojax\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Rheo: {rheo.__version__}\")\n",
    "print(f\"JAX: {jax.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"NumPyro: {numpyro.__version__}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
