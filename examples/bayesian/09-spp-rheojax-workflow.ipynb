{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c53ab7c",
   "metadata": {},
   "source": [
    "# SPP LAOS: Complete NLSQ → NUTS Workflow\n",
    "\n",
    "This notebook demonstrates the complete Sequence of Physical Processes (SPP) framework for\n",
    "Large Amplitude Oscillatory Shear (LAOS) analysis using RheoJAX.\n",
    "\n",
    "## SPP Theory Overview\n",
    "\n",
    "The SPP framework (Rogers et al.) decomposes nonlinear stress responses into:\n",
    "- **Elastic contribution**: Recoverable strain energy (in-phase with strain)\n",
    "- **Viscous contribution**: Dissipated energy (in-phase with strain rate)\n",
    "\n",
    "Key outputs:\n",
    "- `sigma_sy`: Static yield stress (maximum elastic stress)\n",
    "- `sigma_dy`: Dynamic yield stress (maximum viscous stress)  \n",
    "- `S_factor`: Stiffening ratio (-1 to 1, 0 = linear)\n",
    "- `T_factor`: Thickening ratio (-1 to 1, 0 = linear)\n",
    "\n",
    "**Defaults**: n_harmonics=39, step_size=8, num_mode=2, wrapped strain-rate inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb51cad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:00.777397Z",
     "iopub.status.busy": "2026-02-02T21:49:00.777113Z",
     "iopub.status.idle": "2026-02-02T21:49:03.278955Z",
     "shell.execute_reply": "2026-02-02T21:49:03.272894Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# MUST come before importing matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import arviz as az\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.pipeline.workflows import SPPAmplitudeSweepPipeline\n",
    "from rheojax.transforms import SPPDecomposer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic LAOS Data\n",
    "\n",
    "Create amplitude sweep data with power-law yielding behavior:\n",
    "$$\\sigma = A \\cdot \\gamma_0^n \\cdot \\sin(\\omega t)$$\n",
    "\n",
    "where $A=60$ Pa and $n=0.7$ (sublinear yielding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebbe383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:03.283908Z",
     "iopub.status.busy": "2026-02-02T21:49:03.283662Z",
     "iopub.status.idle": "2026-02-02T21:49:03.416726Z",
     "shell.execute_reply": "2026-02-02T21:49:03.409402Z"
    }
   },
   "outputs": [],
   "source": [
    "# Experimental parameters\n",
    "omega = 1.5  # rad/s\n",
    "gamma_levels = jnp.array([0.1, 0.2, 0.4, 0.8, 1.6])  # strain amplitudes\n",
    "n_points = 400  # points per cycle\n",
    "t = jnp.linspace(0, 2 * jnp.pi / omega, n_points)\n",
    "\n",
    "# Power-law yield parameters (ground truth)\n",
    "A_true = 60.0  # Pa\n",
    "n_true = 0.7   # exponent\n",
    "\n",
    "def make_dataset(gamma_0):\n",
    "    \"\"\"Generate synthetic LAOS dataset with power-law yielding.\"\"\"\n",
    "    strain = gamma_0 * jnp.sin(omega * t)\n",
    "    # Add slight nonlinearity for more realistic behavior\n",
    "    stress = A_true * gamma_0**n_true * jnp.sin(omega * t)\n",
    "    # Add small noise\n",
    "    noise = np.random.normal(0, 0.5, len(t))\n",
    "    return RheoData(\n",
    "        x=np.array(t),\n",
    "        y=np.array(stress) + noise,\n",
    "        domain=\"time\",\n",
    "        metadata={\"omega\": float(omega), \"gamma_0\": float(gamma_0), \"strain\": np.array(strain)}\n",
    "    )\n",
    "\n",
    "np.random.seed(42)\n",
    "datasets = [make_dataset(float(g)) for g in gamma_levels]\n",
    "print(f\"Created {len(datasets)} datasets at γ₀ = {list(gamma_levels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6g7h8",
   "metadata": {},
   "source": [
    "## 2. Visualize Lissajous Curves\n",
    "\n",
    "Lissajous (stress-strain) curves reveal nonlinear viscoelastic behavior:\n",
    "- **Ellipse**: Linear viscoelastic\n",
    "- **Distorted ellipse**: Nonlinear response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i9j0k1l2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:03.419866Z",
     "iopub.status.busy": "2026-02-02T21:49:03.419701Z",
     "iopub.status.idle": "2026-02-02T21:49:03.766565Z",
     "shell.execute_reply": "2026-02-02T21:49:03.759703Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(datasets), figsize=(3*len(datasets), 3), sharey=True)\n",
    "if len(datasets) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, ds, gamma in zip(axes, datasets, gamma_levels):\n",
    "    strain = ds.metadata[\"strain\"]\n",
    "    stress = ds.y\n",
    "    ax.plot(strain, stress, 'b-', lw=1.5)\n",
    "    ax.set_xlabel(r'Strain $\\gamma$')\n",
    "    ax.set_title(f'$\\\\gamma_0$ = {gamma:.2f}')\n",
    "    ax.axhline(0, color='gray', lw=0.5, ls='--')\n",
    "    ax.axvline(0, color='gray', lw=0.5, ls='--')\n",
    "\n",
    "axes[0].set_ylabel('Stress (Pa)')\n",
    "fig.suptitle('Lissajous Curves (Stress vs Strain)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m3n4o5p6",
   "metadata": {},
   "source": [
    "## 3. SPP Decomposition (Single Amplitude)\n",
    "\n",
    "Demonstrate the SPPDecomposer on a single dataset to understand the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f5e056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:03.797702Z",
     "iopub.status.busy": "2026-02-02T21:49:03.790932Z",
     "iopub.status.idle": "2026-02-02T21:49:05.250011Z",
     "shell.execute_reply": "2026-02-02T21:49:05.245806Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select middle amplitude for demonstration\n",
    "idx = len(datasets) // 2\n",
    "demo_data = datasets[idx]\n",
    "demo_gamma = float(gamma_levels[idx])\n",
    "\n",
    "# Create decomposer with Rogers defaults\n",
    "decomposer = SPPDecomposer(omega=float(omega), gamma_0=demo_gamma)\n",
    "result = decomposer.transform(demo_data)\n",
    "\n",
    "# Display key results\n",
    "print(f\"SPP Decomposition at γ₀ = {demo_gamma}:\")\n",
    "print(f\"  Static yield stress (σ_sy):  {decomposer.results_['sigma_sy']:.3f} Pa\")\n",
    "print(f\"  Dynamic yield stress (σ_dy): {decomposer.results_['sigma_dy']:.3f} Pa\")\n",
    "print(f\"  Stiffening factor (S):       {decomposer.results_['S_factor']:.4f}\")\n",
    "print(f\"  Thickening factor (T):       {decomposer.results_['T_factor']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7r8s9t0",
   "metadata": {},
   "source": [
    "## 4. Amplitude Sweep Pipeline\n",
    "\n",
    "Process all amplitudes and extract yield stress vs strain amplitude relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1v2w3x4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:05.253681Z",
     "iopub.status.busy": "2026-02-02T21:49:05.253476Z",
     "iopub.status.idle": "2026-02-02T21:49:05.282113Z",
     "shell.execute_reply": "2026-02-02T21:49:05.277945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run SPP amplitude sweep pipeline\n",
    "pipeline = SPPAmplitudeSweepPipeline(omega=float(omega))\n",
    "pipeline.run(datasets, gamma_0_values=list(map(float, gamma_levels)))\n",
    "\n",
    "# Get yield stresses for all amplitudes\n",
    "yield_data = pipeline.get_yield_stresses()\n",
    "sigma_sy = yield_data[\"sigma_sy\"]\n",
    "sigma_dy = yield_data[\"sigma_dy\"]\n",
    "\n",
    "print(\"Amplitude Sweep Results:\")\n",
    "print(f\"{'γ₀':>8} {'σ_sy (Pa)':>12} {'σ_dy (Pa)':>12}\")\n",
    "print(\"-\" * 34)\n",
    "for g, sy, dy in zip(gamma_levels, sigma_sy, sigma_dy):\n",
    "    print(f\"{float(g):>8.3f} {float(sy):>12.3f} {float(dy):>12.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y5z6a7b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:05.284930Z",
     "iopub.status.busy": "2026-02-02T21:49:05.284741Z",
     "iopub.status.idle": "2026-02-02T21:49:05.461768Z",
     "shell.execute_reply": "2026-02-02T21:49:05.460440Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot yield stress vs strain amplitude\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.loglog(gamma_levels, sigma_sy, 'o-', label=r'$\\sigma_{sy}$ (static)', markersize=8)\n",
    "ax.loglog(gamma_levels, sigma_dy, 's--', label=r'$\\sigma_{dy}$ (dynamic)', markersize=8)\n",
    "\n",
    "# Reference power-law\n",
    "gamma_ref = np.linspace(float(gamma_levels.min()), float(gamma_levels.max()), 100)\n",
    "ax.loglog(gamma_ref, A_true * gamma_ref**n_true, 'k:', lw=2, \n",
    "          label=f'True: {A_true}·γ$^{{{n_true}}}$')\n",
    "\n",
    "ax.set_xlabel(r'Strain Amplitude $\\gamma_0$')\n",
    "ax.set_ylabel('Yield Stress (Pa)')\n",
    "ax.set_title('SPP Yield Stress vs Strain Amplitude')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "## 5. NLSQ Fitting (Point Estimation)\n",
    "\n",
    "Fit power-law model to yield stress data using fast NLSQ optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61ae34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:05.465011Z",
     "iopub.status.busy": "2026-02-02T21:49:05.464688Z",
     "iopub.status.idle": "2026-02-02T21:49:05.540122Z",
     "shell.execute_reply": "2026-02-02T21:49:05.538480Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit power-law model: σ_sy = scale * γ^exp\n",
    "pipeline.fit_model(bayesian=False, yield_type=\"static\")\n",
    "model = pipeline.get_model()\n",
    "\n",
    "# Get fitted parameters\n",
    "params = model.parameters\n",
    "scale_nlsq = params[\"sigma_sy_scale\"].value\n",
    "exp_nlsq = params[\"sigma_sy_exp\"].value\n",
    "\n",
    "print(\"NLSQ Fit Results (Point Estimates):\")\n",
    "print(f\"  σ_sy_scale: {scale_nlsq:.4f} Pa (true: {A_true})\")\n",
    "print(f\"  σ_sy_exp:   {exp_nlsq:.4f} (true: {n_true})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g3h4i5j6",
   "metadata": {},
   "source": [
    "## 6. Bayesian Inference with NUTS\n",
    "\n",
    "Quantify parameter uncertainty using Bayesian inference with warm-start from NLSQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k7l8m9n0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:05.547768Z",
     "iopub.status.busy": "2026-02-02T21:49:05.547424Z",
     "iopub.status.idle": "2026-02-02T21:49:43.315244Z",
     "shell.execute_reply": "2026-02-02T21:49:43.312430Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bayesian inference with proper settings for convergence\n",
    "# Key settings:\n",
    "# - num_chains=4: Multiple chains enable proper R-hat computation\n",
    "# - num_warmup=2000: More warmup for better adaptation\n",
    "# - num_samples=2000: Enough samples per chain for reliable posterior estimates\n",
    "# - target_accept_prob=0.99: Very high to minimize divergences\n",
    "# - max_tree_depth=12: Allow deeper trees for complex posteriors\n",
    "bayes = model.fit_bayesian(\n",
    "    gamma_levels, \n",
    "    sigma_sy,\n",
    "    test_mode=\"oscillation\",\n",
    "    num_chains=4,\n",
    "    num_warmup=2000,           # More warmup for better step size adaptation\n",
    "    num_samples=2000,\n",
    "    target_accept_prob=0.99,   # Very high = very small steps = minimal divergences\n",
    "    max_tree_depth=12,         # Allow deeper tree exploration\n",
    ")\n",
    "\n",
    "# Extract posterior statistics\n",
    "print(\"\\nBayesian Posterior Summary:\")\n",
    "print(f\"{'Parameter':>15} {'Mean':>10} {'Std':>10} {'5%':>10} {'95%':>10}\")\n",
    "print(\"-\" * 57)\n",
    "for param in [\"sigma_sy_scale\", \"sigma_sy_exp\"]:\n",
    "    if param in bayes.summary:\n",
    "        s = bayes.summary[param]\n",
    "        print(f\"{param:>15} {s['mean']:>10.4f} {s['std']:>10.4f} \"\n",
    "              f\"{s.get('q05', 0):>10.4f} \"\n",
    "              f\"{s.get('q95', 0):>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o1p2q3r4",
   "metadata": {},
   "source": [
    "## 7. MCMC Diagnostics\n",
    "\n",
    "Check convergence using standard diagnostics:\n",
    "- **R-hat < 1.01**: Chains converged (requires multiple chains for reliable computation)\n",
    "- **ESS > 400**: Sufficient effective samples\n",
    "- **Divergences = 0**: No sampling issues\n",
    "\n",
    "**Note on trace plots**: With only 5 data points and a well-constrained model, the posterior \n",
    "is very tight. Traces may appear \"smooth\" because the sampler explores a narrow region efficiently.\n",
    "This is expected behavior, not a problem. The key diagnostic is that the trace should be \n",
    "stationary (no trends) and the histogram should be unimodal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s5t6u7v8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:43.320077Z",
     "iopub.status.busy": "2026-02-02T21:49:43.319848Z",
     "iopub.status.idle": "2026-02-02T21:49:43.334134Z",
     "shell.execute_reply": "2026-02-02T21:49:43.329553Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check diagnostics - R-hat and ESS are in the diagnostics dict, not summary\n",
    "diag = bayes.diagnostics\n",
    "print(\"MCMC Diagnostics:\")\n",
    "print(f\"  Divergences: {diag.get('divergences', 'N/A')}\")\n",
    "\n",
    "# R-hat and ESS are stored in diagnostics['r_hat'] and diagnostics['ess'] dicts\n",
    "r_hat_dict = diag.get('r_hat', {})\n",
    "ess_dict = diag.get('ess', {})\n",
    "\n",
    "print(\"\\nConvergence by Parameter:\")\n",
    "for param in [\"sigma_sy_scale\", \"sigma_sy_exp\"]:\n",
    "    rhat = r_hat_dict.get(param, 'N/A')\n",
    "    ess = ess_dict.get(param, 'N/A')\n",
    "    rhat_str = f\"{rhat:.4f}\" if isinstance(rhat, (int, float)) else str(rhat)\n",
    "    ess_str = f\"{ess:.0f}\" if isinstance(ess, (int, float)) else str(ess)\n",
    "    print(f\"  {param}: R-hat={rhat_str}, ESS={ess_str}\")\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\nInterpretation:\")\n",
    "divergences = diag.get('divergences', 0)\n",
    "if divergences == 0:\n",
    "    print(\"  ✓ No divergences - sampling is healthy\")\n",
    "elif divergences < 100:\n",
    "    print(f\"  ⚠ {divergences} divergences - likely from noise parameter funnel (see diagnosis below)\")\n",
    "    print(\"    → Parameters of interest (scale, exp) are still reliable if R-hat < 1.01\")\n",
    "else:\n",
    "    print(f\"  ✗ {divergences} divergences - consider reparameterization or more informative priors\")\n",
    "\n",
    "for param in [\"sigma_sy_scale\", \"sigma_sy_exp\"]:\n",
    "    rhat = r_hat_dict.get(param, 1.0)\n",
    "    ess = ess_dict.get(param, 0)\n",
    "    if isinstance(rhat, (int, float)) and rhat < 1.01:\n",
    "        print(f\"  ✓ {param}: R-hat={rhat:.4f} < 1.01 (converged)\")\n",
    "    elif isinstance(rhat, (int, float)):\n",
    "        print(f\"  ⚠ {param}: R-hat={rhat:.4f} >= 1.01 (may need more samples)\")\n",
    "    if isinstance(ess, (int, float)) and ess > 400:\n",
    "        print(f\"  ✓ {param}: ESS={ess:.0f} > 400 (sufficient)\")\n",
    "    elif isinstance(ess, (int, float)):\n",
    "        print(f\"  ⚠ {param}: ESS={ess:.0f} < 400 (may need more samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w9x0y1z2",
   "metadata": {},
   "source": [
    "## 8. Posterior Visualization with ArviZ\n",
    "\n",
    "ArviZ provides comprehensive MCMC diagnostics:\n",
    "\n",
    "| Plot | What to Look For |\n",
    "|------|------------------|\n",
    "| **Trace** | Chains should overlap (\"fuzzy caterpillar\"), no trends |\n",
    "| **Pair** | Correlations between parameters; divergences cluster in problem regions |\n",
    "| **Forest** | HDI intervals should overlap across chains |\n",
    "| **Autocorrelation** | Should drop quickly to zero (good mixing) |\n",
    "| **Rank** | Histograms should be uniform (chains exploring same space) |\n",
    "\n",
    "**About Divergences**: Divergences indicate the sampler encountered difficult geometry.\n",
    "Common causes: (1) tight funnels from hierarchical priors, (2) strong parameter correlations,\n",
    "(3) multimodal posteriors. Solutions: increase `target_accept_prob`, reparameterize, or use\n",
    "more informative priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:43.358583Z",
     "iopub.status.busy": "2026-02-02T21:49:43.358415Z",
     "iopub.status.idle": "2026-02-02T21:49:43.368838Z",
     "shell.execute_reply": "2026-02-02T21:49:43.366094Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create ArviZ InferenceData for comprehensive diagnostics\n",
    "# First, reshape samples for ArviZ (needs shape: chains x draws)\n",
    "samples = bayes.posterior_samples\n",
    "num_chains = bayes.num_chains\n",
    "num_samples = bayes.num_samples\n",
    "\n",
    "# Build posterior dict with correct shape for ArviZ\n",
    "posterior_dict = {}\n",
    "for param in [\"sigma_sy_scale\", \"sigma_sy_exp\", \"noise\", \"sigma\"]:\n",
    "    if param in samples:\n",
    "        vals = np.array(samples[param])\n",
    "        # Reshape to (num_chains, num_draws)\n",
    "        if vals.ndim == 1:\n",
    "            posterior_dict[param] = vals.reshape(num_chains, -1)\n",
    "        else:\n",
    "            posterior_dict[param] = vals\n",
    "\n",
    "# Create InferenceData\n",
    "idata = az.from_dict(posterior=posterior_dict)\n",
    "\n",
    "print(f\"Created ArviZ InferenceData with {num_chains} chains × {num_samples} samples\")\n",
    "print(f\"Parameters: {list(posterior_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ogjp3ilkq8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:43.372448Z",
     "iopub.status.busy": "2026-02-02T21:49:43.371973Z",
     "iopub.status.idle": "2026-02-02T21:49:43.520797Z",
     "shell.execute_reply": "2026-02-02T21:49:43.516389Z"
    }
   },
   "outputs": [],
   "source": [
    "# ArviZ Trace Plot - shows mixing across chains\n",
    "axes = az.plot_trace(idata, var_names=[\"sigma_sy_scale\", \"sigma_sy_exp\"], \n",
    "                     figsize=(10, 4), compact=False)\n",
    "fig = axes.ravel()[0].figure\n",
    "fig.suptitle('Trace Plots (ArviZ)', y=1.02)\n",
    "fig.subplots_adjust(top=0.9, hspace=0.4, wspace=0.3)\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebhxufn55k",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:43.534855Z",
     "iopub.status.busy": "2026-02-02T21:49:43.534457Z",
     "iopub.status.idle": "2026-02-02T21:49:43.653226Z",
     "shell.execute_reply": "2026-02-02T21:49:43.651304Z"
    }
   },
   "outputs": [],
   "source": [
    "# ArviZ Pair Plot - shows parameter correlations and divergences\n",
    "axes = az.plot_pair(idata, var_names=[\"sigma_sy_scale\", \"sigma_sy_exp\"],\n",
    "                    kind=\"kde\", marginals=True, figsize=(6, 6),\n",
    "                    kde_kwargs={\"contourf_kwargs\": {\"alpha\": 0.5}})\n",
    "fig = plt.gcf()\n",
    "fig.suptitle('Pair Plot: Parameter Correlations', y=1.02)\n",
    "fig.subplots_adjust(top=0.92)\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nqnkfqxrty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:43.674648Z",
     "iopub.status.busy": "2026-02-02T21:49:43.674501Z",
     "iopub.status.idle": "2026-02-02T21:49:43.741924Z",
     "shell.execute_reply": "2026-02-02T21:49:43.741485Z"
    }
   },
   "outputs": [],
   "source": [
    "# ArviZ Forest Plot - credible intervals comparison across chains\n",
    "axes = az.plot_forest(idata, var_names=[\"sigma_sy_scale\", \"sigma_sy_exp\"],\n",
    "                      combined=False, hdi_prob=0.94, figsize=(8, 4))\n",
    "fig = plt.gcf()\n",
    "fig.suptitle('Forest Plot: 94% HDI by Chain', y=1.02)\n",
    "fig.subplots_adjust(top=0.9)\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58sw83imz8m",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:43.749117Z",
     "iopub.status.busy": "2026-02-02T21:49:43.748810Z",
     "iopub.status.idle": "2026-02-02T21:49:43.779178Z",
     "shell.execute_reply": "2026-02-02T21:49:43.772146Z"
    }
   },
   "outputs": [],
   "source": [
    "# ArviZ Summary - comprehensive statistics with R-hat and ESS\n",
    "summary_df = az.summary(idata, var_names=[\"sigma_sy_scale\", \"sigma_sy_exp\"],\n",
    "                        hdi_prob=0.94, round_to=4)\n",
    "print(\"ArviZ Summary Statistics:\")\n",
    "print(summary_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dn2e46k3shj",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:43.782239Z",
     "iopub.status.busy": "2026-02-02T21:49:43.782140Z",
     "iopub.status.idle": "2026-02-02T21:49:44.118541Z",
     "shell.execute_reply": "2026-02-02T21:49:44.115153Z"
    }
   },
   "outputs": [],
   "source": [
    "# Diagnose divergences: Check if they correlate with the noise parameter\n",
    "# Divergences often occur in \"funnel\" geometries where noise → 0\n",
    "if \"noise\" in posterior_dict:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    noise_samples = posterior_dict[\"noise\"].flatten()\n",
    "    scale_samples = posterior_dict[\"sigma_sy_scale\"].flatten()\n",
    "    exp_samples = posterior_dict[\"sigma_sy_exp\"].flatten()\n",
    "    \n",
    "    # Plot noise distribution - check for values near zero\n",
    "    axes[0].hist(noise_samples, bins=50, density=True, alpha=0.7, edgecolor='white')\n",
    "    axes[0].axvline(noise_samples.mean(), color='r', ls='--', label=f'Mean: {noise_samples.mean():.2f}')\n",
    "    axes[0].set_xlabel('Noise (σ)')\n",
    "    axes[0].set_ylabel('Density')\n",
    "    axes[0].set_title('Noise Posterior\\n(HalfCauchy prior can cause funnels)')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Noise vs scale - check for funnel shape\n",
    "    axes[1].scatter(noise_samples, scale_samples, alpha=0.1, s=1)\n",
    "    axes[1].set_xlabel('Noise (σ)')\n",
    "    axes[1].set_ylabel('sigma_sy_scale')\n",
    "    axes[1].set_title('Noise vs Scale\\n(Funnel = divergence source)')\n",
    "    \n",
    "    # Noise vs exponent\n",
    "    axes[2].scatter(noise_samples, exp_samples, alpha=0.1, s=1)\n",
    "    axes[2].set_xlabel('Noise (σ)')\n",
    "    axes[2].set_ylabel('sigma_sy_exp')\n",
    "    axes[2].set_title('Noise vs Exponent')\n",
    "    \n",
    "    plt.suptitle('Divergence Diagnosis: Noise Parameter Geometry', y=1.02)\n",
    "    fig.subplots_adjust(top=0.85, wspace=0.3)\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"Noise posterior: mean={noise_samples.mean():.3f}, std={noise_samples.std():.3f}\")\n",
    "    print(f\"Noise range: [{noise_samples.min():.4f}, {noise_samples.max():.3f}]\")\n",
    "    print(f\"\\nNote: Divergences likely occur when noise → 0 (funnel geometry)\")\n",
    "    print(\"The HalfCauchy(scale=10) prior is too vague for only 5 data points.\")\n",
    "else:\n",
    "    print(\"Noise parameter not found in samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "icbn4jkowp",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:44.121990Z",
     "iopub.status.busy": "2026-02-02T21:49:44.121719Z",
     "iopub.status.idle": "2026-02-02T21:49:44.199026Z",
     "shell.execute_reply": "2026-02-02T21:49:44.197330Z"
    }
   },
   "outputs": [],
   "source": [
    "# ArviZ Autocorrelation Plot - shows how quickly samples decorrelate\n",
    "axes = az.plot_autocorr(idata, var_names=[\"sigma_sy_scale\", \"sigma_sy_exp\"],\n",
    "                        figsize=(10, 4), combined=True)\n",
    "fig = plt.gcf()\n",
    "fig.suptitle('Autocorrelation (lower is better)', y=1.02)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ngb7ebtm8g",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:44.212341Z",
     "iopub.status.busy": "2026-02-02T21:49:44.212039Z",
     "iopub.status.idle": "2026-02-02T21:49:44.390515Z",
     "shell.execute_reply": "2026-02-02T21:49:44.388889Z"
    }
   },
   "outputs": [],
   "source": [
    "# ArviZ Rank Plot - uniform ranks indicate good mixing\n",
    "axes = az.plot_rank(idata, var_names=[\"sigma_sy_scale\", \"sigma_sy_exp\"], figsize=(10, 4))\n",
    "fig = plt.gcf()\n",
    "fig.suptitle('Rank Plots (uniform = good mixing)', y=1.02)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8g9h0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:44.404035Z",
     "iopub.status.busy": "2026-02-02T21:49:44.402837Z",
     "iopub.status.idle": "2026-02-02T21:49:44.649447Z",
     "shell.execute_reply": "2026-02-02T21:49:44.646566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Posterior predictive check\n",
    "samples = bayes.posterior_samples\n",
    "scale_samples = np.array(samples.get(\"sigma_sy_scale\", [])).flatten()\n",
    "exp_samples = np.array(samples.get(\"sigma_sy_exp\", [])).flatten()\n",
    "\n",
    "if len(scale_samples) > 0 and len(exp_samples) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    # Data\n",
    "    gamma_plot = np.array(gamma_levels)\n",
    "    ax.scatter(gamma_plot, np.array(sigma_sy), s=80, c='black', zorder=5, label='Data')\n",
    "    \n",
    "    # Posterior predictive samples\n",
    "    gamma_fine = np.linspace(gamma_plot.min() * 0.8, gamma_plot.max() * 1.2, 100)\n",
    "    n_draws = min(100, len(scale_samples))\n",
    "    for i in range(n_draws):\n",
    "        pred = scale_samples[i] * gamma_fine ** exp_samples[i]\n",
    "        ax.plot(gamma_fine, pred, 'b-', alpha=0.05)\n",
    "    \n",
    "    # Mean prediction\n",
    "    mean_pred = scale_samples.mean() * gamma_fine ** exp_samples.mean()\n",
    "    ax.plot(gamma_fine, mean_pred, 'r-', lw=2, label='Posterior Mean')\n",
    "    \n",
    "    # True values\n",
    "    true_pred = A_true * gamma_fine ** n_true\n",
    "    ax.plot(gamma_fine, true_pred, 'g--', lw=2, label='True Model')\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel(r'Strain Amplitude $\\gamma_0$')\n",
    "    ax.set_ylabel(r'Static Yield Stress $\\sigma_{sy}$ (Pa)')\n",
    "    ax.set_title('Posterior Predictive Check')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i1j2k3l4",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "This notebook demonstrated the complete SPP LAOS workflow:\n",
    "\n",
    "1. **Data Generation**: Synthetic LAOS amplitude sweep\n",
    "2. **Visualization**: Lissajous curves reveal nonlinear behavior\n",
    "3. **SPP Decomposition**: Extract yield stresses and nonlinearity factors\n",
    "4. **NLSQ Fitting**: Fast point estimation for power-law model\n",
    "5. **Bayesian Inference**: Uncertainty quantification with NUTS\n",
    "6. **Diagnostics**: Convergence verification (R-hat, ESS, divergences)\n",
    "7. **Posterior Checks**: Visual validation of model fit\n",
    "\n",
    "### Key Settings\n",
    "\n",
    "| Parameter | This Notebook | Production Value |\n",
    "|-----------|---------------|------------------|\n",
    "| `num_warmup` | 1000 | 1000+ |\n",
    "| `num_samples` | 2000 | 2000+ |\n",
    "| R-hat target | < 1.01 | < 1.01 |\n",
    "| ESS target | > 400 | > 400 |\n",
    "| Divergences | 0 | 0 |\n",
    "\n",
    "### References\n",
    "\n",
    "- Rogers, S.A. et al. (2011) \"A sequence of physical processes...\", J. Rheol.\n",
    "- RheoJAX Documentation: https://rheojax.readthedocs.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m5n6o7p8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:49:44.653304Z",
     "iopub.status.busy": "2026-02-02T21:49:44.653177Z",
     "iopub.status.idle": "2026-02-02T21:49:44.668677Z",
     "shell.execute_reply": "2026-02-02T21:49:44.666263Z"
    }
   },
   "outputs": [],
   "source": [
    "# Final comparison: NLSQ vs Bayesian vs True\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PARAMETER COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Parameter':<20} {'True':>10} {'NLSQ':>10} {'Bayesian':>10}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'sigma_sy_scale':<20} {A_true:>10.4f} {scale_nlsq:>10.4f} \"\n",
    "      f\"{bayes.summary['sigma_sy_scale']['mean']:>10.4f}\")\n",
    "print(f\"{'sigma_sy_exp':<20} {n_true:>10.4f} {exp_nlsq:>10.4f} \"\n",
    "      f\"{bayes.summary['sigma_sy_exp']['mean']:>10.4f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rheojax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
