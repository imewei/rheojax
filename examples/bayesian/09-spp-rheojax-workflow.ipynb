{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c53ab7c",
   "metadata": {},
   "source": "# SPP LAOS: Complete NLSQ \u2192 NUTS Workflow\n\n> **Handbook:** See [SPP LAOS Workflow](../../docs/source/transforms/spp_decomposer.rst#complete-workflow) for pipeline implementation and [Rogers SPP Defaults](../../docs/source/transforms/spp_decomposer.rst#theory) for parameter selection guidance.\n\nThis notebook demonstrates the complete Sequence of Physical Processes (SPP) framework for\nLarge Amplitude Oscillatory Shear (LAOS) analysis using RheoJAX.\n\n## Learning Objectives\n\nAfter completing this notebook, you will be able to:\n- Apply SPP decomposition to LAOS amplitude sweep data\n- Extract yield stress scaling relationships using power-law fits\n- Use SPPAmplitudeSweepPipeline for automated analysis\n- Perform NLSQ \u2192 NUTS workflow for SPP parameter uncertainty\n- Interpret convergence diagnostics for SPP models\n- Understand divergence sources in hierarchical noise models\n\n## SPP Theory Overview\n\nThe SPP framework (Rogers et al.) decomposes nonlinear stress responses into:\n- **Elastic contribution**: Recoverable strain energy (in-phase with strain)\n- **Viscous contribution**: Dissipated energy (in-phase with strain rate)\n\nKey outputs:\n- `sigma_sy`: Static yield stress (maximum elastic stress)\n- `sigma_dy`: Dynamic yield stress (maximum viscous stress)  \n- `S_factor`: Stiffening ratio (-1 to 1, 0 = linear)\n- `T_factor`: Thickening ratio (-1 to 1, 0 = linear)\n\n**Defaults**: n_harmonics=39, step_size=8, num_mode=2, wrapped strain-rate inference.\n\n**Estimated Time:** 25-30 minutes"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb51cad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:20.213117Z",
     "iopub.status.busy": "2026-02-09T21:19:20.212885Z",
     "iopub.status.idle": "2026-02-09T21:19:21.995509Z",
     "shell.execute_reply": "2026-02-09T21:19:21.994909Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# MUST come before importing matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import arviz as az\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.pipeline.workflows import SPPAmplitudeSweepPipeline\n",
    "from rheojax.transforms import SPPDecomposer\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(\"\")))\n",
    "from utils.plotting_utils import (\n",
    "    plot_nlsq_fit, display_arviz_diagnostics, plot_posterior_predictive\n",
    ")\n",
    "\n",
    "FAST_MODE = os.environ.get(\"FAST_MODE\", \"1\") == \"1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic LAOS Data\n",
    "\n",
    "Create amplitude sweep data with power-law yielding behavior:\n",
    "$$\\sigma = A \\cdot \\gamma_0^n \\cdot \\sin(\\omega t)$$\n",
    "\n",
    "where $A=60$ Pa and $n=0.7$ (sublinear yielding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebbe383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:21.997211Z",
     "iopub.status.busy": "2026-02-09T21:19:21.997028Z",
     "iopub.status.idle": "2026-02-09T21:19:22.081917Z",
     "shell.execute_reply": "2026-02-09T21:19:22.081206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Experimental parameters\n",
    "omega = 1.5  # rad/s\n",
    "gamma_levels = jnp.array([0.1, 0.2, 0.4, 0.8, 1.6])  # strain amplitudes\n",
    "n_points = 400  # points per cycle\n",
    "t = jnp.linspace(0, 2 * jnp.pi / omega, n_points)\n",
    "\n",
    "# Power-law yield parameters (ground truth)\n",
    "A_true = 60.0  # Pa\n",
    "n_true = 0.7   # exponent\n",
    "\n",
    "def make_dataset(gamma_0):\n",
    "    \"\"\"Generate synthetic LAOS dataset with power-law yielding.\"\"\"\n",
    "    strain = gamma_0 * jnp.sin(omega * t)\n",
    "    # Add slight nonlinearity for more realistic behavior\n",
    "    stress = A_true * gamma_0**n_true * jnp.sin(omega * t)\n",
    "    # Add small noise\n",
    "    noise = np.random.normal(0, 0.5, len(t))\n",
    "    return RheoData(\n",
    "        x=np.array(t),\n",
    "        y=np.array(stress) + noise,\n",
    "        domain=\"time\",\n",
    "        metadata={\"omega\": float(omega), \"gamma_0\": float(gamma_0), \"strain\": np.array(strain)}\n",
    "    )\n",
    "\n",
    "np.random.seed(42)\n",
    "datasets = [make_dataset(float(g)) for g in gamma_levels]\n",
    "print(f\"Created {len(datasets)} datasets at \u03b3\u2080 = {list(gamma_levels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6g7h8",
   "metadata": {},
   "source": [
    "## 2. Visualize Lissajous Curves\n",
    "\n",
    "Lissajous (stress-strain) curves reveal nonlinear viscoelastic behavior:\n",
    "- **Ellipse**: Linear viscoelastic\n",
    "- **Distorted ellipse**: Nonlinear response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i9j0k1l2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:22.083311Z",
     "iopub.status.busy": "2026-02-09T21:19:22.083187Z",
     "iopub.status.idle": "2026-02-09T21:19:22.290453Z",
     "shell.execute_reply": "2026-02-09T21:19:22.289996Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(datasets), figsize=(3*len(datasets), 3), sharey=True)\n",
    "if len(datasets) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, ds, gamma in zip(axes, datasets, gamma_levels):\n",
    "    strain = ds.metadata[\"strain\"]\n",
    "    stress = ds.y\n",
    "    ax.plot(strain, stress, 'b-', lw=1.5)\n",
    "    ax.set_xlabel(r'Strain $\\gamma$')\n",
    "    ax.set_title(f'$\\\\gamma_0$ = {gamma:.2f}')\n",
    "    ax.axhline(0, color='gray', lw=0.5, ls='--')\n",
    "    ax.axvline(0, color='gray', lw=0.5, ls='--')\n",
    "\n",
    "axes[0].set_ylabel('Stress (Pa)')\n",
    "fig.suptitle('Lissajous Curves (Stress vs Strain)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m3n4o5p6",
   "metadata": {},
   "source": [
    "## 3. SPP Decomposition (Single Amplitude)\n",
    "\n",
    "Demonstrate the SPPDecomposer on a single dataset to understand the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f5e056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:22.291692Z",
     "iopub.status.busy": "2026-02-09T21:19:22.291580Z",
     "iopub.status.idle": "2026-02-09T21:19:23.324486Z",
     "shell.execute_reply": "2026-02-09T21:19:23.323988Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select middle amplitude for demonstration\n",
    "idx = len(datasets) // 2\n",
    "demo_data = datasets[idx]\n",
    "demo_gamma = float(gamma_levels[idx])\n",
    "\n",
    "# Create decomposer with Rogers defaults\n",
    "decomposer = SPPDecomposer(omega=float(omega), gamma_0=demo_gamma)\n",
    "result = decomposer.transform(demo_data)\n",
    "\n",
    "# Display key results\n",
    "print(f\"SPP Decomposition at \u03b3\u2080 = {demo_gamma}:\")\n",
    "print(f\"  Static yield stress (\u03c3_sy):  {decomposer.results_['sigma_sy']:.3f} Pa\")\n",
    "print(f\"  Dynamic yield stress (\u03c3_dy): {decomposer.results_['sigma_dy']:.3f} Pa\")\n",
    "print(f\"  Stiffening factor (S):       {decomposer.results_['S_factor']:.4f}\")\n",
    "print(f\"  Thickening factor (T):       {decomposer.results_['T_factor']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7r8s9t0",
   "metadata": {},
   "source": [
    "## 4. Amplitude Sweep Pipeline\n",
    "\n",
    "Process all amplitudes and extract yield stress vs strain amplitude relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1v2w3x4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:23.325700Z",
     "iopub.status.busy": "2026-02-09T21:19:23.325596Z",
     "iopub.status.idle": "2026-02-09T21:19:23.340028Z",
     "shell.execute_reply": "2026-02-09T21:19:23.339644Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run SPP amplitude sweep pipeline\n",
    "pipeline = SPPAmplitudeSweepPipeline(omega=float(omega))\n",
    "pipeline.run(datasets, gamma_0_values=list(map(float, gamma_levels)))\n",
    "\n",
    "# Get yield stresses for all amplitudes\n",
    "yield_data = pipeline.get_yield_stresses()\n",
    "sigma_sy = yield_data[\"sigma_sy\"]\n",
    "sigma_dy = yield_data[\"sigma_dy\"]\n",
    "\n",
    "print(\"Amplitude Sweep Results:\")\n",
    "print(f\"{'\u03b3\u2080':>8} {'\u03c3_sy (Pa)':>12} {'\u03c3_dy (Pa)':>12}\")\n",
    "print(\"-\" * 34)\n",
    "for g, sy, dy in zip(gamma_levels, sigma_sy, sigma_dy):\n",
    "    print(f\"{float(g):>8.3f} {float(sy):>12.3f} {float(dy):>12.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y5z6a7b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:23.341343Z",
     "iopub.status.busy": "2026-02-09T21:19:23.341256Z",
     "iopub.status.idle": "2026-02-09T21:19:23.491834Z",
     "shell.execute_reply": "2026-02-09T21:19:23.491367Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot yield stress vs strain amplitude\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.loglog(gamma_levels, sigma_sy, 'o-', label=r'$\\sigma_{sy}$ (static)', markersize=8)\n",
    "ax.loglog(gamma_levels, sigma_dy, 's--', label=r'$\\sigma_{dy}$ (dynamic)', markersize=8)\n",
    "\n",
    "# Reference power-law\n",
    "gamma_ref = np.linspace(float(gamma_levels.min()), float(gamma_levels.max()), 100)\n",
    "ax.loglog(gamma_ref, A_true * gamma_ref**n_true, 'k:', lw=2, \n",
    "          label=f'True: {A_true}\u00b7\u03b3$^{{{n_true}}}$')\n",
    "\n",
    "ax.set_xlabel(r'Strain Amplitude $\\gamma_0$')\n",
    "ax.set_ylabel('Yield Stress (Pa)')\n",
    "ax.set_title('SPP Yield Stress vs Strain Amplitude')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "## 5. NLSQ Fitting (Point Estimation)\n",
    "\n",
    "Fit power-law model to yield stress data using fast NLSQ optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61ae34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:23.493262Z",
     "iopub.status.busy": "2026-02-09T21:19:23.493152Z",
     "iopub.status.idle": "2026-02-09T21:19:23.531295Z",
     "shell.execute_reply": "2026-02-09T21:19:23.530800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit power-law model: \u03c3_sy = scale * \u03b3^exp\n",
    "pipeline.fit_model(bayesian=False, yield_type=\"static\")\n",
    "model = pipeline.get_model()\n",
    "\n",
    "# Get fitted parameters\n",
    "params = model.parameters\n",
    "scale_nlsq = params[\"sigma_sy_scale\"].value\n",
    "exp_nlsq = params[\"sigma_sy_exp\"].value\n",
    "\n",
    "print(\"NLSQ Fit Results (Point Estimates):\")\n",
    "print(f\"  \u03c3_sy_scale: {scale_nlsq:.4f} Pa (true: {A_true})\")\n",
    "print(f\"  \u03c3_sy_exp:   {exp_nlsq:.4f} (true: {n_true})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g3h4i5j6",
   "metadata": {},
   "source": [
    "## 6. Bayesian Inference with NUTS\n",
    "\n",
    "Quantify parameter uncertainty using Bayesian inference with warm-start from NLSQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k7l8m9n0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:23.532704Z",
     "iopub.status.busy": "2026-02-09T21:19:23.532594Z",
     "iopub.status.idle": "2026-02-09T21:19:52.002093Z",
     "shell.execute_reply": "2026-02-09T21:19:52.001689Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bayesian inference with proper settings for convergence\n",
    "# Key settings:\n",
    "# - num_chains=4: Multiple chains enable proper R-hat computation\n",
    "# - num_warmup=2000: More warmup for better adaptation\n",
    "# - num_samples=2000: Enough samples per chain for reliable posterior estimates\n",
    "# - target_accept_prob=0.99: Very high to minimize divergences\n",
    "# - max_tree_depth=12: Allow deeper trees for complex posteriors\n",
    "bayes = model.fit_bayesian(\n",
    "    gamma_levels, \n",
    "    sigma_sy,\n",
    "    test_mode=\"oscillation\",\n",
    "    num_chains=4,\n",
    "    num_warmup=2000,           # More warmup for better step size adaptation\n",
    "    num_samples=2000,\n",
    "    target_accept_prob=0.99,   # Very high = very small steps = minimal divergences\n",
    "    max_tree_depth=12,         # Allow deeper tree exploration\n",
    ")\n",
    "\n",
    "# Extract posterior statistics\n",
    "print(\"\\nBayesian Posterior Summary:\")\n",
    "print(f\"{'Parameter':>15} {'Mean':>10} {'Std':>10} {'5%':>10} {'95%':>10}\")\n",
    "print(\"-\" * 57)\n",
    "for param in [\"sigma_sy_scale\", \"sigma_sy_exp\"]:\n",
    "    if param in bayes.summary:\n",
    "        s = bayes.summary[param]\n",
    "        print(f\"{param:>15} {s['mean']:>10.4f} {s['std']:>10.4f} \"\n",
    "              f\"{s.get('q05', 0):>10.4f} \"\n",
    "              f\"{s.get('q95', 0):>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o1p2q3r4",
   "metadata": {},
   "source": [
    "## 7. MCMC Diagnostics\n",
    "\n",
    "Check convergence using standard diagnostics:\n",
    "- **R-hat < 1.01**: Chains converged (requires multiple chains for reliable computation)\n",
    "- **ESS > 400**: Sufficient effective samples\n",
    "- **Divergences = 0**: No sampling issues\n",
    "\n",
    "**Note on trace plots**: With only 5 data points and a well-constrained model, the posterior \n",
    "is very tight. Traces may appear \"smooth\" because the sampler explores a narrow region efficiently.\n",
    "This is expected behavior, not a problem. The key diagnostic is that the trace should be \n",
    "stationary (no trends) and the histogram should be unimodal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s5t6u7v8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:52.003612Z",
     "iopub.status.busy": "2026-02-09T21:19:52.003506Z",
     "iopub.status.idle": "2026-02-09T21:19:52.008448Z",
     "shell.execute_reply": "2026-02-09T21:19:52.008072Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check diagnostics - R-hat and ESS are in the diagnostics dict, not summary\n",
    "diag = bayes.diagnostics\n",
    "print(\"MCMC Diagnostics:\")\n",
    "print(f\"  Divergences: {diag.get('divergences', 'N/A')}\")\n",
    "\n",
    "# R-hat and ESS are stored in diagnostics['r_hat'] and diagnostics['ess'] dicts\n",
    "r_hat_dict = diag.get('r_hat', {})\n",
    "ess_dict = diag.get('ess', {})\n",
    "\n",
    "print(\"\\nConvergence by Parameter:\")\n",
    "for param in [\"sigma_sy_scale\", \"sigma_sy_exp\"]:\n",
    "    rhat = r_hat_dict.get(param, 'N/A')\n",
    "    ess = ess_dict.get(param, 'N/A')\n",
    "    rhat_str = f\"{rhat:.4f}\" if isinstance(rhat, (int, float)) else str(rhat)\n",
    "    ess_str = f\"{ess:.0f}\" if isinstance(ess, (int, float)) else str(ess)\n",
    "    print(f\"  {param}: R-hat={rhat_str}, ESS={ess_str}\")\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\nInterpretation:\")\n",
    "divergences = diag.get('divergences', 0)\n",
    "if divergences == 0:\n",
    "    print(\"  \u2713 No divergences - sampling is healthy\")\n",
    "elif divergences < 100:\n",
    "    print(f\"  \u26a0 {divergences} divergences - likely from noise parameter funnel (see diagnosis below)\")\n",
    "    print(\"    \u2192 Parameters of interest (scale, exp) are still reliable if R-hat < 1.01\")\n",
    "else:\n",
    "    print(f\"  \u2717 {divergences} divergences - consider reparameterization or more informative priors\")\n",
    "\n",
    "for param in [\"sigma_sy_scale\", \"sigma_sy_exp\"]:\n",
    "    rhat = r_hat_dict.get(param, 1.0)\n",
    "    ess = ess_dict.get(param, 0)\n",
    "    if isinstance(rhat, (int, float)) and rhat < 1.01:\n",
    "        print(f\"  \u2713 {param}: R-hat={rhat:.4f} < 1.01 (converged)\")\n",
    "    elif isinstance(rhat, (int, float)):\n",
    "        print(f\"  \u26a0 {param}: R-hat={rhat:.4f} >= 1.01 (may need more samples)\")\n",
    "    if isinstance(ess, (int, float)) and ess > 400:\n",
    "        print(f\"  \u2713 {param}: ESS={ess:.0f} > 400 (sufficient)\")\n",
    "    elif isinstance(ess, (int, float)):\n",
    "        print(f\"  \u26a0 {param}: ESS={ess:.0f} < 400 (may need more samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w9x0y1z2",
   "metadata": {},
   "source": [
    "## 8. Posterior Visualization with ArviZ\n",
    "\n",
    "ArviZ provides comprehensive MCMC diagnostics:\n",
    "\n",
    "| Plot | What to Look For |\n",
    "|------|------------------|\n",
    "| **Trace** | Chains should overlap (\"fuzzy caterpillar\"), no trends |\n",
    "| **Pair** | Correlations between parameters; divergences cluster in problem regions |\n",
    "| **Forest** | HDI intervals should overlap across chains |\n",
    "| **Autocorrelation** | Should drop quickly to zero (good mixing) |\n",
    "| **Rank** | Histograms should be uniform (chains exploring same space) |\n",
    "\n",
    "**About Divergences**: Divergences indicate the sampler encountered difficult geometry.\n",
    "Common causes: (1) tight funnels from hierarchical priors, (2) strong parameter correlations,\n",
    "(3) multimodal posteriors. Solutions: increase `target_accept_prob`, reparameterize, or use\n",
    "more informative priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:52.009624Z",
     "iopub.status.busy": "2026-02-09T21:19:52.009550Z",
     "iopub.status.idle": "2026-02-09T21:19:52.014085Z",
     "shell.execute_reply": "2026-02-09T21:19:52.013724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create ArviZ InferenceData for comprehensive diagnostics\n",
    "# First, reshape samples for ArviZ (needs shape: chains x draws)\n",
    "samples = bayes.posterior_samples\n",
    "num_chains = bayes.num_chains\n",
    "num_samples = bayes.num_samples\n",
    "\n",
    "# Build posterior dict with correct shape for ArviZ\n",
    "posterior_dict = {}\n",
    "for param in [\"sigma_sy_scale\", \"sigma_sy_exp\", \"noise\", \"sigma\"]:\n",
    "    if param in samples:\n",
    "        vals = np.array(samples[param])\n",
    "        # Reshape to (num_chains, num_draws)\n",
    "        if vals.ndim == 1:\n",
    "            posterior_dict[param] = vals.reshape(num_chains, -1)\n",
    "        else:\n",
    "            posterior_dict[param] = vals\n",
    "\n",
    "# Create InferenceData\n",
    "idata = az.from_dict(posterior=posterior_dict)\n",
    "\n",
    "print(f\"Created ArviZ InferenceData with {num_chains} chains \u00d7 {num_samples} samples\")\n",
    "print(f\"Parameters: {list(posterior_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c56e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:52.015367Z",
     "iopub.status.busy": "2026-02-09T21:19:52.015285Z",
     "iopub.status.idle": "2026-02-09T21:19:53.231087Z",
     "shell.execute_reply": "2026-02-09T21:19:53.230506Z"
    }
   },
   "outputs": [],
   "source": [
    "# ArviZ diagnostic plots (trace, pair, forest, energy, autocorr, rank)\n",
    "display_arviz_diagnostics(bayes, [\"sigma_sy_scale\", \"sigma_sy_exp\"], fast_mode=FAST_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58sw83imz8m",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:53.232805Z",
     "iopub.status.busy": "2026-02-09T21:19:53.232683Z",
     "iopub.status.idle": "2026-02-09T21:19:53.249544Z",
     "shell.execute_reply": "2026-02-09T21:19:53.249124Z"
    }
   },
   "outputs": [],
   "source": [
    "# ArviZ Summary - comprehensive statistics with R-hat and ESS\n",
    "summary_df = az.summary(idata, var_names=[\"sigma_sy_scale\", \"sigma_sy_exp\"],\n",
    "                        hdi_prob=0.94, round_to=4)\n",
    "print(\"ArviZ Summary Statistics:\")\n",
    "print(summary_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dn2e46k3shj",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:53.251161Z",
     "iopub.status.busy": "2026-02-09T21:19:53.251035Z",
     "iopub.status.idle": "2026-02-09T21:19:53.374169Z",
     "shell.execute_reply": "2026-02-09T21:19:53.373557Z"
    }
   },
   "outputs": [],
   "source": [
    "# Diagnose divergences: Check if they correlate with the noise parameter\n",
    "# Divergences often occur in \"funnel\" geometries where noise \u2192 0\n",
    "if \"noise\" in posterior_dict:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    noise_samples = posterior_dict[\"noise\"].flatten()\n",
    "    scale_samples = posterior_dict[\"sigma_sy_scale\"].flatten()\n",
    "    exp_samples = posterior_dict[\"sigma_sy_exp\"].flatten()\n",
    "    \n",
    "    # Plot noise distribution - check for values near zero\n",
    "    axes[0].hist(noise_samples, bins=50, density=True, alpha=0.7, edgecolor='white')\n",
    "    axes[0].axvline(noise_samples.mean(), color='r', ls='--', label=f'Mean: {noise_samples.mean():.2f}')\n",
    "    axes[0].set_xlabel('Noise (\u03c3)')\n",
    "    axes[0].set_ylabel('Density')\n",
    "    axes[0].set_title('Noise Posterior\\n(HalfCauchy prior can cause funnels)')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Noise vs scale - check for funnel shape\n",
    "    axes[1].scatter(noise_samples, scale_samples, alpha=0.1, s=1)\n",
    "    axes[1].set_xlabel('Noise (\u03c3)')\n",
    "    axes[1].set_ylabel('sigma_sy_scale')\n",
    "    axes[1].set_title('Noise vs Scale\\n(Funnel = divergence source)')\n",
    "    \n",
    "    # Noise vs exponent\n",
    "    axes[2].scatter(noise_samples, exp_samples, alpha=0.1, s=1)\n",
    "    axes[2].set_xlabel('Noise (\u03c3)')\n",
    "    axes[2].set_ylabel('sigma_sy_exp')\n",
    "    axes[2].set_title('Noise vs Exponent')\n",
    "    \n",
    "    plt.suptitle('Divergence Diagnosis: Noise Parameter Geometry', y=1.02)\n",
    "    fig.subplots_adjust(top=0.85, wspace=0.3)\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"Noise posterior: mean={noise_samples.mean():.3f}, std={noise_samples.std():.3f}\")\n",
    "    print(f\"Noise range: [{noise_samples.min():.4f}, {noise_samples.max():.3f}]\")\n",
    "    print(f\"\\nNote: Divergences likely occur when noise \u2192 0 (funnel geometry)\")\n",
    "    print(\"The HalfCauchy(scale=10) prior is too vague for only 5 data points.\")\n",
    "else:\n",
    "    print(\"Noise parameter not found in samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Analysis\n",
    "\n",
    "The posterior predictive check above shows the residual structure (observed - predicted). For the SPP power-law model:\n",
    "\n",
    "- **Random scatter**: Model adequately captures yield stress scaling\n",
    "- **Systematic trends**: May indicate need for more complex yielding model (e.g., Herschel-Bulkley)\n",
    "- **Outliers**: Check SPP decomposition quality for those amplitudes\n",
    "\n",
    "With only 5 data points, visual inspection of residuals is sufficient. For larger datasets, consider quantile-quantile plots or runs tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8g9h0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:53.375717Z",
     "iopub.status.busy": "2026-02-09T21:19:53.375542Z",
     "iopub.status.idle": "2026-02-09T21:19:53.548738Z",
     "shell.execute_reply": "2026-02-09T21:19:53.548078Z"
    }
   },
   "outputs": [],
   "source": [
    "# Posterior predictive check\n",
    "samples = bayes.posterior_samples\n",
    "scale_samples = np.array(samples.get(\"sigma_sy_scale\", [])).flatten()\n",
    "exp_samples = np.array(samples.get(\"sigma_sy_exp\", [])).flatten()\n",
    "\n",
    "if len(scale_samples) > 0 and len(exp_samples) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    # Data\n",
    "    gamma_plot = np.array(gamma_levels)\n",
    "    ax.scatter(gamma_plot, np.array(sigma_sy), s=80, c='black', zorder=5, label='Data')\n",
    "    \n",
    "    # Posterior predictive samples\n",
    "    gamma_fine = np.linspace(gamma_plot.min() * 0.8, gamma_plot.max() * 1.2, 100)\n",
    "    n_draws = min(100, len(scale_samples))\n",
    "    for i in range(n_draws):\n",
    "        pred = scale_samples[i] * gamma_fine ** exp_samples[i]\n",
    "        ax.plot(gamma_fine, pred, 'b-', alpha=0.05)\n",
    "    \n",
    "    # Mean prediction\n",
    "    mean_pred = scale_samples.mean() * gamma_fine ** exp_samples.mean()\n",
    "    ax.plot(gamma_fine, mean_pred, 'r-', lw=2, label='Posterior Mean')\n",
    "    \n",
    "    # True values\n",
    "    true_pred = A_true * gamma_fine ** n_true\n",
    "    ax.plot(gamma_fine, true_pred, 'g--', lw=2, label='True Model')\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel(r'Strain Amplitude $\\gamma_0$')\n",
    "    ax.set_ylabel(r'Static Yield Stress $\\sigma_{sy}$ (Pa)')\n",
    "    ax.set_title('Posterior Predictive Check')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "- **Rogers (2012)**: [\"A sequence of physical processes\"](https://doi.org/10.1122/1.3662962) \u2014 Complete SPP theory and validation\n",
    "- **RheoJAX SPP Pipeline**: [Documentation](../../docs/source/pipeline/workflows.rst#spp-amplitude-sweep) \u2014 Implementation details\n",
    "- **Hyun et al. (2011)**: [\"Nonlinear oscillatory shear review\"](https://doi.org/10.1016/j.progpolymsci.2011.02.002) \u2014 Context for LAOS methods\n",
    "- **NumPyro Hierarchical Models**: [Tutorial](https://num.pyro.ai/en/stable/tutorials/bayesian_hierarchical_linear_regression.html) \u2014 Understanding noise parameter funnels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **[08-spp-laos.ipynb](08-spp-laos.ipynb)**: Detailed SPP theory and single-amplitude decomposition\n",
    "- **[advanced/10-spp-laos-tutorial.ipynb](../advanced/10-spp-laos-tutorial.ipynb)**: Advanced SPP parameter interpretation\n",
    "- Apply this workflow to your own LAOS amplitude sweep datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i1j2k3l4",
   "metadata": {},
   "source": "**For questions or issues:**\n- GitHub: https://github.com/imewei/rheojax/issues\n- Documentation: https://rheojax.readthedocs.io\n\n### Key References\n\n- **Rogers, S.A. et al. (2012).** \"A sequence of physical processes determined from LAOS.\" *J. Rheol.* 56:1-25. [Original SPP theory and implementation]\n- **Rogers, S.A. & Lettinga, M.P. (2012).** \"A sequence of physical processes from LAOS using a simple model.\" *J. Rheol.* 56:1129-1151. [SPP for complex fluids]\n- **Hyun, K. et al. (2011).** \"A review of nonlinear oscillatory shear tests.\" *Prog. Polym. Sci.* 36:1697-1753. [Comprehensive LAOS methods review]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m5n6o7p8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:19:53.549923Z",
     "iopub.status.busy": "2026-02-09T21:19:53.549825Z",
     "iopub.status.idle": "2026-02-09T21:19:53.552321Z",
     "shell.execute_reply": "2026-02-09T21:19:53.551866Z"
    }
   },
   "outputs": [],
   "source": [
    "# Final comparison: NLSQ vs Bayesian vs True\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PARAMETER COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Parameter':<20} {'True':>10} {'NLSQ':>10} {'Bayesian':>10}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'sigma_sy_scale':<20} {A_true:>10.4f} {scale_nlsq:>10.4f} \"\n",
    "      f\"{bayes.summary['sigma_sy_scale']['mean']:>10.4f}\")\n",
    "print(f\"{'sigma_sy_exp':<20} {n_true:>10.4f} {exp_nlsq:>10.4f} \"\n",
    "      f\"{bayes.summary['sigma_sy_exp']['mean']:>10.4f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rheojax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}