{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c53ab7c",
   "metadata": {},
   "source": [
    "# SPP LAOS: Complete NLSQ → NUTS Workflow\n",
    "\n",
    "> **Handbook:** See [SPP LAOS Workflow](../../docs/source/transforms/spp_decomposer.rst#complete-workflow) for pipeline implementation and [Rogers SPP Defaults](../../docs/source/transforms/spp_decomposer.rst#theory) for parameter selection guidance.\n",
    "\n",
    "This notebook demonstrates the complete Sequence of Physical Processes (SPP) framework for\n",
    "Large Amplitude Oscillatory Shear (LAOS) analysis using RheoJAX.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "After completing this notebook, you will be able to:\n",
    "- Apply SPP decomposition to LAOS amplitude sweep data\n",
    "- Extract yield stress scaling relationships using power-law fits\n",
    "- Use SPPAmplitudeSweepPipeline for automated analysis\n",
    "- Perform NLSQ → NUTS workflow for SPP parameter uncertainty\n",
    "- Interpret convergence diagnostics for SPP models\n",
    "- Understand divergence sources in hierarchical noise models\n",
    "\n",
    "## SPP Theory Overview\n",
    "\n",
    "The SPP framework (Rogers et al.) decomposes nonlinear stress responses into:\n",
    "- **Elastic contribution**: Recoverable strain energy (in-phase with strain)\n",
    "- **Viscous contribution**: Dissipated energy (in-phase with strain rate)\n",
    "\n",
    "Key outputs:\n",
    "- `sigma_sy`: Static yield stress (maximum elastic stress)\n",
    "- `sigma_dy`: Dynamic yield stress (maximum viscous stress)  \n",
    "- `S_factor`: Stiffening ratio (-1 to 1, 0 = linear)\n",
    "- `T_factor`: Thickening ratio (-1 to 1, 0 = linear)\n",
    "\n",
    "**Defaults**: n_harmonics=39, step_size=8, num_mode=2, wrapped strain-rate inference.\n",
    "\n",
    "**Estimated Time:** 25-30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb51cad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:10.440659Z",
     "iopub.status.busy": "2026-02-14T03:00:10.440555Z",
     "iopub.status.idle": "2026-02-14T03:00:12.599524Z",
     "shell.execute_reply": "2026-02-14T03:00:12.598575Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# MUST come before importing matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import arviz as az\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from rheojax.core.data import RheoData\n",
    "from rheojax.pipeline.workflows import SPPAmplitudeSweepPipeline\n",
    "from rheojax.transforms import SPPDecomposer\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(\"\")))\n",
    "from utils.plotting_utils import (\n",
    "    display_arviz_diagnostics,\n",
    "    plot_nlsq_fit,\n",
    "    plot_posterior_predictive,\n",
    ")\n",
    "\n",
    "FAST_MODE = os.environ.get(\"FAST_MODE\", \"1\") == \"1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic LAOS Data\n",
    "\n",
    "Create amplitude sweep data with power-law yielding behavior:\n",
    "$$\\sigma = A \\cdot \\gamma_0^n \\cdot \\sin(\\omega t)$$\n",
    "\n",
    "where $A=60$ Pa and $n=0.7$ (sublinear yielding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebbe383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:12.602305Z",
     "iopub.status.busy": "2026-02-14T03:00:12.602104Z",
     "iopub.status.idle": "2026-02-14T03:00:12.705225Z",
     "shell.execute_reply": "2026-02-14T03:00:12.704426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Experimental parameters\n",
    "omega = 1.5  # rad/s\n",
    "gamma_levels = jnp.array([0.1, 0.2, 0.4, 0.8, 1.6])  # strain amplitudes\n",
    "n_points = 400  # points per cycle\n",
    "t = jnp.linspace(0, 2 * jnp.pi / omega, n_points)\n",
    "\n",
    "# Power-law yield parameters (ground truth)\n",
    "A_true = 60.0  # Pa\n",
    "n_true = 0.7   # exponent\n",
    "\n",
    "def make_dataset(gamma_0):\n",
    "    \"\"\"Generate synthetic LAOS dataset with power-law yielding.\"\"\"\n",
    "    strain = gamma_0 * jnp.sin(omega * t)\n",
    "    # Add slight nonlinearity for more realistic behavior\n",
    "    stress = A_true * gamma_0**n_true * jnp.sin(omega * t)\n",
    "    # Add small noise\n",
    "    noise = np.random.normal(0, 0.5, len(t))\n",
    "    return RheoData(\n",
    "        x=np.array(t),\n",
    "        y=np.array(stress) + noise,\n",
    "        domain=\"time\",\n",
    "        metadata={\"omega\": float(omega), \"gamma_0\": float(gamma_0), \"strain\": np.array(strain)}\n",
    "    )\n",
    "\n",
    "np.random.seed(42)\n",
    "datasets = [make_dataset(float(g)) for g in gamma_levels]\n",
    "print(f\"Created {len(datasets)} datasets at γ₀ = {list(gamma_levels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6g7h8",
   "metadata": {},
   "source": [
    "## 2. Visualize Lissajous Curves\n",
    "\n",
    "Lissajous (stress-strain) curves reveal nonlinear viscoelastic behavior:\n",
    "- **Ellipse**: Linear viscoelastic\n",
    "- **Distorted ellipse**: Nonlinear response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i9j0k1l2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:12.706732Z",
     "iopub.status.busy": "2026-02-14T03:00:12.706621Z",
     "iopub.status.idle": "2026-02-14T03:00:12.947980Z",
     "shell.execute_reply": "2026-02-14T03:00:12.947535Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(datasets), figsize=(3*len(datasets), 3), sharey=True)\n",
    "if len(datasets) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, ds, gamma in zip(axes, datasets, gamma_levels):\n",
    "    strain = ds.metadata[\"strain\"]\n",
    "    stress = ds.y\n",
    "    ax.plot(strain, stress, 'b-', lw=1.5)\n",
    "    ax.set_xlabel(r'Strain $\\gamma$')\n",
    "    ax.set_title(f'$\\\\gamma_0$ = {gamma:.2f}')\n",
    "    ax.axhline(0, color='gray', lw=0.5, ls='--')\n",
    "    ax.axvline(0, color='gray', lw=0.5, ls='--')\n",
    "\n",
    "axes[0].set_ylabel('Stress (Pa)')\n",
    "fig.suptitle('Lissajous Curves (Stress vs Strain)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m3n4o5p6",
   "metadata": {},
   "source": [
    "## 3. SPP Decomposition (Single Amplitude)\n",
    "\n",
    "Demonstrate the SPPDecomposer on a single dataset to understand the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f5e056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:12.949585Z",
     "iopub.status.busy": "2026-02-14T03:00:12.949470Z",
     "iopub.status.idle": "2026-02-14T03:00:14.446442Z",
     "shell.execute_reply": "2026-02-14T03:00:14.444949Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select middle amplitude for demonstration\n",
    "idx = len(datasets) // 2\n",
    "demo_data = datasets[idx]\n",
    "demo_gamma = float(gamma_levels[idx])\n",
    "\n",
    "# Create decomposer with Rogers defaults\n",
    "decomposer = SPPDecomposer(omega=float(omega), gamma_0=demo_gamma)\n",
    "result = decomposer.transform(demo_data)\n",
    "\n",
    "# Display key results\n",
    "print(f\"SPP Decomposition at γ₀ = {demo_gamma}:\")\n",
    "print(f\"  Static yield stress (σ_sy):  {decomposer.results_['sigma_sy']:.3f} Pa\")\n",
    "print(f\"  Dynamic yield stress (σ_dy): {decomposer.results_['sigma_dy']:.3f} Pa\")\n",
    "print(f\"  Stiffening factor (S):       {decomposer.results_['S_factor']:.4f}\")\n",
    "print(f\"  Thickening factor (T):       {decomposer.results_['T_factor']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7r8s9t0",
   "metadata": {},
   "source": [
    "## 4. Amplitude Sweep Pipeline\n",
    "\n",
    "Process all amplitudes and extract yield stress vs strain amplitude relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u1v2w3x4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:14.447924Z",
     "iopub.status.busy": "2026-02-14T03:00:14.447828Z",
     "iopub.status.idle": "2026-02-14T03:00:14.465785Z",
     "shell.execute_reply": "2026-02-14T03:00:14.464852Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run SPP amplitude sweep pipeline\n",
    "pipeline = SPPAmplitudeSweepPipeline(omega=float(omega))\n",
    "pipeline.run(datasets, gamma_0_values=list(map(float, gamma_levels)))\n",
    "\n",
    "# Get yield stresses for all amplitudes\n",
    "yield_data = pipeline.get_yield_stresses()\n",
    "sigma_sy = yield_data[\"sigma_sy\"]\n",
    "sigma_dy = yield_data[\"sigma_dy\"]\n",
    "\n",
    "print(\"Amplitude Sweep Results:\")\n",
    "print(f\"{'γ₀':>8} {'σ_sy (Pa)':>12} {'σ_dy (Pa)':>12}\")\n",
    "print(\"-\" * 34)\n",
    "for g, sy, dy in zip(gamma_levels, sigma_sy, sigma_dy):\n",
    "    print(f\"{float(g):>8.3f} {float(sy):>12.3f} {float(dy):>12.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y5z6a7b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:14.467261Z",
     "iopub.status.busy": "2026-02-14T03:00:14.467159Z",
     "iopub.status.idle": "2026-02-14T03:00:14.735392Z",
     "shell.execute_reply": "2026-02-14T03:00:14.734892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot yield stress vs strain amplitude\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.loglog(gamma_levels, sigma_sy, 'o-', label=r'$\\sigma_{sy}$ (static)', markersize=8)\n",
    "ax.loglog(gamma_levels, sigma_dy, 's--', label=r'$\\sigma_{dy}$ (dynamic)', markersize=8)\n",
    "\n",
    "# Reference power-law\n",
    "gamma_ref = np.linspace(float(gamma_levels.min()), float(gamma_levels.max()), 100)\n",
    "ax.loglog(gamma_ref, A_true * gamma_ref**n_true, 'k:', lw=2, \n",
    "          label=f'True: {A_true}·γ$^{{{n_true}}}$')\n",
    "\n",
    "ax.set_xlabel(r'Strain Amplitude $\\gamma_0$')\n",
    "ax.set_ylabel('Yield Stress (Pa)')\n",
    "ax.set_title('SPP Yield Stress vs Strain Amplitude')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "## 5. NLSQ Fitting (Point Estimation)\n",
    "\n",
    "Fit power-law model to yield stress data using fast NLSQ optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61ae34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:14.736777Z",
     "iopub.status.busy": "2026-02-14T03:00:14.736694Z",
     "iopub.status.idle": "2026-02-14T03:00:14.776439Z",
     "shell.execute_reply": "2026-02-14T03:00:14.775668Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit power-law model: σ_sy = scale * γ^exp\n",
    "pipeline.fit_model(bayesian=False, yield_type=\"static\")\n",
    "model = pipeline.get_model()\n",
    "\n",
    "# Get fitted parameters\n",
    "params = model.parameters\n",
    "scale_nlsq = params[\"sigma_sy_scale\"].value\n",
    "exp_nlsq = params[\"sigma_sy_exp\"].value\n",
    "\n",
    "print(\"NLSQ Fit Results (Point Estimates):\")\n",
    "print(f\"  σ_sy_scale: {scale_nlsq:.4f} Pa (true: {A_true})\")\n",
    "print(f\"  σ_sy_exp:   {exp_nlsq:.4f} (true: {n_true})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g3h4i5j6",
   "metadata": {},
   "source": [
    "## 6. Bayesian Inference with NUTS\n",
    "\n",
    "Quantify parameter uncertainty using Bayesian inference with warm-start from NLSQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k7l8m9n0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:14.778106Z",
     "iopub.status.busy": "2026-02-14T03:00:14.777986Z",
     "iopub.status.idle": "2026-02-14T03:00:46.508810Z",
     "shell.execute_reply": "2026-02-14T03:00:46.508062Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bayesian inference with proper settings for convergence\n",
    "# Key settings:\n",
    "# - num_chains=4: Multiple chains enable proper R-hat computation\n",
    "# - num_warmup=2000: More warmup for better adaptation\n",
    "# - num_samples=2000: Enough samples per chain for reliable posterior estimates\n",
    "# - target_accept_prob=0.99: Very high to minimize divergences\n",
    "# - max_tree_depth=12: Allow deeper trees for complex posteriors\n",
    "bayes = model.fit_bayesian(\n",
    "    gamma_levels, \n",
    "    sigma_sy,\n",
    "    test_mode=\"oscillation\",\n",
    "    num_chains=4,\n",
    "    num_warmup=2000,           # More warmup for better step size adaptation\n",
    "    num_samples=2000,\n",
    "    target_accept_prob=0.99,   # Very high = very small steps = minimal divergences\n",
    "    max_tree_depth=12,         # Allow deeper tree exploration\n",
    ")\n",
    "\n",
    "# Extract posterior statistics\n",
    "print(\"\\nBayesian Posterior Summary:\")\n",
    "print(f\"{'Parameter':>15} {'Mean':>10} {'Std':>10} {'5%':>10} {'95%':>10}\")\n",
    "print(\"-\" * 57)\n",
    "for param in [\"sigma_sy_scale\", \"sigma_sy_exp\"]:\n",
    "    if param in bayes.summary:\n",
    "        s = bayes.summary[param]\n",
    "        print(f\"{param:>15} {s['mean']:>10.4f} {s['std']:>10.4f} \"\n",
    "              f\"{s.get('q05', 0):>10.4f} \"\n",
    "              f\"{s.get('q95', 0):>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o1p2q3r4",
   "metadata": {},
   "source": [
    "## 7. MCMC Diagnostics\n",
    "\n",
    "Check convergence using standard diagnostics:\n",
    "- **R-hat < 1.01**: Chains converged (requires multiple chains for reliable computation)\n",
    "- **ESS > 400**: Sufficient effective samples\n",
    "- **Divergences = 0**: No sampling issues\n",
    "\n",
    "**Note on trace plots**: With only 5 data points and a well-constrained model, the posterior \n",
    "is very tight. Traces may appear \"smooth\" because the sampler explores a narrow region efficiently.\n",
    "This is expected behavior, not a problem. The key diagnostic is that the trace should be \n",
    "stationary (no trends) and the histogram should be unimodal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s5t6u7v8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:46.510574Z",
     "iopub.status.busy": "2026-02-14T03:00:46.510477Z",
     "iopub.status.idle": "2026-02-14T03:00:46.515291Z",
     "shell.execute_reply": "2026-02-14T03:00:46.514875Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check diagnostics - R-hat and ESS are in the diagnostics dict, not summary\n",
    "diag = bayes.diagnostics\n",
    "print(\"MCMC Diagnostics:\")\n",
    "print(f\"  Divergences: {diag.get('divergences', 'N/A')}\")\n",
    "\n",
    "# R-hat and ESS are stored in diagnostics['r_hat'] and diagnostics['ess'] dicts\n",
    "r_hat_dict = diag.get('r_hat', {})\n",
    "ess_dict = diag.get('ess', {})\n",
    "\n",
    "print(\"\\nConvergence by Parameter:\")\n",
    "for param in [\"sigma_sy_scale\", \"sigma_sy_exp\"]:\n",
    "    rhat = r_hat_dict.get(param, 'N/A')\n",
    "    ess = ess_dict.get(param, 'N/A')\n",
    "    rhat_str = f\"{rhat:.4f}\" if isinstance(rhat, (int, float)) else str(rhat)\n",
    "    ess_str = f\"{ess:.0f}\" if isinstance(ess, (int, float)) else str(ess)\n",
    "    print(f\"  {param}: R-hat={rhat_str}, ESS={ess_str}\")\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\nInterpretation:\")\n",
    "divergences = diag.get('divergences', 0)\n",
    "if divergences == 0:\n",
    "    print(\"  ✓ No divergences - sampling is healthy\")\n",
    "elif divergences < 100:\n",
    "    print(f\"  ⚠ {divergences} divergences - likely from noise parameter funnel (see diagnosis below)\")\n",
    "    print(\"    → Parameters of interest (scale, exp) are still reliable if R-hat < 1.01\")\n",
    "else:\n",
    "    print(f\"  ✗ {divergences} divergences - consider reparameterization or more informative priors\")\n",
    "\n",
    "for param in [\"sigma_sy_scale\", \"sigma_sy_exp\"]:\n",
    "    rhat = r_hat_dict.get(param, 1.0)\n",
    "    ess = ess_dict.get(param, 0)\n",
    "    if isinstance(rhat, (int, float)) and rhat < 1.01:\n",
    "        print(f\"  ✓ {param}: R-hat={rhat:.4f} < 1.01 (converged)\")\n",
    "    elif isinstance(rhat, (int, float)):\n",
    "        print(f\"  ⚠ {param}: R-hat={rhat:.4f} >= 1.01 (may need more samples)\")\n",
    "    if isinstance(ess, (int, float)) and ess > 400:\n",
    "        print(f\"  ✓ {param}: ESS={ess:.0f} > 400 (sufficient)\")\n",
    "    elif isinstance(ess, (int, float)):\n",
    "        print(f\"  ⚠ {param}: ESS={ess:.0f} < 400 (may need more samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w9x0y1z2",
   "metadata": {},
   "source": [
    "## 8. Posterior Visualization with ArviZ\n",
    "\n",
    "ArviZ provides comprehensive MCMC diagnostics:\n",
    "\n",
    "| Plot | What to Look For |\n",
    "|------|------------------|\n",
    "| **Trace** | Chains should overlap (\"fuzzy caterpillar\"), no trends |\n",
    "| **Pair** | Correlations between parameters; divergences cluster in problem regions |\n",
    "| **Forest** | HDI intervals should overlap across chains |\n",
    "| **Autocorrelation** | Should drop quickly to zero (good mixing) |\n",
    "| **Rank** | Histograms should be uniform (chains exploring same space) |\n",
    "\n",
    "**About Divergences**: Divergences indicate the sampler encountered difficult geometry.\n",
    "Common causes: (1) tight funnels from hierarchical priors, (2) strong parameter correlations,\n",
    "(3) multimodal posteriors. Solutions: increase `target_accept_prob`, reparameterize, or use\n",
    "more informative priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:46.516662Z",
     "iopub.status.busy": "2026-02-14T03:00:46.516564Z",
     "iopub.status.idle": "2026-02-14T03:00:46.521307Z",
     "shell.execute_reply": "2026-02-14T03:00:46.520864Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create ArviZ InferenceData for comprehensive diagnostics\n",
    "# First, reshape samples for ArviZ (needs shape: chains x draws)\n",
    "samples = bayes.posterior_samples\n",
    "num_chains = bayes.num_chains\n",
    "num_samples = bayes.num_samples\n",
    "\n",
    "# Build posterior dict with correct shape for ArviZ\n",
    "posterior_dict = {}\n",
    "for param in [\"sigma_sy_scale\", \"sigma_sy_exp\", \"noise\", \"sigma\"]:\n",
    "    if param in samples:\n",
    "        vals = np.array(samples[param])\n",
    "        # Reshape to (num_chains, num_draws)\n",
    "        if vals.ndim == 1:\n",
    "            posterior_dict[param] = vals.reshape(num_chains, -1)\n",
    "        else:\n",
    "            posterior_dict[param] = vals\n",
    "\n",
    "# Create InferenceData\n",
    "idata = az.from_dict(posterior=posterior_dict)\n",
    "\n",
    "print(f\"Created ArviZ InferenceData with {num_chains} chains × {num_samples} samples\")\n",
    "print(f\"Parameters: {list(posterior_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c56e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:46.522406Z",
     "iopub.status.busy": "2026-02-14T03:00:46.522329Z",
     "iopub.status.idle": "2026-02-14T03:00:47.889034Z",
     "shell.execute_reply": "2026-02-14T03:00:47.888424Z"
    }
   },
   "outputs": [],
   "source": [
    "# ArviZ diagnostic plots (trace, pair, forest, energy, autocorr, rank)\n",
    "display_arviz_diagnostics(bayes, [\"sigma_sy_scale\", \"sigma_sy_exp\"], fast_mode=FAST_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58sw83imz8m",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:47.890590Z",
     "iopub.status.busy": "2026-02-14T03:00:47.890473Z",
     "iopub.status.idle": "2026-02-14T03:00:47.908677Z",
     "shell.execute_reply": "2026-02-14T03:00:47.906875Z"
    }
   },
   "outputs": [],
   "source": [
    "# ArviZ Summary - comprehensive statistics with R-hat and ESS\n",
    "summary_df = az.summary(idata, var_names=[\"sigma_sy_scale\", \"sigma_sy_exp\"],\n",
    "                        hdi_prob=0.94, round_to=4)\n",
    "print(\"ArviZ Summary Statistics:\")\n",
    "print(summary_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dn2e46k3shj",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:47.910120Z",
     "iopub.status.busy": "2026-02-14T03:00:47.910029Z",
     "iopub.status.idle": "2026-02-14T03:00:48.071635Z",
     "shell.execute_reply": "2026-02-14T03:00:48.067793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Diagnose divergences: Check if they correlate with the noise parameter\n",
    "# Divergences often occur in \"funnel\" geometries where noise → 0\n",
    "if \"noise\" in posterior_dict:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    noise_samples = posterior_dict[\"noise\"].flatten()\n",
    "    scale_samples = posterior_dict[\"sigma_sy_scale\"].flatten()\n",
    "    exp_samples = posterior_dict[\"sigma_sy_exp\"].flatten()\n",
    "    \n",
    "    # Plot noise distribution - check for values near zero\n",
    "    axes[0].hist(noise_samples, bins=50, density=True, alpha=0.7, edgecolor='white')\n",
    "    axes[0].axvline(noise_samples.mean(), color='r', ls='--', label=f'Mean: {noise_samples.mean():.2f}')\n",
    "    axes[0].set_xlabel('Noise (σ)')\n",
    "    axes[0].set_ylabel('Density')\n",
    "    axes[0].set_title('Noise Posterior\\n(HalfCauchy prior can cause funnels)')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Noise vs scale - check for funnel shape\n",
    "    axes[1].scatter(noise_samples, scale_samples, alpha=0.1, s=1)\n",
    "    axes[1].set_xlabel('Noise (σ)')\n",
    "    axes[1].set_ylabel('sigma_sy_scale')\n",
    "    axes[1].set_title('Noise vs Scale\\n(Funnel = divergence source)')\n",
    "    \n",
    "    # Noise vs exponent\n",
    "    axes[2].scatter(noise_samples, exp_samples, alpha=0.1, s=1)\n",
    "    axes[2].set_xlabel('Noise (σ)')\n",
    "    axes[2].set_ylabel('sigma_sy_exp')\n",
    "    axes[2].set_title('Noise vs Exponent')\n",
    "    \n",
    "    plt.suptitle('Divergence Diagnosis: Noise Parameter Geometry', y=1.02)\n",
    "    fig.subplots_adjust(top=0.85, wspace=0.3)\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"Noise posterior: mean={noise_samples.mean():.3f}, std={noise_samples.std():.3f}\")\n",
    "    print(f\"Noise range: [{noise_samples.min():.4f}, {noise_samples.max():.3f}]\")\n",
    "    print(f\"\\nNote: Divergences likely occur when noise → 0 (funnel geometry)\")\n",
    "    print(\"The HalfCauchy(scale=10) prior is too vague for only 5 data points.\")\n",
    "else:\n",
    "    print(\"Noise parameter not found in samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "## Residual Analysis\n",
    "\n",
    "The posterior predictive check above shows the residual structure (observed - predicted). For the SPP power-law model:\n",
    "\n",
    "- **Random scatter**: Model adequately captures yield stress scaling\n",
    "- **Systematic trends**: May indicate need for more complex yielding model (e.g., Herschel-Bulkley)\n",
    "- **Outliers**: Check SPP decomposition quality for those amplitudes\n",
    "\n",
    "With only 5 data points, visual inspection of residuals is sufficient. For larger datasets, consider quantile-quantile plots or runs tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8g9h0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:48.074909Z",
     "iopub.status.busy": "2026-02-14T03:00:48.074785Z",
     "iopub.status.idle": "2026-02-14T03:00:48.246115Z",
     "shell.execute_reply": "2026-02-14T03:00:48.245585Z"
    }
   },
   "outputs": [],
   "source": [
    "# Posterior predictive check\n",
    "samples = bayes.posterior_samples\n",
    "scale_samples = np.array(samples.get(\"sigma_sy_scale\", [])).flatten()\n",
    "exp_samples = np.array(samples.get(\"sigma_sy_exp\", [])).flatten()\n",
    "\n",
    "if len(scale_samples) > 0 and len(exp_samples) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    # Data\n",
    "    gamma_plot = np.array(gamma_levels)\n",
    "    ax.scatter(gamma_plot, np.array(sigma_sy), s=80, c='black', zorder=5, label='Data')\n",
    "    \n",
    "    # Posterior predictive samples\n",
    "    gamma_fine = np.linspace(gamma_plot.min() * 0.8, gamma_plot.max() * 1.2, 100)\n",
    "    n_draws = min(100, len(scale_samples))\n",
    "    for i in range(n_draws):\n",
    "        pred = scale_samples[i] * gamma_fine ** exp_samples[i]\n",
    "        ax.plot(gamma_fine, pred, 'b-', alpha=0.05)\n",
    "    \n",
    "    # Mean prediction\n",
    "    mean_pred = scale_samples.mean() * gamma_fine ** exp_samples.mean()\n",
    "    ax.plot(gamma_fine, mean_pred, 'r-', lw=2, label='Posterior Mean')\n",
    "    \n",
    "    # True values\n",
    "    true_pred = A_true * gamma_fine ** n_true\n",
    "    ax.plot(gamma_fine, true_pred, 'g--', lw=2, label='True Model')\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel(r'Strain Amplitude $\\gamma_0$')\n",
    "    ax.set_ylabel(r'Static Yield Stress $\\sigma_{sy}$ (Pa)')\n",
    "    ax.set_title('Posterior Predictive Check')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "- **Rogers (2012)**: [\"A sequence of physical processes\"](https://doi.org/10.1122/1.3662962) — Complete SPP theory and validation\n",
    "- **RheoJAX SPP Pipeline**: [Documentation](../../docs/source/pipeline/workflows.rst#spp-amplitude-sweep) — Implementation details\n",
    "- **Hyun et al. (2011)**: [\"Nonlinear oscillatory shear review\"](https://doi.org/10.1016/j.progpolymsci.2011.02.002) — Context for LAOS methods\n",
    "- **NumPyro Hierarchical Models**: [Tutorial](https://num.pyro.ai/en/stable/tutorials/bayesian_hierarchical_linear_regression.html) — Understanding noise parameter funnels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **[08-spp-laos.ipynb](08-spp-laos.ipynb)**: Detailed SPP theory and single-amplitude decomposition\n",
    "- **[advanced/10-spp-laos-tutorial.ipynb](../advanced/10-spp-laos-tutorial.ipynb)**: Advanced SPP parameter interpretation\n",
    "- Apply this workflow to your own LAOS amplitude sweep datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i1j2k3l4",
   "metadata": {},
   "source": [
    "**For questions or issues:**\n",
    "- GitHub: https://github.com/imewei/rheojax/issues\n",
    "- Documentation: https://rheojax.readthedocs.io\n",
    "\n",
    "### Key References\n",
    "\n",
    "- **Rogers, S.A. et al. (2012).** \"A sequence of physical processes determined from LAOS.\" *J. Rheol.* 56:1-25. [Original SPP theory and implementation]\n",
    "- **Rogers, S.A. & Lettinga, M.P. (2012).** \"A sequence of physical processes from LAOS using a simple model.\" *J. Rheol.* 56:1129-1151. [SPP for complex fluids]\n",
    "- **Hyun, K. et al. (2011).** \"A review of nonlinear oscillatory shear tests.\" *Prog. Polym. Sci.* 36:1697-1753. [Comprehensive LAOS methods review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m5n6o7p8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T03:00:48.247872Z",
     "iopub.status.busy": "2026-02-14T03:00:48.247754Z",
     "iopub.status.idle": "2026-02-14T03:00:48.250648Z",
     "shell.execute_reply": "2026-02-14T03:00:48.250128Z"
    }
   },
   "outputs": [],
   "source": [
    "# Final comparison: NLSQ vs Bayesian vs True\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PARAMETER COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Parameter':<20} {'True':>10} {'NLSQ':>10} {'Bayesian':>10}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'sigma_sy_scale':<20} {A_true:>10.4f} {scale_nlsq:>10.4f} \"\n",
    "      f\"{bayes.summary['sigma_sy_scale']['mean']:>10.4f}\")\n",
    "print(f\"{'sigma_sy_exp':<20} {n_true:>10.4f} {exp_nlsq:>10.4f} \"\n",
    "      f\"{bayes.summary['sigma_sy_exp']['mean']:>10.4f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rheojax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
