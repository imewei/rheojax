{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC Convergence Diagnostics: A Comprehensive Guide to ArviZ Plots\n",
    "\n",
    "This notebook provides a complete guide to using all 6 ArviZ diagnostic plots as an integrated workflow, systematically diagnosing MCMC failures and troubleshooting convergence issues.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "After completing this notebook, you will be able to:\n",
    "- Use all 6 ArviZ diagnostic plots as integrated workflow\n",
    "- Diagnose common MCMC failures systematically\n",
    "- Troubleshoot divergences, poor mixing, and non-convergence\n",
    "- Understand when to increase warmup vs samples\n",
    "- Apply multi-chain MCMC for robust diagnostics\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Bayesian basics (`01-bayesian-basics.ipynb`)\n",
    "- Prior selection (`02-prior-selection.ipynb`)\n",
    "- Understanding of MCMC sampling\n",
    "\n",
    "**Estimated Time:** 45 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab Setup - Run this cell first!\n",
    "# Skip if running locally with rheojax already installed\n",
    "\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install rheojax and dependencies\n",
    "    !pip install -q rheojax\n",
    "    \n",
    "    # Colab uses float32 by default - we need float64 for numerical stability\n",
    "    # This MUST be set before importing JAX\n",
    "    import os\n",
    "    os.environ['JAX_ENABLE_X64'] = 'true'\n",
    "    \n",
    "    print(\"✓ RheoJAX installed successfully!\")\n",
    "    print(\"✓ Float64 precision enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction: The Diagnostic Workflow\n",
    "\n",
    "### Why Convergence Diagnostics Matter\n",
    "\n",
    "MCMC (Markov Chain Monte Carlo) generates samples by exploring parameter space. **Convergence** means:\n",
    "- Chains reached stationary distribution (the posterior)\n",
    "- Samples are representative\n",
    "- Results are reliable\n",
    "\n",
    "**Non-converged MCMC produces misleading posteriors!**\n",
    "\n",
    "### Recommended Diagnostic Sequence\n",
    "\n",
    "1. **R-hat & ESS** (automated) → Quick pass/fail\n",
    "2. **Trace plot** → Visual convergence check\n",
    "3. **Rank plot** → Most sensitive convergence diagnostic\n",
    "4. **Pair plot** → Parameter correlations & divergences\n",
    "5. **Autocorrelation plot** → Mixing quality (if ESS low)\n",
    "6. **ESS plot** → Per-parameter efficiency\n",
    "7. **Energy plot** → Posterior geometry (multi-chain only)\n",
    "\n",
    "### Setup Requirements\n",
    "\n",
    "**Use multi-chain MCMC (num_chains=4)** for robust diagnostics:\n",
    "- R-hat requires multiple chains\n",
    "- Energy plot requires ≥2 chains\n",
    "- Better detection of convergence failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# MUST come before importing matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "\n",
    "# ArviZ for diagnostics\n",
    "import arviz as az\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Rheo imports\n",
    "from rheojax.models import Maxwell\n",
    "\n",
    "from rheojax.core.jax_config import safe_import_jax\n",
    "\n",
    "# Safe JAX import\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting configuration\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"ArviZ version: {az.__version__}\")\n",
    "\n",
    "# Suppress matplotlib backend warning in VS Code\n",
    "warnings.filterwarnings('ignore', message='.*non-interactive.*')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Data and Run Multi-Chain MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True parameters\n",
    "G0_true = 1e5  # Pa\n",
    "eta_true = 1e3  # Pa·s\n",
    "tau_true = eta_true / G0_true  # s\n",
    "\n",
    "# Generate relaxation data\n",
    "t = np.logspace(-2, 2, 50)\n",
    "G_t_true = G0_true * np.exp(-t / tau_true)\n",
    "noise = np.random.normal(0, 0.015 * G_t_true)\n",
    "G_t_noisy = G_t_true + noise\n",
    "\n",
    "print(\"Data Generated:\")\n",
    "print(f\"  True G₀  = {G0_true:.2e} Pa\")\n",
    "print(f\"  True η   = {eta_true:.2e} Pa·s\")\n",
    "print(f\"  True τ   = {tau_true:.4f} s\\n\")\n",
    "\n",
    "# NLSQ warm-start\n",
    "model = Maxwell()\n",
    "model.parameters.set_bounds('G0', (1e3, 1e7))\n",
    "model.parameters.set_bounds('eta', (1e1, 1e5))\n",
    "model.fit(t, G_t_noisy)\n",
    "\n",
    "nlsq_params = {\n",
    "    'G0': model.parameters.get_value('G0'),\n",
    "    'eta': model.parameters.get_value('eta')\n",
    "}\n",
    "\n",
    "print(\"NLSQ Warm-Start:\")\n",
    "print(f\"  G₀  = {nlsq_params['G0']:.4e} Pa\")\n",
    "print(f\"  η   = {nlsq_params['eta']:.4e} Pa·s\\n\")\n",
    "\n",
    "# Multi-chain MCMC (CRITICAL: 4 chains for robust diagnostics)\n",
    "print(\"Running MULTI-CHAIN MCMC (4 chains)...\")\n",
    "print(\"(This may take 2-3 minutes)\\n\")\n",
    "\n",
    "result = model.fit_bayesian(\n",
    "    t, G_t_noisy,\n",
    "    num_warmup=1000,\n",
    "    num_samples=2000,\n",
    "    num_chains=4,  # IMPORTANT: Multiple chains for diagnostics\n",
    "    initial_values=nlsq_params\n",
    ")\n",
    "\n",
    "print(\"✓ Inference complete\\n\")\n",
    "\n",
    "# Convert to ArviZ InferenceData\n",
    "idata = result.to_inference_data()\n",
    "\n",
    "print(\"ArviZ InferenceData structure:\")\n",
    "print(idata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Step 1: Automated Checks (R-hat & ESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated convergence checks\n",
    "diagnostics = result.diagnostics\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"AUTOMATED CONVERGENCE DIAGNOSTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. R-hat (Gelman-Rubin Statistic):\")\n",
    "print(\"   Measures between-chain vs within-chain variance\")\n",
    "print(f\"   Target: < 1.01\\n\")\n",
    "for param in ['G0', 'eta']:\n",
    "    rhat = diagnostics['r_hat'][param]\n",
    "    status = '✓ Converged' if rhat < 1.01 else '✗ NOT converged'\n",
    "    print(f\"   {param:<5} R-hat = {rhat:.4f}  {status}\")\n",
    "\n",
    "print(\"\\n2. ESS (Effective Sample Size):\")\n",
    "print(\"   Accounts for autocorrelation between samples\")\n",
    "print(f\"   Target: > 400 (out of {result.num_samples * result.num_chains} total)\\n\")\n",
    "for param in ['G0', 'eta']:\n",
    "    ess = diagnostics['ess'][param]\n",
    "    status = '✓ Sufficient' if ess > 400 else '✗ Low'\n",
    "    efficiency = ess / (result.num_samples * result.num_chains) * 100\n",
    "    print(f\"   {param:<5} ESS = {ess:.0f}  ({efficiency:.1f}% efficiency)  {status}\")\n",
    "\n",
    "if 'num_divergences' in diagnostics:\n",
    "    div_rate = diagnostics['num_divergences'] / (result.num_samples * result.num_chains) * 100\n",
    "    print(\"\\n3. Divergences:\")\n",
    "    print(f\"   Count: {diagnostics['num_divergences']} ({div_rate:.2f}%)\")\n",
    "    status = '✓ Good' if div_rate < 1 else '✗ High'\n",
    "    print(f\"   Target: < 1%  {status}\")\n",
    "\n",
    "# Overall assessment\n",
    "all_converged = (\n",
    "    all(diagnostics['r_hat'][p] < 1.01 for p in ['G0', 'eta']) and\n",
    "    all(diagnostics['ess'][p] > 400 for p in ['G0', 'eta'])\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if all_converged:\n",
    "    print(\"✓✓✓ QUICK CHECK: PASSED ✓✓✓\")\n",
    "    print(\"Proceed to visual diagnostics for detailed assessment.\")\n",
    "else:\n",
    "    print(\"⚠⚠⚠ QUICK CHECK: FAILED ⚠⚠⚠\")\n",
    "    print(\"Use visual diagnostics below to identify issues.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Step 2: Trace Plot (Visual Convergence)\n",
    "\n",
    "### What It Shows\n",
    "- **Left panels**: Marginal posterior distributions\n",
    "- **Right panels**: Parameter evolution over iterations\n",
    "\n",
    "### Target Patterns\n",
    "- ✓ **Left**: Smooth, unimodal distributions; all chains overlap\n",
    "- ✓ **Right**: Stationary \"fuzzy caterpillar\" with no trends\n",
    "- ✗ **Bad**: Trends, jumps, stuck regions, bimodal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace plot\n",
    "az.plot_trace(idata, var_names=['G0', 'eta'], figsize=(14, 8))\n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()  # Get current figure from ArviZ\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"\\nTRACE PLOT INTERPRETATION:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"LEFT PANELS (Marginal Distributions):\")\n",
    "print(\"  ✓ GOOD: Smooth, unimodal, all chains overlap\")\n",
    "print(\"  ✗ BAD: Bimodal, ragged, chains don't overlap\")\n",
    "print(\"\\nRIGHT PANELS (Parameter vs Iteration):\")\n",
    "print(\"  ✓ GOOD: Fuzzy caterpillar, stationary, no trends\")\n",
    "print(\"  ✗ BAD: Drift, stuck regions, discontinuities\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\\nCOMMON ISSUES:\")\n",
    "print(\"1. Trend in trace → Not converged (increase num_warmup)\")\n",
    "print(\"2. Stuck regions → Chain trapped (check priors, reparameterize)\")\n",
    "print(\"3. Bimodal distribution → Multiple modes (may need more samples)\")\n",
    "print(\"4. Chains don't overlap → Not converged (R-hat will be high)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Step 3: Rank Plot (Most Sensitive)\n",
    "\n",
    "### Why Rank Plot?\n",
    "- **Most sensitive convergence diagnostic**\n",
    "- Detects subtle issues R-hat misses\n",
    "- Standard for modern MCMC validation\n",
    "\n",
    "### What It Shows\n",
    "- Histogram of ranked samples across chains\n",
    "- If converged, histogram should be **uniform** (flat)\n",
    "\n",
    "### Target Pattern\n",
    "- ✓ **Uniform histogram** across all bins\n",
    "- ✗ **Peaks, valleys, trends** indicate non-convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank plot (most sensitive)\n",
    "az.plot_rank(idata, var_names=['G0', 'eta'], figsize=(14, 5))\n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()  # Get current figure from ArviZ\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"\\nRANK PLOT INTERPRETATION:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"UNIFORM HISTOGRAM (all bins similar height):\")\n",
    "print(\"  ✓ CONVERGED: Chains sampling from same distribution\")\n",
    "print(\"\\nNON-UNIFORM (peaks, valleys, trends):\")\n",
    "print(\"  ✗ NOT CONVERGED: Chains exploring different regions\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\\nACTION ITEMS:\")\n",
    "print(\"1. Non-uniform → Increase num_warmup (double: 1000 → 2000)\")\n",
    "print(\"2. Peaks at edges → Chain sticking (check initial values, priors)\")\n",
    "print(\"3. Consistent pattern → Systematic bias (reparameterize model)\")\n",
    "print(\"\\nWHY RANK PLOT OVER TRACE PLOT?\")\n",
    "print(\"  - More sensitive to subtle non-convergence\")\n",
    "print(\"  - Works better for high-dimensional posteriors\")\n",
    "print(\"  - Less sensitive to posterior scale\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Step 4: Pair Plot (Correlations & Divergences)\n",
    "\n",
    "### What It Shows\n",
    "- **Diagonal**: Marginal posteriors\n",
    "- **Off-diagonal**: Joint distributions (correlations)\n",
    "- **Red points**: Divergent transitions (MCMC failures)\n",
    "\n",
    "### Correlation Patterns\n",
    "- **Elliptical**: Moderate correlation (normal)\n",
    "- **Diagonal line**: Strong correlation (identifiability issue)\n",
    "- **Funnel**: One parameter constrains another (reparameterization needed)\n",
    "\n",
    "### Divergences\n",
    "- **< 1%**: Acceptable\n",
    "- **1-5%**: Moderate (increase target_accept_prob)\n",
    "- **> 5%**: Problematic (results unreliable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot with divergences\n",
    "az.plot_pair(\n",
    "    idata,\n",
    "    var_names=['G0', 'eta'],\n",
    "    kind='scatter',\n",
    "    divergences=True,\n",
    "    figsize=(10, 8)\n",
    ")\n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()  # Get current figure from ArviZ\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "# Compute correlation\n",
    "G0_samples = result.posterior_samples['G0']\n",
    "eta_samples = result.posterior_samples['eta']\n",
    "correlation = np.corrcoef(G0_samples, eta_samples)[0, 1]\n",
    "\n",
    "print(\"\\nPAIR PLOT INTERPRETATION:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Parameter Correlation: ρ(G₀, η) = {correlation:.3f}\\n\")\n",
    "print(\"CORRELATION STRENGTH:\")\n",
    "print(\"  |ρ| < 0.3:  Weakly correlated (well-identified) ✓\")\n",
    "print(\"  0.3 < |ρ| < 0.7:  Moderate correlation (acceptable) ✓\")\n",
    "print(\"  |ρ| > 0.7:  Strong correlation (identifiability issue) ✗\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\\nDIVERGENCE TROUBLESHOOTING:\")\n",
    "if 'num_divergences' in diagnostics:\n",
    "    div_rate = diagnostics['num_divergences'] / (result.num_samples * result.num_chains) * 100\n",
    "    print(f\"Divergence rate: {div_rate:.2f}%\")\n",
    "    if div_rate < 1:\n",
    "        print(\"  ✓ < 1%: Acceptable, model fit reliable\")\n",
    "    elif div_rate < 5:\n",
    "        print(\"  ⚠ 1-5%: Moderate\")\n",
    "        print(\"    Solution: Increase target_accept_prob=0.9\")\n",
    "    else:\n",
    "        print(\"  ✗ > 5%: Problematic\")\n",
    "        print(\"    Solution 1: Increase target_accept_prob=0.95\")\n",
    "        print(\"    Solution 2: Reparameterize (non-centered)\")\n",
    "        print(\"    Solution 3: Tighter priors to constrain problematic regions\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\\nFOR MAXWELL MODEL:\")\n",
    "print(f\"  G₀ and η correlation ({correlation:.3f}) is typical\")\n",
    "print(\"  Both affect relaxation time τ = η/G₀\")\n",
    "print(\"  This correlation is physical, not a problem\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Step 5: Autocorrelation Plot (Mixing Quality)\n",
    "\n",
    "### What It Shows\n",
    "- Correlation between samples at different lags\n",
    "- High autocorrelation → many samples needed for good ESS\n",
    "\n",
    "### Target\n",
    "- ✓ Autocorrelation drops to ~0 within 20-30 lags\n",
    "- ✗ Slow decay → high autocorrelation → poor mixing\n",
    "\n",
    "### Relation to ESS\n",
    "```\n",
    "ESS ≈ num_samples / (1 + 2 × Σ autocorrelations)\n",
    "```\n",
    "High autocorrelation → low ESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocorrelation plot\n",
    "az.plot_autocorr(\n",
    "    idata,\n",
    "    var_names=['G0', 'eta'],\n",
    "    max_lag=100,\n",
    "    figsize=(14, 5)\n",
    ")\n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()  # Get current figure from ArviZ\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"\\nAUTOCORRELATION PLOT INTERPRETATION:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"TARGET: Autocorrelation drops to ~0 within 20-30 lags\\n\")\n",
    "print(\"FAST DECAY (< 30 lags):\")\n",
    "print(\"  ✓ Good mixing, independent samples obtained quickly\")\n",
    "print(\"  ✓ High ESS (>50% efficiency)\")\n",
    "print(\"\\nMODERATE DECAY (30-50 lags):\")\n",
    "print(\"  ⚠ Acceptable mixing\")\n",
    "print(\"  ⚠ ESS ~20-50% of num_samples\")\n",
    "print(\"  → Consider increasing num_samples if ESS < 400\")\n",
    "print(\"\\nSLOW DECAY (> 50 lags):\")\n",
    "print(\"  ✗ Poor mixing, high autocorrelation\")\n",
    "print(\"  ✗ ESS < 20% of num_samples\")\n",
    "print(\"  → Solution 1: Increase num_samples significantly\")\n",
    "print(\"  → Solution 2: Check pair plot for strong correlations\")\n",
    "print(\"  → Solution 3: Reparameterize if due to model structure\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\\nRELATION TO ESS:\")\n",
    "for param in ['G0', 'eta']:\n",
    "    ess = diagnostics['ess'][param]\n",
    "    efficiency = ess / (result.num_samples * result.num_chains) * 100\n",
    "    print(f\"  {param}: ESS = {ess:.0f} ({efficiency:.1f}% efficiency)\")\n",
    "    if efficiency > 50:\n",
    "        print(f\"       ✓ Excellent: Fast mixing\")\n",
    "    elif efficiency > 20:\n",
    "        print(f\"       ✓ Good: Acceptable mixing\")\n",
    "    else:\n",
    "        print(f\"       ✗ Poor: High autocorrelation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Step 6: ESS Plot (Sampling Efficiency)\n",
    "\n",
    "### What It Shows\n",
    "- Effective sample size per parameter\n",
    "- Quantifies sampling efficiency\n",
    "\n",
    "### ESS Types\n",
    "- **Bulk ESS**: Central posterior (mean, median)\n",
    "- **Tail ESS**: Extreme quantiles (credible interval ends)\n",
    "- **Local ESS**: ESS at different quantiles (full curve)\n",
    "\n",
    "### Targets\n",
    "- Bulk ESS > 400: Reliable mean/median estimates\n",
    "- Tail ESS > 400: Reliable credible intervals\n",
    "- If tail ESS < bulk ESS: Need more samples for tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESS plot (local)\n",
    "az.plot_ess(\n",
    "    idata,\n",
    "    var_names=['G0', 'eta'],\n",
    "    kind='local',\n",
    "    figsize=(14, 5)\n",
    ")\n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()  # Get current figure from ArviZ\n",
    "display(fig)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"\\nESS PLOT INTERPRETATION:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"ESS measures effective independent samples (accounts for autocorrelation)\\n\")\n",
    "print(\"TARGETS:\")\n",
    "print(\"  Bulk ESS > 400:  Reliable mean/median ✓\")\n",
    "print(\"  Tail ESS > 400:  Reliable credible intervals ✓\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\\nACTION ITEMS:\")\n",
    "print(\"ESS < 100:    Critical - Increase samples 10x\")\n",
    "print(\"ESS 100-400:  Increase samples 2-3x\")\n",
    "print(\"ESS > 400:    ✓ Sufficient\")\n",
    "print(\"Tail << Bulk: Increase samples for CI reliability\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\\nEFFICIENCY CALCULATION:\")\n",
    "total_samples = result.num_samples * result.num_chains\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "for param in ['G0', 'eta']:\n",
    "    ess = diagnostics['ess'][param]\n",
    "    efficiency = ess / total_samples * 100\n",
    "    print(f\"  {param}: ESS = {ess:.0f}, Efficiency = {efficiency:.1f}%\")\n",
    "    if efficiency > 50:\n",
    "        print(f\"       ✓ Excellent sampling efficiency\")\n",
    "    elif efficiency > 20:\n",
    "        print(f\"       ✓ Good efficiency\")\n",
    "    elif efficiency > 10:\n",
    "        print(f\"       ⚠ Acceptable but could be better\")\n",
    "    else:\n",
    "        print(f\"       ✗ Poor efficiency (need more samples or reparameterization)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Step 7: Energy Plot (Posterior Geometry)\n",
    "\n",
    "### What It Shows\n",
    "- NUTS energy diagnostic\n",
    "- **Marginal energy**: Expected under model\n",
    "- **Conditional energy**: Actual from MCMC\n",
    "\n",
    "### Requirements\n",
    "- **Multi-chain MCMC** (num_chains ≥ 2)\n",
    "- Single chain: plot will fail\n",
    "\n",
    "### Target\n",
    "- ✓ **Good overlap** between distributions\n",
    "- ✗ **Mismatch** → posterior geometry issues\n",
    "\n",
    "### Causes of Mismatch\n",
    "- Funnel-shaped posteriors\n",
    "- Heavy tails\n",
    "- Complex correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy plot (requires multi-chain)\n",
    "try:\n",
    "    az.plot_energy(idata)\n",
    "    plt.tight_layout()\n",
    "    fig = plt.gcf()  # Get current figure from ArviZ\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(\"\\nENERGY PLOT INTERPRETATION:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"GOOD FIT (distributions overlap well):\")\n",
    "    print(\"  ✓ Posterior geometry is well-behaved\")\n",
    "    print(\"  ✓ NUTS sampling efficient\")\n",
    "    print(\"\\nPOOR FIT (distributions don't match):\")\n",
    "    print(\"  ✗ Posterior geometry problematic\")\n",
    "    print(\"  → Possible causes:\")\n",
    "    print(\"    - Funnel-shaped posterior\")\n",
    "    print(\"    - Heavy tails\")\n",
    "    print(\"    - Complex parameter correlations\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"\\nACTION ITEMS:\")\n",
    "    print(\"1. Mismatch detected → Reparameterize model\")\n",
    "    print(\"   (Use non-centered parameterization for hierarchical models)\")\n",
    "    print(\"2. Persistent issues → Tighter priors to regularize\")\n",
    "    print(\"3. Use with pair plot to identify problematic parameters\")\n",
    "except Exception as e:\n",
    "    print(\"\\nENERGY PLOT FAILED:\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nLikely cause: Single chain MCMC (energy plot requires ≥2 chains)\")\n",
    "    print(\"Use num_chains=4 when running fit_bayesian()\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Systematic Troubleshooting Guide\n",
    "\n",
    "Follow this decision tree when diagnosing convergence issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated troubleshooting function\n",
    "\n",
    "def diagnose_convergence(result, show_solutions=True):\n",
    "    \"\"\"\n",
    "    Automated convergence diagnostic with actionable recommendations.\n",
    "    \"\"\"\n",
    "    diagnostics = result.diagnostics\n",
    "    issues = []\n",
    "    solutions = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"AUTOMATED TROUBLESHOOTING REPORT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Check R-hat\n",
    "    max_rhat = max(diagnostics['r_hat'].values())\n",
    "    if max_rhat > 1.01:\n",
    "        issues.append(f\"R-hat > 1.01 (max: {max_rhat:.4f})\")\n",
    "        solutions.append(\"1. Increase num_warmup (current → 2× current)\")\n",
    "        solutions.append(\"2. Check trace plot: Are chains exploring same region?\")\n",
    "        solutions.append(\"3. Check rank plot: Is histogram uniform?\")\n",
    "    \n",
    "    # Check ESS\n",
    "    min_ess = min(diagnostics['ess'].values())\n",
    "    if min_ess < 400:\n",
    "        issues.append(f\"ESS < 400 (min: {min_ess:.0f})\")\n",
    "        solutions.append(\"1. Increase num_samples (2000 → 5000)\")\n",
    "        solutions.append(\"2. Check autocorrelation plot: Is mixing slow?\")\n",
    "        solutions.append(\"3. Check pair plot: Are parameters correlated?\")\n",
    "    \n",
    "    # Check divergences\n",
    "    if 'num_divergences' in diagnostics:\n",
    "        div_rate = diagnostics['num_divergences'] / (result.num_samples * result.num_chains)\n",
    "        if div_rate > 0.05:\n",
    "            issues.append(f\"High divergence rate ({div_rate*100:.1f}%)\")\n",
    "            solutions.append(\"1. Increase target_accept_prob (0.8 → 0.9 or 0.95)\")\n",
    "            solutions.append(\"2. Check pair plot: Where do divergences occur?\")\n",
    "            solutions.append(\"3. Use tighter priors or reparameterize\")\n",
    "    \n",
    "    # Report\n",
    "    if not issues:\n",
    "        print(\"\\n✓✓✓ NO ISSUES DETECTED ✓✓✓\")\n",
    "        print(\"All convergence criteria met.\")\n",
    "        print(f\"  - R-hat: {max_rhat:.4f} < 1.01\")\n",
    "        print(f\"  - ESS: {min_ess:.0f} > 400\")\n",
    "        if 'num_divergences' in diagnostics:\n",
    "            print(f\"  - Divergences: {diagnostics['num_divergences']} ({div_rate*100:.2f}%)\")\n",
    "    else:\n",
    "        print(\"\\n⚠⚠⚠ ISSUES DETECTED ⚠⚠⚠\\n\")\n",
    "        for issue in issues:\n",
    "            print(f\"  - {issue}\")\n",
    "        \n",
    "        if show_solutions:\n",
    "            print(\"\\nRECOMMENDED ACTIONS:\\n\")\n",
    "            for solution in solutions:\n",
    "                print(f\"  {solution}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    return len(issues) == 0\n",
    "\n",
    "# Run diagnosis\n",
    "converged = diagnose_convergence(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Common Failure Modes Reference\n",
    "\n",
    "| Symptom | Likely Cause | Primary Diagnostic | Solution |\n",
    "|---------|--------------|-------------------|---------|\n",
    "| R-hat > 1.01 | Not converged | Rank plot | Increase `num_warmup` |\n",
    "| ESS < 400 | High autocorrelation | Autocorr plot | Increase `num_samples` |\n",
    "| Many divergences | Bad geometry | Pair plot | Increase `target_accept_prob` |\n",
    "| Bimodal posterior | Multiple modes | Trace plot | Longer chains |\n",
    "| Strong correlations | Identifiability | Pair plot | More data or tighter priors |\n",
    "| Energy mismatch | Funnel geometry | Energy plot | Non-centered parameterization |\n",
    "| Slow autocorr decay | Poor mixing | Autocorr + Pair | Reparameterize |\n",
    "| Non-uniform rank | Non-convergence | Rank plot | Increase warmup (most sensitive) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Key Takeaways\n",
    "\n",
    "### Main Concepts\n",
    "\n",
    "1. **Diagnostic Workflow**\n",
    "   - Use all 6 plots as integrated system\n",
    "   - Rank plot is most sensitive convergence diagnostic\n",
    "   - Pair plot reveals correlations and divergences\n",
    "   - Multi-chain MCMC (4 chains) is best practice\n",
    "\n",
    "2. **Convergence Criteria**\n",
    "   - R-hat < 1.01 (all parameters)\n",
    "   - ESS > 400 (all parameters)\n",
    "   - Divergences < 1%\n",
    "   - **Always verify before trusting results!**\n",
    "\n",
    "3. **Common Issues and Solutions**\n",
    "   - R-hat > 1.01 → Increase warmup\n",
    "   - ESS < 400 → Increase samples\n",
    "   - Divergences > 1% → Increase target_accept_prob or tighten priors\n",
    "   - Strong correlations → More data, different test mode, or accept\n",
    "\n",
    "4. **Multi-Chain Benefits**\n",
    "   - Robust R-hat estimation\n",
    "   - Energy plot requires ≥2 chains\n",
    "   - Parallel execution (no time penalty)\n",
    "   - Reliably detects non-convergence\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Always use num_chains=4** for production work\n",
    "2. **Run all 6 diagnostics** before interpreting results\n",
    "3. **Rank plot first** for convergence assessment\n",
    "4. **Pair plot second** for correlations and divergences\n",
    "5. **Document convergence** in reports (R-hat, ESS, divergences)\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### Apply Diagnostics\n",
    "- **[04-model-comparison.ipynb](04-model-comparison.ipynb)**: WAIC and LOO for model selection\n",
    "- **[05-uncertainty-propagation.ipynb](05-uncertainty-propagation.ipynb)**: Propagate uncertainty to predictions\n",
    "\n",
    "### Related Content\n",
    "- All `basic/` notebooks demonstrate Bayesian sections\n",
    "- **[01-bayesian-basics.ipynb](01-bayesian-basics.ipynb)**: NLSQ → NUTS workflow\n",
    "- **[02-prior-selection.ipynb](02-prior-selection.ipynb)**: Prior choices and sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Session Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import rheojax\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Rheo: {rheojax.__version__}\")\n",
    "print(f\"JAX: {jax.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"ArviZ: {az.__version__}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rheojax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
