{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Bayesian Workflow Demo: Complete NLSQ \u2192 NUTS \u2192 ArviZ Pipeline\n\n> **Handbook:** See [Complete Bayesian Workflow](../../docs/source/_includes/bayesian_workflow.rst) for step-by-step implementation guide and [Three-Stage Pipeline](../../docs/source/user_guide/03_advanced_topics/bayesian_inference.rst#workflow) for theoretical background.\n\nThis notebook demonstrates the recommended three-stage Bayesian workflow:\n1. **Stage 1**: NLSQ point estimation (fast, ~seconds)\n2. **Stage 2**: NUTS posterior sampling with warm-start (~minutes)\n3. **Stage 3**: ArviZ diagnostic plots (visual verification)\n\n## Learning Objectives\n\nAfter completing this notebook, you will be able to:\n- Execute the complete three-stage Bayesian workflow\n- Understand warm-start benefits for MCMC convergence\n- Interpret posterior summaries and credible intervals\n- Use ArviZ for comprehensive MCMC diagnostics\n- Apply the workflow to any RheoJAX model\n\n**Estimated Time:** 15-20 minutes\n\n**Expected runtime**: ~30 seconds (depending on hardware)\n\n**Requirements**:\n- rheojax with Bayesian dependencies (numpyro, arviz)\n- matplotlib for visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:15.600004Z",
     "iopub.status.busy": "2026-02-09T21:18:15.599509Z",
     "iopub.status.idle": "2026-02-09T21:18:15.607312Z",
     "shell.execute_reply": "2026-02-09T21:18:15.606285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Google Colab Setup - Run this cell first!\n",
    "# Skip if running locally with rheojax already installed\n",
    "\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install rheojax and dependencies\n",
    "    !pip install -q rheojax\n",
    "    \n",
    "    # Colab uses float32 by default - we need float64 for numerical stability\n",
    "    # This MUST be set before importing JAX\n",
    "    import os\n",
    "    os.environ['JAX_ENABLE_X64'] = 'true'\n",
    "    \n",
    "    print(\"\u2713 RheoJAX installed successfully!\")\n",
    "    print(\"\u2713 Float64 precision enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:15.609829Z",
     "iopub.status.busy": "2026-02-09T21:18:15.609629Z",
     "iopub.status.idle": "2026-02-09T21:18:17.066286Z",
     "shell.execute_reply": "2026-02-09T21:18:17.065598Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from rheojax.models import Maxwell\n",
    "\n",
    "from rheojax.core.jax_config import safe_import_jax\n",
    "\n",
    "# Safe JAX import (ensures float64 precision)\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BAYESIAN WORKFLOW DEMONSTRATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nThis demo shows the recommended NLSQ \u2192 NUTS \u2192 ArviZ workflow\")\n",
    "print(\"for uncertainty quantification in rheological modeling.\\n\")\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(\"\")))\n",
    "from utils.plotting_utils import (\n",
    "    plot_nlsq_fit, display_arviz_diagnostics, plot_posterior_predictive\n",
    ")\n",
    "\n",
    "FAST_MODE = os.environ.get(\"FAST_MODE\", \"1\") == \"1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Synthetic Relaxation Data\n",
    "\n",
    "We'll create synthetic Maxwell relaxation data with realistic noise to demonstrate the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:17.067732Z",
     "iopub.status.busy": "2026-02-09T21:18:17.067571Z",
     "iopub.status.idle": "2026-02-09T21:18:17.070795Z",
     "shell.execute_reply": "2026-02-09T21:18:17.070399Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Step 1: Generating synthetic Maxwell relaxation data...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# True parameters\n",
    "G0_true = 1e5  # Pa\n",
    "eta_true = 1e3  # Pa\u00b7s\n",
    "tau_true = eta_true / G0_true  # 0.01 s\n",
    "\n",
    "print(f\"  True parameters:\")\n",
    "print(f\"    G\u2080  = {G0_true:.2e} Pa\")\n",
    "print(f\"    \u03b7   = {eta_true:.2e} Pa\u00b7s\")\n",
    "print(f\"    \u03c4   = {tau_true:.4f} s\")\n",
    "\n",
    "# Time array (log-spaced for relaxation)\n",
    "t = np.logspace(-2, 2, 50)  # 0.01 to 100 seconds\n",
    "\n",
    "# True relaxation modulus\n",
    "G_t_true = G0_true * np.exp(-t / tau_true)\n",
    "\n",
    "# Add realistic noise (1.5% relative)\n",
    "np.random.seed(42)\n",
    "noise_level = 0.015\n",
    "noise = np.random.normal(0, noise_level * G_t_true)\n",
    "G_t_noisy = G_t_true + noise\n",
    "\n",
    "print(f\"\\n  Generated {len(t)} data points from {t.min():.2e} to {t.max():.1f} s\")\n",
    "print(f\"  Noise level: {noise_level*100:.1f}% relative\")\n",
    "print(f\"  Signal-to-noise ratio: {np.mean(G_t_true)/np.std(noise):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: NLSQ Point Estimation (Fast)\n",
    "\n",
    "First, we obtain fast point estimates using nonlinear least squares optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:17.071937Z",
     "iopub.status.busy": "2026-02-09T21:18:17.071849Z",
     "iopub.status.idle": "2026-02-09T21:18:18.301321Z",
     "shell.execute_reply": "2026-02-09T21:18:18.300743Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STAGE 1: NLSQ POINT ESTIMATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model = Maxwell()\n",
    "model.parameters.set_bounds('G0', (1e3, 1e7))\n",
    "model.parameters.set_bounds('eta', (1e1, 1e5))\n",
    "\n",
    "print(\"\\nRunning NLSQ optimization...\")\n",
    "import time\n",
    "\n",
    "start_nlsq = time.time()\n",
    "\n",
    "model.fit(t, G_t_noisy, method='nlsq')\n",
    "\n",
    "nlsq_time = time.time() - start_nlsq\n",
    "\n",
    "# Extract NLSQ results\n",
    "G0_nlsq = model.parameters.get_value('G0')\n",
    "eta_nlsq = model.parameters.get_value('eta')\n",
    "tau_nlsq = eta_nlsq / G0_nlsq\n",
    "\n",
    "print(f\"\\n\u2713 NLSQ completed in {nlsq_time:.3f} seconds\")\n",
    "print(f\"\\nNLSQ Point Estimates:\")\n",
    "print(f\"  G\u2080  = {G0_nlsq:.4e} Pa  (error: {abs(G0_nlsq-G0_true)/G0_true*100:.2f}%)\")\n",
    "print(f\"  \u03b7   = {eta_nlsq:.4e} Pa\u00b7s  (error: {abs(eta_nlsq-eta_true)/eta_true*100:.2f}%)\")\n",
    "print(f\"  \u03c4   = {tau_nlsq:.6f} s  (error: {abs(tau_nlsq-tau_true)/tau_true*100:.2f}%)\")\n",
    "print(f\"\\n\u26a0  Note: NLSQ provides point estimates only (no uncertainty)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Bayesian Inference with Warm-Start\n",
    "\n",
    "Now we perform MCMC sampling using NUTS, warm-starting from the NLSQ estimates for faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:18.302802Z",
     "iopub.status.busy": "2026-02-09T21:18:18.302688Z",
     "iopub.status.idle": "2026-02-09T21:18:25.889912Z",
     "shell.execute_reply": "2026-02-09T21:18:25.889474Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STAGE 2: BAYESIAN INFERENCE (NUTS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nRunning NUTS sampling with NLSQ warm-start...\")\n",
    "print(\"  Configuration:\")\n",
    "print(f\"    \u2022 num_chains: 4 (for robust diagnostics)\")\n",
    "print(f\"    \u2022 num_warmup: 1000 (burn-in iterations)\")\n",
    "print(f\"    \u2022 num_samples: 2000 (posterior samples per chain)\")\n",
    "print(f\"    \u2022 warm-start: Yes (from NLSQ estimates)\")\n",
    "print(\"\\n  This may take 20-60 seconds depending on your hardware...\")\n",
    "\n",
    "start_bayes = time.time()\n",
    "\n",
    "# Run Bayesian inference with warm-start\n",
    "result = model.fit_bayesian(\n",
    "    t, G_t_noisy,\n",
    "    num_warmup=1000,\n",
    "    num_samples=2000,\n",
    "    num_chains=4,\n",
    "    initial_values={  # Warm-start from NLSQ\n",
    "        'G0': G0_nlsq,\n",
    "        'eta': eta_nlsq\n",
    "    }\n",
    ")\n",
    "\n",
    "bayes_time = time.time() - start_bayes\n",
    "\n",
    "print(f\"\\n\u2713 Bayesian inference completed in {bayes_time:.1f} seconds\")\n",
    "print(f\"  Total time (NLSQ + Bayes): {nlsq_time + bayes_time:.1f} seconds\")\n",
    "print(f\"  Generated {result.num_chains * result.num_samples} posterior samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Results\n",
    "\n",
    "Extract and display the posterior summary statistics and credible intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:25.891602Z",
     "iopub.status.busy": "2026-02-09T21:18:25.891490Z",
     "iopub.status.idle": "2026-02-09T21:18:25.895797Z",
     "shell.execute_reply": "2026-02-09T21:18:25.895353Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"POSTERIOR RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "posterior = result.posterior_samples\n",
    "summary = result.summary\n",
    "\n",
    "print(\"\\nPosterior Estimates (mean \u00b1 std):\")\n",
    "print(f\"  G\u2080  = {summary['G0']['mean']:.4e} \u00b1 {summary['G0']['std']:.4e} Pa\")\n",
    "print(f\"  \u03b7   = {summary['eta']['mean']:.4e} \u00b1 {summary['eta']['std']:.4e} Pa\u00b7s\")\n",
    "\n",
    "# Compute credible intervals\n",
    "intervals = model.get_credible_intervals(posterior, credibility=0.95)\n",
    "print(\"\\n95% Credible Intervals:\")\n",
    "print(f\"  G\u2080:  [{intervals['G0'][0]:.4e}, {intervals['G0'][1]:.4e}] Pa\")\n",
    "print(f\"  \u03b7:   [{intervals['eta'][0]:.4e}, {intervals['eta'][1]:.4e}] Pa\u00b7s\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  'There is 95% probability that G\u2080 lies in the interval above'\")\n",
    "print(\"  This is a DIRECT probabilistic statement (Bayesian interpretation)\")\n",
    "\n",
    "# Relative uncertainties\n",
    "print(\"\\nRelative Uncertainties:\")\n",
    "print(f\"  G\u2080:  {summary['G0']['std']/summary['G0']['mean']*100:.2f}%\")\n",
    "print(f\"  \u03b7:   {summary['eta']['std']/summary['eta']['mean']*100:.2f}%\")\n",
    "\n",
    "# Check if true values are in credible intervals\n",
    "G0_in_CI = intervals['G0'][0] <= G0_true <= intervals['G0'][1]\n",
    "eta_in_CI = intervals['eta'][0] <= eta_true <= intervals['eta'][1]\n",
    "print(\"\\nValidation (true values in 95% CI):\")\n",
    "print(f\"  G\u2080:  {'\u2713 Yes' if G0_in_CI else '\u2717 No'}\")\n",
    "print(f\"  \u03b7:   {'\u2713 Yes' if eta_in_CI else '\u2717 No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Convergence Diagnostics (CRITICAL!)\n",
    "\n",
    "**Always check convergence before interpreting Bayesian results!**\n",
    "\n",
    "We examine:\n",
    "- **R-hat (Gelman-Rubin)**: Should be < 1.01 for all parameters\n",
    "- **ESS (Effective Sample Size)**: Should be > 400 for reliable inference\n",
    "- **Divergences**: Should be < 1% of total samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:25.897038Z",
     "iopub.status.busy": "2026-02-09T21:18:25.896954Z",
     "iopub.status.idle": "2026-02-09T21:18:25.901248Z",
     "shell.execute_reply": "2026-02-09T21:18:25.900797Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STAGE 3: CONVERGENCE DIAGNOSTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "diagnostics = result.diagnostics\n",
    "\n",
    "print(\"\\n\u26a0  ALWAYS check convergence before interpreting Bayesian results!\")\n",
    "print(\"\\n1. R-hat (Gelman-Rubin Statistic):\")\n",
    "print(f\"   Target: < 1.01 for all parameters\")\n",
    "for param in ['G0', 'eta']:\n",
    "    rhat = diagnostics['r_hat'][param]\n",
    "    status = '\u2713 Converged' if rhat < 1.01 else '\u2717 NOT converged'\n",
    "    print(f\"     {param:<5} R-hat = {rhat:.4f}  {status}\")\n",
    "\n",
    "print(\"\\n2. ESS (Effective Sample Size):\")\n",
    "print(f\"   Target: > 400 (out of {result.num_chains * result.num_samples} total)\")\n",
    "for param in ['G0', 'eta']:\n",
    "    ess = diagnostics['ess'][param]\n",
    "    efficiency = ess / (result.num_chains * result.num_samples) * 100\n",
    "    status = '\u2713 Sufficient' if ess > 400 else '\u2717 Low (increase samples)'\n",
    "    print(f\"     {param:<5} ESS = {ess:.0f} ({efficiency:.1f}% efficient)  {status}\")\n",
    "\n",
    "if 'num_divergences' in diagnostics:\n",
    "    div_rate = diagnostics['num_divergences'] / (result.num_chains * result.num_samples) * 100\n",
    "    print(\"\\n3. Divergences:\")\n",
    "    print(f\"   Count: {diagnostics['num_divergences']} ({div_rate:.2f}%)\")\n",
    "    status = '\u2713 Good' if div_rate < 1 else '\u2717 High (results unreliable)'\n",
    "    print(f\"   Target: < 1%  {status}\")\n",
    "\n",
    "# Overall convergence assessment\n",
    "all_converged = (\n",
    "    all(diagnostics['r_hat'][p] < 1.01 for p in ['G0', 'eta']) and\n",
    "    all(diagnostics['ess'][p] > 400 for p in ['G0', 'eta'])\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "if all_converged:\n",
    "    print(\"\u2713\u2713\u2713 EXCELLENT CONVERGENCE \u2713\u2713\u2713\")\n",
    "    print(\"All diagnostic criteria met. Results are reliable.\")\n",
    "else:\n",
    "    print(\"\u26a0\u26a0\u26a0 CONVERGENCE ISSUES \u26a0\u26a0\u26a0\")\n",
    "    print(\"Increase num_warmup or num_samples and rerun.\")\n",
    "print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Diagnostics (ArviZ Integration)\n",
    "\n",
    "ArviZ provides comprehensive diagnostic visualizations. We'll generate 6 key plots:\n",
    "\n",
    "1. **Trace plot**: Visual convergence check\n",
    "2. **Rank plot**: Most sensitive convergence test\n",
    "3. **Pair plot**: Parameter correlations + divergences\n",
    "4. **Autocorrelation plot**: Mixing quality\n",
    "5. **ESS plot**: Sampling efficiency\n",
    "6. **Forest plot**: Credible interval comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:25.902625Z",
     "iopub.status.busy": "2026-02-09T21:18:25.902520Z",
     "iopub.status.idle": "2026-02-09T21:18:26.690085Z",
     "shell.execute_reply": "2026-02-09T21:18:26.689367Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VISUAL DIAGNOSTICS (ArviZ Integration)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nGenerating diagnostic plots...\")\n",
    "\n",
    "# Convert to ArviZ InferenceData\n",
    "\n",
    "idata = result.to_inference_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:26.691822Z",
     "iopub.status.busy": "2026-02-09T21:18:26.691608Z",
     "iopub.status.idle": "2026-02-09T21:18:27.357037Z",
     "shell.execute_reply": "2026-02-09T21:18:27.356637Z"
    }
   },
   "outputs": [],
   "source": [
    "# ArviZ diagnostic plots (trace, pair, forest, energy, autocorr, rank)\n",
    "display_arviz_diagnostics(result, ['G0', 'eta'], fast_mode=FAST_MODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Summary\n",
    "\n",
    "Recap of the complete 3-stage workflow and key results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:27.358305Z",
     "iopub.status.busy": "2026-02-09T21:18:27.358212Z",
     "iopub.status.idle": "2026-02-09T21:18:27.360990Z",
     "shell.execute_reply": "2026-02-09T21:18:27.360634Z"
    }
   },
   "outputs": [],
   "source": "### Residual Analysis in Workflow\n\n**Examining residuals** at each stage reveals model adequacy:\n\n| Workflow Stage | Residual Check | Interpretation |\n|----------------|----------------|----------------|\n| **Stage 1 (NLSQ)** | Quick visual check | Random scatter \u2192 proceed to Bayesian |\n| **Stage 2 (NUTS)** | Posterior predictive | Bands capture data \u2192 model adequate |\n| **Stage 3 (ArviZ)** | Diagnostic plots | No systematic patterns \u2192 converged |\n\nIf residuals show systematic patterns (trends, heteroscedasticity), consider:\n- Different model (e.g., Zener instead of Maxwell)\n- Additional parameters\n- Weighted least squares for non-constant variance"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "- **Gelman et al. (2020)**: [\"Bayesian Workflow\"](https://arxiv.org/abs/1507.03246) \u2014 Comprehensive workflow for applied Bayesian modeling\n",
    "- **Betancourt (2018)**: [\"Towards a Principled Bayesian Workflow\"](https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html) \u2014 Deep dive into workflow stages\n",
    "- **RheoJAX Bayesian Guide**: [Documentation](../../docs/source/_includes/bayesian_workflow.rst) \u2014 Implementation details and best practices\n",
    "- **ArviZ Workflow Tools**: [Tutorial](https://python.arviz.org/en/stable/getting_started/WorkingWithInferenceData.html) \u2014 Using InferenceData for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **[07-gmm_bayesian_workflow.ipynb](07-gmm_bayesian_workflow.ipynb)**: Apply workflow to multi-mode Generalized Maxwell models\n",
    "- **[08-spp-laos.ipynb](08-spp-laos.ipynb)** & **[09-spp-rheojax-workflow.ipynb](09-spp-rheojax-workflow.ipynb)**: Workflow for nonlinear LAOS analysis\n",
    "- Adapt this workflow template to your own rheological datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**For questions or issues:**\n- GitHub: https://github.com/imewei/rheojax\n- Docs: https://rheojax.readthedocs.io\n\n### Key References\n\n- **Gelman, A. et al. (2020).** \"Bayesian Workflow.\" arXiv:2011.01808. [Modern best practices for applied Bayesian analysis]\n- **McElreath, R. (2020).** *Statistical Rethinking*. 2nd ed. CRC Press. [Complete workflow with practical examples]\n- **Gabry, J. et al. (2019).** \"Visualization in Bayesian workflow.\" *J. Royal Stat. Soc. A* 182:389-402. [Diagnostic visualization strategies]"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rheojax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}