{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Workflow Demo: Complete NLSQ → NUTS → ArviZ Pipeline\n",
    "\n",
    "This notebook demonstrates the recommended three-stage Bayesian workflow:\n",
    "1. **Stage 1**: NLSQ point estimation (fast, ~seconds)\n",
    "2. **Stage 2**: NUTS posterior sampling with warm-start (~minutes)\n",
    "3. **Stage 3**: ArviZ diagnostic plots (visual verification)\n",
    "\n",
    "**Expected runtime**: ~30 seconds (depending on hardware)\n",
    "\n",
    "**Requirements**:\n",
    "- rheojax with Bayesian dependencies (numpyro, arviz)\n",
    "- matplotlib for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:15.600004Z",
     "iopub.status.busy": "2026-02-09T21:18:15.599509Z",
     "iopub.status.idle": "2026-02-09T21:18:15.607312Z",
     "shell.execute_reply": "2026-02-09T21:18:15.606285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Google Colab Setup - Run this cell first!\n",
    "# Skip if running locally with rheojax already installed\n",
    "\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install rheojax and dependencies\n",
    "    !pip install -q rheojax\n",
    "    \n",
    "    # Colab uses float32 by default - we need float64 for numerical stability\n",
    "    # This MUST be set before importing JAX\n",
    "    import os\n",
    "    os.environ['JAX_ENABLE_X64'] = 'true'\n",
    "    \n",
    "    print(\"✓ RheoJAX installed successfully!\")\n",
    "    print(\"✓ Float64 precision enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:15.609829Z",
     "iopub.status.busy": "2026-02-09T21:18:15.609629Z",
     "iopub.status.idle": "2026-02-09T21:18:17.066286Z",
     "shell.execute_reply": "2026-02-09T21:18:17.065598Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from rheojax.models import Maxwell\n",
    "\n",
    "from rheojax.core.jax_config import safe_import_jax\n",
    "\n",
    "# Safe JAX import (ensures float64 precision)\n",
    "jax, jnp = safe_import_jax()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BAYESIAN WORKFLOW DEMONSTRATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nThis demo shows the recommended NLSQ → NUTS → ArviZ workflow\")\n",
    "print(\"for uncertainty quantification in rheological modeling.\\n\")\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(\"\")))\n",
    "from utils.plotting_utils import (\n",
    "    plot_nlsq_fit, display_arviz_diagnostics, plot_posterior_predictive\n",
    ")\n",
    "\n",
    "FAST_MODE = os.environ.get(\"FAST_MODE\", \"1\") == \"1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Synthetic Relaxation Data\n",
    "\n",
    "We'll create synthetic Maxwell relaxation data with realistic noise to demonstrate the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:17.067732Z",
     "iopub.status.busy": "2026-02-09T21:18:17.067571Z",
     "iopub.status.idle": "2026-02-09T21:18:17.070795Z",
     "shell.execute_reply": "2026-02-09T21:18:17.070399Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Step 1: Generating synthetic Maxwell relaxation data...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# True parameters\n",
    "G0_true = 1e5  # Pa\n",
    "eta_true = 1e3  # Pa·s\n",
    "tau_true = eta_true / G0_true  # 0.01 s\n",
    "\n",
    "print(f\"  True parameters:\")\n",
    "print(f\"    G₀  = {G0_true:.2e} Pa\")\n",
    "print(f\"    η   = {eta_true:.2e} Pa·s\")\n",
    "print(f\"    τ   = {tau_true:.4f} s\")\n",
    "\n",
    "# Time array (log-spaced for relaxation)\n",
    "t = np.logspace(-2, 2, 50)  # 0.01 to 100 seconds\n",
    "\n",
    "# True relaxation modulus\n",
    "G_t_true = G0_true * np.exp(-t / tau_true)\n",
    "\n",
    "# Add realistic noise (1.5% relative)\n",
    "np.random.seed(42)\n",
    "noise_level = 0.015\n",
    "noise = np.random.normal(0, noise_level * G_t_true)\n",
    "G_t_noisy = G_t_true + noise\n",
    "\n",
    "print(f\"\\n  Generated {len(t)} data points from {t.min():.2e} to {t.max():.1f} s\")\n",
    "print(f\"  Noise level: {noise_level*100:.1f}% relative\")\n",
    "print(f\"  Signal-to-noise ratio: {np.mean(G_t_true)/np.std(noise):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: NLSQ Point Estimation (Fast)\n",
    "\n",
    "First, we obtain fast point estimates using nonlinear least squares optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:17.071937Z",
     "iopub.status.busy": "2026-02-09T21:18:17.071849Z",
     "iopub.status.idle": "2026-02-09T21:18:18.301321Z",
     "shell.execute_reply": "2026-02-09T21:18:18.300743Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STAGE 1: NLSQ POINT ESTIMATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model = Maxwell()\n",
    "model.parameters.set_bounds('G0', (1e3, 1e7))\n",
    "model.parameters.set_bounds('eta', (1e1, 1e5))\n",
    "\n",
    "print(\"\\nRunning NLSQ optimization...\")\n",
    "import time\n",
    "\n",
    "start_nlsq = time.time()\n",
    "\n",
    "model.fit(t, G_t_noisy, method='nlsq')\n",
    "\n",
    "nlsq_time = time.time() - start_nlsq\n",
    "\n",
    "# Extract NLSQ results\n",
    "G0_nlsq = model.parameters.get_value('G0')\n",
    "eta_nlsq = model.parameters.get_value('eta')\n",
    "tau_nlsq = eta_nlsq / G0_nlsq\n",
    "\n",
    "print(f\"\\n✓ NLSQ completed in {nlsq_time:.3f} seconds\")\n",
    "print(f\"\\nNLSQ Point Estimates:\")\n",
    "print(f\"  G₀  = {G0_nlsq:.4e} Pa  (error: {abs(G0_nlsq-G0_true)/G0_true*100:.2f}%)\")\n",
    "print(f\"  η   = {eta_nlsq:.4e} Pa·s  (error: {abs(eta_nlsq-eta_true)/eta_true*100:.2f}%)\")\n",
    "print(f\"  τ   = {tau_nlsq:.6f} s  (error: {abs(tau_nlsq-tau_true)/tau_true*100:.2f}%)\")\n",
    "print(f\"\\n⚠  Note: NLSQ provides point estimates only (no uncertainty)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Bayesian Inference with Warm-Start\n",
    "\n",
    "Now we perform MCMC sampling using NUTS, warm-starting from the NLSQ estimates for faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:18.302802Z",
     "iopub.status.busy": "2026-02-09T21:18:18.302688Z",
     "iopub.status.idle": "2026-02-09T21:18:25.889912Z",
     "shell.execute_reply": "2026-02-09T21:18:25.889474Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STAGE 2: BAYESIAN INFERENCE (NUTS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nRunning NUTS sampling with NLSQ warm-start...\")\n",
    "print(\"  Configuration:\")\n",
    "print(f\"    • num_chains: 4 (for robust diagnostics)\")\n",
    "print(f\"    • num_warmup: 1000 (burn-in iterations)\")\n",
    "print(f\"    • num_samples: 2000 (posterior samples per chain)\")\n",
    "print(f\"    • warm-start: Yes (from NLSQ estimates)\")\n",
    "print(\"\\n  This may take 20-60 seconds depending on your hardware...\")\n",
    "\n",
    "start_bayes = time.time()\n",
    "\n",
    "# Run Bayesian inference with warm-start\n",
    "result = model.fit_bayesian(\n",
    "    t, G_t_noisy,\n",
    "    num_warmup=1000,\n",
    "    num_samples=2000,\n",
    "    num_chains=4,\n",
    "    initial_values={  # Warm-start from NLSQ\n",
    "        'G0': G0_nlsq,\n",
    "        'eta': eta_nlsq\n",
    "    }\n",
    ")\n",
    "\n",
    "bayes_time = time.time() - start_bayes\n",
    "\n",
    "print(f\"\\n✓ Bayesian inference completed in {bayes_time:.1f} seconds\")\n",
    "print(f\"  Total time (NLSQ + Bayes): {nlsq_time + bayes_time:.1f} seconds\")\n",
    "print(f\"  Generated {result.num_chains * result.num_samples} posterior samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Results\n",
    "\n",
    "Extract and display the posterior summary statistics and credible intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:25.891602Z",
     "iopub.status.busy": "2026-02-09T21:18:25.891490Z",
     "iopub.status.idle": "2026-02-09T21:18:25.895797Z",
     "shell.execute_reply": "2026-02-09T21:18:25.895353Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"POSTERIOR RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "posterior = result.posterior_samples\n",
    "summary = result.summary\n",
    "\n",
    "print(\"\\nPosterior Estimates (mean ± std):\")\n",
    "print(f\"  G₀  = {summary['G0']['mean']:.4e} ± {summary['G0']['std']:.4e} Pa\")\n",
    "print(f\"  η   = {summary['eta']['mean']:.4e} ± {summary['eta']['std']:.4e} Pa·s\")\n",
    "\n",
    "# Compute credible intervals\n",
    "intervals = model.get_credible_intervals(posterior, credibility=0.95)\n",
    "print(\"\\n95% Credible Intervals:\")\n",
    "print(f\"  G₀:  [{intervals['G0'][0]:.4e}, {intervals['G0'][1]:.4e}] Pa\")\n",
    "print(f\"  η:   [{intervals['eta'][0]:.4e}, {intervals['eta'][1]:.4e}] Pa·s\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  'There is 95% probability that G₀ lies in the interval above'\")\n",
    "print(\"  This is a DIRECT probabilistic statement (Bayesian interpretation)\")\n",
    "\n",
    "# Relative uncertainties\n",
    "print(\"\\nRelative Uncertainties:\")\n",
    "print(f\"  G₀:  {summary['G0']['std']/summary['G0']['mean']*100:.2f}%\")\n",
    "print(f\"  η:   {summary['eta']['std']/summary['eta']['mean']*100:.2f}%\")\n",
    "\n",
    "# Check if true values are in credible intervals\n",
    "G0_in_CI = intervals['G0'][0] <= G0_true <= intervals['G0'][1]\n",
    "eta_in_CI = intervals['eta'][0] <= eta_true <= intervals['eta'][1]\n",
    "print(\"\\nValidation (true values in 95% CI):\")\n",
    "print(f\"  G₀:  {'✓ Yes' if G0_in_CI else '✗ No'}\")\n",
    "print(f\"  η:   {'✓ Yes' if eta_in_CI else '✗ No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Convergence Diagnostics (CRITICAL!)\n",
    "\n",
    "**Always check convergence before interpreting Bayesian results!**\n",
    "\n",
    "We examine:\n",
    "- **R-hat (Gelman-Rubin)**: Should be < 1.01 for all parameters\n",
    "- **ESS (Effective Sample Size)**: Should be > 400 for reliable inference\n",
    "- **Divergences**: Should be < 1% of total samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:25.897038Z",
     "iopub.status.busy": "2026-02-09T21:18:25.896954Z",
     "iopub.status.idle": "2026-02-09T21:18:25.901248Z",
     "shell.execute_reply": "2026-02-09T21:18:25.900797Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STAGE 3: CONVERGENCE DIAGNOSTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "diagnostics = result.diagnostics\n",
    "\n",
    "print(\"\\n⚠  ALWAYS check convergence before interpreting Bayesian results!\")\n",
    "print(\"\\n1. R-hat (Gelman-Rubin Statistic):\")\n",
    "print(f\"   Target: < 1.01 for all parameters\")\n",
    "for param in ['G0', 'eta']:\n",
    "    rhat = diagnostics['r_hat'][param]\n",
    "    status = '✓ Converged' if rhat < 1.01 else '✗ NOT converged'\n",
    "    print(f\"     {param:<5} R-hat = {rhat:.4f}  {status}\")\n",
    "\n",
    "print(\"\\n2. ESS (Effective Sample Size):\")\n",
    "print(f\"   Target: > 400 (out of {result.num_chains * result.num_samples} total)\")\n",
    "for param in ['G0', 'eta']:\n",
    "    ess = diagnostics['ess'][param]\n",
    "    efficiency = ess / (result.num_chains * result.num_samples) * 100\n",
    "    status = '✓ Sufficient' if ess > 400 else '✗ Low (increase samples)'\n",
    "    print(f\"     {param:<5} ESS = {ess:.0f} ({efficiency:.1f}% efficient)  {status}\")\n",
    "\n",
    "if 'num_divergences' in diagnostics:\n",
    "    div_rate = diagnostics['num_divergences'] / (result.num_chains * result.num_samples) * 100\n",
    "    print(\"\\n3. Divergences:\")\n",
    "    print(f\"   Count: {diagnostics['num_divergences']} ({div_rate:.2f}%)\")\n",
    "    status = '✓ Good' if div_rate < 1 else '✗ High (results unreliable)'\n",
    "    print(f\"   Target: < 1%  {status}\")\n",
    "\n",
    "# Overall convergence assessment\n",
    "all_converged = (\n",
    "    all(diagnostics['r_hat'][p] < 1.01 for p in ['G0', 'eta']) and\n",
    "    all(diagnostics['ess'][p] > 400 for p in ['G0', 'eta'])\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "if all_converged:\n",
    "    print(\"✓✓✓ EXCELLENT CONVERGENCE ✓✓✓\")\n",
    "    print(\"All diagnostic criteria met. Results are reliable.\")\n",
    "else:\n",
    "    print(\"⚠⚠⚠ CONVERGENCE ISSUES ⚠⚠⚠\")\n",
    "    print(\"Increase num_warmup or num_samples and rerun.\")\n",
    "print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Diagnostics (ArviZ Integration)\n",
    "\n",
    "ArviZ provides comprehensive diagnostic visualizations. We'll generate 6 key plots:\n",
    "\n",
    "1. **Trace plot**: Visual convergence check\n",
    "2. **Rank plot**: Most sensitive convergence test\n",
    "3. **Pair plot**: Parameter correlations + divergences\n",
    "4. **Autocorrelation plot**: Mixing quality\n",
    "5. **ESS plot**: Sampling efficiency\n",
    "6. **Forest plot**: Credible interval comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:25.902625Z",
     "iopub.status.busy": "2026-02-09T21:18:25.902520Z",
     "iopub.status.idle": "2026-02-09T21:18:26.690085Z",
     "shell.execute_reply": "2026-02-09T21:18:26.689367Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VISUAL DIAGNOSTICS (ArviZ Integration)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nGenerating diagnostic plots...\")\n",
    "\n",
    "# Convert to ArviZ InferenceData\n",
    "\n",
    "idata = result.to_inference_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:26.691822Z",
     "iopub.status.busy": "2026-02-09T21:18:26.691608Z",
     "iopub.status.idle": "2026-02-09T21:18:27.357037Z",
     "shell.execute_reply": "2026-02-09T21:18:27.356637Z"
    }
   },
   "outputs": [],
   "source": [
    "# ArviZ diagnostic plots (trace, pair, forest, energy, autocorr, rank)\n",
    "display_arviz_diagnostics(result, ['G0', 'eta'], fast_mode=FAST_MODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Summary\n",
    "\n",
    "Recap of the complete 3-stage workflow and key results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T21:18:27.358305Z",
     "iopub.status.busy": "2026-02-09T21:18:27.358212Z",
     "iopub.status.idle": "2026-02-09T21:18:27.360990Z",
     "shell.execute_reply": "2026-02-09T21:18:27.360634Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WORKFLOW SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n✓ Completed 3-stage Bayesian workflow:\")\n",
    "print(f\"  [1] NLSQ point estimation:      {nlsq_time:.2f}s\")\n",
    "print(f\"  [2] NUTS posterior sampling:     {bayes_time:.1f}s (warm-start)\")\n",
    "print(f\"  [3] ArviZ diagnostic plots:      6 plots generated\")\n",
    "\n",
    "print(f\"\\n✓ Convergence assessment:\")\n",
    "if all_converged:\n",
    "    print(\"  • All parameters converged (R-hat < 1.01, ESS > 400)\")\n",
    "    print(\"  • Results are reliable and can be interpreted\")\n",
    "else:\n",
    "    print(\"  • ⚠ Convergence issues detected\")\n",
    "    print(\"  • Increase num_warmup or num_samples and rerun\")\n",
    "\n",
    "print(f\"\\n✓ Uncertainty quantification:\")\n",
    "print(f\"  • G₀ uncertainty: ±{summary['G0']['std']/summary['G0']['mean']*100:.1f}%\")\n",
    "print(f\"  • η uncertainty:  ±{summary['eta']['std']/summary['eta']['mean']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Apply this workflow to your own rheological data\n",
    "2. Try different models (20 models available)\n",
    "3. Explore tutorial notebooks in `examples/bayesian/`:\n",
    "   - `01-bayesian-basics.ipynb` (40 min)\n",
    "   - `02-prior-selection.ipynb` (35 min)\n",
    "   - `03-convergence-diagnostics.ipynb` (45 min)\n",
    "   - `04-model-comparison.ipynb` (40 min)\n",
    "   - `05-uncertainty-propagation.ipynb` (45 min)\n",
    "\n",
    "4. Read documentation:\n",
    "   - `docs/BAYESIAN_QUICK_START.md`\n",
    "   - `docs/BAYESIAN_WORKFLOW_SUMMARY.md`\n",
    "\n",
    "**For questions or issues:**\n",
    "- GitHub: https://github.com/imewei/rheojax\n",
    "- Docs: https://rheojax.readthedocs.io"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rheojax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
