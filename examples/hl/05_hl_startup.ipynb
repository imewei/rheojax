{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
   "metadata": {},
   "source": [
    "# HL Startup Shear: Stress Overshoot and Transient Dynamics\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Understand stress overshoot in startup shear flow\n",
    "2. Generate synthetic startup data from calibrated HL parameters\n",
    "3. Extract the microscopic timescale τ from transient dynamics\n",
    "4. Analyze peak stress and peak time as functions of shear rate\n",
    "5. Compare transient vs steady-state behavior\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- HL flow curve tutorial (hl/01_hl_flow_curve.ipynb) — parameters calibrated there\n",
    "- Bayesian inference fundamentals (bayesian/01-bayesian-basics.ipynb)\n",
    "\n",
    "## Runtime\n",
    "\n",
    "- Fast demo (NUM_CHAINS=1, NUM_SAMPLES=500): ~2-3 minutes\n",
    "- Full run (NUM_CHAINS=4, NUM_SAMPLES=2000): ~8-12 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5-f6a7-8901-bcde-f12345678901",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6-a7b8-9012-cdef-123456789012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:32.181861Z",
     "iopub.status.busy": "2026-02-09T06:06:32.181782Z",
     "iopub.status.idle": "2026-02-09T06:06:32.185154Z",
     "shell.execute_reply": "2026-02-09T06:06:32.184646Z"
    }
   },
   "outputs": [],
   "source": [
    "# Google Colab setup\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    %pip install -q rheojax\n",
    "    import os\n",
    "    os.environ[\"JAX_ENABLE_X64\"] = \"true\"\n",
    "    print(\"RheoJAX installed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-b8c9-0123-def0-234567890123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:32.186557Z",
     "iopub.status.busy": "2026-02-09T06:06:32.186461Z",
     "iopub.status.idle": "2026-02-09T06:06:33.885447Z",
     "shell.execute_reply": "2026-02-09T06:06:33.885067Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from rheojax.core.jax_config import safe_import_jax, verify_float64\n",
    "from rheojax.models.hl import HebraudLequeux\n",
    "\n",
    "jax, jnp = safe_import_jax()\n",
    "verify_float64()\n",
    "\n",
    "FAST_MODE = os.environ.get(\"FAST_MODE\", \"1\") == \"1\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*jit.*|.*tracer.*\", category=FutureWarning)\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"Devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-c9d0-1234-ef01-345678901234",
   "metadata": {},
   "source": [
    "## 2. Theory: Startup Shear in HL\n",
    "\n",
    "In startup shear, a constant shear rate γ̇ is suddenly applied at t = 0, and the stress σ(t) evolves from zero toward steady state.\n",
    "\n",
    "### Key Physics\n",
    "\n",
    "**Stress overshoot**: A characteristic feature of yield-stress fluids:\n",
    "1. **Elastic loading** (t << τ): σ(t) ≈ G·γ̇·t (linear growth)\n",
    "2. **Peak stress** (t ≈ τ): Maximum stress σ_peak at peak time t_peak\n",
    "3. **Yielding** (t > t_peak): Stress decreases as blocks yield\n",
    "4. **Steady state** (t >> τ): σ → σ_ss (flow curve value)\n",
    "\n",
    "### HL Predictions\n",
    "\n",
    "The stress overshoot magnitude depends on:\n",
    "- **Shear rate γ̇**: Higher rates → larger overshoot\n",
    "- **α parameter**: Lower α → more pronounced overshoot (more elastic)\n",
    "- **τ**: Sets the peak time t_peak ≈ τ\n",
    "\n",
    "### Overshoot Metrics\n",
    "\n",
    "$$\n",
    "\\text{Overshoot ratio} = \\frac{\\sigma_{peak}}{\\sigma_{ss}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Peak strain} = \\gamma_{peak} = \\dot{\\gamma} \\cdot t_{peak}\n",
    "$$\n",
    "\n",
    "For HL, γ_peak ≈ O(1) (strain of order unity at yielding)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9-d0e1-2345-f012-456789012345",
   "metadata": {},
   "source": [
    "## 3. Load Calibrated Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0-e1f2-3456-0123-567890123456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:33.886874Z",
     "iopub.status.busy": "2026-02-09T06:06:33.886704Z",
     "iopub.status.idle": "2026-02-09T06:06:33.889619Z",
     "shell.execute_reply": "2026-02-09T06:06:33.889241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Try to load calibrated parameters from NB 01\n",
    "params_file = os.path.join(\"..\", \"outputs\", \"hl\", \"flow_curve\", \"nlsq_params_flow_curve.json\")\n",
    "\n",
    "if os.path.exists(params_file):\n",
    "    with open(params_file) as f:\n",
    "        calibrated_params = json.load(f)\n",
    "    print(\"Loaded calibrated parameters from flow curve:\")\n",
    "else:\n",
    "    # Fallback: use typical glass-phase parameters\n",
    "    calibrated_params = {\n",
    "        \"alpha\": 0.3,\n",
    "        \"tau\": 1.0,\n",
    "        \"sigma_c\": 100.0,\n",
    "    }\n",
    "    print(\"Using default glass-phase parameters:\")\n",
    "\n",
    "for name, val in calibrated_params.items():\n",
    "    print(f\"  {name:8s} = {val:.4g}\")\n",
    "\n",
    "phase = \"glass\" if calibrated_params[\"alpha\"] < 0.5 else \"fluid\"\n",
    "print(f\"\\nPhase: {phase}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2-a3b4-5678-2345-789012345678",
   "metadata": {},
   "source": [
    "## 4. Generate Synthetic Startup Data\n",
    "\n",
    "We use the HL model to generate startup stress transients at different shear rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3-b4c5-6789-3456-890123456789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:33.890908Z",
     "iopub.status.busy": "2026-02-09T06:06:33.890819Z",
     "iopub.status.idle": "2026-02-09T06:06:34.133236Z",
     "shell.execute_reply": "2026-02-09T06:06:34.132798Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create HL model with calibrated parameters\n",
    "model = HebraudLequeux()\n",
    "model.parameters.set_value(\"alpha\", calibrated_params[\"alpha\"])\n",
    "model.parameters.set_value(\"tau\", calibrated_params[\"tau\"])\n",
    "model.parameters.set_value(\"sigma_c\", calibrated_params[\"sigma_c\"])\n",
    "\n",
    "# Generate startup data at multiple shear rates\n",
    "gamma_dot_values = [0.1, 1.0, 10.0]\n",
    "t_end = 20.0  # Enough time for steady state\n",
    "n_points = 200\n",
    "time_data = np.linspace(0.01, t_end, n_points)\n",
    "\n",
    "startup_data = {}\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Use direct predict instead of fit(max_iter=1) to avoid expensive NLSQ JIT compilation\n",
    "for gamma_dot in gamma_dot_values:\n",
    "    # Set internal state for prediction (avoids NLSQ overhead)\n",
    "    model._test_mode = \"startup\"\n",
    "    model._last_fit_kwargs = {\"gdot\": gamma_dot}\n",
    "    \n",
    "    # Predict using PDE solver directly\n",
    "    stress_clean = model.predict(time_data)\n",
    "    \n",
    "    # Add noise (3%)\n",
    "    noise = rng.normal(0, 0.03 * np.mean(np.abs(stress_clean)), size=stress_clean.shape)\n",
    "    stress = stress_clean + noise\n",
    "    \n",
    "    startup_data[gamma_dot] = {\n",
    "        \"time\": time_data.copy(),\n",
    "        \"stress\": stress,\n",
    "        \"stress_clean\": stress_clean,\n",
    "    }\n",
    "    print(f\"γ̇={gamma_dot:5.1f}: Generated {n_points} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4-c5d6-7890-4567-901234567890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:34.134725Z",
     "iopub.status.busy": "2026-02-09T06:06:34.134627Z",
     "iopub.status.idle": "2026-02-09T06:06:34.248686Z",
     "shell.execute_reply": "2026-02-09T06:06:34.248111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot startup transients\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(gamma_dot_values)))\n",
    "\n",
    "for i, gamma_dot in enumerate(gamma_dot_values):\n",
    "    d = startup_data[gamma_dot]\n",
    "    ax1.plot(d[\"time\"], d[\"stress\"], \"o\", markersize=2, color=colors[i], alpha=0.5)\n",
    "    ax1.plot(d[\"time\"], d[\"stress_clean\"], \"-\", lw=2, color=colors[i], label=f\"γ̇={gamma_dot}\")\n",
    "\n",
    "ax1.set_xlabel(\"Time [s]\")\n",
    "ax1.set_ylabel(\"Stress [Pa]\")\n",
    "ax1.set_title(f\"Startup Transients (α={calibrated_params['alpha']:.2f})\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot stress vs strain\n",
    "for i, gamma_dot in enumerate(gamma_dot_values):\n",
    "    d = startup_data[gamma_dot]\n",
    "    strain = gamma_dot * d[\"time\"]\n",
    "    ax2.plot(strain, d[\"stress_clean\"], \"-\", lw=2, color=colors[i], label=f\"γ̇={gamma_dot}\")\n",
    "\n",
    "ax2.axvline(1.0, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"γ = 1 (yield strain)\")\n",
    "ax2.set_xlabel(\"Strain γ [-]\")\n",
    "ax2.set_ylabel(\"Stress [Pa]\")\n",
    "ax2.set_title(\"Stress vs Strain\")\n",
    "ax2.set_xlim(0, 10)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b4c5-d6e7-8901-5678-012345678901",
   "metadata": {},
   "source": [
    "## 5. Analyze Stress Overshoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6-e7f8-9012-6789-123456789012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:34.250299Z",
     "iopub.status.busy": "2026-02-09T06:06:34.250201Z",
     "iopub.status.idle": "2026-02-09T06:06:34.253332Z",
     "shell.execute_reply": "2026-02-09T06:06:34.252946Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract overshoot metrics\n",
    "overshoot_results = {}\n",
    "\n",
    "print(f\"{'γ̇':>8s}  {'t_peak':>8s}  {'σ_peak':>10s}  {'σ_ss':>10s}  {'Overshoot':>10s}  {'γ_peak':>8s}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for gamma_dot in gamma_dot_values:\n",
    "    d = startup_data[gamma_dot]\n",
    "    stress = d[\"stress_clean\"]\n",
    "    t_arr = d[\"time\"]\n",
    "    \n",
    "    # Find peak\n",
    "    peak_idx = np.argmax(stress)\n",
    "    t_peak = t_arr[peak_idx]\n",
    "    sigma_peak = stress[peak_idx]\n",
    "    \n",
    "    # Steady state (last 20% of data)\n",
    "    sigma_ss = np.mean(stress[-40:])\n",
    "    \n",
    "    # Overshoot ratio\n",
    "    overshoot = sigma_peak / sigma_ss if sigma_ss > 0 else np.nan\n",
    "    \n",
    "    # Peak strain\n",
    "    gamma_peak = gamma_dot * t_peak\n",
    "    \n",
    "    overshoot_results[gamma_dot] = {\n",
    "        \"t_peak\": t_peak,\n",
    "        \"sigma_peak\": sigma_peak,\n",
    "        \"sigma_ss\": sigma_ss,\n",
    "        \"overshoot\": overshoot,\n",
    "        \"gamma_peak\": gamma_peak,\n",
    "    }\n",
    "    \n",
    "    print(f\"{gamma_dot:8.1f}  {t_peak:8.2f}  {sigma_peak:10.2f}  {sigma_ss:10.2f}  {overshoot:10.2f}  {gamma_peak:8.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5d6e7-f8a9-0123-7890-234567890123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:34.255163Z",
     "iopub.status.busy": "2026-02-09T06:06:34.255053Z",
     "iopub.status.idle": "2026-02-09T06:06:34.549183Z",
     "shell.execute_reply": "2026-02-09T06:06:34.548607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot overshoot trends\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "gdots = list(overshoot_results.keys())\n",
    "t_peaks = [overshoot_results[g][\"t_peak\"] for g in gdots]\n",
    "overshoots = [overshoot_results[g][\"overshoot\"] for g in gdots]\n",
    "gamma_peaks = [overshoot_results[g][\"gamma_peak\"] for g in gdots]\n",
    "\n",
    "# Peak time vs shear rate\n",
    "ax1.loglog(gdots, t_peaks, \"o-\", markersize=10, lw=2)\n",
    "ax1.axhline(calibrated_params[\"tau\"], color=\"red\", linestyle=\"--\", label=f\"τ = {calibrated_params['tau']:.1f}\")\n",
    "ax1.set_xlabel(\"Shear rate γ̇ [1/s]\")\n",
    "ax1.set_ylabel(\"Peak time t_peak [s]\")\n",
    "ax1.set_title(\"Peak Time vs Shear Rate\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, which=\"both\")\n",
    "\n",
    "# Overshoot ratio vs shear rate\n",
    "ax2.semilogx(gdots, overshoots, \"s-\", markersize=10, lw=2, color=\"C1\")\n",
    "ax2.axhline(1.0, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "ax2.set_xlabel(\"Shear rate γ̇ [1/s]\")\n",
    "ax2.set_ylabel(\"Overshoot ratio σ_peak/σ_ss\")\n",
    "ax2.set_title(\"Overshoot Magnitude\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Peak strain (should be ~constant for HL)\n",
    "ax3.semilogx(gdots, gamma_peaks, \"^-\", markersize=10, lw=2, color=\"C2\")\n",
    "ax3.axhline(1.0, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"γ = 1\")\n",
    "ax3.set_xlabel(\"Shear rate γ̇ [1/s]\")\n",
    "ax3.set_ylabel(\"Peak strain γ_peak [-]\")\n",
    "ax3.set_title(\"Peak Strain (Yield Strain)\")\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0c1d2-e3f4-5678-2345-789012345678",
   "metadata": {},
   "source": [
    "## 6. NLSQ Fitting\n",
    "\n",
    "Fit the HL model to recover parameters from a startup transient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1d2e3-f4a5-6789-3456-890123456789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:34.550586Z",
     "iopub.status.busy": "2026-02-09T06:06:34.550473Z",
     "iopub.status.idle": "2026-02-09T06:06:35.961374Z",
     "shell.execute_reply": "2026-02-09T06:06:35.960959Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "jax.clear_caches()\n",
    "\n",
    "# Fit to γ̇ = 1.0 data\n",
    "gamma_dot_fit = 1.0\n",
    "d_fit = startup_data[gamma_dot_fit]\n",
    "\n",
    "model_fit = HebraudLequeux()\n",
    "\n",
    "t0 = time.time()\n",
    "model_fit.fit(d_fit[\"time\"], d_fit[\"stress\"], test_mode=\"startup\", gdot=gamma_dot_fit)\n",
    "t_nlsq = time.time() - t0\n",
    "\n",
    "print(f\"NLSQ fit time: {t_nlsq:.2f} s\")\n",
    "print(f\"\\nFitted parameters:\")\n",
    "for name in [\"alpha\", \"tau\", \"sigma_c\"]:\n",
    "    fitted = model_fit.parameters.get_value(name)\n",
    "    true = calibrated_params[name]\n",
    "    print(f\"  {name:8s} = {fitted:.4g} (true: {true:.4g})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3-b4c5-6789-3456-890123456790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:35.962710Z",
     "iopub.status.busy": "2026-02-09T06:06:35.962612Z",
     "iopub.status.idle": "2026-02-09T06:06:36.037643Z",
     "shell.execute_reply": "2026-02-09T06:06:36.037111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot fit\n",
    "stress_pred = model_fit.predict(d_fit[\"time\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(d_fit[\"time\"], d_fit[\"stress\"], \"ko\", markersize=4, alpha=0.5, label=\"Data\")\n",
    "ax.plot(d_fit[\"time\"], stress_pred, \"-\", lw=2, color=\"C0\", label=\"HL fit\")\n",
    "ax.plot(d_fit[\"time\"], d_fit[\"stress_clean\"], \"--\", lw=1, color=\"C2\", alpha=0.7, label=\"True (no noise)\")\n",
    "\n",
    "ax.set_xlabel(\"Time [s]\")\n",
    "ax.set_ylabel(\"Stress [Pa]\")\n",
    "ax.set_title(f\"Startup Fit: γ̇={gamma_dot_fit}\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4-a5b6-7890-4567-901234567890",
   "metadata": {},
   "source": [
    "## 7. Bayesian Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3f4a5-b6c7-8901-5678-012345678901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:36.038981Z",
     "iopub.status.busy": "2026-02-09T06:06:36.038880Z",
     "iopub.status.idle": "2026-02-09T06:06:36.131942Z",
     "shell.execute_reply": "2026-02-09T06:06:36.131404Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "jax.clear_caches()\n",
    "\n",
    "# Bayesian inference with NLSQ warm-start\n",
    "# NOTE: HL startup NUTS with PDE solver is expensive. Skip in FAST_MODE.\n",
    "if not FAST_MODE:\n",
    "    initial_values = {\n",
    "        name: model_fit.parameters.get_value(name)\n",
    "        for name in [\"alpha\", \"tau\", \"sigma_c\"]\n",
    "    }\n",
    "    print(\"Warm-start values:\", initial_values)\n",
    "\n",
    "    NUM_WARMUP = 200\n",
    "    NUM_SAMPLES = 500\n",
    "    NUM_CHAINS = 1\n",
    "\n",
    "    t0 = time.time()\n",
    "    result = model_fit.fit_bayesian(\n",
    "        d_fit[\"time\"],\n",
    "        d_fit[\"stress\"],\n",
    "        test_mode=\"startup\",\n",
    "        gdot=gamma_dot_fit,\n",
    "        num_warmup=NUM_WARMUP,\n",
    "        num_samples=NUM_SAMPLES,\n",
    "        num_chains=NUM_CHAINS,\n",
    "        initial_values=initial_values,\n",
    "        seed=42,\n",
    "        max_tree_depth=5,\n",
    "    )\n",
    "    t_bayes = time.time() - t0\n",
    "    print(f\"\\nBayesian inference time: {t_bayes:.1f} s\")\n",
    "else:\n",
    "    result = None\n",
    "    print(\"Skipping NUTS in FAST_MODE (HL startup PDE solver too expensive)\")\n",
    "    print(\"Set FAST_MODE=0 for full Bayesian analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5b6c7-d8e9-0123-7890-234567890123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:36.133199Z",
     "iopub.status.busy": "2026-02-09T06:06:36.133074Z",
     "iopub.status.idle": "2026-02-09T06:06:36.136020Z",
     "shell.execute_reply": "2026-02-09T06:06:36.135562Z"
    }
   },
   "outputs": [],
   "source": [
    "if result is not None:\n",
    "    # Convergence diagnostics\n",
    "    diag = result.diagnostics\n",
    "    param_names = [\"alpha\", \"tau\", \"sigma_c\"]\n",
    "\n",
    "    print(\"Convergence Diagnostics\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"{'Parameter':>10s}  {'R-hat':>8s}  {'ESS':>8s}\")\n",
    "    print(\"-\" * 50)\n",
    "    for p in param_names:\n",
    "        r_hat = diag.get(\"r_hat\", {}).get(p, float(\"nan\"))\n",
    "        ess = diag.get(\"ess\", {}).get(p, float(\"nan\"))\n",
    "        print(f\"{p:>10s}  {r_hat:8.4f}  {ess:8.0f}\")\n",
    "\n",
    "    n_div = diag.get(\"divergences\", diag.get(\"num_divergences\", 0))\n",
    "    print(f\"\\nDivergences: {n_div}\")\n",
    "else:\n",
    "    print(\"Skipped (no Bayesian result in FAST_MODE)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6c7d8-e9f0-1234-8901-345678901234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:36.137348Z",
     "iopub.status.busy": "2026-02-09T06:06:36.137238Z",
     "iopub.status.idle": "2026-02-09T06:06:36.140004Z",
     "shell.execute_reply": "2026-02-09T06:06:36.139521Z"
    }
   },
   "outputs": [],
   "source": [
    "if result is not None:\n",
    "    # Glass probability\n",
    "    posterior = result.posterior_samples\n",
    "    alpha_samples = np.array(posterior[\"alpha\"])\n",
    "\n",
    "    p_glass = np.mean(alpha_samples < 0.5)\n",
    "    print(f\"P(glass) = P(α < 0.5) = {p_glass:.1%}\")\n",
    "\n",
    "    # τ estimation quality\n",
    "    tau_samples = np.array(posterior[\"tau\"])\n",
    "    tau_median = np.median(tau_samples)\n",
    "    tau_lo = np.percentile(tau_samples, 2.5)\n",
    "    tau_hi = np.percentile(tau_samples, 97.5)\n",
    "    print(f\"τ estimate: {tau_median:.3f} [{tau_lo:.3f}, {tau_hi:.3f}] (true: {calibrated_params['tau']:.3f})\")\n",
    "else:\n",
    "    print(\"Skipped (no Bayesian result in FAST_MODE)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7d8e9-f0a1-2345-9012-456789012345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:36.141292Z",
     "iopub.status.busy": "2026-02-09T06:06:36.141193Z",
     "iopub.status.idle": "2026-02-09T06:06:36.144233Z",
     "shell.execute_reply": "2026-02-09T06:06:36.143907Z"
    }
   },
   "outputs": [],
   "source": [
    "if result is not None:\n",
    "    # Plot posterior for τ (key parameter from startup)\n",
    "    posterior = result.posterior_samples\n",
    "    alpha_samples = np.array(posterior[\"alpha\"])\n",
    "    tau_samples = np.array(posterior[\"tau\"])\n",
    "    tau_median = np.median(tau_samples)\n",
    "    p_glass = np.mean(alpha_samples < 0.5)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # α posterior\n",
    "    ax1.hist(alpha_samples, bins=50, density=True, alpha=0.7, color=\"C0\", edgecolor=\"black\")\n",
    "    ax1.axvline(0.5, color=\"red\", linestyle=\"--\", linewidth=2, label=\"Glass transition\")\n",
    "    ax1.axvline(calibrated_params[\"alpha\"], color=\"green\", linestyle=\"-\", linewidth=2, label=f\"True α\")\n",
    "    ax1.set_xlabel(\"α\")\n",
    "    ax1.set_ylabel(\"Posterior density\")\n",
    "    ax1.set_title(f\"Phase Classification: P(glass) = {p_glass:.1%}\")\n",
    "    ax1.legend()\n",
    "    ax1.set_xlim(0, 1)\n",
    "\n",
    "    # τ posterior (key insight from startup)\n",
    "    ax2.hist(tau_samples, bins=50, density=True, alpha=0.7, color=\"C1\", edgecolor=\"black\")\n",
    "    ax2.axvline(calibrated_params[\"tau\"], color=\"green\", linestyle=\"-\", linewidth=2, label=f\"True τ = {calibrated_params['tau']:.2f}\")\n",
    "    ax2.axvline(tau_median, color=\"C1\", linestyle=\"--\", linewidth=2, label=f\"Median τ = {tau_median:.2f}\")\n",
    "    ax2.set_xlabel(\"τ [s]\")\n",
    "    ax2.set_ylabel(\"Posterior density\")\n",
    "    ax2.set_title(\"τ Estimation from Startup Transient\")\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "else:\n",
    "    print(\"Skipped (no Bayesian result in FAST_MODE)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8e9f0-a1b2-3456-0123-567890123457",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:36.145579Z",
     "iopub.status.busy": "2026-02-09T06:06:36.145497Z",
     "iopub.status.idle": "2026-02-09T06:06:36.148155Z",
     "shell.execute_reply": "2026-02-09T06:06:36.147775Z"
    }
   },
   "outputs": [],
   "source": [
    "if result is not None:\n",
    "    # Parameter summary\n",
    "    posterior = result.posterior_samples\n",
    "    param_names = [\"alpha\", \"tau\", \"sigma_c\"]\n",
    "\n",
    "    print(\"Parameter Comparison: True vs Fitted\")\n",
    "    print(\"=\" * 65)\n",
    "    print(f\"{'Param':>10s}  {'True':>12s}  {'Median':>12s}  {'95% CI':>24s}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    for name in param_names:\n",
    "        true_val = calibrated_params[name]\n",
    "        samples = posterior[name]\n",
    "        median = np.median(samples)\n",
    "        lo = np.percentile(samples, 2.5)\n",
    "        hi = np.percentile(samples, 97.5)\n",
    "        print(f\"{name:>10s}  {true_val:12.4g}  {median:12.4g}  [{lo:.4g}, {hi:.4g}]\")\n",
    "else:\n",
    "    print(\"Skipped (no Bayesian result in FAST_MODE)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-e5f6-7891-4567-901234567890",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6-a7b8-9012-6789-123456789013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-09T06:06:36.149410Z",
     "iopub.status.busy": "2026-02-09T06:06:36.149337Z",
     "iopub.status.idle": "2026-02-09T06:06:36.229312Z",
     "shell.execute_reply": "2026-02-09T06:06:36.228906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_dir = os.path.join(\"..\", \"outputs\", \"hl\", \"startup\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save NLSQ point estimates (always)\n",
    "nlsq_params = {\n",
    "    name: float(model_fit.parameters.get_value(name))\n",
    "    for name in [\"alpha\", \"tau\", \"sigma_c\"]\n",
    "}\n",
    "with open(os.path.join(output_dir, \"nlsq_params_startup.json\"), \"w\") as f:\n",
    "    json.dump(nlsq_params, f, indent=2)\n",
    "\n",
    "# Save overshoot analysis (always)\n",
    "with open(os.path.join(output_dir, \"overshoot_analysis.json\"), \"w\") as f:\n",
    "    json.dump({str(k): v for k, v in overshoot_results.items()}, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {output_dir}/\")\n",
    "print(f\"  nlsq_params_startup.json: {len(nlsq_params)} parameters\")\n",
    "print(f\"  overshoot_analysis.json: {len(overshoot_results)} shear rates\")\n",
    "\n",
    "# Save posterior (only if Bayesian was run)\n",
    "if result is not None:\n",
    "    posterior = result.posterior_samples\n",
    "    posterior_dict = {k: np.array(v).tolist() for k, v in posterior.items()}\n",
    "    with open(os.path.join(output_dir, \"posterior_startup.json\"), \"w\") as f:\n",
    "        json.dump(posterior_dict, f)\n",
    "    print(f\"  posterior_startup.json: {len(posterior['alpha'])} draws\")\n",
    "else:\n",
    "    print(\"  Posterior not saved (FAST_MODE)\")\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7-b8c9-0123-7890-234567890124",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Stress overshoot** is a signature of yield-stress fluids in startup shear — the stress exceeds steady state before relaxing.\n",
    "\n",
    "2. **Peak time t_peak ≈ τ**: The transient dynamics directly reveal the microscopic timescale, making startup an excellent protocol for τ estimation.\n",
    "\n",
    "3. **Peak strain γ_peak ≈ O(1)**: Yielding occurs at strains of order unity, consistent with the yield strain interpretation.\n",
    "\n",
    "4. **Overshoot magnitude increases with γ̇**: Higher shear rates drive more stress buildup before yielding.\n",
    "\n",
    "5. **Startup vs flow curve**:\n",
    "   - Flow curve: Steady-state σ(γ̇) — good for α, σ_c\n",
    "   - Startup: Transient σ(t) at fixed γ̇ — excellent for τ\n",
    "   - Combine both for robust parameter estimation\n",
    "\n",
    "### Physical Interpretation\n",
    "\n",
    "| Observation | HL Interpretation |\n",
    "|-------------|-------------------|\n",
    "| Linear stress growth | Elastic loading, blocks accumulate stress |\n",
    "| Peak stress | Yielding onset, blocks start to flow |\n",
    "| Stress decay | Stress redistribution via mechanical noise |\n",
    "| Steady state | Balance of loading, yielding, and diffusion |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **NB 06**: LAOS (nonlinear oscillatory response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
