{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Workflows with Modular API\n",
    "\n",
    "This notebook demonstrates advanced rheological analysis workflows using rheo's modular API for fine-grained control.\n",
    "\n",
    "Topics covered:\n",
    "1. Direct model instantiation from ModelRegistry\n",
    "2. Custom optimization with constraints\n",
    "3. Multi-start optimization to avoid local minima\n",
    "4. Parameter sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from rheo.core.registry import ModelRegistry\n",
    "from rheo.core.data import RheoData\n",
    "from rheo.utils.optimization import nlsq_optimize\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Realistic Polymer Relaxation Data\n",
    "\n",
    "We'll simulate data from a fractional Maxwell model (gel variant) which exhibits power-law relaxation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate time vector\n",
    "time = np.logspace(-3, 2, 60)  # 0.001 to 100 seconds\n",
    "\n",
    "# True parameters for fractional Maxwell gel model\n",
    "c_alpha_true = 5e5  # Quasi-property (Pa·s^alpha)\n",
    "alpha_true = 0.4    # Fractional order\n",
    "eta_true = 1e4      # Viscosity (Pa·s)\n",
    "\n",
    "# Generate synthetic data using Mittag-Leffler function\n",
    "# G(t) = c_alpha * t^(-alpha) * E_{alpha}(-t^alpha / tau_alpha)\n",
    "# Simplified approximation for demonstration\n",
    "tau_alpha = eta_true / c_alpha_true\n",
    "stress_true = c_alpha_true * time**(-alpha_true) * np.exp(-(time / tau_alpha)**(alpha_true))\n",
    "\n",
    "# Add heteroscedastic noise (higher relative error at longer times)\n",
    "noise_level = 0.03 + 0.02 * (time / time.max())\n",
    "stress_noisy = stress_true * (1 + noise_level * np.random.randn(len(stress_true)))\n",
    "\n",
    "# Create RheoData object\n",
    "data = RheoData(\n",
    "    x=time,\n",
    "    y=stress_noisy,\n",
    "    x_units='s',\n",
    "    y_units='Pa',\n",
    "    domain='time',\n",
    "    test_mode='relaxation'\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(time)} data points\")\n",
    "print(f\"Time range: {time[0]:.3f} to {time[-1]:.1f} seconds\")\n",
    "print(f\"Stress range: {stress_noisy.min():.2e} to {stress_noisy.max():.2e} Pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.loglog(time, stress_noisy, 'o', label='Synthetic Data', alpha=0.6, markersize=5)\n",
    "plt.loglog(time, stress_true, '--', label='True Model', color='red', linewidth=2)\n",
    "plt.xlabel('Time (s)', fontsize=12)\n",
    "plt.ylabel('Stress Modulus G(t) (Pa)', fontsize=12)\n",
    "plt.title('Fractional Viscoelastic Relaxation Data', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Model Instantiation from ModelRegistry\n",
    "\n",
    "Instead of using the Pipeline API, we can directly create model instances for maximum control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance directly\n",
    "model = ModelRegistry.create('fractional_maxwell_gel')\n",
    "\n",
    "print(\"\\nModel Information:\")\n",
    "print(f\"  Name: {model.__class__.__name__}\")\n",
    "print(f\"  Number of parameters: {len(model.parameters)}\")\n",
    "print(f\"\\nDefault Parameters:\")\n",
    "for name, param in model.parameters.items():\n",
    "    print(f\"  {name}: {param.value:.3e} (bounds: {param.bounds})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Intelligent Initial Guesses\n",
    "\n",
    "Good initial guesses can significantly improve optimization convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate initial values from data characteristics\n",
    "G_initial = stress_noisy[0]  # Initial modulus\n",
    "G_final = stress_noisy[-1]    # Final modulus\n",
    "time_mid = time[len(time)//2]\n",
    "\n",
    "# Set initial parameter guesses\n",
    "model.parameters['c_alpha'].value = G_initial * 2  # Higher than initial stress\n",
    "model.parameters['alpha'].value = 0.5               # Middle of typical range\n",
    "model.parameters['eta'].value = 1e4                 # Typical viscosity scale\n",
    "\n",
    "print(\"\\nInitial Parameter Guesses:\")\n",
    "for name, param in model.parameters.items():\n",
    "    print(f\"  {name}: {param.value:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Optimization with Constraints\n",
    "\n",
    "We'll define a custom objective function and add physical constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(params_array):\n",
    "    \"\"\"\n",
    "    Objective function for optimization.\n",
    "    Returns sum of squared residuals (weighted by inverse variance).\n",
    "    \"\"\"\n",
    "    # Update model parameters\n",
    "    param_names = list(model.parameters.keys())\n",
    "    for i, name in enumerate(param_names):\n",
    "        model.parameters[name].value = params_array[i]\n",
    "    \n",
    "    # Get model predictions\n",
    "    predictions = model.predict(data)\n",
    "    \n",
    "    # Calculate weighted residuals (inverse variance weighting)\n",
    "    weights = 1.0 / (noise_level * stress_noisy)**2\n",
    "    residuals = (predictions - stress_noisy) * np.sqrt(weights)\n",
    "    \n",
    "    return np.sum(residuals**2)\n",
    "\n",
    "# Get initial parameter values and bounds\n",
    "initial_params = np.array([p.value for p in model.parameters.values()])\n",
    "bounds = [p.bounds for p in model.parameters.values()]\n",
    "\n",
    "print(f\"\\nOptimization Setup:\")\n",
    "print(f\"  Number of parameters: {len(initial_params)}\")\n",
    "print(f\"  Initial objective value: {objective_function(initial_params):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Physical Constraints\n",
    "\n",
    "We can add constraints to ensure physically meaningful results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constraints\n",
    "constraints = []\n",
    "\n",
    "# Constraint 1: alpha must be between 0 and 1\n",
    "# (This is already handled by parameter bounds)\n",
    "\n",
    "# Constraint 2: c_alpha should be reasonable relative to data scale\n",
    "def constraint_c_alpha(params):\n",
    "    c_alpha = params[0]\n",
    "    return c_alpha - stress_noisy.min() / 10  # c_alpha > G_min/10\n",
    "\n",
    "constraints.append({'type': 'ineq', 'fun': constraint_c_alpha})\n",
    "\n",
    "print(f\"Added {len(constraints)} custom constraints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize using scipy.optimize.minimize\n",
    "result = minimize(\n",
    "    objective_function,\n",
    "    initial_params,\n",
    "    method='L-BFGS-B',\n",
    "    bounds=bounds,\n",
    "    options={'maxiter': 1000, 'ftol': 1e-9}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTIMIZATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Message: {result.message}\")\n",
    "print(f\"Iterations: {result.nit}\")\n",
    "print(f\"Final objective value: {result.fun:.3e}\")\n",
    "print(f\"\\nOptimized Parameters:\")\n",
    "param_names = list(model.parameters.keys())\n",
    "for i, name in enumerate(param_names):\n",
    "    true_val = [c_alpha_true, alpha_true, eta_true][i]\n",
    "    print(f\"  {name}: {result.x[i]:.3e} (true: {true_val:.3e})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update model with optimized parameters\n",
    "for i, name in enumerate(param_names):\n",
    "    model.parameters[name].value = result.x[i]\n",
    "\n",
    "# Get optimized predictions\n",
    "predictions_opt = model.predict(data)\n",
    "\n",
    "# Plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Data and fit\n",
    "ax1.loglog(time, stress_noisy, 'o', label='Data', alpha=0.6, markersize=5)\n",
    "ax1.loglog(time, stress_true, '--', label='True Model', color='red', linewidth=2)\n",
    "ax1.loglog(time, predictions_opt, '-', label='Optimized Fit', color='green', linewidth=2)\n",
    "ax1.set_xlabel('Time (s)', fontsize=12)\n",
    "ax1.set_ylabel('Stress Modulus G(t) (Pa)', fontsize=12)\n",
    "ax1.set_title('Optimized Fit', fontsize=13)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Residuals\n",
    "residuals = (stress_noisy - predictions_opt) / stress_noisy * 100\n",
    "ax2.semilogx(time, residuals, 'o-', alpha=0.6)\n",
    "ax2.axhline(y=0, color='k', linestyle='--', linewidth=1)\n",
    "ax2.set_xlabel('Time (s)', fontsize=12)\n",
    "ax2.set_ylabel('Relative Error (%)', fontsize=12)\n",
    "ax2.set_title('Fit Residuals', fontsize=13)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Start Optimization\n",
    "\n",
    "To avoid local minima, we can try multiple initial guesses and select the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple initial guesses using Latin Hypercube Sampling\n",
    "n_starts = 5\n",
    "\n",
    "# Generate initial guesses within parameter bounds\n",
    "initial_guesses = []\n",
    "for i in range(n_starts):\n",
    "    guess = []\n",
    "    for bound in bounds:\n",
    "        # Sample logarithmically within bounds\n",
    "        log_min, log_max = np.log10(bound[0]), np.log10(bound[1])\n",
    "        log_val = log_min + (log_max - log_min) * np.random.rand()\n",
    "        guess.append(10**log_val)\n",
    "    initial_guesses.append(np.array(guess))\n",
    "\n",
    "print(f\"\\nMulti-Start Optimization with {n_starts} initial guesses:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_multi = []\n",
    "for i, guess in enumerate(initial_guesses):\n",
    "    result_i = minimize(\n",
    "        objective_function,\n",
    "        guess,\n",
    "        method='L-BFGS-B',\n",
    "        bounds=bounds,\n",
    "        options={'maxiter': 500}\n",
    "    )\n",
    "    results_multi.append(result_i)\n",
    "    print(f\"Start {i+1}: Objective = {result_i.fun:.3e}, Success = {result_i.success}\")\n",
    "\n",
    "# Select best result\n",
    "best_idx = np.argmin([r.fun for r in results_multi])\n",
    "best_result = results_multi[best_idx]\n",
    "\n",
    "print(f\"\\nBest result from start {best_idx+1}:\")\n",
    "print(f\"  Objective value: {best_result.fun:.3e}\")\n",
    "print(f\"  Parameters:\")\n",
    "for i, name in enumerate(param_names):\n",
    "    print(f\"    {name}: {best_result.x[i]:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Sensitivity Analysis\n",
    "\n",
    "Understand how sensitive the model predictions are to each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best-fit parameters as baseline\n",
    "baseline_params = best_result.x.copy()\n",
    "\n",
    "# Vary each parameter by ±20% and observe effect\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, (name, ax) in enumerate(zip(param_names, axes)):\n",
    "    # Create parameter variations\n",
    "    variations = np.linspace(0.5, 1.5, 5)  # 50% to 150% of baseline\n",
    "    \n",
    "    for var in variations:\n",
    "        params_varied = baseline_params.copy()\n",
    "        params_varied[i] *= var\n",
    "        \n",
    "        # Update model and predict\n",
    "        for j, pname in enumerate(param_names):\n",
    "            model.parameters[pname].value = params_varied[j]\n",
    "        \n",
    "        pred = model.predict(data)\n",
    "        \n",
    "        label = f\"{var*100:.0f}%\" if var in [0.5, 1.0, 1.5] else None\n",
    "        alpha = 1.0 if var == 1.0 else 0.4\n",
    "        linewidth = 2.5 if var == 1.0 else 1.5\n",
    "        \n",
    "        ax.loglog(time, pred, alpha=alpha, linewidth=linewidth, label=label)\n",
    "    \n",
    "    ax.loglog(time, stress_noisy, 'o', color='black', alpha=0.3, markersize=3, label='Data')\n",
    "    ax.set_xlabel('Time (s)', fontsize=10)\n",
    "    ax.set_ylabel('G(t) (Pa)', fontsize=10)\n",
    "    ax.set_title(f'Sensitivity to {name}', fontsize=11)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored advanced workflows using rheo's modular API:\n",
    "\n",
    "### Key Techniques:\n",
    "\n",
    "1. **Direct Model Instantiation**: Using `ModelRegistry.create()` for fine-grained control\n",
    "2. **Custom Optimization**: Defining objective functions with weighted residuals and constraints\n",
    "3. **Multi-Start Optimization**: Avoiding local minima by trying multiple initial guesses\n",
    "4. **Sensitivity Analysis**: Understanding parameter influence on model predictions\n",
    "\n",
    "### When to Use Modular API:\n",
    "\n",
    "- Custom optimization strategies (constraints, multi-objective, Bayesian)\n",
    "- Advanced parameter analysis (confidence intervals, correlations)\n",
    "- Research applications requiring maximum flexibility\n",
    "- Integration with other optimization frameworks\n",
    "\n",
    "### When to Use Pipeline API:\n",
    "\n",
    "- Standard workflows and quick analysis\n",
    "- Batch processing multiple datasets\n",
    "- Production/routine analysis\n",
    "- Users new to rheological analysis\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Explore multi-technique fitting (see `multi_technique_fitting.ipynb`)\n",
    "- Try model comparison with information criteria (see `multi_model_comparison.ipynb`)\n",
    "- Apply Bayesian inference for uncertainty quantification (Phase 3 feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
