{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Technique Fitting with Shared Parameters\n",
    "\n",
    "This notebook demonstrates simultaneous fitting of the same rheological model to multiple experimental techniques with shared parameters.\n",
    "\n",
    "Topics covered:\n",
    "1. Loading relaxation and oscillation data from the same material\n",
    "2. Creating models with shared parameters\n",
    "3. Defining multi-technique objective functions\n",
    "4. Optimizing parameters across both datasets\n",
    "5. Cross-validation of fitted parameters\n",
    "6. Assessing parameter uniqueness and consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from rheo.core.parameters import ParameterSet\n",
    "from rheo.core.registry import ModelRegistry\n",
    "from rheo.core.data import RheoData\n",
    "from rheo.utils.optimization import nlsq_optimize\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Multi-Technique Data\n",
    "\n",
    "We'll create both relaxation and oscillation data from the same Zener model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Zener model parameters\n",
    "Ge_true = 1e5    # Equilibrium modulus (Pa)\n",
    "Gm_true = 5e5    # Maxwell arm modulus (Pa)\n",
    "eta_true = 1e5   # Viscosity (Pa·s)\n",
    "tau_true = eta_true / Gm_true  # Relaxation time (s)\n",
    "\n",
    "print(\"True Zener Model Parameters:\")\n",
    "print(f\"  Ge (equilibrium modulus) = {Ge_true:.2e} Pa\")\n",
    "print(f\"  Gm (Maxwell modulus) = {Gm_true:.2e} Pa\")\n",
    "print(f\"  eta (viscosity) = {eta_true:.2e} Pa·s\")\n",
    "print(f\"  tau (relaxation time) = {tau_true:.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Stress Relaxation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time vector for relaxation\n",
    "time_relax = np.logspace(-2, 2, 40)  # 0.01 to 100 seconds\n",
    "\n",
    "# Zener relaxation: G(t) = Ge + Gm * exp(-t/tau)\n",
    "G_relax_true = Ge_true + Gm_true * np.exp(-time_relax / tau_true)\n",
    "\n",
    "# Add 4% noise\n",
    "noise_relax = 0.04\n",
    "G_relax_noisy = G_relax_true * (1 + noise_relax * np.random.randn(len(G_relax_true)))\n",
    "\n",
    "# Create RheoData object\n",
    "relaxation_data = RheoData(\n",
    "    x=time_relax,\n",
    "    y=G_relax_noisy,\n",
    "    x_units='s',\n",
    "    y_units='Pa',\n",
    "    domain='time',\n",
    "    test_mode='relaxation'\n",
    ")\n",
    "\n",
    "print(f\"\\nRelaxation Data:\")\n",
    "print(f\"  Time range: {time_relax[0]:.2e} to {time_relax[-1]:.2e} s\")\n",
    "print(f\"  Modulus range: {G_relax_noisy.min():.2e} to {G_relax_noisy.max():.2e} Pa\")\n",
    "print(f\"  Number of points: {len(time_relax)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Oscillatory Shear Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency vector for oscillation\n",
    "freq_osc = np.logspace(-2, 2, 35)  # 0.01 to 100 rad/s\n",
    "\n",
    "# Zener oscillation: G' = Ge + Gm * (omega*tau)^2 / (1 + (omega*tau)^2)\n",
    "omega_tau = freq_osc * tau_true\n",
    "G_storage_true = Ge_true + Gm_true * omega_tau**2 / (1 + omega_tau**2)\n",
    "\n",
    "# Loss modulus: G\" = Gm * (omega*tau) / (1 + (omega*tau)^2)\n",
    "G_loss_true = Gm_true * omega_tau / (1 + omega_tau**2)\n",
    "\n",
    "# Complex modulus magnitude\n",
    "G_star_true = np.sqrt(G_storage_true**2 + G_loss_true**2)\n",
    "\n",
    "# Add 5% noise\n",
    "noise_osc = 0.05\n",
    "G_star_noisy = G_star_true * (1 + noise_osc * np.random.randn(len(G_star_true)))\n",
    "\n",
    "# Create RheoData object\n",
    "oscillation_data = RheoData(\n",
    "    x=freq_osc,\n",
    "    y=G_star_noisy,\n",
    "    x_units='rad/s',\n",
    "    y_units='Pa',\n",
    "    domain='frequency',\n",
    "    test_mode='oscillation'\n",
    ")\n",
    "\n",
    "print(f\"\\nOscillation Data:\")\n",
    "print(f\"  Frequency range: {freq_osc[0]:.2e} to {freq_osc[-1]:.2e} rad/s\")\n",
    "print(f\"  Complex modulus range: {G_star_noisy.min():.2e} to {G_star_noisy.max():.2e} Pa\")\n",
    "print(f\"  Number of points: {len(freq_osc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Both Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Relaxation data\n",
    "ax1.loglog(time_relax, G_relax_noisy, 'o', label='Data', markersize=6, alpha=0.7)\n",
    "ax1.loglog(time_relax, G_relax_true, '--', label='True Model', \n",
    "           color='red', linewidth=2)\n",
    "ax1.axhline(y=Ge_true, color='green', linestyle=':', \n",
    "            linewidth=2, label=f'Ge = {Ge_true:.1e} Pa')\n",
    "ax1.set_xlabel('Time (s)', fontsize=12)\n",
    "ax1.set_ylabel('Relaxation Modulus G(t) (Pa)', fontsize=12)\n",
    "ax1.set_title('Stress Relaxation', fontsize=13)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Oscillation data\n",
    "ax2.loglog(freq_osc, G_star_noisy, 's', label='Data (|G*|)', markersize=6, alpha=0.7)\n",
    "ax2.loglog(freq_osc, G_star_true, '--', label='True Model', \n",
    "           color='red', linewidth=2)\n",
    "ax2.loglog(freq_osc, G_storage_true, ':', label=\"G'\", \n",
    "           color='blue', linewidth=2, alpha=0.5)\n",
    "ax2.loglog(freq_osc, G_loss_true, ':', label='G\"', \n",
    "           color='orange', linewidth=2, alpha=0.5)\n",
    "ax2.set_xlabel('Frequency (rad/s)', fontsize=12)\n",
    "ax2.set_ylabel('Modulus (Pa)', fontsize=12)\n",
    "ax2.set_title('Oscillatory Shear', fontsize=13)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Multi-Technique Data from Same Material', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Technique Fits (Baseline)\n",
    "\n",
    "First, let's fit each dataset independently to establish a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rheo.pipeline import Pipeline\n",
    "\n",
    "# Fit relaxation data only\n",
    "pipeline_relax = Pipeline()\n",
    "pipeline_relax.load_data(relaxation_data)\n",
    "pipeline_relax.fit('zener')\n",
    "params_relax_only = pipeline_relax.get_fitted_parameters()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FIT FROM RELAXATION DATA ONLY\")\n",
    "print(\"=\"*60)\n",
    "for name, param in params_relax_only.items():\n",
    "    true_val = {'Ge': Ge_true, 'Gm': Gm_true, 'eta': eta_true}[name]\n",
    "    error = abs(param.value - true_val) / true_val * 100\n",
    "    print(f\"  {name}: {param.value:.3e} Pa (true: {true_val:.3e}, error: {error:.1f}%)\")\n",
    "\n",
    "# Fit oscillation data only\n",
    "pipeline_osc = Pipeline()\n",
    "pipeline_osc.load_data(oscillation_data)\n",
    "pipeline_osc.fit('zener')\n",
    "params_osc_only = pipeline_osc.get_fitted_parameters()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FIT FROM OSCILLATION DATA ONLY\")\n",
    "print(\"=\"*60)\n",
    "for name, param in params_osc_only.items():\n",
    "    true_val = {'Ge': Ge_true, 'Gm': Gm_true, 'eta': eta_true}[name]\n",
    "    error = abs(param.value - true_val) / true_val * 100\n",
    "    print(f\"  {name}: {param.value:.3e} Pa (true: {true_val:.3e}, error: {error:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Technique Fitting with Shared Parameters\n",
    "\n",
    "Now we'll fit both datasets simultaneously, sharing parameters between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance\n",
    "model = ModelRegistry.create('zener')\n",
    "\n",
    "# Set initial guesses (average of single-technique fits)\n",
    "model.parameters['Ge'].value = (params_relax_only['Ge'].value + params_osc_only['Ge'].value) / 2\n",
    "model.parameters['Gm'].value = (params_relax_only['Gm'].value + params_osc_only['Gm'].value) / 2\n",
    "model.parameters['eta'].value = (params_relax_only['eta'].value + params_osc_only['eta'].value) / 2\n",
    "\n",
    "print(\"\\nInitial Parameter Guesses (average of single-technique fits):\")\n",
    "for name, param in model.parameters.items():\n",
    "    print(f\"  {name}: {param.value:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Multi-Technique Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_technique_objective(params_array, weight_relax=1.0, weight_osc=1.0):\n",
    "    \"\"\"\n",
    "    Objective function combining relaxation and oscillation data.\n",
    "    \n",
    "    Parameters:\n",
    "        params_array: Array of parameter values [Ge, Gm, eta]\n",
    "        weight_relax: Weight for relaxation data contribution\n",
    "        weight_osc: Weight for oscillation data contribution\n",
    "    \n",
    "    Returns:\n",
    "        Combined weighted sum of squared residuals\n",
    "    \"\"\"\n",
    "    # Update model parameters\n",
    "    param_names = list(model.parameters.keys())\n",
    "    for i, name in enumerate(param_names):\n",
    "        model.parameters[name].value = params_array[i]\n",
    "    \n",
    "    # Predict relaxation data\n",
    "    relax_pred = model.predict(relaxation_data)\n",
    "    relax_residuals = (relaxation_data.y - relax_pred) / relaxation_data.y\n",
    "    relax_sse = np.sum(relax_residuals**2)\n",
    "    \n",
    "    # Predict oscillation data\n",
    "    osc_pred = model.predict(oscillation_data)\n",
    "    osc_residuals = (oscillation_data.y - osc_pred) / oscillation_data.y\n",
    "    osc_sse = np.sum(osc_residuals**2)\n",
    "    \n",
    "    # Combined objective (weighted sum)\n",
    "    total_objective = weight_relax * relax_sse + weight_osc * osc_sse\n",
    "    \n",
    "    return total_objective\n",
    "\n",
    "# Test initial objective value\n",
    "initial_params = np.array([p.value for p in model.parameters.values()])\n",
    "initial_obj = multi_technique_objective(initial_params)\n",
    "print(f\"\\nInitial multi-technique objective value: {initial_obj:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize with Different Weighting Schemes\n",
    "\n",
    "We'll try three weighting schemes:\n",
    "1. Equal weights (1:1)\n",
    "2. Favor relaxation (2:1)\n",
    "3. Favor oscillation (1:2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weighting schemes\n",
    "weighting_schemes = [\n",
    "    (1.0, 1.0, 'Equal (1:1)'),\n",
    "    (2.0, 1.0, 'Favor Relaxation (2:1)'),\n",
    "    (1.0, 2.0, 'Favor Oscillation (1:2)')\n",
    "]\n",
    "\n",
    "results_multi = []\n",
    "bounds = [p.bounds for p in model.parameters.values()]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MULTI-TECHNIQUE OPTIMIZATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for w_relax, w_osc, scheme_name in weighting_schemes:\n",
    "    # Optimize\n",
    "    result = minimize(\n",
    "        lambda p: multi_technique_objective(p, w_relax, w_osc),\n",
    "        initial_params,\n",
    "        method='L-BFGS-B',\n",
    "        bounds=bounds,\n",
    "        options={'maxiter': 1000, 'ftol': 1e-10}\n",
    "    )\n",
    "    \n",
    "    results_multi.append((result, scheme_name))\n",
    "    \n",
    "    print(f\"\\n{scheme_name}:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"  Success: {result.success}\")\n",
    "    print(f\"  Objective: {result.fun:.4e}\")\n",
    "    print(f\"  Parameters:\")\n",
    "    param_names = list(model.parameters.keys())\n",
    "    true_vals = [Ge_true, Gm_true, eta_true]\n",
    "    for i, (name, true_val) in enumerate(zip(param_names, true_vals)):\n",
    "        error = abs(result.x[i] - true_val) / true_val * 100\n",
    "        print(f\"    {name}: {result.x[i]:.3e} (true: {true_val:.3e}, error: {error:.1f}%)\")\n",
    "\n",
    "# Select equal-weight result as the best\n",
    "best_result_multi, _ = results_multi[0]\n",
    "param_names = list(model.parameters.keys())\n",
    "for i, name in enumerate(param_names):\n",
    "    model.parameters[name].value = best_result_multi.x[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Multi-Technique Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get multi-technique predictions\n",
    "relax_pred_multi = model.predict(relaxation_data)\n",
    "osc_pred_multi = model.predict(oscillation_data)\n",
    "\n",
    "# Also get single-technique predictions for comparison\n",
    "relax_pred_single = pipeline_relax.predict(relaxation_data)\n",
    "osc_pred_single = pipeline_osc.predict(oscillation_data)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 11))\n",
    "\n",
    "# Top left: Relaxation fits\n",
    "ax = axes[0, 0]\n",
    "ax.loglog(time_relax, G_relax_noisy, 'o', label='Data', markersize=6, alpha=0.6)\n",
    "ax.loglog(time_relax, relax_pred_single, '--', label='Single-technique fit', linewidth=2)\n",
    "ax.loglog(time_relax, relax_pred_multi, '-', label='Multi-technique fit', linewidth=2.5)\n",
    "ax.loglog(time_relax, G_relax_true, ':', label='True model', color='red', linewidth=2)\n",
    "ax.set_xlabel('Time (s)', fontsize=11)\n",
    "ax.set_ylabel('G(t) (Pa)', fontsize=11)\n",
    "ax.set_title('Relaxation: Model Comparison', fontsize=12)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Top right: Oscillation fits\n",
    "ax = axes[0, 1]\n",
    "ax.loglog(freq_osc, G_star_noisy, 's', label='Data', markersize=6, alpha=0.6)\n",
    "ax.loglog(freq_osc, osc_pred_single, '--', label='Single-technique fit', linewidth=2)\n",
    "ax.loglog(freq_osc, osc_pred_multi, '-', label='Multi-technique fit', linewidth=2.5)\n",
    "ax.loglog(freq_osc, G_star_true, ':', label='True model', color='red', linewidth=2)\n",
    "ax.set_xlabel('Frequency (rad/s)', fontsize=11)\n",
    "ax.set_ylabel('|G*| (Pa)', fontsize=11)\n",
    "ax.set_title('Oscillation: Model Comparison', fontsize=12)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom left: Relaxation residuals\n",
    "ax = axes[1, 0]\n",
    "residuals_relax_single = (G_relax_noisy - relax_pred_single) / G_relax_noisy * 100\n",
    "residuals_relax_multi = (G_relax_noisy - relax_pred_multi) / G_relax_noisy * 100\n",
    "ax.semilogx(time_relax, residuals_relax_single, 'o--', label='Single-technique', alpha=0.7)\n",
    "ax.semilogx(time_relax, residuals_relax_multi, 's-', label='Multi-technique', alpha=0.7)\n",
    "ax.axhline(y=0, color='k', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel('Time (s)', fontsize=11)\n",
    "ax.set_ylabel('Relative Error (%)', fontsize=11)\n",
    "ax.set_title('Relaxation Residuals', fontsize=12)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom right: Oscillation residuals\n",
    "ax = axes[1, 1]\n",
    "residuals_osc_single = (G_star_noisy - osc_pred_single) / G_star_noisy * 100\n",
    "residuals_osc_multi = (G_star_noisy - osc_pred_multi) / G_star_noisy * 100\n",
    "ax.semilogx(freq_osc, residuals_osc_single, 's--', label='Single-technique', alpha=0.7)\n",
    "ax.semilogx(freq_osc, residuals_osc_multi, 'o-', label='Multi-technique', alpha=0.7)\n",
    "ax.axhline(y=0, color='k', linestyle='--', linewidth=1)\n",
    "ax.set_xlabel('Frequency (rad/s)', fontsize=11)\n",
    "ax.set_ylabel('Relative Error (%)', fontsize=11)\n",
    "ax.set_title('Oscillation Residuals', fontsize=12)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Multi-Technique Fitting Results', fontsize=14, y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation: Parameter Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare parameter estimates\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PARAMETER CONSISTENCY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "param_comparison = pd.DataFrame({\n",
    "    'Parameter': ['Ge', 'Gm', 'eta'],\n",
    "    'True Value': [Ge_true, Gm_true, eta_true],\n",
    "    'Relaxation Only': [params_relax_only[p].value for p in ['Ge', 'Gm', 'eta']],\n",
    "    'Oscillation Only': [params_osc_only[p].value for p in ['Ge', 'Gm', 'eta']],\n",
    "    'Multi-Technique': [model.parameters[p].value for p in ['Ge', 'Gm', 'eta']]\n",
    "})\n",
    "\n",
    "# Calculate errors\n",
    "for col in ['Relaxation Only', 'Oscillation Only', 'Multi-Technique']:\n",
    "    param_comparison[f'{col} Error (%)'] = (\n",
    "        abs(param_comparison[col] - param_comparison['True Value']) / \n",
    "        param_comparison['True Value'] * 100\n",
    "    )\n",
    "\n",
    "print(\"\\n\" + param_comparison.to_string(index=False))\n",
    "\n",
    "# Calculate average errors\n",
    "avg_error_relax = param_comparison['Relaxation Only Error (%)'].mean()\n",
    "avg_error_osc = param_comparison['Oscillation Only Error (%)'].mean()\n",
    "avg_error_multi = param_comparison['Multi-Technique Error (%)'].mean()\n",
    "\n",
    "print(f\"\\n\\nAverage Parameter Errors:\")\n",
    "print(f\"  Relaxation only:   {avg_error_relax:.2f}%\")\n",
    "print(f\"  Oscillation only:  {avg_error_osc:.2f}%\")\n",
    "print(f\"  Multi-technique:   {avg_error_multi:.2f}%\")\n",
    "\n",
    "improvement = min(avg_error_relax, avg_error_osc) - avg_error_multi\n",
    "print(f\"\\n  Improvement: {improvement:.2f}% reduction in average error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Parameter Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "param_names = ['Ge', 'Gm', 'eta']\n",
    "param_labels = ['Ge (Pa)', 'Gm (Pa)', 'eta (Pa·s)']\n",
    "true_values = [Ge_true, Gm_true, eta_true]\n",
    "\n",
    "for ax, param_name, param_label, true_val in zip(axes, param_names, param_labels, true_values):\n",
    "    estimates = [\n",
    "        params_relax_only[param_name].value,\n",
    "        params_osc_only[param_name].value,\n",
    "        model.parameters[param_name].value\n",
    "    ]\n",
    "    \n",
    "    x_pos = np.arange(3)\n",
    "    bars = ax.bar(x_pos, estimates, alpha=0.7, color=['blue', 'orange', 'green'])\n",
    "    ax.axhline(y=true_val, color='red', linestyle='--', linewidth=2, label='True value')\n",
    "    \n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(['Relax\\nOnly', 'Osc\\nOnly', 'Multi-\\nTech'], fontsize=10)\n",
    "    ax.set_ylabel(param_label, fontsize=11)\n",
    "    ax.set_title(f'{param_name} Estimates', fontsize=12)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, val) in enumerate(zip(bars, estimates)):\n",
    "        height = bar.get_height()\n",
    "        error = abs(val - true_val) / true_val * 100\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{error:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.suptitle('Parameter Estimation Comparison (% error shown)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated multi-technique fitting with shared parameters:\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Improved Accuracy**: Multi-technique fitting typically provides more accurate parameter estimates than single-technique fits\n",
    "2. **Parameter Consistency**: Shared parameters enforce consistency across different experimental techniques\n",
    "3. **Reduced Uncertainty**: Combining complementary data reduces parameter correlation and uncertainty\n",
    "4. **Cross-Validation**: Different techniques probe different aspects of material behavior\n",
    "\n",
    "### Benefits of Multi-Technique Fitting:\n",
    "\n",
    "- **Better Parameter Uniqueness**: Reduces parameter correlation (identifiability)\n",
    "- **Increased Data Coverage**: Extends frequency/time range by combining techniques\n",
    "- **Physical Consistency**: Ensures same material properties across experiments\n",
    "- **Robustness**: Less sensitive to noise in individual datasets\n",
    "\n",
    "### When to Use Multi-Technique Fitting:\n",
    "\n",
    "- When you have multiple datasets from the same material\n",
    "- When parameters are poorly constrained by single technique\n",
    "- For materials with complex relaxation spectra\n",
    "- When validating model consistency across techniques\n",
    "\n",
    "### Practical Considerations:\n",
    "\n",
    "1. **Weighting**: Balance contributions from techniques with different noise levels\n",
    "2. **Model Validity**: Ensure model is appropriate for all techniques\n",
    "3. **Data Quality**: Poor data from one technique can degrade overall fit\n",
    "4. **Computational Cost**: Multi-technique optimization is more expensive\n",
    "\n",
    "### Advanced Extensions:\n",
    "\n",
    "- Bayesian multi-technique fitting for uncertainty quantification (Phase 3)\n",
    "- Hierarchical models with shared and technique-specific parameters\n",
    "- Time-temperature-superposition with multi-technique validation\n",
    "- Global fitting across multiple samples with shared parameters\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Explore model comparison (see `multi_model_comparison.ipynb`)\n",
    "- Apply advanced optimization strategies (see `advanced_workflows.ipynb`)\n",
    "- Try mastercurve generation (see `mastercurve_generation.ipynb`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
